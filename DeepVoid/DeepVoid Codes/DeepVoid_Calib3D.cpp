#include "stdafx.h"

#include "DeepVoid.h"
#include "MainFrm.h"

// 根据提供的绕X轴顺时针旋转的角度（角度表示非弧度）得到4×4的旋转矩阵Rx
CMatrix DeepVoid::GenRX(double angle)
{
	double radian = angle * CV_PI / 180;

	CMatrix mRotX(4, 4);

	mRotX(1, 1) = mRotX(4, 4) = 1;
	mRotX(2, 2) = cos(radian);
	mRotX(2, 3) = -sin(radian);
	mRotX(3, 2) = sin(radian);
	mRotX(3, 3) = cos(radian);

	return mRotX;
}

// 根据提供的绕X轴顺时针旋转的弧度得到4×4的旋转矩阵Rx
CMatrix DeepVoid::GenRX_Radian(double radian)
{
	CMatrix mRotX(4, 4);

	mRotX(1, 1) = mRotX(4, 4) = 1;
	mRotX(2, 2) = cos(radian);
	mRotX(2, 3) = -sin(radian);
	mRotX(3, 2) = sin(radian);
	mRotX(3, 3) = cos(radian);

	return mRotX;
}

// 20150114
Matx33d DeepVoid::GenRX_Radian_CV(double radian)
{
	Matx33d R;

	double sa = sin(radian);
	double ca = cos(radian);

	R(0,0) = 1;
	R(1,1) = ca;
	R(1,2) = -sa;
	R(2,1) = sa;
	R(2,2) = ca;

	return R;
}

// 根据提供的绕Y轴顺时针旋转的角度（角度表示非弧度）得到4×4的旋转矩阵Ry
CMatrix DeepVoid::GenRY(double angle)
{
	double radian = angle * CV_PI / 180;

	CMatrix mRotY(4, 4);

	mRotY(2, 2) = mRotY(4, 4) = 1;
	mRotY(1, 1) = cos(radian);
	mRotY(1, 3) = sin(radian);
	mRotY(3, 1) = -sin(radian);
	mRotY(3, 3) = cos(radian);

	return mRotY;
}

// 根据提供的绕Y轴顺时针旋转的弧度得到4×4的旋转矩阵Ry
CMatrix DeepVoid::GenRY_Radian(double radian)
{
	CMatrix mRotY(4, 4);

	mRotY(2, 2) = mRotY(4, 4) = 1;
	mRotY(1, 1) = cos(radian);
	mRotY(1, 3) = sin(radian);
	mRotY(3, 1) = -sin(radian);
	mRotY(3, 3) = cos(radian);

	return mRotY;
}

// 20150114
Matx33d DeepVoid::GenRY_Radian_CV(double radian)
{
	Matx33d R;

	double sa = sin(radian);
	double ca = cos(radian);

	R(1,1) = 1;
	R(0,0) = ca;
	R(0,2) = sa;
	R(2,0) = -sa;
	R(2,2) = ca;

	return R;
}

// 根据提供的绕Z轴顺时针旋转的角度（角度表示非弧度）得到4×4的旋转矩阵Rz
CMatrix DeepVoid::GenRZ(double angle)
{
	double radian = angle * CV_PI / 180;

	CMatrix mRotZ(4, 4);

	mRotZ(3, 3) = mRotZ(4, 4) = 1;
	mRotZ(1, 1) = cos(radian);
	mRotZ(1, 2) = -sin(radian);
	mRotZ(2, 1) = sin(radian);
	mRotZ(2, 2) = cos(radian);

	return mRotZ;
}

// 根据提供的绕Z轴顺时针旋转的弧度得到4×4的旋转矩阵Rz
CMatrix DeepVoid::GenRZ_Radian(double radian)
{
	CMatrix mRotZ(4, 4);

	mRotZ(3, 3) = mRotZ(4, 4) = 1;
	mRotZ(1, 1) = cos(radian);
	mRotZ(1, 2) = -sin(radian);
	mRotZ(2, 1) = sin(radian);
	mRotZ(2, 2) = cos(radian);

	return mRotZ;
}

// 20150114
Matx33d DeepVoid::GenRZ_Radian_CV(double radian)
{
	Matx33d R;

	double sa = sin(radian);
	double ca = cos(radian);

	R(2,2) = 1;
	R(0,0) = ca;
	R(0,1) = -sa;
	R(1,0) = sa;
	R(1,1) = ca;

	return R;
}

// 根据提供的世界坐标系原点在像机坐标系中坐标t生成4×4的平移矩阵T
CMatrix DeepVoid::GenT(double X, double Y, double Z)
{
	CMatrix mT(4, 4);

	mT(1, 1) = mT(2, 2) = mT(3, 3) = mT(4, 4) = 1;
	mT(1, 4) = X;
	mT(2, 4) = Y;
	mT(3, 4) = Z;

	return mT;
}

// 根据提供的绕XYZ三轴旋转的角度（角度表示非弧度）以及旋转顺序来确定4×4的旋转矩阵R
CMatrix DeepVoid::GenR_Euler(double angleX, double angleY, double angleZ, RotationOrder order /*= XYZ*/)
{
	CMatrix mRot(4, 4);

	CMatrix mX = GenRX(angleX);
	CMatrix mY = GenRY(angleY);
	CMatrix mZ = GenRZ(angleZ);

	switch (order)
	{
	case XYZ:
		mRot = mZ * mY * mX;
		break;
	case XZY:
		mRot = mY * mZ * mX;
		break;
	case YXZ:
		mRot = mZ * mX * mY;
		break;
	case YZX:
		mRot = mX * mZ * mY;
		break;
	case ZXY:
		mRot = mY * mX * mZ;
		break;
	case ZYX:
		mRot = mX * mY * mZ;
		break;
	default:
		break;
	}

	return mRot;
}

// 根据提供的绕 XYZ 三轴旋转的弧度以及旋转顺序来确定 4×4 的旋转矩阵 R
CMatrix DeepVoid::GenR_Euler_Radian(double radianX, double radianY, double radianZ, RotationOrder order /*= XYZ*/)
{
	CMatrix mRot(4, 4);

	CMatrix mX = GenRX_Radian(radianX);
	CMatrix mY = GenRY_Radian(radianY);
	CMatrix mZ = GenRZ_Radian(radianZ);

	switch (order)
	{
	case XYZ:
		mRot = mZ * mY * mX;
		break;
	case XZY:
		mRot = mY * mZ * mX;
		break;
	case YXZ:
		mRot = mZ * mX * mY;
		break;
	case YZX:
		mRot = mX * mZ * mY;
		break;
	case ZXY:
		mRot = mY * mX * mZ;
		break;
	case ZYX:
		mRot = mX * mY * mZ;
		break;
	default:
		break;
	}

	return mRot;
}

// 20150114
Matx33d DeepVoid::GenR_Euler_Radian_CV(double radianX, double radianY, double radianZ, RotationOrder order/* = XYZ*/)
{
	Matx33d R;

	Matx33d RX = GenRX_Radian_CV(radianX);
	Matx33d RY = GenRY_Radian_CV(radianY);
	Matx33d RZ = GenRZ_Radian_CV(radianZ);

	switch (order)
	{
	case XYZ:
		R = RZ * RY * RX;
		break;
	case XZY:
		R = RY * RZ * RX;
		break;
	case YXZ:
		R = RZ * RX * RY;
		break;
	case YZX:
		R = RX * RZ * RY;
		break;
	case ZXY:
		R = RY * RX * RZ;
		break;
	case ZYX:
		R = RX * RY * RZ;
		break;
	default:
		break;
	}

	return R;
}

// 根据输入的旋转向量（即旋转弧度和旋转轴单位向量的乘积），利用Rodrigues旋转公式生成3×3旋转矩阵:R = Icosθ + [n]sinθ + nn'(1 - cosθ)
// 或者R = I + [n]sinθ + [n]^2(1 - cosθ)
CMatrix DeepVoid::GenR_Rodrigues(const CMatrix & mRotVec)
{
	double radian = mRotVec.Norm();

	CMatrix mV;
	if (fabs(radian)<1.0E-8)
	{
		// if rotation angle is approximately 0, then the rotation axis will not be that
		// important again, we can choose any arbitrary unit axis, and the rotation matrix
		// acquired will still be approximately identity matrix
		mV = CMatrix(3, 1, 0);
		mV(1) = 1;
	} 
	else
	{
		mV = mRotVec / radian;
	}

	double cos_a = cos(radian);
	double sin_a = sin(radian);

	CMatrix mCross = GenCrossMat(mV);

	CMatrix mR = GenI(3) + sin_a * mCross + (1 - cos_a) * mCross * mCross;

	CMatrix mR44 = GenI(4);

	int i,j;
	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mR44(i+1,j+1) = mR(i+1,j+1);
		}
	}

// 	mR.AddOneCol(0);
// 	mR.AddOneRow(0);
// 	mR(4, 4) = 1;

	return mR44;
}

// 根据输入的旋转向量（即旋转弧度和旋转轴单位向量的乘积），利用Rodrigues旋转公式生成3×3旋转矩阵:R = Icosθ + [n]sinθ + nn'(1 - cosθ)
// 或者R = I + [n]sinθ + [n]^2(1 - cosθ)
CMatrix DeepVoid::GenR_Rodrigues(double rv1, double rv2, double rv3)
{
	CMatrix mRotVec(3, 1);
	mRotVec(1) = rv1;
	mRotVec(2) = rv2;
	mRotVec(3) = rv3;

	return GenR_Rodrigues(mRotVec);
}

// 从旋转矩阵中分解出αβ和γ三个角度值，分别为偏航角、俯仰角和滚转角，先绕Z轴旋转形成偏航角，再绕Y轴旋转形成俯仰角，最后绕X轴旋转形成滚转角，形成的旋转矩阵为R = RxRyRz
// X轴定义为目标轴向，Y轴定义为目标水平径向，Z轴定义为目标垂直径向
CMatrix DeepVoid::GetEulerAngleFromR(const CMatrix & mR)
{
	// [ c2c1			-c2s1			s2;
	//   c3s1+s3s2c1	c3c1-s3s2s1		-s3c2;
	//   s3s1-c3s2c1	s3c1+c3s2s1		c3c2 ]
	CMatrix mRTmp = mR.GetRect(1, 1, 3, 3);

	// 返回的矩阵共2列，分别是旋转矩阵欧拉角分解的两种解
	CMatrix mAngle(3, 2);

	// s2 = R(1, 3)
	double s2 = mRTmp(1, 3);

	// β = arcsin(s2) ∈ [-90, 90]。若β位于(90, 180]或[-180, -90)两个象限则是确定不了的
	double b1 = asind(s2);
	double a1, c1;

	// 当s2=1，即β=90°时，只能利用R(2,1)和R(2,2)确定(α+γ)值的大小∈[-180, 180]
	// 此时α定为(α+γ)，β为90，γ为0
	double eps = 1.0E-15;
	double s2Sub1 = fabs(s2 - 1.0);
	double s2Add1 = fabs(s2 + 1.0);
	if ( s2Sub1 < eps)
	{
		double s13 = mRTmp(2, 1);
		double c13 = mRTmp(2, 2);

		double ang1Add3 = atand(s13, c13);

		a1 = ang1Add3;
		c1 = 0;

		mAngle(1, 1) = a1;
		mAngle(2, 1) = b1;
		mAngle(3, 1) = c1;
	}
	// 当s2=-1，即β=-90°时，只能利用R(2,1)和R(2,2)确定(α-γ)值的大小∈[-180, 180]
	// 此时α定为(α-γ)，β为-90，γ为0
	else if ( s2Add1 < eps)
	{
		double s13 = mRTmp(2, 1);
		double c13 = mRTmp(2, 2);

		double ang1Sub3 = atand(s13, c13);

		a1 = ang1Sub3;
		c1 = 0;

		mAngle(1, 1) = a1;
		mAngle(2, 1) = b1;
		mAngle(3, 1) = c1;
	}
	else
	{
		// 当β∈(-90, 90)，这一区间内的cos(β)>0，因此α可以直接这样算得α=-arctan(-c2s1, c2c1)，α∈[-180, 180]
		// γ也可以直接从γ=-arctan(-c2s3, c2c3)算得，γ∈[-180, 180]
		// 但实际的情况β有可能在左半象限，此时真实的β应为π-β，并且cos(β)<0，从而导致真实的α=α-π，γ=γ-π。
		double _c2s1 = mRTmp(1, 2);
		double  c2c1 = mRTmp(1, 1);
		a1 = -atand(_c2s1, c2c1);

		double _s3c2 = mRTmp(2, 3);
		double  c3c2 = mRTmp(3, 3);
		c1 = -atand(_s3c2, c3c2);

		mAngle(1, 1) = a1;
		mAngle(2, 1) = b1;
		mAngle(3, 1) = c1;
	}


	// 下面的代码计算另一种角度组合α=α-π，β=π-β和γ=γ-π，实际中为了让角度范围统一在[-180, 180]，做了以下的一些处理
	double a2, b2, c2;

	// b1在第1象限则另一个角度b2=π-b1就在第2象限；b1在第4象限则另一个角度b2=-π-b1就在第3象限
	if (b1 >= 0 && b1 <= 90)
	{
		b2 = 180 - b1;
	} 
	else
	{
		b2 = -180 - b1;
	}

	// a1在[0, 180]范围内时，另一个角度a2=a1-π就在[-180, 0]范围内；a1在[-180, 0)范围内时，a2=a1+π就在[0, 180)范围内
	if (a1 >= 0)
	{
		a2 = a1 - 180;
	} 
	else
	{
		a2 = a1 + 180;
	}

	// c1在[0, 180]范围内时，另一个角度c2=c1-π就在[-180, 0]范围内；c1在[-180, 0)范围内时，c2=c1+π就在[0, 180)范围内
	if (c1 >= 0)
	{
		c2 = c1 - 180;
	} 
	else
	{
		c2 = c1 + 180;
	}

	mAngle(1, 2) = a2;
	mAngle(2, 2) = b2;
	mAngle(3, 2) = c2;

	return mAngle;
}

// 根据输入的旋转矩阵，返回一个 3 维的向量，其为 θ|v|，其中 v 为旋转轴的单位向量，θ 为旋转弧度
CMatrix DeepVoid::GetRotVecFromR(const CMatrix & mR)
{
	// according to information given on http://en.wikipedia.org/wiki/Rotation_matrix#Quaternion
	double x = mR(3,2) - mR(2,3);
	double y = mR(1,3) - mR(3,1);
	double z = mR(2,1) - mR(1,2);
	double r = sqrt(x*x + y*y + z*z);
	double t = mR(1,1) + mR(2,2) + mR(3,3);
	double radian = atan2(r, t-1);

	CMatrix v(3, 1);

	if (fabs(radian)<1.0E-8) // less than 0.002 seconds
	{
		v(1)=0; v(2)=0;	v(3)=0;
	}
	else
	{
		double rinv = 1/r;
		x*=rinv; y*=rinv; z*=rinv;

		v(1) = x*radian;
		v(2) = y*radian;
		v(3) = z*radian;
	}

	return v;
}

// 根据输入的旋转矩阵，返回一个 3 维的向量，其为 θ|v|，其中 v 为旋转轴的单位向量，θ 为旋转弧度
Matx31d DeepVoid::GetRotVecFromR(const Matx33d & mR)
{
	// according to information given on http://en.wikipedia.org/wiki/Rotation_matrix#Quaternion
	double x = mR(2,1) - mR(1,2);
	double y = mR(0,2) - mR(2,0);
	double z = mR(1,0) - mR(0,1);
	double r = sqrt(x*x + y*y + z*z);
	double t = mR(0,0) + mR(1,1) + mR(2,2);
	double radian = atan2(r, t-1);

	Matx31d v;

	if (fabs(radian)<1.0E-8) // less than 0.002 seconds
	{
		v(0)=0; v(1)=0;	v(2)=0;
	}
	else
	{
		double rinv = 1/r;
		x*=rinv; y*=rinv; z*=rinv;

		v(0) = x*radian;
		v(1) = y*radian;
		v(2) = z*radian;
	}

	return v;
}

// 已知不共线的三个点的世界坐标系坐标，利用这三个点建立一个局部坐标系，并输出这一局部坐标系与世界坐标系之间的旋转平移矩阵Hlw
// pt1->pt2的向量方向为x轴方向，(pt1->pt2)×(pt1->pt3)为z轴方向，(pt1->pt2)×(pt1->pt3)×(pt1->pt2)为y轴方向
CMatrix DeepVoid::BuildCoordSysBy3Pt(CMatrix mWrdPt)
{
	// 向量pt1->pt2，也即x轴方向
	CMatrix mVec12(3, 1);
	mVec12(1, 1) = mWrdPt(1, 2) - mWrdPt(1, 1);
	mVec12(2, 1) = mWrdPt(2, 2) - mWrdPt(2, 1);
	mVec12(3, 1) = mWrdPt(3, 2) - mWrdPt(3, 1);

	// 向量pt1->pt3
	CMatrix mVec13(3, 1);
	mVec13(1, 1) = mWrdPt(1, 3) - mWrdPt(1, 1);
	mVec13(2, 1) = mWrdPt(2, 3) - mWrdPt(2, 1);
	mVec13(3, 1) = mWrdPt(3, 3) - mWrdPt(3, 1);

	// (pt1->pt2)×(pt1->pt3)得到z轴方向
	CMatrix mZ = Cross(mVec12, mVec13);

	// (pt1->pt2)×(pt1->pt3)×(pt1->pt2)为y轴方向
	CMatrix mY = Cross(mZ, mVec12);

	// 有了局部坐标系各轴的方向矢量以后，再将其归一化得到单位轴向矢量
	CMatrix mX = mVec12 / mVec12.Norm();
	mY = mY / mY.Norm();
	mZ = mZ / mZ.Norm();

	// 生成局部坐标系l至世界坐标系w的旋转平移矩阵Hlw
	CMatrix mHlw(3, 4);
	mHlw.SetCol(1, mX);
	mHlw.SetCol(2, mY);
	mHlw.SetCol(3, mZ);
	mHlw.SetCol(4, mWrdPt.GetRect(1, 1, 1, 3));
	mHlw.AddOneRow();
	mHlw(4, 4) = 1;

	return mHlw;

// 	// 矩阵mHlw的逆即为最终输出mHwl
// 	CMatrix mHwl = mHlw.Inverse();
// 
// 	return mHwl;
}

CMatrix DeepVoid::Intersect(const CMatrix & mImgPt, const CMatrix & mProjArray)
{
	int i;
	int eyeNum = mImgPt.m_nCol;
	CMatrix mA(2 * eyeNum, 3);
	CMatrix mb(2 * eyeNum, 1);

	for (i = 1; i <= eyeNum; i++)
	{
		mA((i - 1) * 2 + 1, 1) = mProjArray(1, 4 * (i - 1) + 1) - mImgPt(1, i) * mProjArray(3, 4 * (i - 1) + 1);
		mA((i - 1) * 2 + 1, 2) = mProjArray(1, 4 * (i - 1) + 2) - mImgPt(1, i) * mProjArray(3, 4 * (i - 1) + 2);
		mA((i - 1) * 2 + 1, 3) = mProjArray(1, 4 * (i - 1) + 3) - mImgPt(1, i) * mProjArray(3, 4 * (i - 1) + 3);
		mb((i - 1) * 2 + 1, 1) = -(mProjArray(1, 4 * (i - 1) + 4) - mImgPt(1, i) * mProjArray(3, 4 * (i - 1) + 4));

		mA((i - 1) * 2 + 2, 1) = mProjArray(2, 4 * (i - 1) + 1) - mImgPt(2, i) * mProjArray(3, 4 * (i - 1) + 1);
		mA((i - 1) * 2 + 2, 2) = mProjArray(2, 4 * (i - 1) + 2) - mImgPt(2, i) * mProjArray(3, 4 * (i - 1) + 2);
		mA((i - 1) * 2 + 2, 3) = mProjArray(2, 4 * (i - 1) + 3) - mImgPt(2, i) * mProjArray(3, 4 * (i - 1) + 3);
		mb((i - 1) * 2 + 2, 1) = -(mProjArray(2, 4 * (i - 1) + 4) - mImgPt(2, i) * mProjArray(3, 4 * (i - 1) + 4));
	}

	CMatrix mWrdPt = Solve(mA, mb);

	mWrdPt.AddOneRow(1);

	return mWrdPt;
}

// 已知像机的投影矩阵mP，计算空间点 4×n的矩阵mWrdPt(X, Y, Z, 1) 投影在像面上的理想像点 3×n的矩阵mImgPt(x, y, 1)，其中n为空间点个数，也即图像点个数
CMatrix DeepVoid::Proj2IdealImgPt_3Dto2D(const CMatrix & mWrdPt, const CMatrix & mP)
{
	CMatrix mImgPt = mP * mWrdPt;

	CMatrix mImgRow1 = mImgPt.GetRow(1);
	CMatrix mImgRow2 = mImgPt.GetRow(2);
	CMatrix mImgRow3 = mImgPt.GetRow(3);

	mImgRow1 /= mImgRow3;
	mImgRow2 /= mImgRow3;
	mImgRow3 /= mImgRow3;

	mImgPt.SetRow(1, mImgRow1);
	mImgPt.SetRow(2, mImgRow2);
	mImgPt.SetRow(3, mImgRow3);

	return mImgPt;
}

// 为了完全仿真真实的像机成像，引入视景体（视锥体）的概念，在视景体外面的空间点不参与投影，直接赋值成某一不合理像点坐标；在视景体内部的空间点按照正常的透视模型进行成像投影
CMatrix DeepVoid::Proj2IdealImgPt_3Dto2D_VisualCone(const CMatrix & mWrdPts, // 4×n的矩阵，控制点齐次坐标矩阵
													double imgWidth,         // 仿真像机的像面宽度
													double imgHeight,        // 仿真像机的像面高度
													const CMatrix & mK,      // 3×4的像机内参数矩阵
													const CMatrix & mRT)     // 4×4的像机外参数矩阵
{
	// 得到空间点在像机系中的坐标
	CMatrix mWrdPts_Cam = mRT * mWrdPts;

	CMatrix mImgPt = mK * mWrdPts_Cam;

	CMatrix mImgRow1 = mImgPt.GetRow(1);
	CMatrix mImgRow2 = mImgPt.GetRow(2);
	CMatrix mImgRow3 = mImgPt.GetRow(3);

	// 20120217，对像机坐标系 Z 轴向坐标值小于等于 0 的点做相应处理，也就是对在像机镜头后面的点做相应处理，让其成像点坐标固定为某值
	// 20120219，加入视景体判断
	CMatrix mIndex(mImgPt.m_nCol, 1, 0);

	double fx = mK(1, 1);
	double fy = mK(2, 2);
	double cx = mK(1, 3);
	double cy = mK(2, 3);

	double LX = -cx / fx;               // 视景体的左边缘
	double RX = (imgWidth - cx) / fx;   // 视景体的右边缘

	double TY = -cy / fy;               // 视景体的上边缘
	double BY = (imgHeight - cy) / fy;  // 视景体的下边缘

	int i;
	for (i = 1; i <= mImgPt.m_nCol; i++)
	{
		double X = mWrdPts_Cam(1, i);
		double Y = mWrdPts_Cam(2, i);
		double Z = mWrdPts_Cam(3, i);

		double XZ = X / Z;
		double YZ = Y / Z;

		if ((mImgRow3(i) <= 0) || (XZ < LX) || (XZ > RX) || (YZ < TY) || (YZ > BY))
			/*if (mImgRow3(i) <= 0.00001)*/
		{
			mIndex(i) = 1;
		}
	}

	mImgRow1 /= mImgRow3;
	mImgRow2 /= mImgRow3;
	mImgRow3 /= mImgRow3;

	for (i = 1; i <= mImgPt.m_nCol; i++)
	{
		if (mIndex(i) == 1)
		{
			mImgRow1(i) = -100;
			mImgRow2(i) = -100;
			mImgRow3(i) = 1;
		}
	}

	mImgPt.SetRow(1, mImgRow1);
	mImgPt.SetRow(2, mImgRow2);
	mImgPt.SetRow(3, mImgRow3);

	return mImgPt;
}

double DeepVoid::GetAngleBetweenOpticalAxes_Radian(Matx33d mR)
{
	Matx31d mZ1;
	mZ1(0) = 0;
	mZ1(1) = 0;
	mZ1(2) = 1;

	Matx31d mZ2 = mR * mZ1;

	Matx<double, 1, 1> cosa = mZ1.t() * mZ2;

	return acos(cosa(0));
}

double DeepVoid::GetAngleBetweenOpticalAxes_Angle(Matx33d mR)
{
	return GetAngleBetweenOpticalAxes_Radian(mR) * 180 / CV_PI;
}

// return the computed XYZ given the depth
Matx31d DeepVoid::GetXYZ_givenDepth(const Matx33d & mK,					// input:	3*3, camera matrix
									const Matx33d & mR,					// input:	3*3, rotation matrix
									const Matx31d & mt,					// input:	3*1, translation vector
									double img_x, double img_y,			// input:	the distortion free image coordinates of the point
									double depth						// input:	the depth of this point relative to this camera
									)
{
	Matx31d mImgPt;
	mImgPt(0) = img_x;
	mImgPt(1) = img_y;
	mImgPt(2) = 1;

	Matx31d mDir = mK.inv()*mImgPt;
// 	double nd_1 = 1/norm(mDir);
// 	mDir *= nd_1; // unit direction vector

	// get the coordinates of the optical center
// 	Matx31d mC = -mR.t() * mt;
// 
// 	return (mC + depth * mDir);

	return mR.t()*(depth*mDir-mt); // Xc=RXw+t -> Xw=R'(Xc-t)
}

// return the computed XYZ given the depth
Matx31d DeepVoid::GetXYZ_givenDepth(const Matx33d & mR,					// input:	3*3, rotation matrix
								    const Matx31d & mt,					// input:	3*1, translation vector
								    double nimgx, double nimgy,			// input:	the distortion free normalized image coordinates of the point
								    double depth							// input:	the depth of this point relative to this camera
								    )
{
	Matx31d mDir;
	mDir(0) = nimgx;
	mDir(1) = nimgy;
	mDir(2) = 1;

	return mR.t()*(depth*mDir-mt); // Xc=RXw+t -> Xw=R'(Xc-t)
}

// this function first match features by feature descriptors
// then use epipolar geometry based RANSAC to compute fundamental matrix
// and output refined matches with outliers discarded
// Mat DeepVoid::CalibFundamentalMat_RANSAC_Features(const Features & feat1,	// input:	features extracted from the 1st image
// 												  const Features & feat2,	// input:	features extracted from the 2nd image
// 												  vector<DMatch> & matches,	// output:	matches obtained after feature matching and RANSAC
// 												  double param1 /*= 3*/,	// input:	defining "good" matches (i.e. whose distance is less than param1*min_dist) in feature matching stage
// 												  double param2 /*= 3*/,	// input:	the distance threshold between point and epiline, used in RANSAC stage
// 												  double param3 /*= 0.99*/	// input:	specifying a desirable level of confidence (probability) that the estimated matrix is correct
// 												  )
// {
// 	int i;
// 
// 	// first do feature matching
// 	FlannBasedMatcher matcher_flann;
// 
// 	vector<DMatch> matches_raw;
// 
// 	// feature matching is based only on feature descriptors
// 	matcher_flann.match(feat1.descriptors, feat2.descriptors, matches_raw);
// 
// 	double max_dist = 0; double min_dist = 1000;
// 	//-- Quick calculation of max and min distances between keypoints
// 	for(i=0;i<feat1.descriptors.rows;i++)
// 	{
// 		double dist = matches_raw[i].distance;
// 		if(dist<min_dist)
// 			min_dist = dist;
// 		if(dist>max_dist)
// 			max_dist = dist;
// 	}
// 
// 	//-- Draw only "good" matches (i.e. whose distance is less than param1*min_dist )
// 	//-- PS.- radiusMatch can also be used here.
// 	vector<DMatch> matches_good;
// 	for(i=0;i<feat1.descriptors.rows;i++)
// 	{
// 		if(matches_raw[i].distance<param1*min_dist)
// 		{
// 			matches_good.push_back(matches_raw[i]);
// 		}
// 	}
// 
// 	// RANSAC to discard outliers
// 	vector<Point2f> points1(matches_good.size());
// 	vector<Point2f> points2(matches_good.size());
// 
// 	// initialize the points here ... */
// 	for(i=0;i<matches_good.size();i++)
// 	{
// 		points1[i] = feat1.key_points[matches_good[i].queryIdx].pt;
// 		points2[i] = feat2.key_points[matches_good[i].trainIdx].pt;
// 	}
// 
// 	vector<uchar> status;
// 
// 	Mat fundamental_matrix = findFundamentalMat(points1, points2, FM_RANSAC, param2, param3, status);
// 
// 	matches.clear();
// 	for (i=0;i<matches_good.size();i++)
// 	{
// 		if (status[i])
// 		{
// 			matches.push_back(matches_good[i]);
// 		}
// 	}
// 
// 	return fundamental_matrix;
// }

// this function first match features by feature descriptors
// then use epipolar geometry based RANSAC to compute fundamental matrix
// and output refined matches with outliers discarded
Matx33d DeepVoid::CalibFundamentalMat_RANSAC_Features(const Features & feat1,		// input:	n1 features extracted from the 1st image
													  const Features & feat2,		// input:	n2 features extracted from the 2nd image
													  vector<DMatch> & matches,		// output:	matches obtained after feature matching and RANSAC
													  double param1 /*= 3*/,		// input:	defining "good" matches (i.e. whose distance is less than param1*min_dist) in feature matching stage
													  double param2 /*= 3*/,		// input:	the distance threshold between point and epiline, used in RANSAC stage
													  double param3 /*= 0.99*/		// input:	specifying a desirable level of confidence (probability) that the estimated matrix is correct
													  )
{
	int i,j;

	// first do feature matching
	FlannBasedMatcher matcher_flann;

	vector<DMatch> matches_raw;

	// feature matching is based only on feature descriptors

	try
	{
		matcher_flann.match(feat1.descriptors, feat2.descriptors, matches_raw);
	}
	catch (cv::Exception & e)
	{
		CString str;
		str = e.msg.c_str();
		AfxMessageBox(str);
	}

	double max_dist = 0; double min_dist = 1000;
	//-- Quick calculation of max and min distances between keypoints
	for(i=0;i<feat1.descriptors.rows;i++)
	{
		double dist = matches_raw[i].distance;
		if(dist<min_dist)
			min_dist = dist;
		if(dist>max_dist)
			max_dist = dist;
	}

	//-- Draw only "good" matches (i.e. whose distance is less than param1*min_dist )
	//-- PS.- radiusMatch can also be used here.
	vector<DMatch> matches_good;
	for(i=0;i<feat1.descriptors.rows;i++)
	{
		if(matches_raw[i].distance<param1*min_dist)
		{
			matches_good.push_back(matches_raw[i]);
		}
	}

	// RANSAC to discard outliers
	vector<Point2f> points1(matches_good.size());
	vector<Point2f> points2(matches_good.size());

	// initialize the points here ... */
	for(i=0;i<matches_good.size();i++)
	{
		points1[i] = feat1.key_points[matches_good[i].queryIdx].pt;
		points2[i] = feat2.key_points[matches_good[i].trainIdx].pt;
	}

	vector<uchar> status;
	
	Matx33d fundamental_matrix;
	try
	{
		fundamental_matrix = findFundamentalMat(points1, points2, FM_RANSAC, param2, param3, status);
	}
	catch (cv::Exception & e)
	{
		CString str;
		str = e.msg.c_str();
		AfxMessageBox(str);
	}

	matches.clear();
	for (i=0;i<matches_good.size();i++)
	{
		if (status[i])
		{
			matches.push_back(matches_good[i]);
		}
	}

	// zhaokunz, 20140317, sometimes, a feature is matched to more than one feature
	// we have to eliminate those ambiguilties by choosing the one with shortest matching distance in feature matching stage
	// zhaokunz, 20140319, when these ambiguilties happen, eliminate all ambiguilties directly, including the one with
	// the shortest matching distance
	vector<int> vCancel(matches.size());
	for (i=0;i<matches.size();i++)
	{
		DMatch m1 = matches[i];

		for (j=i+1;j<matches.size();j++)
		{
			DMatch m2 = matches[j];

			if (m1.queryIdx != m2.queryIdx && m1.trainIdx != m2.trainIdx)
			{
				continue;
			}

			vCancel[i] = 1;
			vCancel[j] = 1;
		}

// 		DMatch m1 = matches[i];
// 
// 		// indicating that i-th match is not the smallest
// 		if (vCancel[i])
// 		{
// 			continue;
// 		}
// 
// 		for (j=i+1;j<matches.size();j++)
// 		{
// 			DMatch m2 = matches[j];
// 
// 			if (m1.queryIdx != m2.queryIdx && m1.trainIdx != m2.trainIdx)
// 			{
// 				continue;
// 			}
// 
// 			if (m1.distance <= m2.distance)
// 			{
// 				vCancel[j] = 1;
// 			}
// 			else
// 			{
// 				vCancel[i] = 1;
// 			}
// 		}
	}
	
	vector<DMatch> vMatch_final;
	for (i=0;i<matches.size();i++) 
	{
		if (!vCancel[i])
		{
			vMatch_final.push_back(matches[i]);
		}
	}
	matches = vMatch_final;
	//////////////////////////////////////////////////////////////////////////

	return fundamental_matrix;
}

// this function first match features by feature descriptors
// then use epipolar geometry based RANSAC to compute fundamental matrix
// and output refined matches with outliers discarded
Matx33d DeepVoid::CalibFundamentalMat_RANSAC_Features_idxImgPt(const Features & feat1,		// input:	n1 features extracted from the 1st image
															   const Features & feat2,		// input:	n2 features extracted from the 2nd image
															   vector<DMatch> & matches,	// output:	matches obtained after feature matching and RANSAC
															   double param1 /*= 3*/,			// input:	defining "good" matches (i.e. whose distance is less than param1*min_dist) in feature matching stage
															   double param2 /*= 3*/,			// input:	the distance threshold between point and epiline, used in RANSAC stage
															   double param3 /*= 0.99*/		// input:	specifying a desirable level of confidence (probability) that the estimated matrix is correct
															   )
{
	int i,j;

	// first do feature matching
	FlannBasedMatcher matcher_flann;

	vector<DMatch> matches_raw;

	// feature matching is based only on feature descriptors

	try
	{
		matcher_flann.match(feat1.descriptors, feat2.descriptors, matches_raw);
	}
	catch (cv::Exception & e)
	{
		CString str;
		str = e.msg.c_str();
		AfxMessageBox(str);
	}

	double max_dist = 0; double min_dist = 1000;
	//-- Quick calculation of max and min distances between keypoints
	for(i=0;i<feat1.descriptors.rows;i++)
	{
		double dist = matches_raw[i].distance;
		if(dist<min_dist)
			min_dist = dist;
		if(dist>max_dist)
			max_dist = dist;
	}

	//-- Draw only "good" matches (i.e. whose distance is less than param1*min_dist )
	//-- PS.- radiusMatch can also be used here.
	vector<DMatch> matches_good;
	for(i=0;i<feat1.descriptors.rows;i++)
	{
		if(matches_raw[i].distance<param1*min_dist)
		{
			matches_good.push_back(matches_raw[i]);
		}
	}

	// RANSAC to discard outliers
	vector<Point2f> points1(matches_good.size());
	vector<Point2f> points2(matches_good.size());

	// initialize the points here ... */
	for(i=0;i<matches_good.size();i++)
	{
		points1[i] = feat1.key_points[matches_good[i].queryIdx].pt;
		points2[i] = feat2.key_points[matches_good[i].trainIdx].pt;
	}

	vector<uchar> status;

	Matx33d fundamental_matrix;
	try
	{
		fundamental_matrix = findFundamentalMat(points1, points2, FM_RANSAC, param2, param3, status);
	}
	catch (cv::Exception & e)
	{
		CString str;
		str = e.msg.c_str();
		AfxMessageBox(str);
	}

	matches.clear();
	for (i=0;i<matches_good.size();i++)
	{
		if (status[i])
		{
			/*matches.push_back(matches_good[i]);*/

			// zhaokunz, 20140324, use the unique image point index
			DMatch match_idxImgPt = matches_good[i];
			match_idxImgPt.queryIdx = feat1.idx_pt[match_idxImgPt.queryIdx];
			match_idxImgPt.trainIdx = feat2.idx_pt[match_idxImgPt.trainIdx];

			matches.push_back(match_idxImgPt);
		}
	}

	// zhaokunz, 20140324, eliminate those identical matches
	vector<int> vIdentical(matches.size(), 0);
	for (i=0;i<matches.size();i++)
	{
		if (vIdentical[i])
		{
			continue;
		}

		DMatch m1 = matches[i];

		for (j=i+1;j<matches.size();j++)
		{
			DMatch m2 = matches[j];

			if (m1.queryIdx == m2.queryIdx && m1.trainIdx == m2.trainIdx)
			{
				// found a identical match
				vIdentical[j] = 1;
			}
		}
	}

	vector<DMatch> vMatch_noIdentical;
	for (i=0;i<matches.size();i++) 
	{
		if (!vIdentical[i])
		{
			vMatch_noIdentical.push_back(matches[i]);
		}
	}
	matches = vMatch_noIdentical;

	// zhaokunz, 20140317, sometimes, a feature is matched to more than one feature
	// we have to eliminate those ambiguilties by choosing the one with shortest matching distance in feature matching stage
	// zhaokunz, 20140319, when these ambiguilties happen, eliminate all ambiguilties directly, including the one with
	// the shortest matching distance
	vector<int> vCancel(matches.size(), 0);
	for (i=0;i<matches.size();i++)
	{
		DMatch m1 = matches[i];

		for (j=i+1;j<matches.size();j++)
		{
			DMatch m2 = matches[j];

			if (m1.queryIdx != m2.queryIdx && m1.trainIdx != m2.trainIdx)
			{
				continue;
			}

			vCancel[i] = 1;
			vCancel[j] = 1;
		}
	}

	vector<DMatch> vMatch_final;
	for (i=0;i<matches.size();i++) 
	{
		if (!vCancel[i])
		{
			vMatch_final.push_back(matches[i]);
		}
	}
	matches = vMatch_final;
	//////////////////////////////////////////////////////////////////////////

	return fundamental_matrix;
}

// match features in two input images based on RANSAC, coordinates of input features are supposed to be distortion free
// and each feature in one image may be matched with more than one feature in the other image
Matx33d DeepVoid::CalibFundamentalMat_RANSAC_Features_Original(const Features & feat1,	// input:	n1 features extracted from the 1st image
															   const Features & feat2,	// input:	n2 features extracted from the 2nd image
															   vector<DMatch> & matches,	// output:	matches obtained after feature matching and RANSAC
															   double param1 /*= 3*/,		// input:	defining "good" matches (i.e. whose distance is less than param1*min_dist) in feature matching stage
															   double param2 /*= 3*/,		// input:	the distance threshold between point and epiline, used in RANSAC stage
															   double param3 /*= 0.99*/	// input:	specifying a desirable level of confidence (probability) that the estimated matrix is correct
															   )
{
	int i,j;

	// first do feature matching
	FlannBasedMatcher matcher_flann;

	vector<DMatch> matches_raw;

	// feature matching is based only on feature descriptors

	try
	{
		matcher_flann.match(feat1.descriptors, feat2.descriptors, matches_raw);
	}
	catch (cv::Exception & e)
	{
		CString str;
		str = e.msg.c_str();
		AfxMessageBox(str);
	}

	double max_dist = 0; double min_dist = 1000;
	//-- Quick calculation of max and min distances between keypoints
	for(i=0;i<feat1.descriptors.rows;i++)
	{
		double dist = matches_raw[i].distance;
		if(dist<min_dist)
			min_dist = dist;
		if(dist>max_dist)
			max_dist = dist;
	}

	//-- Draw only "good" matches (i.e. whose distance is less than param1*min_dist )
	//-- PS.- radiusMatch can also be used here.
	vector<DMatch> matches_good;
	for(i=0;i<feat1.descriptors.rows;i++)
	{
		if(matches_raw[i].distance<param1*min_dist)
		{
			matches_good.push_back(matches_raw[i]);
		}
	}

	// RANSAC to discard outliers
	vector<Point2f> points1(matches_good.size());
	vector<Point2f> points2(matches_good.size());

	// initialize the points here ... */
	for(i=0;i<matches_good.size();i++)
	{
		points1[i] = feat1.key_points[matches_good[i].queryIdx].pt;
		points2[i] = feat2.key_points[matches_good[i].trainIdx].pt;
	}

	vector<uchar> status;

	Matx33d fundamental_matrix;

	try
	{
		fundamental_matrix = findFundamentalMat(points1, points2, FM_RANSAC, param2, param3, status);
	}
	catch (cv::Exception & e)
	{
		CString str;
		str = e.msg.c_str();
		AfxMessageBox(str);
	}

	matches.clear();
	for (i=0;i<matches_good.size();i++)
	{
		if (status[i])
		{
			matches.push_back(matches_good[i]);
		}
	}

	return fundamental_matrix;
}

// 20150113, zhaokunz
// 1. get initial matches based on descriptors
// 2. refine matches and get initial fundamental matrix using RANSAC
// 3. optimize fundamental matrix using only inliers
// 4. augment inlier set using optimized fundamental matrix
void DeepVoid::Get_F_Matches(const Features & feats0,		// input:	n1 features extracted from the 1st image
						     const Features & feats1,		// input:	n2 features extracted from the 2nd image
						     Matx33d & mF,					// output:	the estimated fundamental matrix
						     vector<DMatch> & matches,		// output:	matches obtained after feature matching and RANSAC
						     double thresh_p2l /*= 3.*/,	// input:	the distance threshold between point and epiline, used in RANSAC stage
							 double thresh_conf /*= 0.99*/,	// input:	specifying a desirable level of confidence (probability) that the estimated matrix is correct
							 int maxIter /*= 10*/,			// input:	the maximum number of iterations
							 double xEps /*= 1.0E-8*/,		// input:	threshold
							 double fEps /*= 1.0E-6*/		// input:	threshold
						     )
{
	int i;

	int nFeat0 = feats0.key_points.size();
	int nFeat1 = feats1.key_points.size();

	// do flann matching
	FlannBasedMatcher matcher_flann;

	vector<DMatch> matches_raw;
//	vector<vector<DMatch>> matches_kNN;

	// ensure that the first i.e. the reference image has less features than the second i.e. matching image does
	if (nFeat0<=nFeat1)
	{
		matcher_flann.match(feats0.descriptors, feats1.descriptors, matches_raw);
	} 
	else
	{
		matcher_flann.match(feats1.descriptors, feats0.descriptors, matches_raw);

		for (i=0;i<matches_raw.size();i++)
		{
			// zhaokunz, 20150106, reverse the index
			int tmp = matches_raw[i].queryIdx;
			matches_raw[i].queryIdx = matches_raw[i].trainIdx;
			matches_raw[i].trainIdx = tmp;
		}
	}

//	matcher_flann.knnMatch(des0, des1, matches_kNN, 3);

	// use the image point index, especially for SIFT features
	vector<DMatch> matches_raw_idxImgPt;

	for (i=0;i<matches_raw.size();i++)
	{
		// zhaokunz, 20140324, use the unique image point index
		DMatch match_idxImgPt = matches_raw[i];
		match_idxImgPt.queryIdx = feats0.idx_pt[matches_raw[i].queryIdx];
		match_idxImgPt.trainIdx = feats1.idx_pt[matches_raw[i].trainIdx];

		matches_raw_idxImgPt.push_back(match_idxImgPt);
	}

	// then detect and delete those identical matches
	vector<DMatch> matches_noIdentical;
	DeleteIdenticalMatches(matches_raw_idxImgPt, matches_noIdentical);

	// enforce one-to-one constraint
	vector<DMatch> matches_one2one;
	EnsureOne2OneMatches(matches_noIdentical, matches_one2one);

	// RANSAC //////////////////////////////////////////////////////////////////////////
	vector<Point2f> points0(matches_one2one.size());
	vector<Point2f> points1(matches_one2one.size());

	// initialize the points here ... */
	for(i=0;i<matches_one2one.size();i++)
	{
		points0[i] = feats0.key_points[matches_one2one[i].queryIdx].pt;
		points1[i] = feats1.key_points[matches_one2one[i].trainIdx].pt;
	}

	vector<uchar> status;

	Matx33d fundamental_matrix;

	fundamental_matrix = findFundamentalMat(points0, points1, status, FM_RANSAC, thresh_p2l, thresh_conf);

	vector<DMatch> matches_RANSAC;
	vector<Point2d> vImgPts0, vImgPts1;

	for (i=0;i<matches_one2one.size();i++)
	{
		if (status[i])
		{
			matches_RANSAC.push_back(matches_one2one[i]);

			Point2d pt0,pt1;
			pt0.x = points0[i].x; pt0.y = points0[i].y;
			pt1.x = points1[i].x; pt1.y = points1[i].y;
			vImgPts0.push_back(pt0);
			vImgPts1.push_back(pt1);
		}
	}

	// optimize the fundamental matrix using only the inliers
	bool bSuc = optim_gn_F(vImgPts0,vImgPts1,fundamental_matrix,mF,maxIter,xEps,fEps);
	
	// augment matches given the optimized fundamental matrix
	vector<DMatch> matches_aug;
	int nInliers = GetInliers(feats0.key_points,feats1.key_points,mF,matches_noIdentical,matches_aug,thresh_p2l);

	// once again ensure one-to-one matches to get the final matches
	EnsureOne2OneMatches(matches_aug, matches);
}

// 20150128, zhaokunz
// 1. get initial matches based on descriptors
// 2. refine matches and get initial fundamental matrix using RANSAC
// 3. optimize fundamental matrix using only inliers
// 4. augment inlier set using optimized fundamental matrix
bool DeepVoid::Get_F_Matches_knn(const Features & feats0,				// input:	n1 features extracted from the 1st image
							     const Features & feats1,				// input:	n2 features extracted from the 2nd image
							     Matx33d & mF,							// output:	the estimated fundamental matrix
							     vector<DMatch> & matches,				// output:	matches obtained after feature matching and RANSAC
								 bool bOptim /*= true*/,				// input:	whether optimize F using Golden Standard algorithm or not
								 double thresh_ratioTest /*= 0.3*/,		// input:	the ratio threshold for ratio test
								 double thresh_minInlierRatio /*= 0.5*/,// input:	the allowed minimum ratio of inliers
							     double thresh_p2l /*= 3.*/,			// input:	the distance threshold between point and epiline, used in RANSAC stage
							     double thresh_conf /*= 0.99*/,			// input:	specifying a desirable level of confidence (probability) that the estimated matrix is correct
							     int maxIter /*= 10*/,					// input:	the maximum number of iterations
							     double xEps /*= 1.0E-8*/,				// input:	threshold
							     double fEps /*= 1.0E-6*/				// input:	threshold
							     )
{
	int i,j;

	matches.clear();

	int K = 2; // the number of nearest neighbors

	int nFeat0 = feats0.key_points.size();
	int nFeat1 = feats1.key_points.size();

//	FlannBasedMatcher matcher; // do flann matching
	BFMatcher matcher(NORM_L2, false); // do brute force matching

	vector<vector<DMatch>> matches01_knn, matches10_knn;
	// 1. extract k nearest neigbors for each feature in the each image
	matcher.knnMatch(feats0.descriptors, feats1.descriptors, matches01_knn, K); // 0->1 matching
	matcher.knnMatch(feats1.descriptors, feats0.descriptors, matches10_knn, K); // 1->0 matching
	//////////////////////////////////////////////////////////////////////////

	// 2. using the unique image point index, useful for SIFT, since for one image point
	// there will be more than one SIFT features with different directions, but it's one-to-one for SURF
	for (auto iter=matches01_knn.begin();iter!=matches01_knn.end();++iter)
	{
		for (auto iter_k=iter->begin();iter_k!=iter->end();++iter_k)
		{
			int queryIdx_uni = feats0.idx_pt[iter_k->queryIdx];
			int trainIdx_uni = feats1.idx_pt[iter_k->trainIdx];

			iter_k->queryIdx = queryIdx_uni;
			iter_k->trainIdx = trainIdx_uni;
		}
	}

	for (auto iter=matches10_knn.begin();iter!=matches10_knn.end();++iter)
	{
		for (auto iter_k=iter->begin();iter_k!=iter->end();++iter_k)
		{
			int queryIdx_uni = feats1.idx_pt[iter_k->queryIdx];
			int trainIdx_uni = feats0.idx_pt[iter_k->trainIdx];

			iter_k->queryIdx = queryIdx_uni;
			iter_k->trainIdx = trainIdx_uni;
		}
	}
	//////////////////////////////////////////////////////////////////////////


	// 3. reorganize all matches, again only neccesary for SIFT
	// (0,25) (0,16)
	// (0,25) (0,19)
	// (1,10) (1,11)
	//      to
	// (0,25) (0,16) (0,25) (0,19)
	// (1,10) (1,11)
	vector<vector<DMatch>> matches01_knn_idximgpt, matches10_knn_idximgpt;
	vector<uchar> status01(matches01_knn.size()), status10(matches10_knn.size());

	auto iter01_begin = matches01_knn.begin();
	auto iter10_begin = matches10_knn.begin();

	for (auto iter=matches01_knn.begin();iter!=matches01_knn.end();++iter)
	{
		i = iter-iter01_begin;

		if (status01[i])
		{
			continue;
		}

		matches01_knn_idximgpt.push_back(*iter);

		status01[i] = 1;

		auto iter_end = matches01_knn_idximgpt.end()-1;

		for (auto iter_k=iter+1;iter_k!=matches01_knn.end();++iter_k)
		{
			if ((*iter_k)[0].queryIdx!=(*iter)[0].queryIdx)
			{
				continue;
			}
			
			iter_end->insert(iter_end->end(), iter_k->begin(), iter_k->end());

			status01[iter_k-iter01_begin] = 1;
		}
	}

	for (auto iter=matches10_knn.begin();iter!=matches10_knn.end();++iter)
	{
		i = iter-iter10_begin;

		if (status10[i])
		{
			continue;
		}

		matches10_knn_idximgpt.push_back(*iter);

		status10[i] = 1;

		auto iter_end = matches10_knn_idximgpt.end()-1;

		for (auto iter_k=iter+1;iter_k!=matches10_knn.end();++iter_k)
		{
			if ((*iter_k)[0].queryIdx!=(*iter)[0].queryIdx)
			{
				continue;
			}

			iter_end->insert(iter_end->end(), iter_k->begin(), iter_k->end());

			status10[iter_k-iter10_begin] = 1;
		}
	}
	//////////////////////////////////////////////////////////////////////////

	// 4. select best 2 different matches for each image point
	// (0,25) (0,16) (0,25) (0,19)
	// (1,10) (1,11)
	//      to
	// (0,25) (0,19)
	// (1,10) (1,11)
	// there may be matches like this     (2,14) (2,14) (2,14) (2,14)
	// after this step, they will be like (2,14) only, since they are all basically the same matches
	for (auto iter=matches01_knn_idximgpt.begin();iter!=matches01_knn_idximgpt.end();++iter)
	{
		sort(iter->begin(),iter->end(),[](const DMatch & a, const DMatch & b){return a.distance<b.distance;});

		int idxBest = (*iter)[0].trainIdx;

		if (idxBest != (*iter)[1].trainIdx)
		{
			iter->erase(iter->begin()+2, iter->end());
			continue;
		}

		auto iter_find = find_if(iter->begin(),iter->end(),[idxBest](const DMatch & a){return a.trainIdx!=idxBest;});

		if (iter_find != iter->end())
		{
			iter_swap(iter->begin()+1,iter_find);
			iter->erase(iter->begin()+2, iter->end());
		}
		else // all matches are the same
		{
			iter->erase(iter->begin()+1, iter->end());
		}
	}

	for (auto iter=matches10_knn_idximgpt.begin();iter!=matches10_knn_idximgpt.end();++iter)
	{
		sort(iter->begin(),iter->end(),[](const DMatch & a, const DMatch & b){return a.distance<b.distance;});

		int idxBest = (*iter)[0].trainIdx;

		if (idxBest != (*iter)[1].trainIdx)
		{
			iter->erase(iter->begin()+2, iter->end());
			continue;
		}

		auto iter_find = find_if(iter->begin(),iter->end(),[idxBest](const DMatch & a){return a.trainIdx!=idxBest;});

		if (iter_find != iter->end())
		{
			iter_swap(iter->begin()+1,iter_find);
			iter->erase(iter->begin()+2, iter->end());
		}
		else // all matches are the same
		{
			iter->erase(iter->begin()+1, iter->end());
		}
	}
	//////////////////////////////////////////////////////////////////////////

	vector<DMatch> matches01_passRatioTest, matches10_passRatioTest;
	// 5. ratio test, only those matches that the best candidate are far better than the 2nd best are kept
	ratioTest(matches01_knn_idximgpt, matches01_passRatioTest, thresh_ratioTest);
	ratioTest(matches10_knn_idximgpt, matches10_passRatioTest, thresh_ratioTest);
	//////////////////////////////////////////////////////////////////////////

	vector<DMatch> matches_passSymTest;
	// 6. symmetry test, only those symmetric matches are kept
	// i.e. (0,14) for left image, there is (14,0) for the right image, then (0,14) is kept
	symmetryTest(matches01_passRatioTest, matches10_passRatioTest, matches_passSymTest);
	//////////////////////////////////////////////////////////////////////////

	if (matches_passSymTest.size()<8)
	{
		return false;
	}

	// 7. RANSAC, further filter those matches that do not satisfy epipolar geometry
	vector<Point2f> points0(matches_passSymTest.size());
	vector<Point2f> points1(matches_passSymTest.size());

	// initialize the points here ... */
	for(i=0;i<matches_passSymTest.size();i++)
	{
		points0[i] = feats0.key_points[matches_passSymTest[i].queryIdx].pt;
		points1[i] = feats1.key_points[matches_passSymTest[i].trainIdx].pt;
	}

	vector<uchar> status;

	Matx33d fundamental_matrix;

	fundamental_matrix = findFundamentalMat(points0, points1, status, FM_RANSAC, thresh_p2l, thresh_conf);

	vector<DMatch> matches_RANSAC;
	vector<Point2d> vImgPts0, vImgPts1;

	for (i=0;i<matches_passSymTest.size();i++)
	{
		if (status[i])
		{
			matches_RANSAC.push_back(matches_passSymTest[i]);

			Point2d pt0,pt1;
			pt0.x = points0[i].x; pt0.y = points0[i].y;
			pt1.x = points1[i].x; pt1.y = points1[i].y;
			vImgPts0.push_back(pt0);
			vImgPts1.push_back(pt1);
		}
	}

	double ratioInliers = (double)matches_RANSAC.size()/matches_passSymTest.size();

	if (matches_RANSAC.size()<8 || ratioInliers<thresh_minInlierRatio)
	{
		// number of inliers must be bigger than 8
		// and the ratio of inliers should be more than certain threshold
		return false;
	}
	//////////////////////////////////////////////////////////////////////////

	// 8. using all the inliers to calculate a better initial F for optimization based on the Normalized 8-points algorithm
	// because of the usage of normalization, this DLT algorithm is quite robust
	mF = findFundamentalMat(vImgPts0, vImgPts1, FM_8POINT);
	//////////////////////////////////////////////////////////////////////////

	// 9. optimize the fundamental matrix using only the inliers, optional step
	if (bOptim)
	{
		Matx33d mF_optim;
		
// 		if (vImgPts0.size()>=12 && optim_gn_F(vImgPts0,vImgPts1,/*fundamental_matrix*/mF,mF_optim,maxIter,xEps,fEps))
// 		{
// 			// to ensure robustness, the minimum number of matches required should be at least 12, 4n>=3n+12 => n>=12
// 			// accept the optimized F only if the optimization succeeds
// 			mF = mF_optim;
// 		}

		if (vImgPts0.size()>=12)
		{
			// to ensure robustness, the minimum number of matches required should be at least 12, 4n>=3n+12 => n>=12
			// accept the optimized F only if the optimization succeeds
			optim_lm_F(vImgPts0,vImgPts1,/*fundamental_matrix*/mF,mF_optim,1.0E-6,maxIter,1.0E-8,1.0E-10);
			mF = mF_optim;
		}
	}
	//////////////////////////////////////////////////////////////////////////

	// 10. augment matching set by checking which match satisfys the determined epipolar geometry, pls refer to Christos's 2014 paper for more details
	// first delete all inliers from the candidate set to avoid replicates
	for (auto iter=matches_RANSAC.begin();iter!=matches_RANSAC.end();++iter)
	{
		auto iter01_found = find_if(matches01_knn_idximgpt.begin(),matches01_knn_idximgpt.end(),
			[iter](const vector<DMatch> & a){return (a[0].queryIdx==iter->queryIdx&&a[0].trainIdx==iter->trainIdx);});

		auto iter10_found = find_if(matches10_knn_idximgpt.begin(),matches10_knn_idximgpt.end(),
			[iter](const vector<DMatch> & a){return (a[0].queryIdx==iter->trainIdx&&a[0].trainIdx==iter->queryIdx);});

		// delete
		matches01_knn_idximgpt.erase(iter01_found);
		matches10_knn_idximgpt.erase(iter10_found);
	}

	vector<DMatch> matches01_aug,matches10_aug;
	GetInliers_knn(feats0.key_points,feats1.key_points,mF,    matches01_knn_idximgpt,matches01_aug,thresh_p2l);
	GetInliers_knn(feats1.key_points,feats0.key_points,mF.t(),matches10_knn_idximgpt,matches10_aug,thresh_p2l);

	// do symmetry test one more time
	vector<DMatch> matches_aug_passSymTest;
	symmetryTest(matches01_aug, matches10_aug, matches_aug_passSymTest);

	matches = matches_RANSAC;
	matches.insert(matches.end(), matches_aug_passSymTest.begin(), matches_aug_passSymTest.end());
	//////////////////////////////////////////////////////////////////////////

	return true;
}

// 20150128, zhaokunz, output those matches that pass the ratio test
void DeepVoid::ratioTest(const vector<vector<DMatch>> & matches_knn,	// input:	knn matches
					     vector<DMatch> & matches,					// output:	matches that have past the ratio test
					     double ratio /*= 0.3*/						// input:	the maximum allowed ratio between the best match and 2nd best match
					     )
{
	matches.clear();

	for (auto iter=matches_knn.begin();iter!=matches_knn.end();++iter)
	{
		if (iter->size()<2) // must contain more than 1 candidate NN
		{
			continue;
		} 
		
		if ((*iter)[0].distance/(*iter)[1].distance<ratio)
		{
			matches.push_back((*iter)[0]); // accept the best NN
		}
	}
}

// 20150129, zhaokunz, output those matches that pass the symmetry test
void DeepVoid::symmetryTest(const vector<DMatch> & matches01,	// input:	matches generated from 0->1
						    const vector<DMatch> & matches10,	// input:	matches generated from 1->0
						    vector<DMatch> & matches			// output:	
						    )
{
	matches.clear();

	for (auto iter01=matches01.begin();iter01!=matches01.end();++iter01)
	{
		int t = iter01->trainIdx;

		auto iter10 = find_if(matches10.begin(),matches10.end(),[t](const DMatch & m){return m.queryIdx==t;});

		if (iter10 == matches10.end()) // didn't find
		{
			continue;
		}

		// found
		if (iter10->trainIdx == iter01->queryIdx)
		{
			matches.push_back(*iter01);
		}
	}
}

// first, feature matching, then compute fundamental matrix and filter outlier matches using RANSAC
// once we get fundamental matrix, given intrinsic parameters we can get initial essential matrix,
// which includes 4 possible relative orientation [R|t] between image 1 and 2, then we find the
// true one using method described in <Multiple View Geometry> by Richard Hartley, this function
// do not do bundle adjustment after [R|t] obtained, only the linear solution
// this function returns the final fundamental 3*3 matrix
// Mat DeepVoid::RelativeOrientation_RANSAC_Features_Linear(const cam_data & cam1,			// input:	all the information about the image 1
// 														 const cam_data & cam2,			// input:	all the information about the image 2
// 														 Mat & mP,						// output:	3*4 matrix, the relative orientation of these two images [R|t]
// 														 vector<CloudPoint> & clouds,	// output:	the reconstructed cloud points in reference camera frame, which is the first image
// 														 double param1 /*= 3*/,			// input:	defining "good" matches (i.e. whose distance is less than param1*min_dist) in feature matching stage
// 														 double param2 /*= 3*/,			// input:	the distance threshold between point and epiline, used in RANSAC stage
// 														 double param3 /*= 0.99*/		// input:	specifying a desirable level of confidence (probability) that the estimated matrix is correct
// 														 )
// {
// 	int i;
// 
// 	int nFeat1 = cam1.m_feats.key_points.size();
// 	int nFeat2 = cam2.m_feats.key_points.size();
// 
// 	Mat mK1(3, 3, CV_64F), mK2(3, 3, CV_64F);
// 
// 	mK1.at<double>(0,0) = cam1.fx;	mK1.at<double>(0,1) = cam1.s;	mK1.at<double>(0,2) = cam1.cx;
// 	mK1.at<double>(1,0) = 0;		mK1.at<double>(1,1) = cam1.fy;	mK1.at<double>(1,2) = cam1.cy;
// 	mK1.at<double>(2,0) = 0;		mK1.at<double>(2,1) = 0;		mK1.at<double>(2,2) = 1;
// 
// 	mK2.at<double>(0,0) = cam2.fx;	mK2.at<double>(0,1) = cam2.s;	mK2.at<double>(0,2) = cam2.cx;
// 	mK2.at<double>(1,0) = 0;		mK2.at<double>(1,1) = cam2.fy;	mK2.at<double>(1,2) = cam2.cy;
// 	mK2.at<double>(2,0) = 0;		mK2.at<double>(2,1) = 0;		mK2.at<double>(2,2) = 1;
// 
// 	// it's preferable to first rectify the features' image coordinates if the distortion coefficients are not 0
// 	// this is not critical, but can improve the accuracy of Essential matrix a little bit
// 	// and it is preferable if the features are extracted from a whole rectified distortion free image too, because
// 	// the descriptors are generated from distortion free image
// 	Features feat1_rectified = cam1.m_feats;
// 	Features feat2_rectified = cam2.m_feats;
// 
// 	for (i=0;i<nFeat1;i++)
// 	{
// 		RemoveDistortion_DCBrown(cam1.cx, cam1.cy, cam1.fx, cam1.fy, cam1.k, feat1_rectified.key_points[i].pt.x, feat1_rectified.key_points[i].pt.y,
// 			feat1_rectified.key_points[i].pt.x, feat1_rectified.key_points[i].pt.y);
// 	}
// 	for (i=0;i<nFeat2;i++)
// 	{
// 		RemoveDistortion_DCBrown(cam2.cx, cam2.cy, cam2.fx, cam2.fy, cam2.k, feat2_rectified.key_points[i].pt.x, feat2_rectified.key_points[i].pt.y,
// 			feat2_rectified.key_points[i].pt.x, feat2_rectified.key_points[i].pt.y);
// 	}
// 
// 	// calibrate fundamental matrix using rectified features and RANSAC
// 	vector<DMatch> matches;
// 
// 	Mat mF = CalibFundamentalMat_RANSAC_Features(feat1_rectified, feat2_rectified, matches, param1, param2, param3);
// 
// 	// get the essential matrix given camera matrix
// 	Mat mE = mK2.t() * mF * mK1;
// 
// 	// normalize all matched image points
// 	vector<Point2f> imgPts1(matches.size());
// 	vector<Point2f> imgPts2(matches.size());
// 
// 	for (i=0;i<matches.size();i++)
// 	{
// 		imgPts1[i].x = (feat1_rectified.key_points[matches[i].queryIdx].pt.x - cam1.cx) / cam1.fx;
// 		imgPts1[i].y = (feat1_rectified.key_points[matches[i].queryIdx].pt.y - cam1.cy) / cam1.fy;
// 
// 		imgPts2[i].x = (feat2_rectified.key_points[matches[i].trainIdx].pt.x - cam2.cx) / cam2.fx;
// 		imgPts2[i].y = (feat2_rectified.key_points[matches[i].trainIdx].pt.y - cam2.cy) / cam2.fy;
// 	}
// 
// 	vector<Point3d> wrdPts;
// 	
// 	DisambiguateRT_givenE(imgPts1, imgPts2, mE, mP, wrdPts);
// 
// 	//////////////////////////////////////////////////////////////////////////
// 	CMatrix mWrdPts(4, wrdPts.size(), 1), mImgPts1(3, wrdPts.size(), 1), mImgPts2(3, wrdPts.size(), 1), mDist1(5, 1, 0), mDist2(5, 1, 0), cmK1(3,4,0),cmK2(3,4,0),cmRT(4,4,0);
// 	FILE * file = fopen("D:\\result.txt", "w");
// 	for (i=0;i<wrdPts.size();i++)
// 	{
// 		int R = 255;
// 		int G = 255;
// 		int B = 255;
// 		fprintf(file, "%lf;%lf;%lf;%d;%d;%d\n", wrdPts[i].x, wrdPts[i].y, wrdPts[i].z, R, G, B);
// 
// 		mWrdPts(1, i+1) = wrdPts[i].x;
// 		mWrdPts(2, i+1) = wrdPts[i].y;
// 		mWrdPts(3, i+1) = wrdPts[i].z;
// 
// 		mImgPts1(1, i+1) = cam1.m_feats.key_points[matches[i].queryIdx].pt.x;
// 		mImgPts1(2, i+1) = cam1.m_feats.key_points[matches[i].queryIdx].pt.y;
// 
// 		mImgPts2(1, i+1) = cam2.m_feats.key_points[matches[i].trainIdx].pt.x;
// 		mImgPts2(2, i+1) = cam2.m_feats.key_points[matches[i].trainIdx].pt.y;
// 	}
// 
// 	fclose(file);
// 
// 	mDist1(1) = cam1.k[0];
// 	mDist1(2) = cam1.k[1];
// 	mDist1(3) = cam1.k[2];
// 	mDist1(4) = cam1.k[3];
// 	mDist1(5) = cam1.k[4];
// 
// 	mDist2(1) = cam2.k[0];
// 	mDist2(2) = cam2.k[1];
// 	mDist2(3) = cam2.k[2];
// 	mDist2(4) = cam2.k[3];
// 	mDist2(5) = cam2.k[4];
// 
// 	int j;
// 	for (i=0;i<3;i++)
// 	{
// 		for (j=0;j<3;j++)
// 		{
// 			cmK1(i+1,j+1) = mK1.at<double>(i,j);
// 			cmK2(i+1,j+1) = mK2.at<double>(i,j);
// 		}
// 	}
// 
// 	for (i=0;i<3;i++)
// 	{
// 		for (j=0;j<4;j++)
// 		{
// 			cmRT(i+1,j+1) = mP.at<double>(i,j);
// 		}
// 	}
// 	cmRT(4,4)=1;
// 
// // 	mImgPts1.PrintMatrix2Screen();
// // 	mImgPts2.PrintMatrix2Screen();
// 
// // 	cmK1.PrintMatrix2Screen();
// // 	cmK2.PrintMatrix2Screen();
// // 	cmRT.PrintMatrix2Screen();
// 
// 	double info[10]; CMatrix mCovar;
// 
// // 	mWrdPts = mWrdPts.GetRect(1,1,100,mWrdPts.m_nRow);
// // 	mImgPts1 = mImgPts1.GetRect(1,1,100,mImgPts1.m_nRow);
// // 	mImgPts2 = mImgPts2.GetRect(1,1,100,mImgPts2.m_nRow);
// 
// 	optim_levmar_relative_XYZ_ext_euler(mWrdPts, mImgPts1, mImgPts2, cmK1, cmK2, cmRT, mDist1, mDist2, cam1.dist_type, cam2.dist_type, 256, NULL, info, mCovar);
// 	CString strInfo = InterpretOptimInfo(info, mCovar);
// 	AfxMessageBox(strInfo);
// 	double reprojErr = sqrt(info[1] / (2*mWrdPts.m_nCol));
// 
// 	file = fopen("D:\\resultOptim.txt", "w");
// 	for (i=0;i<mWrdPts.m_nCol;i++)
// 	{
// 		int R = 0;
// 		int G = 255;
// 		int B = 0;
// 		fprintf(file, "%lf;%lf;%lf;%d;%d;%d\n", mWrdPts(1, i+1), mWrdPts(2, i+1), mWrdPts(3, i+1), R, G, B);
// 	}
// 
// 	fclose(file);
// 	//////////////////////////////////////////////////////////////////////////
// 	
// 	return Mat();
// }

// first, feature matching, then compute fundamental matrix and filter outlier matches using RANSAC
// once we get fundamental matrix, given intrinsic parameters we can get initial essential matrix,
// which includes 4 possible relative orientation [R|t] between image 1 and 2, then we find the
// true one using method described in <Multiple View Geometry> by Richard Hartley, this function
// do not do bundle adjustment after [R|t] obtained, only the linear solution
// this function returns the final fundamental 3*3 matrix
CMatrix DeepVoid::RelativeOrientation_RANSAC_Features_Linear(const cam_data & cam1,			// input:	all the information about the image 1
															 const cam_data & cam2,			// input:	all the information about the image 2
															 CMatrix & mP,					// output:	3*4 matrix, the relative orientation of these two images [R|t]
															 vector<CloudPoint> & clouds,	// output:	the reconstructed cloud points in reference camera frame, which is the first image
															 double param1 /*= 3*/,			// input:	defining "good" matches (i.e. whose distance is less than param1*min_dist) in feature matching stage
															 double param2 /*= 3*/,			// input:	the distance threshold between point and epiline, used in RANSAC stage
															 double param3 /*= 0.99*/		// input:	specifying a desirable level of confidence (probability) that the estimated matrix is correct
															 )
{
	int i,j;

	int nFeat1 = cam1.m_feats.key_points.size();
	int nFeat2 = cam2.m_feats.key_points.size();

	CMatrix mK1(3, 3, 0), mK2(3, 3, 0);

	mK1(1,1) = cam1.fx; mK1(2,2) = cam1.fy;
	mK1(1,3) = cam1.cx; mK1(2,3) = cam1.cy;
	mK1(1,2) = cam1.s;  mK1(3,3) = 1;

	mK2(1,1) = cam2.fx; mK2(2,2) = cam2.fy;
	mK2(1,3) = cam2.cx; mK2(2,3) = cam2.cy;
	mK2(1,2) = cam2.s;  mK2(3,3) = 1;

	// it's preferable to first rectify the features' image coordinates if the distortion coefficients are not 0
	// this is not critical, but can improve the accuracy of Essential matrix a little bit
	// and it is preferable if the features are extracted from a whole rectified distortion free image too, because
	// the descriptors are generated from distortion free image
	Features feat1_rectified = cam1.m_feats;
	Features feat2_rectified = cam2.m_feats;

	for (i=0;i<nFeat1;i++)
	{
		double d_x, d_y, i_x, i_y;
		d_x = feat1_rectified.key_points[i].pt.x; d_y = feat1_rectified.key_points[i].pt.y;
		RemoveDistortion_DCBrown(cam1.cx, cam1.cy, cam1.fx, cam1.fy, cam1.k, d_x, d_y, i_x, i_y);
		feat1_rectified.key_points[i].pt.x = i_x; feat1_rectified.key_points[i].pt.y = i_y;
	}
	for (i=0;i<nFeat2;i++)
	{
		double d_x, d_y, i_x, i_y;
		d_x = feat2_rectified.key_points[i].pt.x; d_y = feat2_rectified.key_points[i].pt.y;
		RemoveDistortion_DCBrown(cam2.cx, cam2.cy, cam2.fx, cam2.fy, cam2.k, d_x, d_y, i_x, i_y);
		feat2_rectified.key_points[i].pt.x = i_x; feat2_rectified.key_points[i].pt.y = i_y;
	}

	// calibrate fundamental matrix using rectified features and RANSAC
	vector<DMatch> matches;

	Matx33d mF33d = CalibFundamentalMat_RANSAC_Features(feat1_rectified, feat2_rectified, matches, param1, param2, param3);

	CMatrix mF(3,3);
	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mF(i+1,j+1) = mF33d(i,j);
		}
	}

	// get the essential matrix given camera matrix
	CMatrix mE = mK2.Transpose() * mF * mK1;

	CMatrix mImgPts1(3, matches.size(), 1), mImgPts2(3, matches.size(), 1);
	for (i=0;i<matches.size();i++)
	{
		mImgPts1(1, i+1) = feat1_rectified.key_points[matches[i].queryIdx].pt.x;
		mImgPts1(2, i+1) = feat1_rectified.key_points[matches[i].queryIdx].pt.y;

		mImgPts2(1, i+1) = feat2_rectified.key_points[matches[i].trainIdx].pt.x;
		mImgPts2(2, i+1) = feat2_rectified.key_points[matches[i].trainIdx].pt.y;
	}

	// get normalized image points
	CMatrix mImgPts1_norm = mK1.Inverse() * mImgPts1;
	CMatrix mImgPts2_norm = mK2.Inverse() * mImgPts2;

	CMatrix mWrdPts;
	DisambiguateRT_givenE(mImgPts1_norm, mImgPts2_norm, mE, mP, mWrdPts);

	//////////////////////////////////////////////////////////////////////////
	CMatrix mDist1(5, 1, 0), mDist2(5, 1, 0), cmRT(4,4,0);
	FILE * file = fopen("D:\\result.txt", "w");
	for (i=0;i<mWrdPts.m_nCol;i++)
	{
		int R = 255;
		int G = 255;
		int B = 255;
		fprintf(file, "%lf;%lf;%lf;%d;%d;%d\n", mWrdPts(1,i+1), mWrdPts(2,i+1), mWrdPts(3,i+1), R, G, B);
	}

	fclose(file);

	mDist1(1) = cam1.k[0];
	mDist1(2) = cam1.k[1];
	mDist1(3) = cam1.k[2];
	mDist1(4) = cam1.k[3];
	mDist1(5) = cam1.k[4];

	mDist2(1) = cam2.k[0];
	mDist2(2) = cam2.k[1];
	mDist2(3) = cam2.k[2];
	mDist2(4) = cam2.k[3];
	mDist2(5) = cam2.k[4];

	for (i=0;i<3;i++)
	{
		for (j=0;j<4;j++)
		{
			cmRT(i+1,j+1) = mP(i+1,j+1);
		}
	}
	cmRT(4,4)=1;


	// test PIRO ////////////////////////////////////////////////////////////////////////////////////////////
	//CMatrix mRT_PIRO = cmRT.Clone();
	CMatrix mRT_PIRO;
	
	//Optim_GaussNewton_PIRO_omg_fai_AXAYAZ(mImgPts1_norm, mImgPts2_norm, mRT_PIRO, 1024, 1.0E-12, 1.0E-12);
	double Y_optim, Z_optim, AX_optim, AY_optim, AZ_optim;
	PIRO_Y_Z_AXAYAZ_GaussNewton(mImgPts1_norm, mImgPts2_norm, mRT_PIRO, 1/mK1(1,1), Y_optim, Z_optim, AX_optim, AY_optim, AZ_optim, 1024, 1.0E-12, 1.0E-12, -1);

	CMatrix P1 = GenI(3); P1.AddOneCol(0);
	int n = mImgPts2_norm.m_nCol;
	CMatrix mProjs(3, 8), mImgPts(2, 2);
	CMatrix mWrdPts_reconstruct_1_1(4, n);
	mProjs.SetRect(1, 1, P1); mProjs.SetRect(1, 5, mRT_PIRO.GetRect(1,1,4,3));

	for (i = 1; i <= n; i++)
	{
		mImgPts(1, 1) = mImgPts1_norm(1, i);	mImgPts(2, 1) = mImgPts1_norm(2, i);
		mImgPts(1, 2) = mImgPts2_norm(1, i);	mImgPts(2, 2) = mImgPts2_norm(2, i);
		mWrdPts_reconstruct_1_1.SetCol(i, Intersect(mImgPts, mProjs));
	}

	file = fopen("D:\\result_PIRO.txt", "w");
	for (i=0;i<mWrdPts_reconstruct_1_1.m_nCol;i++)
	{
		int R = 0;
		int G = 255;
		int B = 255;
		fprintf(file, "%lf;%lf;%lf;%d;%d;%d\n", mWrdPts_reconstruct_1_1(1,i+1), mWrdPts_reconstruct_1_1(2,i+1), mWrdPts_reconstruct_1_1(3,i+1), R, G, B);
	}

	fclose(file);

	cmRT = mRT_PIRO.Clone();
	mWrdPts = mWrdPts_reconstruct_1_1.Clone();
	////////////////////////////////////////////////////////////////////////////////////////////////////////


	double info[10]; CMatrix mCovar;
	optim_levmar_relative_XYZ_ext_euler(mWrdPts, mImgPts1, mImgPts2, mK1, mK2, cmRT, mDist1, mDist2, cam1.dist_type, cam2.dist_type, 256, NULL, info, mCovar);
	CString strInfo = InterpretOptimInfo(info, mCovar);
	AfxMessageBox(strInfo);
	double reprojErr = sqrt(info[1] / (2*mWrdPts.m_nCol));

	file = fopen("D:\\resultOptim.txt", "w");
	for (i=0;i<mWrdPts.m_nCol;i++)
	{
		int R = 0;
		int G = 255;
		int B = 0;
		fprintf(file, "%lf;%lf;%lf;%d;%d;%d\n", mWrdPts(1, i+1), mWrdPts(2, i+1), mWrdPts(3, i+1), R, G, B);
	}

	fclose(file);
	//////////////////////////////////////////////////////////////////////////

	return CMatrix(0);
}

// given a essential matrix, find the true one using method described in <Multiple View Geometry> by Richard Hartley
// void DeepVoid::DisambiguateRT_givenE(const vector<Point2f> & imgPts1,					// input:	normalized image coordinates
// 									 const vector<Point2f> & imgPts2,					// input:	normalized image coordinates
// 									 const Mat & mE,									// input:	the given essential matrix
// 									 Mat & mP,											// output:	3*4 matrix, the relative orientation of these two images [R|t]
// 									 vector<Point3d> & wrdPts							// output:	the reconstructed 3d points in reference camera frame, which is the first image
// 									 )
// {
// 	int nPts = imgPts1.size();
// 
// 	int i,j;
// 
// 	Mat mU,mD,mVt;
// 	SVD svd;
// 	svd.compute(mE, mD, mU, mVt, SVD::FULL_UV);
// 
// 	double detU = determinant(mU);
// 	double detV = determinant(mVt);
// 
// 	if (detU*detV < 0)
// 	{
// 		for (i=0;i<mU.rows;i++)
// 		{
// 			mU.at<double>(i, 2) = -mU.at<double>(i, 2);
// 		}
// 	}
// 
// 	Mat mZ = Mat::zeros(3, 3, CV_64F);
// 	Mat mW = Mat::zeros(3, 3, CV_64F);
// 
// 	mZ.at<double>(0,1) = 1;		mZ.at<double>(1,0) = -1;
// 	mW.at<double>(0,1) = -1;	mW.at<double>(1,0) = 1;		mW.at<double>(2,2) = 1;
// 
// 	Mat mS = mU * mZ * mU.t();
// 	Mat mR1 = mU * mW * mVt;	Mat mR2 = mU * mW.t() * mVt;
// 	Mat u3 = mU.col(2);
// 
// 	// S = UZU', S = -u2u1' + u1u2', u1×u2 = +or-u3, expand S will find that S = [+or-u3]x,
// 	// so E = SR，and E = [t]xR，then t could be +or-u3
// 	Mat mP1  = Mat::zeros(3, 4, CV_64F); // [I    0]
// 	// all possible relative orientation listed below
// 	Mat mP21 = Mat::zeros(3, 4, CV_64F); // [R1  u3]
// 	Mat mP22 = Mat::zeros(3, 4, CV_64F); // [R1 -u3]
// 	Mat mP23 = Mat::zeros(3, 4, CV_64F); // [R2  u3]
// 	Mat mP24 = Mat::zeros(3, 4, CV_64F); // [R2 -u3]
// 
// 	mP1.at<double>(0,0)=mP1.at<double>(1,1)=mP1.at<double>(2,2)=1; // [I 0]
// 
// 	for (i=0;i<3;i++)
// 	{
// 		for (j=0;j<3;j++)
// 		{
// 			mP21.at<double>(i,j) = mR1.at<double>(i,j);
// 			mP22.at<double>(i,j) = mR1.at<double>(i,j);
// 			mP23.at<double>(i,j) = mR2.at<double>(i,j);
// 			mP24.at<double>(i,j) = mR2.at<double>(i,j);
// 		}
// 	}
// 
// 	mP21.at<double>(0,3)= u3.at<double>(0); mP21.at<double>(1,3)= u3.at<double>(1); mP21.at<double>(2,3)= u3.at<double>(2);
// 	mP22.at<double>(0,3)=-u3.at<double>(0); mP22.at<double>(1,3)=-u3.at<double>(1); mP22.at<double>(2,3)=-u3.at<double>(2);
// 	mP23.at<double>(0,3)= u3.at<double>(0); mP23.at<double>(1,3)= u3.at<double>(1); mP23.at<double>(2,3)= u3.at<double>(2);
// 	mP24.at<double>(0,3)=-u3.at<double>(0); mP24.at<double>(1,3)=-u3.at<double>(1); mP24.at<double>(2,3)=-u3.at<double>(2);
// 
// 	Mat mRT21 = Mat::zeros(4, 4, CV_32F); // [R1  u3; 0 0 0 1]
// 	Mat mRT22 = Mat::zeros(4, 4, CV_32F); // [R1 -u3; 0 0 0 1]
// 	Mat mRT23 = Mat::zeros(4, 4, CV_32F); // [R2  u3; 0 0 0 1]
// 	Mat mRT24 = Mat::zeros(4, 4, CV_32F); // [R2 -u3; 0 0 0 1]
// 
// 	for (i=0;i<3;i++)
// 	{
// 		for (j=0;j<4;j++)
// 		{
// 			mRT21.at<float>(i,j)=mP21.at<double>(i,j);
// 			mRT22.at<float>(i,j)=mP22.at<double>(i,j);
// 			mRT23.at<float>(i,j)=mP23.at<double>(i,j);
// 			mRT24.at<float>(i,j)=mP24.at<double>(i,j);
// 		}
// 	}
// 
// 	mRT21.at<float>(3,3)=mRT22.at<float>(3,3)=mRT23.at<float>(3,3)=mRT24.at<float>(3,3)=1;
// 
// 	// possible RT 1 //////////////////////////////////////////////////////////
// 	Mat mWrdPts1_H;
// 	triangulatePoints(mP1, mP21, imgPts1, imgPts2, mWrdPts1_H);
// 	Mat mWrdPts1_2_H = mRT21 * mWrdPts1_H;
// 	vector<Point3d> pts1_3d(nPts);
// 
// 	int nPosZ1 = 0;
// 	for (i=0;i<nPts;i++)
// 	{
// 		pts1_3d[i].x = mWrdPts1_H.at<float>(0,i)/mWrdPts1_H.at<float>(3,i);
// 		pts1_3d[i].y = mWrdPts1_H.at<float>(1,i)/mWrdPts1_H.at<float>(3,i);
// 		pts1_3d[i].z = mWrdPts1_H.at<float>(2,i)/mWrdPts1_H.at<float>(3,i);
// 
// 		double Z2 = mWrdPts1_2_H.at<float>(2,i)/mWrdPts1_2_H.at<float>(3,i);
// 
// 		if (pts1_3d[i].z>0 && Z2>0)
// 		{
// 			nPosZ1++;
// 		}
// 	}
// 
// 	int nMax = nPosZ1;
// 	int idxMax = 0;
// 
// 	// possible RT 2 //////////////////////////////////////////////////////////
// 	Mat mWrdPts2_H;
// 	triangulatePoints(mP1, mP22, imgPts1, imgPts2, mWrdPts2_H);
// 	Mat mWrdPts2_2_H = mRT22 * mWrdPts2_H;
// 	vector<Point3d> pts2_3d(nPts);
// 	
// 	int nPosZ2 = 0;
// 	for (i=0;i<nPts;i++)
// 	{
// 		pts2_3d[i].x = mWrdPts2_H.at<float>(0,i)/mWrdPts2_H.at<float>(3,i);
// 		pts2_3d[i].y = mWrdPts2_H.at<float>(1,i)/mWrdPts2_H.at<float>(3,i);
// 		pts2_3d[i].z = mWrdPts2_H.at<float>(2,i)/mWrdPts2_H.at<float>(3,i);
// 
// 		double Z2 = mWrdPts2_2_H.at<float>(2,i)/mWrdPts2_2_H.at<float>(3,i);
// 
// 		if (pts2_3d[i].z>0 && Z2>0)
// 		{
// 			nPosZ2++;
// 		}
// 	}
// 
// 	if (nPosZ2>nMax)
// 	{
// 		nMax = nPosZ2;
// 		idxMax = 1;
// 	}
// 
// 	// possible RT 3 //////////////////////////////////////////////////////////
// 	Mat mWrdPts3_H;
// 	triangulatePoints(mP1, mP23, imgPts1, imgPts2, mWrdPts3_H);
// 	Mat mWrdPts3_2_H = mRT23 * mWrdPts3_H;
// 	vector<Point3d> pts3_3d(nPts);
// 
// 	int nPosZ3 = 0;
// 	for (i=0;i<nPts;i++)
// 	{
// 		pts3_3d[i].x = mWrdPts3_H.at<float>(0,i)/mWrdPts3_H.at<float>(3,i);
// 		pts3_3d[i].y = mWrdPts3_H.at<float>(1,i)/mWrdPts3_H.at<float>(3,i);
// 		pts3_3d[i].z = mWrdPts3_H.at<float>(2,i)/mWrdPts3_H.at<float>(3,i);
// 
// 		double Z2 = mWrdPts3_2_H.at<float>(2,i)/mWrdPts3_2_H.at<float>(3,i);
// 
// 		if (pts3_3d[i].z>0 && Z2>0)
// 		{
// 			nPosZ3++;
// 		}
// 	}
// 
// 	if (nPosZ3>nMax)
// 	{
// 		nMax = nPosZ3;
// 		idxMax = 2;
// 	}
// 
// 	// possible RT 4 //////////////////////////////////////////////////////////
// 	Mat mWrdPts4_H;
// 	triangulatePoints(mP1, mP24, imgPts1, imgPts2, mWrdPts4_H);
// 	Mat mWrdPts4_2_H = mRT24 * mWrdPts4_H;
// 	vector<Point3d> pts4_3d(nPts);
// 	
// 	int nPosZ4 = 0;
// 	for (i=0;i<nPts;i++)
// 	{
// 		pts4_3d[i].x = mWrdPts4_H.at<float>(0,i)/mWrdPts4_H.at<float>(3,i);
// 		pts4_3d[i].y = mWrdPts4_H.at<float>(1,i)/mWrdPts4_H.at<float>(3,i);
// 		pts4_3d[i].z = mWrdPts4_H.at<float>(2,i)/mWrdPts4_H.at<float>(3,i);
// 
// 		double Z2 = mWrdPts4_2_H.at<float>(2,i)/mWrdPts4_2_H.at<float>(3,i);
// 
// 		if (pts4_3d[i].z>0 && Z2>0)
// 		{
// 			nPosZ4++;
// 		}
// 	}
// 
// 	if (nPosZ4>nMax)
// 	{
// 		nMax = nPosZ4;
// 		idxMax = 3;
// 	}
// 	//////////////////////////////////////////////////////////////////////////
// 	
// 	if (idxMax == 0)
// 	{
// 		mP = mP21.clone();
// 		wrdPts = pts1_3d;
// 	} 
// 	else if (idxMax == 1)
// 	{
// 		mP = mP22.clone();
// 		wrdPts = pts2_3d;
// 	}
// 	else if (idxMax == 2)
// 	{
// 		mP = mP23.clone();
// 		wrdPts = pts3_3d;
// 	}
// 	else
// 	{
// 		mP = mP24.clone();
// 		wrdPts = pts4_3d;
// 	}
// }

// 利用 8 以上归一化像点对应来通过《计算机视觉中的多视图几何》一书 p193 页中的归一化 8 点算法10.1求解两视图之间的本质矩阵，返回 3×3 的两视图之间的本质矩阵
void DeepVoid::DisambiguateRT_givenE(const CMatrix & mImgPts1,        // input:	3*n or 2*n matrix, normalized image coordinates
									 const CMatrix & mImgPts2,        // input:	3*n or 2*n matrix, normalized image coordinates
									 const CMatrix & mE,				// input:	3*3 matrix, the given essential matrix
									 CMatrix & mP,					// output:	3*4 matrix, the relative orientation of these two images [R|t]
									 CMatrix & mWrdPts				// output:	4*n matrix, the reconstructed 3d points in reference camera frame, which is the first image
									 )
{
	int i;

	int n = mImgPts1.m_nCol;

	// 接着对线性求解出来的 E 加上 det(E) = 0 的强制约束，另外还要加上前两个奇异值相等且第3个奇异值为 0 的强制约束
	CMatrix mU,mD0,mV;
	mE.SVD(mD0, mU, mV);

	double detU = mU.Det(); 
	double detV = mV.Det();

	if (detU * detV < 0)
	{
		for (i = 1; i <= mU.m_nRow; i++)
		{
			mU(i, 3) = -mU(i, 3);
		}
	}

	// 再在 E 的SVD分解基础上寻找 P2 = [R|t]
	CMatrix mZ(3, 3, 0);    mZ(1, 2) = 1;    mZ(2, 1) = -1;  
	CMatrix mW(3, 3, 0);    mW(1, 2) = -1;   mW(2, 1) = 1;    mW(3, 3) = 1;
	CMatrix mS = mU * mZ * mU.Transpose();
	CMatrix mR1 = mU * mW * mV.Transpose();    CMatrix mR2 = mU * mW.Transpose() * mV.Transpose();
	CMatrix u3 = mU.GetCol(3);
	// S = UZU', S = -u2u1' + u1u2', u1×u2 = +或-u3,把 S 展开来可以发现 S = [+或-u3]x，因此由 E = SR，且 E = [t]xR，知平移向量 t 有可能为 +或-u3
	CMatrix P1(3, 4), P2_1(3, 4), P2_2(3, 4), P2_3(3, 4), P2_4(3, 4);
	P2_1.SetRect(1, 1, mR1); P2_1.SetCol(4, u3);     // [R1  u3]
	P2_2.SetRect(1, 1, mR1); P2_2.SetCol(4,-u3);     // [R1 -u3]
	P2_3.SetRect(1, 1, mR2); P2_3.SetCol(4, u3);     // [R2  u3]
	P2_4.SetRect(1, 1, mR2); P2_4.SetCol(4,-u3);     // [R2 -u3]

	P1.SetRect(1, 1, GenI(3)); P1.SetCol(4, CMatrix(3, 1, 0));   // [I 0]

	// 紧接着利用 P1 和 P2 对所有同名点进行前方交会，得到所有点在两个像机系中的坐标
	CMatrix mProjs(3, 8), mImgPts(2, 2);
	CMatrix mWrdPts_reconstruct_1_1(4, n), mWrdPts_reconstruct_2_1(4, n), mWrdPts_reconstruct_3_1(4, n), mWrdPts_reconstruct_4_1(4, n);
	mProjs.SetRect(1, 1, P1);

	for (i = 1; i <= n; i++)
	{
		mImgPts(1, 1) = mImgPts1(1, i);	mImgPts(2, 1) = mImgPts1(2, i);
		mImgPts(1, 2) = mImgPts2(1, i);	mImgPts(2, 2) = mImgPts2(2, i);

		mProjs.SetRect(1, 5, P2_1);
		mWrdPts_reconstruct_1_1.SetCol(i, Intersect(mImgPts, mProjs));

		mProjs.SetRect(1, 5, P2_2);
		mWrdPts_reconstruct_2_1.SetCol(i, Intersect(mImgPts, mProjs));

		mProjs.SetRect(1, 5, P2_3);
		mWrdPts_reconstruct_3_1.SetCol(i, Intersect(mImgPts, mProjs));

		mProjs.SetRect(1, 5, P2_4);
		mWrdPts_reconstruct_4_1.SetCol(i, Intersect(mImgPts, mProjs));
	}

	CMatrix mRT2_1 = P2_1.Clone(); mRT2_1.AddOneRow(0); mRT2_1(4, 4) = 1;
	CMatrix mRT2_2 = P2_2.Clone(); mRT2_2.AddOneRow(0); mRT2_2(4, 4) = 1;
	CMatrix mRT2_3 = P2_3.Clone(); mRT2_3.AddOneRow(0); mRT2_3(4, 4) = 1;
	CMatrix mRT2_4 = P2_4.Clone(); mRT2_4.AddOneRow(0); mRT2_4(4, 4) = 1;

	CMatrix mWrdPts_reconstruct_1_2 = mRT2_1 * mWrdPts_reconstruct_1_1;
	CMatrix mWrdPts_reconstruct_2_2 = mRT2_2 * mWrdPts_reconstruct_2_1;
	CMatrix mWrdPts_reconstruct_3_2 = mRT2_3 * mWrdPts_reconstruct_3_1;
	CMatrix mWrdPts_reconstruct_4_2 = mRT2_4 * mWrdPts_reconstruct_4_1;

	// 接着看 4 种交会点集中，统计 1 号像机坐标系 Z 坐标以及 2 号像机坐标系 Z 坐标同时大于零的点个数
	int iii = 1;
	int nnn1 = 0;
	for (i = 1; i <= n; i++)
	{
		if (mWrdPts_reconstruct_1_1(3, i) > 0 && mWrdPts_reconstruct_1_2(3, i) > 0)
		{
			nnn1++;
		}
	}
	int nnn = nnn1;

	int nnn2 = 0;
	for (i = 1; i <= n; i++)
	{
		if (mWrdPts_reconstruct_2_1(3, i) > 0 && mWrdPts_reconstruct_2_2(3, i) > 0)
		{
			nnn2++;
		}
	}

	if (nnn2 > nnn)
	{
		iii = 2;
		nnn = nnn2;
	}

	int nnn3 = 0;
	for (i = 1; i <= n; i++)
	{
		if (mWrdPts_reconstruct_3_1(3, i) > 0 && mWrdPts_reconstruct_3_2(3, i) > 0)
		{
			nnn3++;
		}
	}

	if (nnn3 > nnn)
	{
		iii = 3;
		nnn = nnn3;
	}

	int nnn4 = 0;
	for (i = 1; i <= n; i++)
	{
		if (mWrdPts_reconstruct_4_1(3, i) > 0 && mWrdPts_reconstruct_4_2(3, i) > 0)
		{
			nnn4++;
		}
	}

	if (nnn4 > nnn)
	{
		iii = 4;
		nnn = nnn4;
	}

	
	if (iii == 1)
	{
		mP = P2_1.Clone();
		mWrdPts = mWrdPts_reconstruct_1_1.Clone();
	}
	if (iii == 2)
	{
		mP = P2_2.Clone();
		mWrdPts = mWrdPts_reconstruct_2_1.Clone();
	}
	if (iii == 3)
	{
		mP = P2_3.Clone();
		mWrdPts = mWrdPts_reconstruct_3_1.Clone();
	}
	if (iii == 4)
	{
		mP = P2_4.Clone();
		mWrdPts = mWrdPts_reconstruct_4_1.Clone();
	}
}

// Remove D.C.Brown image distortion 
void DeepVoid::RemoveDistortion_DCBrown(double Cx, double Cy,                            // input：pricipal point
										double Fx, double Fy,                            // input：equvalent focal length
										const double * k,                                // input: D.C.Brown's distortion
										double distorted_Ix, double distorted_Iy,		 // input：distorted coordinates
										double &ideal_Ix, double &ideal_Iy,				 // output:coordinates with distortion removed
										int maxIteration /*= 32*/,                       // input：maximal iterations
										double eps /*= 1e-10*/                           // input：conditions to quit iteration
										)     
{
	double idealTmp_Ix, idealTmp_Iy, oldIdealTmp_Ix, oldIdealTmp_Iy,
		tmp_Ix, tmp_Iy, residue_Ix, residue_Iy;

	idealTmp_Ix = distorted_Ix;
	idealTmp_Iy = distorted_Iy;

	oldIdealTmp_Ix = idealTmp_Ix;
	oldIdealTmp_Iy = idealTmp_Iy;

	for (int i = 0; i < maxIteration; i++)
	{
		CalcuDistedImgPt_DCBrown(Cx, Cy, Fx, Fy, k, idealTmp_Ix, idealTmp_Iy, tmp_Ix, tmp_Iy);
		idealTmp_Ix = distorted_Ix - (tmp_Ix - idealTmp_Ix);
		idealTmp_Iy = distorted_Iy - (tmp_Iy - idealTmp_Iy);

		residue_Ix = idealTmp_Ix - oldIdealTmp_Ix;
		residue_Iy = idealTmp_Iy - oldIdealTmp_Iy;

		oldIdealTmp_Ix = idealTmp_Ix;
		oldIdealTmp_Iy = idealTmp_Iy;

		if ((fabs(residue_Ix) < eps) && (fabs(residue_Iy) < eps))
		{
			break;
		}
	}

	ideal_Ix = idealTmp_Ix;
	ideal_Iy = idealTmp_Iy;
}

// remove D.C.Brown distortions of all feature points
void DeepVoid::RemoveDistortion_DCBrown(cam_data & cam)
{
	int i;
	for (i=0;i<cam.m_feats.key_points.size();i++)
	{
		double d_x, d_y, i_x, i_y;
		d_x = cam.m_feats.key_points[i].pt.x; d_y = cam.m_feats.key_points[i].pt.y;
		RemoveDistortion_DCBrown(cam.cx, cam.cy, cam.fx, cam.fy, cam.k, d_x, d_y, i_x, i_y);
		cam.m_feats.key_points[i].pt.x = i_x; cam.m_feats.key_points[i].pt.y = i_y;
	}
}

// calculate the distorted image coordinates of corresponding ideal ones
void DeepVoid::CalcuDistedImgPt_DCBrown(double Cx, double Cy,                       // input：pricipal point
										double Fx, double Fy,                       // input：equvalent focal length
										const double * k,                           // input：D.C.Brown's distortion
																					// k1：2nd order radial distortion r^2
																					// k2：4th order radial distortion r^4
																					// k3：tangential distortion
																					// k4：tangential distortion
																					// k5：6th order radial distortion r^6
										double ideal_Ix, double ideal_Iy,			// input：ideal image coordinates
										double &distorted_Ix, double &distorted_Iy	// output：distorted image coordinates
										)
{
	// normalized image coordinates
	double xn, yn;
	xn = (ideal_Ix - Cx) / Fx;
	yn = (ideal_Iy - Cy) / Fy;

	// r^2，r^4 and r^6
	double radiusSquare, radiusQuad, radiusHex;
	radiusSquare = xn * xn + yn * yn;
	radiusQuad = radiusSquare * radiusSquare;
	radiusHex = radiusQuad * radiusSquare;

	// 
	double xd, yd;
	xd = (1 + k[0] * radiusSquare + k[1] * radiusQuad + k[4] * radiusHex) * xn
		+ 2 * k[2] * xn * yn + k[3] * (radiusSquare + 2 * xn * xn);

	yd = (1 + k[0] * radiusSquare + k[1] * radiusQuad + k[4] * radiusHex) * yn
		+ k[2] * (radiusSquare + 2 * yn * yn) + 2 * k[3] * xn * yn;

	distorted_Ix = Fx * xd + Cx;
	distorted_Iy = Fy * yd + Cy;
}

// 采用 D.C.Brown 的 5 系数像差模型，和 weng 的 5 系数像差模型有所不同，输出为 3×n 的齐次像点坐标
CMatrix DeepVoid::CalcuDistedImgPt_DCBrown(const CMatrix & mImgPtIdeal,               // 输入：理想的像点坐标，可以为 3×n 的齐次像点坐标，也可以为 2×n 的非齐次像点坐标 
										   const CMatrix & mK,                        // 输入：像机内参数矩阵，可以为 3×4 的矩阵，也可为 3×3 的矩阵
										   const CMatrix & mDist                      // 输入：D.C.Brown 像差系数，5 维的向量
										   )
{
	int ptNum = mImgPtIdeal.m_nCol;

	CMatrix mImgPtDisted(3, ptNum, 1);

	double fx = mK(1, 1);
	double fy = mK(2, 2);
	double cx = mK(1, 3);
	double cy = mK(2, 3);

	double k[5];
	k[0] = mDist(1);
	k[1] = mDist(2);
	k[2] = mDist(3);
	k[3] = mDist(4);
	k[4] = mDist(5);

	int i;
	for (i = 1; i <= ptNum; i++)
	{
		CalcuDistedImgPt_DCBrown(cx, cy, fx, fy, k, mImgPtIdeal(1, i), mImgPtIdeal(2, i), mImgPtDisted(1, i), mImgPtDisted(2, i));
	}

	return mImgPtDisted;
}

CMatrix DeepVoid::CalcuDistortion_Weng(const CMatrix & mImgPtIdeal, const CMatrix & mK, const CMatrix & mDist, double k6/* = 0*/)
{
	int ptNum = mImgPtIdeal.m_nCol;
	CMatrix mDeviation(3, ptNum);

	// 2011.11.13屏蔽
	/*CMatrix mImgNormed = Convt2NormImgPt(mImgPtIdeal, mK);*/
	CMatrix mImgNormed = mK.GetRect(1, 1, 3, 3).Inverse() * mImgPtIdeal;

	double k1 = mDist(1);
	double k2 = mDist(2);
	double k3 = mDist(3);
	double k4 = mDist(4);
	double k5 = mDist(5);

	double fx = mK(1, 1);
	double fy = mK(2, 2);
	double xd, yd, xd2, yd2, xdyd, xd2yd2;
	int i;
	for (i = 1; i < ptNum + 1; i++)
	{
		xd     = mImgNormed(1, i);
		yd     = mImgNormed(2, i);
		xd2    = xd * xd;
		yd2    = yd * yd;
		xdyd   = xd * yd;
		xd2yd2 = xd2 + yd2;

		mDeviation(1, i) = ((k1 * xd + k2) * xd2yd2 + k4 * xd2 + k5 * xdyd + k6 * (xd2 + yd2) * (xd2 + yd2) * xd) * fx;
		mDeviation(2, i) = ((k1 * yd + k3) * xd2yd2 + k4 * xdyd + k5 * yd2 + k6 * (xd2 + yd2) * (xd2 + yd2) * yd) * fy;
	}

	return mDeviation;
}

CMatrix DeepVoid::CalcuDistedImgPt_Weng(const CMatrix & mImgPtIdeal, const CMatrix & mK, const CMatrix & mDist)
{
	CMatrix mDeviation = CalcuDistortion_Weng(mImgPtIdeal, mK, mDist);
	CMatrix mImgPtDisted = mImgPtIdeal + mDeviation;
	return mImgPtDisted;
}

bool DeepVoid::ExteriorOrientation_PnP_RANSAC(vector<cam_data> & vCams,		// input&output:	all the images
											  int idx_cam1,					// input:	the index of the first camera
											  int idx_cam2,					// input:	the index of the second camera
											  vector<CloudPoint> & clouds,	// input&output:	the reconstructed cloud points in reference camera frame, which is the first image	 
											  double param1/* = 3*/,		// input:	defining "good" matches (i.e. whose distance is less than param1*min_dist) in feature matching stage
											  double param2/* = 1*/,		// input:	the distance threshold between point and epiline, used in RANSAC stage
											  double param3/* = 0.99*/,		// input:	specifying a desirable level of confidence (probability) that the estimated matrix is correct
											  double param4/* = 1*/,		// input:	the allowed level of reprojection error, used for RANSAC to determine outlier
											  double param5 /*= 0.75*/		// input:	the allowed minimum ratio of inliers within all reconstructed matches
											  )
{
	cam_data cam1 = vCams[idx_cam1];
	cam_data cam2 = vCams[idx_cam2];

// 	CString strInfo;
// 	strInfo.Format("EO between %03d and %03d starts, number of images is %d", idx_cam1, idx_cam2, vCams.size());
// 	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

	if (cam1.R[0]<-90)
	{
		// this means that cam1 hasn't been exterior oriented yet which also means that its features are still not
		// connected to any object points
		return false;
	}

	int i,j,k;

	int n_allCldPts = clouds.size();

	int nFeat1 = cam1.m_feats.key_points.size();
	int nFeat2 = cam2.m_feats.key_points.size();

	Matx33d mK1, mK2;
	mK1(0,0) = cam1.fx;	mK2(0,0) = cam2.fx;
	mK1(1,1) = cam1.fy;	mK2(1,1) = cam2.fy;
	mK1(0,1) = cam1.s;	mK2(0,1) = cam2.s;
	mK1(0,2) = cam1.cx;	mK2(0,2) = cam2.cx;
	mK1(1,2) = cam1.cy;	mK2(1,2) = cam2.cy;
	mK1(2,2) = 1;		mK2(2,2) = 1;

	Matx34d mRT1_34;
	Matx33d mR1;
	Matx31d mt1;
	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mRT1_34(i,j)=cam1.R[i*3+j];
			mR1(i,j)=cam1.R[i*3+j];
		}
	}
	mRT1_34(0,3) = mt1(0) = cam1.t[0];
	mRT1_34(1,3) = mt1(1) = cam1.t[1];
	mRT1_34(2,3) = mt1(2) = cam1.t[2];

	Matx34d mProj1 = mK1*mRT1_34;

	// it's preferable to first rectify the features' image coordinates if the distortion coefficients are not 0
	// this is not critical, but can improve the accuracy of Essential matrix a little bit
	// and it is preferable if the features are extracted from a whole rectified distortion free image too, because
	// the descriptors are generated from distortion free image
	Features feat1_rectified = cam1.m_feats;
	Features feat2_rectified = cam2.m_feats;

	for (i=0;i<nFeat1;i++)
	{
		double d_x, d_y, i_x, i_y;
		d_x = feat1_rectified.key_points[i].pt.x; d_y = feat1_rectified.key_points[i].pt.y;
		RemoveDistortion_DCBrown(cam1.cx, cam1.cy, cam1.fx, cam1.fy, cam1.k, d_x, d_y, i_x, i_y);
		feat1_rectified.key_points[i].pt.x = i_x; feat1_rectified.key_points[i].pt.y = i_y;
	}
	for (i=0;i<nFeat2;i++)
	{
		double d_x, d_y, i_x, i_y;
		d_x = feat2_rectified.key_points[i].pt.x; d_y = feat2_rectified.key_points[i].pt.y;
		RemoveDistortion_DCBrown(cam2.cx, cam2.cy, cam2.fx, cam2.fy, cam2.k, d_x, d_y, i_x, i_y);
		feat2_rectified.key_points[i].pt.x = i_x; feat2_rectified.key_points[i].pt.y = i_y;
	}

	// matching using rectified features and RANSAC
	vector<DMatch> matches;

	CalibFundamentalMat_RANSAC_Features(feat1_rectified, feat2_rectified, matches, param1, param2, param3);

	int n_match = matches.size();

	if (n_match < 6)
	{
		return false;
	}

	// check how many matches have already been reconstructed
	vector<Point3f> objectPoints;
	vector<Point2f> imagePoints;

	vector<Point2f> vImgPts1; // all the non-reconstructed matched image points in image 1
	vector<Point2f> vImgPts2; // all the non-reconstructed matched image points in image 2

	vector<Point2i> vIdx; // the idx of image points in image 2 that has already been reconstructed

	vector<int> vIdxMatch_nonExist;

	for (i=0;i<n_match;i++)
	{
		int idx_imgPt = matches[i].queryIdx;

		bool bExist = false;

		for (j=0;j<n_allCldPts;j++)
		{
			CloudPoint cldpt = clouds[j]; 
			for (k=0;k<cldpt.m_vImgInfos.size();k++)
			{
				if (cldpt.m_vImgInfos[k].m_idxImg==idx_cam1)
				{
					if (cldpt.m_vImgInfos[k].m_idxImgPt==idx_imgPt)
					{
						Point2i idx;
						idx.x = j; // the corresponding object index
						idx.y = matches[i].trainIdx; // the corresponding image index in image 2
						vIdx.push_back(idx);

						Point3f pt3;
						pt3.x = cldpt.m_pt.x;
						pt3.y = cldpt.m_pt.y;
						pt3.z = cldpt.m_pt.z;
						objectPoints.push_back(pt3);

						Point2f pt2;
						pt2.x = feat2_rectified.key_points[matches[i].trainIdx].pt.x;
						pt2.y = feat2_rectified.key_points[matches[i].trainIdx].pt.y;
						imagePoints.push_back(pt2);

						bExist = true;

						break;
					}
				}
			}

			if (bExist)
			{
				break;
			}
		}

		if (!bExist)
		{
			vIdxMatch_nonExist.push_back(i);

			Point2f imgpt;
			imgpt.x = feat1_rectified.key_points[matches[i].queryIdx].pt.x;
			imgpt.y = feat1_rectified.key_points[matches[i].queryIdx].pt.y;
			vImgPts1.push_back(imgpt);

			imgpt.x = feat2_rectified.key_points[matches[i].trainIdx].pt.x;
			imgpt.y = feat2_rectified.key_points[matches[i].trainIdx].pt.y;
			vImgPts2.push_back(imgpt);
		}
	}

	int n_exist = objectPoints.size(); // the number of matched points already been reconstructed
	int n_nonExist = vIdxMatch_nonExist.size(); // the number of matched points haven't been reconstructed yet

	if (n_exist < 6)
	{
		return false;
	}

	Mat distCoeffs;
	Matx31d rvec, mt2;
	vector<int> vInliers;

	try
	{
		solvePnPRansac(objectPoints, imagePoints, mK2, distCoeffs, rvec, mt2, false, 256, param4, n_exist, vInliers, CV_ITERATIVE);
	}
	catch (cv::Exception & e)
	{
		CString str;
		str = e.msg.c_str();
		AfxMessageBox(str);
	}

	int n_inliers = vInliers.size();

	double ratio_inliers = n_inliers/(double)n_exist;

	// if the ratio of inliers is not big enough then this eo is considered failure
	if (ratio_inliers < param5 || n_inliers < 6)
	{
		return false;
	}

	for (i=0;i<n_inliers;i++)
	{
		int idx_obj = vIdx[vInliers[i]].x;
		int idx_img = vIdx[vInliers[i]].y;

		CloudPoint_ImgInfo imgInfo;
		imgInfo.m_idxImg = idx_cam2;
		imgInfo.m_idxImgPt = idx_img;
		
		clouds[idx_obj].m_vImgInfos.push_back(imgInfo);
	}

	Matx33d mR2;

	try
	{
		Rodrigues(rvec, mR2);
	}
	catch (cv::Exception & e)
	{
		CString str;
		str = e.msg.c_str();
		AfxMessageBox(str);
	}
	
	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			vCams[idx_cam2].R[i*3+j] = mR2(i,j);
		}
	}
	vCams[idx_cam2].t[0] = mt2(0);
	vCams[idx_cam2].t[1] = mt2(1);
	vCams[idx_cam2].t[2] = mt2(2);

	Matx34d mProj2;
	Matx33d mKR = mK2 * mR2;
	Matx31d mKt = mK2 * mt2;
	Matx41d mObj;
	mObj(3) = 1;
	Matx31d mImg;

	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mProj2(i,j)=mKR(i,j);
		}
	}
	mProj2(0,3)=mKt(0);
	mProj2(1,3)=mKt(1);
	mProj2(2,3)=mKt(2);

	Mat mWrdPts;

	try
	{
		triangulatePoints(mProj1, mProj2, vImgPts1, vImgPts2, mWrdPts);
	}
	catch (cv::Exception & e)
	{
		CString str;
		str = e.msg.c_str();
		AfxMessageBox(str);
	}

	for (i=0;i<n_nonExist;i++)
	{
		CloudPoint cldpt;

		try
		{
			cldpt.m_pt.x = mWrdPts.at<float>(0,i)/mWrdPts.at<float>(3,i);
			cldpt.m_pt.y = mWrdPts.at<float>(1,i)/mWrdPts.at<float>(3,i);
			cldpt.m_pt.z = mWrdPts.at<float>(2,i)/mWrdPts.at<float>(3,i);
		}
		catch (cv::Exception & e)
		{
			CString str;
			str = e.msg.c_str();
			AfxMessageBox(str);
		}

		// check if the point is behind any of these two images
		Matx31d objPtw;
		objPtw(0) = cldpt.m_pt.x; objPtw(1) = cldpt.m_pt.y; objPtw(2) = cldpt.m_pt.z;

		Matx31d objPt1 = mR1 * objPtw + mt1;
		Matx31d objPt2 = mR2 * objPtw + mt2;

		if (objPt1(2) <= 0 || objPt2(2) <= 0)
		{
			continue;
		}

		CloudPoint_ImgInfo cldpt_imginfo;
		cldpt_imginfo.m_idxImg = idx_cam1;
		cldpt_imginfo.m_idxImgPt = matches[vIdxMatch_nonExist[i]].queryIdx;
		cldpt.m_vImgInfos.push_back(cldpt_imginfo);

		cldpt_imginfo.m_idxImg = idx_cam2;
		cldpt_imginfo.m_idxImgPt = matches[vIdxMatch_nonExist[i]].trainIdx;
		cldpt.m_vImgInfos.push_back(cldpt_imginfo);

		clouds.push_back(cldpt);
	}

	return true;
}

bool DeepVoid::ExteriorOrientation_PnP_RANSAC_Round(vector<cam_data> & vCams,	// input&output:	all the images
													vector<int> & status,		// input&output:	if status[i] = 0, means that vCams[i] is still not oriented yet
													int idx_cam,				// input:	the index of current image
													vector<CloudPoint> & clouds,// input&output:	the reconstructed cloud points in reference camera frame, which is the first image	 
													double param1 /*= 3*/,		// input:	defining "good" matches (i.e. whose distance is less than param1*min_dist) in feature matching stage
													double param2 /*= 1*/,		// input:	the distance threshold between point and epiline, used in RANSAC stage
													double param3 /*= 0.99*/,	// input:	specifying a desirable level of confidence (probability) that the estimated matrix is correct
													double param4 /*= 1*/,		// input:	the allowed level of reprojection error, used for RANSAC to determine outlier
													double param5 /*= 0.75*/	// input:	the allowed minimum ratio of inliers within all reconstructed matches
													)
{
	int i,j;

	int n_img = vCams.size();

	for (i=0;i<n_img;i++)
	{
		if (!status[i] || i == idx_cam)
		{
			continue;
		}

		if (ExteriorOrientation_PnP_RANSAC(vCams, i, idx_cam, clouds, param1, param2, param3, param4, param5))
		{
			status[idx_cam] = 1;
			return true;
		}
	}

	return false;
}

void DeepVoid::ExteriorOrientation_PnP_RANSAC_All(vector<cam_data> & vCams,		// input&output:	all the images
												  vector<int> & status,			// input&output:	if status[i] = 0, means that vCams[i] is still not oriented yet
												  vector<CloudPoint> & clouds,	// input&output:	the reconstructed cloud points in reference camera frame, which is the first image	 
												  double param1 /*= 3*/,		// input:	defining "good" matches (i.e. whose distance is less than param1*min_dist) in feature matching stage
												  double param2 /*= 1*/,		// input:	the distance threshold between point and epiline, used in RANSAC stage
												  double param3 /*= 0.99*/,		// input:	specifying a desirable level of confidence (probability) that the estimated matrix is correct
												  double param4 /*= 1*/,		// input:	the allowed level of reprojection error, used for RANSAC to determine outlier
												  double param5 /*= 0.75*/		// input:	the allowed minimum ratio of inliers within all reconstructed matches
												  )
{
	int i,j;

	int n_img = vCams.size();

	deque<int> qValid;

	for (i=0;i<n_img;i++)
	{
		if (status[i])
		{
			qValid.push_back(i);
		}
	}

	while (qValid.size()>0)
	{
		int idx_ref = qValid.back();
		qValid.pop_back();

		for (i=0;i<n_img;i++)
		{
			if (status[i])
			{
				continue;
			}

			if (ExteriorOrientation_PnP_RANSAC(vCams, idx_ref, i, clouds, param1, param2, param3, param4, param5))
			{
				CString strInfo;
				strInfo.Format("Exterior orientation of image %03d matched with image %03d finished, number of cloud points are %d", i, idx_ref, clouds.size());
				theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

				theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(_T("SBA starts"));
				double info[10];
				int nnn = optim_sba_levmar_XYZ_ext_rotvec(clouds, vCams, 10, NULL, info);
				double rrr = sqrt(info[1]/nnn);
				strInfo.Format("SBA ends, err: %lf, iter: %04.0f, code: %01.0f", rrr, info[5], info[6]);
				theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

				status[i] = 1;
				qValid.push_back(i);
			} 
		}
	}
}

void DeepVoid::der_f_PIRO_omg_fai(double nx1, double ny1,								// input: normalized image coordinates in reference image
								  double nx2, double ny2,								// input: normalized image coordinates in the other image
								  double omg, double fai,								// input: radians, current two angles representing the direction of the unit baseline vector
								  double AX,  double AY, double AZ,						// input: radians, current relative rotation angles between reference image and the other image
								  double & df_domg, double & df_dfai,					// output:current derivatives of omg and fai
								  double & df_dAX, double & df_dAY, double & df_dAZ,	// output:current derivatives of AX, AY and AZ
								  double & f											// output:current value of objective function
								  )
{
	double sinomg = sin(omg); double cosomg = cos(omg);
	double sinfai = sin(fai); double cosfai = cos(fai);
	double sinAX = sin(AX);	  double cosAX = cos(AX);
	double sinAY = sin(AY);   double cosAY = cos(AY);
	double sinAZ = sin(AZ);   double cosAZ = cos(AZ);

	double sinomgsinfai = sinomg*sinfai;
	double cosomgcosfai = cosomg*cosfai;
	double sinomgcosfai = sinomg*cosfai;
	double cosomgsinfai = cosomg*sinfai;

	double sinAXsinAY = sinAX*sinAY;
	double sinAXcosAY = sinAX*cosAY;
	double sinAXsinAZ = sinAX*sinAZ;
	double sinAXcosAZ = sinAX*cosAZ;
	double cosAXsinAY = cosAX*sinAY;
	double cosAXcosAY = cosAX*cosAY;
	double cosAXsinAZ = cosAX*sinAZ;
	double cosAXcosAZ = cosAX*cosAZ;

	double sinAXsinAYsinAZ = sinAXsinAY*sinAZ;
	double sinAXsinAYcosAZ = sinAXsinAY*cosAZ;
	double cosAXsinAYsinAZ = cosAXsinAY*sinAZ;
	double cosAXsinAYcosAZ = cosAXsinAY*cosAZ;

	CMatrix mR = GenR_Euler_Radian(AX, AY, AZ, ZYX);
	mR = mR.GetRect(1,1,3,3);

	CMatrix mcol1 = mR.GetCol(1);
	CMatrix mcol2 = mR.GetCol(2);
	CMatrix mcol3 = mR.GetCol(3);

	CMatrix mImgPt2(3, 1, 1);
	mImgPt2(1) = nx2;
	mImgPt2(2) = ny2;

	CMatrix mTmp = mcol1.Transpose()*mImgPt2;
	double r1 = mTmp(1);
	mTmp = mcol2.Transpose()*mImgPt2;
	double r2 = mTmp(1);
	mTmp = mcol3.Transpose()*mImgPt2;
	double r3 = mTmp(1);

	CMatrix mdcol1_dAX(1, 3, 0), mdcol2_dAX(1, 3, 0), mdcol3_dAX(1, 3, 0), mdcol3_dAY(1, 3, 0);

	mdcol1_dAX(1) = 0;
	mdcol1_dAX(2) = -sinAXsinAZ+cosAXsinAYcosAZ;
	mdcol1_dAX(3) =  cosAXsinAZ+sinAXsinAYcosAZ;

	mdcol2_dAX(1) = 0;
	mdcol2_dAX(2) = -sinAXcosAZ-cosAXsinAYsinAZ;
	mdcol2_dAX(3) =  cosAXcosAZ-sinAXsinAYsinAZ;

	mdcol3_dAX(1) = 0;
	mdcol3_dAX(2) = -cosAXcosAY;
	mdcol3_dAX(3) = -sinAXcosAY;

	mdcol3_dAY(1) =  cosAY;
	mdcol3_dAY(2) =  sinAXsinAY;
	mdcol3_dAY(3) = -cosAXsinAY;

	CMatrix mdf_domg(3, 3), mdf_dfai(3, 3);
	CMatrix mdf_dAX(3, 3),  mdf_dAY(3, 3), mdf_dAZ(3, 3);
	CMatrix mF(3, 3);

	// compute df_domg
	mdf_domg(1,1)=-sinomgcosfai;	mdf_domg(1,2)=nx1;	mdf_domg(1,3)=r1;
	mdf_domg(2,1)= 0;				mdf_domg(2,2)=ny1;	mdf_domg(2,3)=r2;
	mdf_domg(3,1)= cosomgcosfai;	mdf_domg(3,2)=1;	mdf_domg(3,3)=r3;
	df_domg = mdf_domg.Det();

	// compute df_dfai
	mdf_dfai(1,1)=-cosomgsinfai;	mdf_dfai(1,2)=nx1;	mdf_dfai(1,3)=r1;
	mdf_dfai(2,1)= cosfai;			mdf_dfai(2,2)=ny1;	mdf_dfai(2,3)=r2;
	mdf_dfai(3,1)=-sinomgsinfai;	mdf_dfai(3,2)=1;	mdf_dfai(3,3)=r3;
	df_dfai = mdf_dfai.Det();

	// compute df_dAX
	mdf_dAX(1,1)=cosomgcosfai;		mdf_dAX(1,2)=nx1;	mTmp=mdcol1_dAX*mImgPt2; mdf_dAX(1,3)=mTmp(1);
	mdf_dAX(2,1)=sinfai;			mdf_dAX(2,2)=ny1;	mTmp=mdcol2_dAX*mImgPt2; mdf_dAX(2,3)=mTmp(1);
	mdf_dAX(3,1)=sinomgcosfai;		mdf_dAX(3,2)=1;		mTmp=mdcol3_dAX*mImgPt2; mdf_dAX(3,3)=mTmp(1);
	df_dAX = mdf_dAX.Det();

	// compute df_dAY
	mdf_dAY(1,1)=cosomgcosfai;		mdf_dAY(1,2)=nx1;	mdf_dAY(1,3)=-cosAZ*r3;
	mdf_dAY(2,1)=sinfai;			mdf_dAY(2,2)=ny1;	mdf_dAY(2,3)= sinAZ*r3;
	mdf_dAY(3,1)=sinomgcosfai;		mdf_dAY(3,2)=1;		mTmp=mdcol3_dAY*mImgPt2; mdf_dAY(3,3)= mTmp(1);
	df_dAY = mdf_dAY.Det();

	// compute df_dAZ
	mdf_dAZ(1,1)=cosomgcosfai;		mdf_dAZ(1,2)=nx1;	mdf_dAZ(1,3)= r2;
	mdf_dAZ(2,1)=sinfai;			mdf_dAZ(2,2)=ny1;	mdf_dAZ(2,3)=-r1;
	mdf_dAZ(3,1)=sinomgcosfai;		mdf_dAZ(3,2)=1;		mdf_dAZ(3,3)= 0;
	df_dAZ = mdf_dAZ.Det();

	// compute f
	mF(1,1)=cosomgcosfai;	mF(1,2)=nx1;	mF(1,3)= r1;
	mF(2,1)=sinfai;			mF(2,2)=ny1;	mF(2,3)= r2;
	mF(3,1)=sinomgcosfai;	mF(3,2)=1;		mF(3,3)= r3;
	f = mF.Det();
}

void DeepVoid::der_f_PIRO_Y_Z(double nx1, double ny1,								// input: normalized image coordinates in reference image
							  double nx2, double ny2,								// input: normalized image coordinates in the other image
							  double Y, double Z,									// input: current Y and Z coordinates of the other image's optical center
							  double AX,  double AY, double AZ,						// input: radians, current relative rotation angles between reference image and the other image
							  double & df_dY, double & df_dZ,						// output:current derivatives of Y and Z
							  double & df_dAX, double & df_dAY, double & df_dAZ,	// output:current derivatives of AX, AY and AZ
							  double & f,											// output:current value of objective function
							  double & df_dnx1, double & df_dny1,					// output:current derivatives of nx1 and ny1
							  double & df_dnx2, double & df_dny2,					// output:current derivatives of nx2 and ny2
							  double bx /*= 1*/										// input: default fixed value for X coordinate of the other image's optical center in reference
							  )
{
	double sinAX = sin(AX);	  double cosAX = cos(AX);
	double sinAY = sin(AY);   double cosAY = cos(AY);
	double sinAZ = sin(AZ);   double cosAZ = cos(AZ);

	double sinAXsinAY = sinAX*sinAY;
	double sinAXcosAY = sinAX*cosAY;
	double sinAXsinAZ = sinAX*sinAZ;
	double sinAXcosAZ = sinAX*cosAZ;
	double cosAXsinAY = cosAX*sinAY;
	double cosAXcosAY = cosAX*cosAY;
	double cosAXsinAZ = cosAX*sinAZ;
	double cosAXcosAZ = cosAX*cosAZ;

	double sinAXsinAYsinAZ = sinAXsinAY*sinAZ;
	double sinAXsinAYcosAZ = sinAXsinAY*cosAZ;
	double cosAXsinAYsinAZ = cosAXsinAY*sinAZ;
	double cosAXsinAYcosAZ = cosAXsinAY*cosAZ;

	CMatrix mR = GenR_Euler_Radian(AX, AY, AZ, ZYX);
	mR = mR.GetRect(1,1,3,3);

	CMatrix mcol1 = mR.GetCol(1);
	CMatrix mcol2 = mR.GetCol(2);
	CMatrix mcol3 = mR.GetCol(3);

	CMatrix mImgPt2(3, 1, 1);
	mImgPt2(1) = nx2;
	mImgPt2(2) = ny2;

	CMatrix mTmp = mcol1.Transpose()*mImgPt2;
	double r1 = mTmp(1);
	mTmp = mcol2.Transpose()*mImgPt2;
	double r2 = mTmp(1);
	mTmp = mcol3.Transpose()*mImgPt2;
	double r3 = mTmp(1);

	CMatrix mdcol1_dAX(1, 3, 0), mdcol2_dAX(1, 3, 0), mdcol3_dAX(1, 3, 0), mdcol3_dAY(1, 3, 0);

	mdcol1_dAX(1) = 0;
	mdcol1_dAX(2) = -sinAXsinAZ+cosAXsinAYcosAZ;
	mdcol1_dAX(3) =  cosAXsinAZ+sinAXsinAYcosAZ;

	mdcol2_dAX(1) = 0;
	mdcol2_dAX(2) = -sinAXcosAZ-cosAXsinAYsinAZ;
	mdcol2_dAX(3) =  cosAXcosAZ-sinAXsinAYsinAZ;

	mdcol3_dAX(1) = 0;
	mdcol3_dAX(2) = -cosAXcosAY;
	mdcol3_dAX(3) = -sinAXcosAY;

	mdcol3_dAY(1) =  cosAY;
	mdcol3_dAY(2) =  sinAXsinAY;
	mdcol3_dAY(3) = -cosAXsinAY;

	CMatrix mdf_dY(3, 3), mdf_dZ(3, 3);
	CMatrix mdf_dAX(3, 3),  mdf_dAY(3, 3), mdf_dAZ(3, 3);
	CMatrix mF(3, 3);
	CMatrix mdf_dnx1(3, 3), mdf_dny1(3, 3);
	CMatrix mdf_dnx2(3, 3), mdf_dny2(3, 3);

	// compute df_dY
	mdf_dY(1,1)= 0;	mdf_dY(1,2)=nx1;	mdf_dY(1,3)=r1;
	mdf_dY(2,1)= 1;	mdf_dY(2,2)=ny1;	mdf_dY(2,3)=r2;
	mdf_dY(3,1)= 0;	mdf_dY(3,2)=1;		mdf_dY(3,3)=r3;
	df_dY = mdf_dY.Det();

	// compute df_dZ
	mdf_dZ(1,1)= 0;	mdf_dZ(1,2)=nx1;	mdf_dZ(1,3)=r1;
	mdf_dZ(2,1)= 0;	mdf_dZ(2,2)=ny1;	mdf_dZ(2,3)=r2;
	mdf_dZ(3,1)= 1;	mdf_dZ(3,2)=1;		mdf_dZ(3,3)=r3;
	df_dZ = mdf_dZ.Det();

	// compute df_dAX
	mdf_dAX(1,1)= bx;	mdf_dAX(1,2)=nx1;	mTmp=mdcol1_dAX*mImgPt2; mdf_dAX(1,3)=mTmp(1);
	mdf_dAX(2,1)= Y;	mdf_dAX(2,2)=ny1;	mTmp=mdcol2_dAX*mImgPt2; mdf_dAX(2,3)=mTmp(1);
	mdf_dAX(3,1)= Z;	mdf_dAX(3,2)=1;		mTmp=mdcol3_dAX*mImgPt2; mdf_dAX(3,3)=mTmp(1);
	df_dAX = mdf_dAX.Det();

	// compute df_dAY
	mdf_dAY(1,1)= bx;	mdf_dAY(1,2)=nx1;	mdf_dAY(1,3)=-cosAZ*r3;
	mdf_dAY(2,1)= Y;	mdf_dAY(2,2)=ny1;	mdf_dAY(2,3)= sinAZ*r3;
	mdf_dAY(3,1)= Z;	mdf_dAY(3,2)=1;		mTmp=mdcol3_dAY*mImgPt2; mdf_dAY(3,3)= mTmp(1);
	df_dAY = mdf_dAY.Det();

	// compute df_dAZ
	mdf_dAZ(1,1)= bx;	mdf_dAZ(1,2)=nx1;	mdf_dAZ(1,3)= r2;
	mdf_dAZ(2,1)= Y;	mdf_dAZ(2,2)=ny1;	mdf_dAZ(2,3)=-r1;
	mdf_dAZ(3,1)= Z;	mdf_dAZ(3,2)=1;		mdf_dAZ(3,3)= 0;
	df_dAZ = mdf_dAZ.Det();

	// compute f
	mF(1,1)= bx;	mF(1,2)=nx1;	mF(1,3)= r1;
	mF(2,1)= Y;		mF(2,2)=ny1;	mF(2,3)= r2;
	mF(3,1)= Z;		mF(3,2)=1;		mF(3,3)= r3;
	f = mF.Det();

	// compute df_dnx1
	mdf_dnx1(1,1)= bx;	mdf_dnx1(1,2)= 1;	mdf_dnx1(1,3)= r1;
	mdf_dnx1(2,1)= Y;	mdf_dnx1(2,2)= 0;	mdf_dnx1(2,3)= r2;
	mdf_dnx1(3,1)= Z;	mdf_dnx1(3,2)= 0;	mdf_dnx1(3,3)= r3;
	df_dnx1 = mdf_dnx1.Det();

	// compute df_dny1
	mdf_dny1(1,1)= bx;	mdf_dny1(1,2)= 0;	mdf_dny1(1,3)= r1;
	mdf_dny1(2,1)= Y;	mdf_dny1(2,2)= 1;	mdf_dny1(2,3)= r2;
	mdf_dny1(3,1)= Z;	mdf_dny1(3,2)= 0;	mdf_dny1(3,3)= r3;
	df_dny1 = mdf_dny1.Det();

	// compute df_dnx2
	mdf_dnx2(1,1)= bx;	mdf_dnx2(1,2)=nx1;	mdf_dnx2(1,3)= mR(1,1);
	mdf_dnx2(2,1)= Y;	mdf_dnx2(2,2)=ny1;	mdf_dnx2(2,3)= mR(1,2);
	mdf_dnx2(3,1)= Z;	mdf_dnx2(3,2)=1;	mdf_dnx2(3,3)= mR(1,3);
	df_dnx2 = mdf_dnx2.Det();

	// compute df_dny2
	mdf_dny2(1,1)= bx;	mdf_dny2(1,2)=nx1;	mdf_dny2(1,3)= mR(2,1);
	mdf_dny2(2,1)= Y;	mdf_dny2(2,2)=ny1;	mdf_dny2(2,3)= mR(2,2);
	mdf_dny2(3,1)= Z;	mdf_dny2(3,2)=1;	mdf_dny2(3,3)= mR(2,3);
	df_dny2 = mdf_dny2.Det();
}

// 20150114, zhaokunz, output all derivatives and objective function
void DeepVoid::der_f_PIRO(double nx1, double ny1,							// input: normalized image coordinates in reference image
						  double nx2, double ny2,							// input: normalized image coordinates in the other image
						  double X, double Y, double Z,						// input: current X, Y and Z coordinates of the other image's optical center
						  double AX,  double AY, double AZ,					// input: radians, current relative rotation angles between reference image and the other image
						  double & df_dX, double & df_dY, double & df_dZ,	// output:current derivatives of Y and Z
						  double & df_dAX, double & df_dAY, double & df_dAZ,// output:current derivatives of AX, AY and AZ
						  double & f,										// output:current value of objective function
						  double & df_dnx1, double & df_dny1,				// output:current derivatives of nx1 and ny1
						  double & df_dnx2, double & df_dny2				// output:current derivatives of nx2 and ny2
					 	  )
{
	double sinAX = sin(AX);	  double cosAX = cos(AX);
	double sinAY = sin(AY);   double cosAY = cos(AY);
	double sinAZ = sin(AZ);   double cosAZ = cos(AZ);

	double sinAXsinAY = sinAX*sinAY;
	double sinAXcosAY = sinAX*cosAY;
	double sinAXsinAZ = sinAX*sinAZ;
	double sinAXcosAZ = sinAX*cosAZ;
	double cosAXsinAY = cosAX*sinAY;
	double cosAXcosAY = cosAX*cosAY;
	double cosAXsinAZ = cosAX*sinAZ;
	double cosAXcosAZ = cosAX*cosAZ;

	double sinAXsinAYsinAZ = sinAXsinAY*sinAZ;
	double sinAXsinAYcosAZ = sinAXsinAY*cosAZ;
	double cosAXsinAYsinAZ = cosAXsinAY*sinAZ;
	double cosAXsinAYcosAZ = cosAXsinAY*cosAZ;

	Matx33d mR = GenR_Euler_Radian_CV(AX, AY, AZ, ZYX);
	
	Matx31d c1,c2,c3;
	c1(0)=mR(0,0); c1(1)=mR(1,0); c1(2)=mR(2,0); 
	c2(0)=mR(0,1); c2(1)=mR(1,1); c2(2)=mR(2,1);
	c3(0)=mR(0,2); c3(1)=mR(1,2); c3(2)=mR(2,2); 

	Matx31d mImgPt2;
	mImgPt2(0) = nx2;
	mImgPt2(1) = ny2;
	mImgPt2(2) = 1;

	Matx<double,1,1> mTmp = c1.t()*mImgPt2;
	double r1 = mTmp(0);

	mTmp = c2.t()*mImgPt2;
	double r2 = mTmp(0);

	mTmp = c3.t()*mImgPt2;
	double r3 = mTmp(0);

	Matx13d dc1t_dAX, dc2t_dAX, dc3t_dAX, dc3t_dAY;

	dc1t_dAX(1) = -sinAXsinAZ+cosAXsinAYcosAZ;
	dc1t_dAX(2) =  cosAXsinAZ+sinAXsinAYcosAZ;

	dc2t_dAX(1) = -sinAXcosAZ-cosAXsinAYsinAZ;
	dc2t_dAX(2) =  cosAXcosAZ-sinAXsinAYsinAZ;

	dc3t_dAX(1) = -cosAXcosAY;
	dc3t_dAX(2) = -sinAXcosAY;

	dc3t_dAY(0) = cosAY;
	dc3t_dAY(1) = sinAXsinAY;
	dc3t_dAY(2) = -cosAXsinAY;

	Matx33d mdf_dX, mdf_dY, mdf_dZ;
	Matx33d mdf_dAX, mdf_dAY, mdf_dAZ;
	Matx33d mF;
	Matx33d mdf_dnx1, mdf_dny1;
	Matx33d mdf_dnx2, mdf_dny2;

	// compute df_dX
	mdf_dX(0,0)=1; mdf_dX(0,1)=nx1; mdf_dX(0,2)=r1;
	mdf_dX(1,0)=0; mdf_dX(1,1)=ny1; mdf_dX(1,2)=r2;
	mdf_dX(2,0)=0; mdf_dX(2,1)=1;   mdf_dX(2,2)=r3;
	df_dX = determinant(mdf_dX);

	// compute df_dY
	mdf_dY(0,0)=0; mdf_dY(0,1)=nx1; mdf_dY(0,2)=r1;
	mdf_dY(1,0)=1; mdf_dY(1,1)=ny1; mdf_dY(1,2)=r2;
	mdf_dY(2,0)=0; mdf_dY(2,1)=1;	mdf_dY(2,2)=r3;
	df_dY = determinant(mdf_dY);

	// compute df_dZ
	mdf_dZ(0,0)=0; mdf_dZ(0,1)=nx1; mdf_dZ(0,2)=r1;
	mdf_dZ(1,0)=0; mdf_dZ(1,1)=ny1; mdf_dZ(1,2)=r2;
	mdf_dZ(2,0)=1; mdf_dZ(2,1)=1;	mdf_dZ(2,2)=r3;
	df_dZ = determinant(mdf_dZ);

	// compute df_dAX
	mdf_dAX(0,0)=X; mdf_dAX(0,1)=nx1; mTmp=dc1t_dAX*mImgPt2; mdf_dAX(0,2)=mTmp(0);
	mdf_dAX(1,0)=Y; mdf_dAX(1,1)=ny1; mTmp=dc2t_dAX*mImgPt2; mdf_dAX(1,2)=mTmp(0);
	mdf_dAX(2,0)=Z; mdf_dAX(2,1)=1;   mTmp=dc3t_dAX*mImgPt2; mdf_dAX(2,2)=mTmp(0);
	df_dAX = determinant(mdf_dAX);

	// compute df_dAY
	mdf_dAY(0,0)=X; mdf_dAY(0,1)=nx1; mdf_dAY(0,2)=-cosAZ*r3;
	mdf_dAY(1,0)=Y; mdf_dAY(1,1)=ny1; mdf_dAY(1,2)= sinAZ*r3;
	mdf_dAY(2,0)=Z; mdf_dAY(2,1)=1;	  mTmp=dc3t_dAY*mImgPt2; mdf_dAY(2,2)= mTmp(0);
	df_dAY = determinant(mdf_dAY);

	// compute df_dAZ
	mdf_dAZ(0,0)=X;	mdf_dAZ(0,1)=nx1; mdf_dAZ(0,2)= r2;
	mdf_dAZ(1,0)=Y; mdf_dAZ(1,1)=ny1; mdf_dAZ(1,2)=-r1;
	mdf_dAZ(2,0)=Z;	mdf_dAZ(2,1)=1;	  mdf_dAZ(2,2)= 0;
	df_dAZ = determinant(mdf_dAZ);

	// compute f
	mF(0,0)=X; mF(0,1)=nx1;	mF(0,2)=r1;
	mF(1,0)=Y; mF(1,1)=ny1;	mF(1,2)=r2;
	mF(2,0)=Z; mF(2,1)=1;	mF(2,2)=r3;
	f = determinant(mF);

	// compute df_dnx1
	mdf_dnx1(0,0)=X; mdf_dnx1(0,1)=1; mdf_dnx1(0,2)= r1;
	mdf_dnx1(1,0)=Y; mdf_dnx1(1,1)=0; mdf_dnx1(1,2)= r2;
	mdf_dnx1(2,0)=Z; mdf_dnx1(2,1)=0; mdf_dnx1(2,2)= r3;
	df_dnx1 = determinant(mdf_dnx1);

	// compute df_dny1
	mdf_dny1(0,0)=X; mdf_dny1(0,1)=0; mdf_dny1(0,2)=r1;
	mdf_dny1(1,0)=Y; mdf_dny1(1,1)=1; mdf_dny1(1,2)=r2;
	mdf_dny1(2,0)=Z; mdf_dny1(2,1)=0; mdf_dny1(2,2)=r3;
	df_dny1 = determinant(mdf_dny1);

	// compute df_dnx2
	mdf_dnx2(0,0)=X; mdf_dnx2(0,1)=nx1; mdf_dnx2(0,2)=mR(0,0);
	mdf_dnx2(1,0)=Y; mdf_dnx2(1,1)=ny1; mdf_dnx2(1,2)=mR(0,1);
	mdf_dnx2(2,0)=Z; mdf_dnx2(2,1)=1;   mdf_dnx2(2,2)=mR(0,2);
	df_dnx2 = determinant(mdf_dnx2);

	// compute df_dny2
	mdf_dny2(0,0)=X; mdf_dny2(0,1)=nx1;	mdf_dny2(0,2)=mR(1,0);
	mdf_dny2(1,0)=Y; mdf_dny2(1,1)=ny1;	mdf_dny2(1,2)=mR(1,1);
	mdf_dny2(2,0)=Z; mdf_dny2(2,1)=1;	mdf_dny2(2,2)=mR(1,2);
	df_dny2 = determinant(mdf_dny2);
}

void DeepVoid::get_omg_fai_fromXYZ(double X, double Y, double Z,		// input: the coordinates of optical center of the other image in reference image frame
								   double & omg, double & fai			// output:radians, the two angles corresponding to unit baseline vector
								   )
{
	// first get the unit vector of baseline
	double d = sqrt(X*X + Y*Y + Z*Z);

	double bx = X/d;
	double by = Y/d;
	double bz = Z/d;

	omg = atan2(bz, bx);
	fai = asin(by);
}

void DeepVoid::get_XYZ_fromOmgFai(double omg, double fai,				// input: radians, the two angles corresponding to unit baseline vector
								  double & X, double & Y, double & Z	// output:the coordinates of optical center of the other image in reference image frame
								  )
{
	X = cos(omg)*cos(fai);
	Y = sin(fai);
	Z = sin(omg)*cos(fai);
}

void DeepVoid::Optim_GaussNewton_PIRO_omg_fai_AXAYAZ(const CMatrix & mImgPts1,									// input: 2*n or 3*n matrix, the distortion free normalized image coordinates on reference image
													 const CMatrix & mImgPts2,									// input: 2*n or 3*n matrix, the distortion free normalized image coordinates on the other image
													 double omg_init, double fai_init,							// input: radians, initial values of omg and fai
													 double AX_init, double AY_init, double AZ_init,			// input: radians, initial values of AX,AY,AZ
													 double & omg_optim, double & fai_optim,					// output:radians, optimized values of omg and fai
													 double & AX_optim, double & AY_optim, double & AZ_optim,	// output:radians, optimized values of AX,AY,AZ
													 int maxIter /*= 128*/,										// input: max iteration
													 double xEps /*= 1.0E-7*/,									// input: threshold
													 double fEps /*= 1.0E-6*/,									// input: threshold
													 int * iterNum /*= NULL*/									// output:iteration number when quiting
													 )
{
	int n = mImgPts1.m_nCol; // number of matches
	int m = 5;

	CMatrix mJacob_Fi_Paras(n, m);
	CMatrix mFi(n, 1);
	CMatrix mA(m, m), mb(m, 1), mh(m, 1);

	double omg = omg_init;
	double fai = fai_init;
	double AX  = AX_init;
	double AY  = AY_init;
	double AZ  = AZ_init;

	double fVal_old = 0;
	double fVal_new;
	double hVal;

	int i, j;
	for (i = 0; i < maxIter; i++)
	{
		// 计算此次迭代的 Jocobian matrix J 和目标函数向量 f
		for (j = 1; j <= n; j++)
		{
			der_f_PIRO_omg_fai(mImgPts1(1,j), mImgPts1(2,j), mImgPts2(1,j), mImgPts2(2,j),
				omg, fai, AX, AY, AZ, mJacob_Fi_Paras(j,1), mJacob_Fi_Paras(j,2), mJacob_Fi_Paras(j,3), mJacob_Fi_Paras(j,4), mJacob_Fi_Paras(j,5), mFi(j));
		}

		double rankFi = mJacob_Fi_Paras.Rank();
		
		// 解方程组 (J'J) h = -J'f 得到的 h 即为待优化参数的改正量，下次迭代的 x(k + 1) = x(k) + h
		mA = mJacob_Fi_Paras.Transpose() * mJacob_Fi_Paras;
		mb = -mJacob_Fi_Paras.Transpose() * mFi;

		mh = Solve(mA, mb);

		fVal_new = mFi.Norm() * mFi.Norm();
		hVal     = mh.Norm();

		// 当目标函数值的平方和变化量小于一定阈值或者改正量的范数值小于一定阈值时认为迭代收敛，退出迭代
		if ((fabs(fVal_new - fVal_old) < fEps) || (hVal < xEps))
		{
			break;
		}

		fVal_old = fVal_new;

		omg += mh(1);
		fai += mh(2);
		AX  += mh(3);
		AY  += mh(4);
		AZ  += mh(5);
	}

	if (iterNum)
	{
		*iterNum = i;
	}

	omg_optim = omg;
	fai_optim = fai;
	AX_optim  = AX;
	AY_optim  = AY;
	AZ_optim  = AZ;
}

void DeepVoid::Optim_GaussNewton_PIRO_omg_fai_AXAYAZ(const CMatrix & mImgPts1,									// input: 2*n or 3*n matrix, the distortion free normalized image coordinates on reference image
													 const CMatrix & mImgPts2,									// input: 2*n or 3*n matrix, the distortion free normalized image coordinates on the other image
													 CMatrix & mRT,												// input&output: 4*4 matrix, the initial relative orientation and the optimized one
													 int maxIter /*= 128*/,										// input: max iteration
													 double xEps /*= 1.0E-7*/,									// input: threshold
													 double fEps /*= 1.0E-6*/,									// input: threshold
													 int * iterNum /*= NULL*/									// output:iteration number when quiting
													 )
{
	// extract initial values
	CMatrix mAngs = GetEulerAngleFromR(mRT);
	double AX_init = mAngs(3, 1) * CV_PI / 180;
	double AY_init = mAngs(2, 1) * CV_PI / 180;
	double AZ_init = mAngs(1, 1) * CV_PI / 180;

	CMatrix mOptCnt = -mRT.GetRect(1,1,3,3).Transpose()*mRT.GetRect(1,4,1,3);

	double omg_init, fai_init;
	get_omg_fai_fromXYZ(mOptCnt(1), mOptCnt(2), mOptCnt(3), omg_init, fai_init);

	double omg_optim, fai_optim, AX_optim, AY_optim, AZ_optim;
	Optim_GaussNewton_PIRO_omg_fai_AXAYAZ(mImgPts1, mImgPts2, omg_init, fai_init, AX_init, AY_init, AZ_init, 
		omg_optim, fai_optim, AX_optim, AY_optim, AZ_optim, maxIter, xEps, fEps, iterNum);

	mRT = GenR_Euler_Radian(AX_optim, AY_optim, AZ_optim, ZYX);

	get_XYZ_fromOmgFai(omg_optim, fai_optim, mOptCnt(1), mOptCnt(2), mOptCnt(3));

	CMatrix mT = -mRT.GetRect(1,1,3,3)*mOptCnt;

	mRT(1,4) = mT(1);
	mRT(2,4) = mT(2);
	mRT(3,4) = mT(3);
}

void DeepVoid::PIRO_Y_Z_AXAYAZ_GaussNewton(const CMatrix & mImgPts1,										// input: 2*n or 3*n matrix, the distortion free normalized image coordinates on reference image
												 const CMatrix & mImgPts2,									// input: 2*n or 3*n matrix, the distortion free normalized image coordinates on the other image
												 double Y_init, double Z_init,								// input: initial values of Y and Z
												 double AX_init, double AY_init, double AZ_init,			// input: radians, initial values of AX,AY,AZ
												 double & Y_optim, double & Z_optim,						// output:optimized values of Y and Z
												 double & AX_optim, double & AY_optim, double & AZ_optim,	// output:radians, optimized values of AX,AY,AZ
												 double sigma_nxny,											// input: the standard deviation of normalized image coordinates, sigma_xy/fx
												 double & Y_stdev, double & Z_stdev,						// output:optimized values of Y and Z
												 double & AX_stdev, double & AY_stdev, double & AZ_stdev,	// output:radians, optimized values of AX,AY,AZ
												 int maxIter /*= 128*/,										// input: max iteration
												 double xEps /*= 1.0E-7*/,									// input: threshold
												 double fEps /*= 1.0E-6*/,									// input: threshold
												 double bx /*= 1*/,											// input: default fixed value for X coordinate of the other image's optical center in reference
												 int * iterNum /*= NULL*/									// output:iteration number when quiting
												 )
{
	int n = mImgPts1.m_nCol; // number of matches
	int m = 5;

	CMatrix mJacob_Fi_Paras(n, m);
	CMatrix mFi(n, 1);
	CMatrix mA(m, m), mb(m, 1), mh(m, 1), mJacob_Fi_obsers(n, 4*n, 0);

	double Y  = Y_init;
	double Z  = Z_init;
	double AX = AX_init;
	double AY = AY_init;
	double AZ = AZ_init;

	double fVal_old = 0;
	double fVal_new;
	double hVal;

	int i, j;
	for (i = 0; i < maxIter; i++)
	{
		// 计算此次迭代的 Jocobian matrix J 和目标函数向量 f
		for (j = 1; j <= n; j++)
		{
			der_f_PIRO_Y_Z(mImgPts1(1,j), mImgPts1(2,j), mImgPts2(1,j), mImgPts2(2,j),
				Y, Z, AX, AY, AZ, mJacob_Fi_Paras(j,1), mJacob_Fi_Paras(j,2), mJacob_Fi_Paras(j,3), mJacob_Fi_Paras(j,4), mJacob_Fi_Paras(j,5), mFi(j),
				mJacob_Fi_obsers(j,(j-1)*4+1), mJacob_Fi_obsers(j,(j-1)*4+2), mJacob_Fi_obsers(j,(j-1)*4+3), mJacob_Fi_obsers(j,(j-1)*4+4), bx);
		}

		double rankFi = mJacob_Fi_Paras.Rank();

		// 解方程组 (J'J) h = -J'f 得到的 h 即为待优化参数的改正量，下次迭代的 x(k + 1) = x(k) + h
		mA = mJacob_Fi_Paras.Transpose() * mJacob_Fi_Paras;
		mb = -mJacob_Fi_Paras.Transpose() * mFi;

		mh = Solve(mA, mb);

		fVal_new = mFi.Norm() * mFi.Norm();
		hVal     = mh.Norm();

		// 当目标函数值的平方和变化量小于一定阈值或者改正量的范数值小于一定阈值时认为迭代收敛，退出迭代
		if ((fabs(fVal_new - fVal_old) < fEps) || (hVal < xEps))
		{
			break;
		}

		fVal_old = fVal_new;

		Y  += mh(1);
		Z  += mh(2);
		AX += mh(3);
		AY += mh(4);
		AZ += mh(5);
	}

	if (iterNum)
	{
		*iterNum = i;
	}

	Y_optim  = Y;
	Z_optim	 = Z;
	AX_optim = AX;
	AY_optim = AY;
	AZ_optim = AZ;

	// compute covariance matrix of parameters
	CMatrix mCyy = GenI(4*n)*(sigma_nxny*sigma_nxny);

	CMatrix mJyCyyJyt = mJacob_Fi_obsers*mCyy*mJacob_Fi_obsers.Transpose(); // Jy*Cyy*Jy'

	CMatrix mCxx_inv = mJacob_Fi_Paras.Transpose()*mJyCyyJyt.Inverse()*mJacob_Fi_Paras; // inv(Cxx) = Jx'*inv(Jy*Cyy*Jy')*Jx

	CMatrix mCovar = mCxx_inv.Inverse();

	Y_stdev  = sqrt(mCovar(1,1));
	Z_stdev  = sqrt(mCovar(2,2));
	AX_stdev = sqrt(mCovar(3,3));
	AY_stdev = sqrt(mCovar(4,4));
	AZ_stdev = sqrt(mCovar(5,5));
}

void DeepVoid::PIRO_Y_Z_AXAYAZ_GaussNewton(const CMatrix & mImgPts1,										// input: 2*n or 3*n matrix, the distortion free normalized image coordinates on reference image
												 const CMatrix & mImgPts2,									// input: 2*n or 3*n matrix, the distortion free normalized image coordinates on the other image
												 CMatrix & mRT,												// output:4*4 matrix, the output relative orientation
												 double sigma_nxny,											// input: the standard deviation of normalized image coordinates, sigma_xy/fx
												 double & Y_stdev, double & Z_stdev,						// output:optimized values of Y and Z
												 double & AX_stdev, double & AY_stdev, double & AZ_stdev,	// output:radians, optimized values of AX,AY,AZ
												 int maxIter /*= 128*/,										// input: max iteration
												 double xEps /*= 1.0E-12*/,									// input: threshold
												 double fEps /*= 1.0E-12*/,									// input: threshold
												 double bx /*= 1*/,											// input: default fixed value for X coordinate of the other image's optical center in reference
												 int * iterNum /*= NULL*/									// output:iteration number when quiting
												 )
{
	// assume that initially the other image's coordinate system is parallel to the reference image's coordinate system
	double AX_init = 0;
	double AY_init = 0;
	double AZ_init = 0;
	// assume that initially the other image's optical center is on the X-axis of the reference image's coordinate system
	double Y_init = 0;
	double Z_init = 0;

	double Y_optim, Z_optim, AX_optim, AY_optim, AZ_optim;
	PIRO_Y_Z_AXAYAZ_GaussNewton(mImgPts1, mImgPts2, Y_init, Z_init, AX_init, AY_init, AZ_init, 
		Y_optim, Z_optim, AX_optim, AY_optim, AZ_optim, sigma_nxny, Y_stdev, Z_stdev, AX_stdev, AY_stdev, AZ_stdev, maxIter, xEps, fEps, bx, iterNum);

	// change to angle standard deviations
	AX_stdev = AX_stdev*180/CV_PI;
	AY_stdev = AY_stdev*180/CV_PI;
	AZ_stdev = AZ_stdev*180/CV_PI;

	mRT = GenR_Euler_Radian(AX_optim, AY_optim, AZ_optim, ZYX);

	CMatrix mOptCnt(3,1);
	mOptCnt(1) = bx;
	mOptCnt(2) = Y_optim;
	mOptCnt(3) = Z_optim;

	CMatrix mT = -mRT.GetRect(1,1,3,3)*mOptCnt; // t=-RC

	mRT(1,4) = mT(1);
	mRT(2,4) = mT(2);
	mRT(3,4) = mT(3);
}

// 20150114, zhaokunz, photogrammetric iterative relative orientation
// fix the X coordinate of the optical center of the matching image to given value, then optimize Y and Z
void DeepVoid::PIRO_Y_Z_AXAYAZ_GN(const vector<Point2d> & nimgpts0,							// input:	distortion free normalized image points in the reference image
								  const vector<Point2d> & nimgpts1,							// input:	distortion free normalized image points in the matching image
								  double Y_init, double Z_init,								// input:	initial values of Y and Z
								  double AX_init, double AY_init, double AZ_init,			// input:	radians, initial values of AX,AY,AZ
								  double & Y_optim, double & Z_optim,						// output:	optimized values of Y and Z
								  double & AX_optim, double & AY_optim, double & AZ_optim,	// output:	radians, optimized values of AX,AY,AZ
								  double bx /*= 1*/,										// input:	default fixed value for X coordinate of the matching image's optical center in reference
								  int maxIter /*= 128*/,									// input:	max iteration
								  double xEps /*= 1.0E-12*/,								// input:	threshold
								  double fEps /*= 1.0E-12*/									// input:	threshold
								  )
{
	int i,k;

	int M = nimgpts0.size(); // number of matches
	int N = 5; // number of variables

	Mat mJ(M, N, CV_64FC1, Scalar(0)); // the jacobian matrix
	Mat mF(M, 1, CV_64FC1, Scalar(0)); // the error vector

	double Y = Y_init;
	double Z = Z_init;
	double AX = AX_init;
	double AY = AY_init;
	double AZ = AZ_init;

	double fVal_old = 0;
	double fVal_new;
	double hVal;

	for (k=0;k<maxIter;k++)
	{
		for (i=0;i<M;i++)
		{
			Point2d nimgpt0 = nimgpts0[i];
			Point2d nimgpt1 = nimgpts1[i];
			double nx0 = nimgpt0.x;
			double ny0 = nimgpt0.y;
			double nx1 = nimgpt1.x;
			double ny1 = nimgpt1.y;

			double f, df_dX, df_dY, df_dZ, df_dAX, df_dAY, df_dAZ, df_dnimgx0, df_dnimgy0, df_dnimgx1, df_dnimgy1;
			der_f_PIRO(nx0,ny0,nx1,ny1,bx,Y,Z,AX,AY,AZ,df_dX,df_dY,df_dZ,df_dAX,df_dAY,df_dAZ,f,df_dnimgx0,df_dnimgy0,df_dnimgx1,df_dnimgy1);

			mJ.at<double>(i,0) = df_dY;
			mJ.at<double>(i,1) = df_dZ;
			mJ.at<double>(i,2) = df_dAX;
			mJ.at<double>(i,3) = df_dAY;
			mJ.at<double>(i,4) = df_dAZ;

			mF.at<double>(i) = f;
		}

		Mat mA = mJ.t() * mJ;
		Mat mb = -mJ.t() * mF;
		Mat mh;

		solve(mA, mb, mh, DECOMP_CHOLESKY); // not working, maybe it's because the A matrix is not symmetrical and positive definite
//		solve(mA, mb, mh, DECOMP_LU); // fast, and always get the best results here
//		solve(mA, mb, mh, DECOMP_SVD); // too slow, always get the same results as the QR method does
//		solve(mA, mb, mh, DECOMP_QR); // also too slow

		fVal_new = norm(mF)*norm(mF);
		hVal     = norm(mh);

		double df2 = fVal_new - fVal_old;

		if ((fabs(df2) < fEps) || (hVal < xEps))
		{
			break;
		}

		fVal_old = fVal_new;

		Y +=mh.at<double>(0);
		Z +=mh.at<double>(1);
		AX+=mh.at<double>(2);
		AY+=mh.at<double>(3);
		AZ+=mh.at<double>(4);
	}

	Y_optim  = Y;
	Z_optim  = Z;
	AX_optim = AX;
	AY_optim = AY;
	AZ_optim = AZ;
}

// 20150114, zhaokunz, photogrammetric iterative relative orientation
// fix the Y coordinate of the optical center of the matching image to given value, then optimize X and Z
void DeepVoid::PIRO_X_Z_AXAYAZ_GN(const vector<Point2d> & nimgpts0,							// input:	distortion free normalized image points in the reference image
								  const vector<Point2d> & nimgpts1,							// input:	distortion free normalized image points in the matching image
								  double X_init, double Z_init,								// input:	initial values of X and Z
								  double AX_init, double AY_init, double AZ_init,			// input:	radians, initial values of AX,AY,AZ
								  double & X_optim, double & Z_optim,						// output:	optimized values of X and Z
								  double & AX_optim, double & AY_optim, double & AZ_optim,	// output:	radians, optimized values of AX,AY,AZ
								  double by /*= 1*/,										// input:	default fixed value for Y coordinate of the matching image's optical center in reference
								  int maxIter /*= 128*/,									// input:	max iteration
								  double xEps /*= 1.0E-12*/,								// input:	threshold
								  double fEps /*= 1.0E-12*/									// input:	threshold
								  )
{
	int i,k;

	int M = nimgpts0.size(); // number of matches
	int N = 5; // number of variables

	Mat mJ(M, N, CV_64FC1, Scalar(0)); // the jacobian matrix
	Mat mF(M, 1, CV_64FC1, Scalar(0)); // the error vector

	double X = X_init;
	double Z = Z_init;
	double AX = AX_init;
	double AY = AY_init;
	double AZ = AZ_init;

	double fVal_old = 0;
	double fVal_new;
	double hVal;

	for (k=0;k<maxIter;k++)
	{
		for (i=0;i<M;i++)
		{
			Point2d nimgpt0 = nimgpts0[i];
			Point2d nimgpt1 = nimgpts1[i];
			double nx0 = nimgpt0.x;
			double ny0 = nimgpt0.y;
			double nx1 = nimgpt1.x;
			double ny1 = nimgpt1.y;

			double f, df_dX, df_dY, df_dZ, df_dAX, df_dAY, df_dAZ, df_dnimgx0, df_dnimgy0, df_dnimgx1, df_dnimgy1;
			der_f_PIRO(nx0,ny0,nx1,ny1,X,by,Z,AX,AY,AZ,df_dX,df_dY,df_dZ,df_dAX,df_dAY,df_dAZ,f,df_dnimgx0,df_dnimgy0,df_dnimgx1,df_dnimgy1);

			mJ.at<double>(i,0) = df_dX;
			mJ.at<double>(i,1) = df_dZ;
			mJ.at<double>(i,2) = df_dAX;
			mJ.at<double>(i,3) = df_dAY;
			mJ.at<double>(i,4) = df_dAZ;

			mF.at<double>(i) = f;
		}

		Mat mA = mJ.t() * mJ;
		Mat mb = -mJ.t() * mF;
		Mat mh;

		solve(mA, mb, mh, DECOMP_CHOLESKY); // not working, maybe it's because the A matrix is not symmetrical and positive definite
//		solve(mA, mb, mh, DECOMP_LU); // fast, and always get the best results here
//		solve(mA, mb, mh, DECOMP_SVD); // too slow, always get the same results as the QR method does
//		solve(mA, mb, mh, DECOMP_QR); // also too slow

		fVal_new = norm(mF)*norm(mF);
		hVal     = norm(mh);

		double df2 = fVal_new - fVal_old;

		if ((fabs(df2) < fEps) || (hVal < xEps))
		{
			break;
		}

		fVal_old = fVal_new;

		X +=mh.at<double>(0);
		Z +=mh.at<double>(1);
		AX+=mh.at<double>(2);
		AY+=mh.at<double>(3);
		AZ+=mh.at<double>(4);
	}

	X_optim  = X;
	Z_optim  = Z;
	AX_optim = AX;
	AY_optim = AY;
	AZ_optim = AZ;
}

// 20150115, zhaokunz, photogrammetric iterative relative orientation
// fix the Z coordinate of the optical center of the matching image to given value, then optimize X and Y
void DeepVoid::PIRO_X_Y_AXAYAZ_GN(const vector<Point2d> & nimgpts0,							// input:	distortion free normalized image points in the reference image
								  const vector<Point2d> & nimgpts1,							// input:	distortion free normalized image points in the matching image
								  double X_init, double Y_init,								// input:	initial values of X and Y
								  double AX_init, double AY_init, double AZ_init,			// input:	radians, initial values of AX,AY,AZ
								  double & X_optim, double & Y_optim,						// output:	optimized values of X and Y
								  double & AX_optim, double & AY_optim, double & AZ_optim,	// output:	radians, optimized values of AX,AY,AZ
								  double bz /*= 1.0*/,										// input:	default fixed value for Z coordinate of the matching image's optical center in reference
								  int maxIter /*= 128*/,									// input:	max iteration
								  double xEps /*= 1.0E-12*/,								// input:	threshold
								  double fEps /*= 1.0E-12*/									// input:	threshold
								  )
{
	int i,k;

	int M = nimgpts0.size(); // number of matches
	int N = 5; // number of variables

	Mat mJ(M, N, CV_64FC1, Scalar(0)); // the jacobian matrix
	Mat mF(M, 1, CV_64FC1, Scalar(0)); // the error vector

	double X = X_init;
	double Y = Y_init;
	double AX = AX_init;
	double AY = AY_init;
	double AZ = AZ_init;

	double fVal_old = 0;
	double fVal_new;
	double hVal;

	for (k=0;k<maxIter;k++)
	{
		for (i=0;i<M;i++)
		{
			Point2d nimgpt0 = nimgpts0[i];
			Point2d nimgpt1 = nimgpts1[i];
			double nx0 = nimgpt0.x;
			double ny0 = nimgpt0.y;
			double nx1 = nimgpt1.x;
			double ny1 = nimgpt1.y;

			double f, df_dX, df_dY, df_dZ, df_dAX, df_dAY, df_dAZ, df_dnimgx0, df_dnimgy0, df_dnimgx1, df_dnimgy1;
			der_f_PIRO(nx0,ny0,nx1,ny1,X,Y,bz,AX,AY,AZ,df_dX,df_dY,df_dZ,df_dAX,df_dAY,df_dAZ,f,df_dnimgx0,df_dnimgy0,df_dnimgx1,df_dnimgy1);

			mJ.at<double>(i,0) = df_dX;
			mJ.at<double>(i,1) = df_dY;
			mJ.at<double>(i,2) = df_dAX;
			mJ.at<double>(i,3) = df_dAY;
			mJ.at<double>(i,4) = df_dAZ;

			mF.at<double>(i) = f;
		}

		Mat mA = mJ.t() * mJ;
		Mat mb = -mJ.t() * mF;
		Mat mh;

		solve(mA, mb, mh, DECOMP_CHOLESKY); // not working, maybe it's because the A matrix is not symmetrical and positive definite
//		solve(mA, mb, mh, DECOMP_LU); // fast, and always get the best results here
//		solve(mA, mb, mh, DECOMP_SVD); // too slow, always get the same results as the QR method does
//		solve(mA, mb, mh, DECOMP_QR); // also too slow

		fVal_new = norm(mF)*norm(mF);
		hVal     = norm(mh);

		double df2 = fVal_new - fVal_old;

		if ((fabs(df2) < fEps) || (hVal < xEps))
		{
			break;
		}

		fVal_old = fVal_new;

		X +=mh.at<double>(0);
		Y +=mh.at<double>(1);
		AX+=mh.at<double>(2);
		AY+=mh.at<double>(3);
		AZ+=mh.at<double>(4);
	}

	X_optim  = X;
	Y_optim  = Y;
	AX_optim = AX;
	AY_optim = AY;
	AZ_optim = AZ;
}

// 20150114, zhaokunz
double DeepVoid::PIRO_GN(const vector<Point2d> & imgpts0,	// input:	measured distortion free image points in reference image
					     const vector<Point2d> & imgpts1,	// input:	measured distortion free image points in matching image
					     const Matx33d & mK0,				// input:	the calibration matrix of the reference image
					     const Matx33d & mK1,				// input:	the calibration matrix of the matching image
					     Matx33d & mR,						// output:	the relative rotation matrix between the matching and reference image
					     Matx31d & mt,						// output:	the relative translation vector between the matching and reference image
					     vector<Point3d> & wrdpts,			// output:	the reconstructed 3D coordinates of all correspondences
					     int maxIter /*= 128*/,				// input:	max iteration
					     double xEps /*= 1.0E-12*/,			// input:	threshold
					     double fEps /*= 1.0E-12*/			// input:	threshold
					     )
{
	int i,j;

	int n = imgpts0.size(); // number of correspondences

	Matx33d mK0_1 = mK0.inv();
	Matx33d mK1_1 = mK1.inv();

	Matx34d mP0;

	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mP0(i,j)=mK0(i,j);
		}
	}

	vector<Point2d> nimgpts0,nimgpts1;

	// first, normalize all image points
	for (i=0;i<n;i++)
	{
		Point2d pt0 = imgpts0[i];
		Point2d pt1 = imgpts1[i];

		Matx31d imgpt0,imgpt1;
		imgpt0(0)=pt0.x;
		imgpt0(1)=pt0.y;
		imgpt0(2)=1;

		imgpt1(0)=pt1.x;
		imgpt1(1)=pt1.y;
		imgpt1(2)=1;

		imgpt0=mK0_1*imgpt0;
		imgpt1=mK1_1*imgpt1;

		pt0.x=imgpt0(0);
		pt0.y=imgpt0(1);
		pt1.x=imgpt1(0);
		pt1.y=imgpt1(1);

		nimgpts0.push_back(pt0);
		nimgpts1.push_back(pt1);
	}

	vector<vector<Point3d>> wrdpts_all;
	vector<double> err_rpj_all;
	vector<int> n_pos_all;
	vector<Matx33d> R_all;
	vector<Matx31d> t_all;

	// try fix bx = 1 //////////////////////////////////////////////////////////////////////////
	double bx = 1.0;
	double Y_optim,Z_optim,AX_optim,AY_optim,AZ_optim;
	PIRO_Y_Z_AXAYAZ_GN(nimgpts0,nimgpts1,0,0,0,0,0,Y_optim,Z_optim,AX_optim,AY_optim,AZ_optim,bx,maxIter,xEps,fEps);
	mR = GenR_Euler_Radian_CV(AX_optim,AY_optim,AZ_optim,ZYX);
	Matx31d C;
	C(0)=bx;
	C(1)=Y_optim;
	C(2)=Z_optim;
	mt = -mR*C; // t=-RC
	Matx33d mKR = mK1*mR;
	Matx31d mKt = mK1*mt;
	Matx34d mP1;
	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mP1(i,j)=mKR(i,j);
		}
	}
	mP1(0,3)=mKt(0);
	mP1(1,3)=mKt(1);
	mP1(2,3)=mKt(2);
	// get fundamental matrix
	Matx33d mF = GetF_Stereo(mK0,mK1,mR,mt);
	vector<Point2d> imgpts0_crct, imgpts1_crct;
	correctMatches(mF,imgpts0,imgpts1,imgpts0_crct,imgpts1_crct);
	Mat mWrdPts;
	triangulatePoints(mP0, mP1, imgpts0_crct, imgpts1_crct, mWrdPts);

	vector<Point3d> vWrdPts;
	double sum_d2 = 0;
	int n_pos = 0;

	for (i=0;i<n;i++)
	{
		Point3d pt;
		double w_1 = 1.0/mWrdPts.at<double>(3,i);

		pt.x = mWrdPts.at<double>(0,i)*w_1;
		pt.y = mWrdPts.at<double>(1,i)*w_1;
		pt.z = mWrdPts.at<double>(2,i)*w_1;

		if (pt.z>0)
		{
			n_pos++;
		}

		vWrdPts.push_back(pt);

		double dx0 = imgpts0_crct[i].x-imgpts0[i].x;
		double dy0 = imgpts0_crct[i].y-imgpts0[i].y;
		double dx1 = imgpts1_crct[i].x-imgpts1[i].x;
		double dy1 = imgpts1_crct[i].y-imgpts1[i].y;
		double d2 = dx0*dx0+dy0*dy0+dx1*dx1+dy1*dy1;
		sum_d2+=d2;
	}

	double err_rpj = sqrt(sum_d2*0.5/n);

	wrdpts_all.push_back(vWrdPts);
	err_rpj_all.push_back(err_rpj);
	n_pos_all.push_back(n_pos);
	R_all.push_back(mR);
	t_all.push_back(mt);
	/////////////////////////////////////////////////////////////////////////////////

	// try fix bx = -1 //////////////////////////////////////////////////////////////////////////
	bx = -1.0;
	PIRO_Y_Z_AXAYAZ_GN(nimgpts0,nimgpts1,0,0,0,0,0,Y_optim,Z_optim,AX_optim,AY_optim,AZ_optim,bx,maxIter,xEps,fEps);
	mR = GenR_Euler_Radian_CV(AX_optim,AY_optim,AZ_optim,ZYX);
	C(0)=bx;
	C(1)=Y_optim;
	C(2)=Z_optim;
	mt = -mR*C; // t=-RC
	mKR = mK1*mR;
	mKt = mK1*mt;
	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mP1(i,j)=mKR(i,j);
		}
	}
	mP1(0,3)=mKt(0);
	mP1(1,3)=mKt(1);
	mP1(2,3)=mKt(2);
	// get fundamental matrix
	mF = GetF_Stereo(mK0,mK1,mR,mt);
	correctMatches(mF,imgpts0,imgpts1,imgpts0_crct,imgpts1_crct);
	triangulatePoints(mP0, mP1, imgpts0_crct, imgpts1_crct, mWrdPts);

	vWrdPts.clear();
	sum_d2 = 0;
	n_pos = 0;

	for (i=0;i<n;i++)
	{
		Point3d pt;
		double w_1 = 1.0/mWrdPts.at<double>(3,i);

		pt.x = mWrdPts.at<double>(0,i)*w_1;
		pt.y = mWrdPts.at<double>(1,i)*w_1;
		pt.z = mWrdPts.at<double>(2,i)*w_1;

		if (pt.z>0)
		{
			n_pos++;
		}

		vWrdPts.push_back(pt);

		double dx0 = imgpts0_crct[i].x-imgpts0[i].x;
		double dy0 = imgpts0_crct[i].y-imgpts0[i].y;
		double dx1 = imgpts1_crct[i].x-imgpts1[i].x;
		double dy1 = imgpts1_crct[i].y-imgpts1[i].y;
		double d2 = dx0*dx0+dy0*dy0+dx1*dx1+dy1*dy1;
		sum_d2+=d2;
	}

	err_rpj = sqrt(sum_d2*0.5/n);

	wrdpts_all.push_back(vWrdPts);
	err_rpj_all.push_back(err_rpj);
	n_pos_all.push_back(n_pos);
	R_all.push_back(mR);
	t_all.push_back(mt);
	/////////////////////////////////////////////////////////////////////////////////

	// try fix by = 1 //////////////////////////////////////////////////////////////////////////
	double by = 1.0;
	double X_optim;
	PIRO_X_Z_AXAYAZ_GN(nimgpts0,nimgpts1,0,0,0,0,0,X_optim,Z_optim,AX_optim,AY_optim,AZ_optim,by,maxIter,xEps,fEps);
	mR = GenR_Euler_Radian_CV(AX_optim,AY_optim,AZ_optim,ZYX);
	C(0)=X_optim;
	C(1)=by;
	C(2)=Z_optim;
	mt = -mR*C; // t=-RC
	mKR = mK1*mR;
	mKt = mK1*mt;
	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mP1(i,j)=mKR(i,j);
		}
	}
	mP1(0,3)=mKt(0);
	mP1(1,3)=mKt(1);
	mP1(2,3)=mKt(2);
	// get fundamental matrix
	mF = GetF_Stereo(mK0,mK1,mR,mt);
	correctMatches(mF,imgpts0,imgpts1,imgpts0_crct,imgpts1_crct);
	triangulatePoints(mP0, mP1, imgpts0_crct, imgpts1_crct, mWrdPts);

	vWrdPts.clear();
	sum_d2 = 0;
	n_pos = 0;

	for (i=0;i<n;i++)
	{
		Point3d pt;
		double w_1 = 1.0/mWrdPts.at<double>(3,i);

		pt.x = mWrdPts.at<double>(0,i)*w_1;
		pt.y = mWrdPts.at<double>(1,i)*w_1;
		pt.z = mWrdPts.at<double>(2,i)*w_1;

		if (pt.z>0)
		{
			n_pos++;
		}

		vWrdPts.push_back(pt);

		double dx0 = imgpts0_crct[i].x-imgpts0[i].x;
		double dy0 = imgpts0_crct[i].y-imgpts0[i].y;
		double dx1 = imgpts1_crct[i].x-imgpts1[i].x;
		double dy1 = imgpts1_crct[i].y-imgpts1[i].y;
		double d2 = dx0*dx0+dy0*dy0+dx1*dx1+dy1*dy1;
		sum_d2+=d2;
	}

	err_rpj = sqrt(sum_d2*0.5/n);

	wrdpts_all.push_back(vWrdPts);
	err_rpj_all.push_back(err_rpj);
	n_pos_all.push_back(n_pos);
	R_all.push_back(mR);
	t_all.push_back(mt);
	/////////////////////////////////////////////////////////////////////////////////

	// try fix by = -1 //////////////////////////////////////////////////////////////////////////
	by = -1.0;
	PIRO_X_Z_AXAYAZ_GN(nimgpts0,nimgpts1,0,0,0,0,0,X_optim,Z_optim,AX_optim,AY_optim,AZ_optim,by,maxIter,xEps,fEps);
	mR = GenR_Euler_Radian_CV(AX_optim,AY_optim,AZ_optim,ZYX);
	C(0)=X_optim;
	C(1)=by;
	C(2)=Z_optim;
	mt = -mR*C; // t=-RC
	mKR = mK1*mR;
	mKt = mK1*mt;
	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mP1(i,j)=mKR(i,j);
		}
	}
	mP1(0,3)=mKt(0);
	mP1(1,3)=mKt(1);
	mP1(2,3)=mKt(2);
	// get fundamental matrix
	mF = GetF_Stereo(mK0,mK1,mR,mt);
	correctMatches(mF,imgpts0,imgpts1,imgpts0_crct,imgpts1_crct);
	triangulatePoints(mP0, mP1, imgpts0_crct, imgpts1_crct, mWrdPts);

	vWrdPts.clear();
	sum_d2 = 0;
	n_pos = 0;

	for (i=0;i<n;i++)
	{
		Point3d pt;
		double w_1 = 1.0/mWrdPts.at<double>(3,i);

		pt.x = mWrdPts.at<double>(0,i)*w_1;
		pt.y = mWrdPts.at<double>(1,i)*w_1;
		pt.z = mWrdPts.at<double>(2,i)*w_1;

		if (pt.z>0)
		{
			n_pos++;
		}

		vWrdPts.push_back(pt);

		double dx0 = imgpts0_crct[i].x-imgpts0[i].x;
		double dy0 = imgpts0_crct[i].y-imgpts0[i].y;
		double dx1 = imgpts1_crct[i].x-imgpts1[i].x;
		double dy1 = imgpts1_crct[i].y-imgpts1[i].y;
		double d2 = dx0*dx0+dy0*dy0+dx1*dx1+dy1*dy1;
		sum_d2+=d2;
	}

	err_rpj = sqrt(sum_d2*0.5/n);

	wrdpts_all.push_back(vWrdPts);
	err_rpj_all.push_back(err_rpj);
	n_pos_all.push_back(n_pos);
	R_all.push_back(mR);
	t_all.push_back(mt);
	/////////////////////////////////////////////////////////////////////////////////

	// try fix bz = 1 //////////////////////////////////////////////////////////////////////////
	double bz = 1.0;
	PIRO_X_Y_AXAYAZ_GN(nimgpts0,nimgpts1,0,0,0,0,0,X_optim,Y_optim,AX_optim,AY_optim,AZ_optim,bz,maxIter,xEps,fEps);
	mR = GenR_Euler_Radian_CV(AX_optim,AY_optim,AZ_optim,ZYX);
	C(0)=X_optim;
	C(1)=Y_optim;
	C(2)=bz;
	mt = -mR*C; // t=-RC
	mKR = mK1*mR;
	mKt = mK1*mt;
	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mP1(i,j)=mKR(i,j);
		}
	}
	mP1(0,3)=mKt(0);
	mP1(1,3)=mKt(1);
	mP1(2,3)=mKt(2);
	// get fundamental matrix
	mF = GetF_Stereo(mK0,mK1,mR,mt);
	correctMatches(mF,imgpts0,imgpts1,imgpts0_crct,imgpts1_crct);
	triangulatePoints(mP0, mP1, imgpts0_crct, imgpts1_crct, mWrdPts);

	vWrdPts.clear();
	sum_d2 = 0;
	n_pos = 0;

	for (i=0;i<n;i++)
	{
		Point3d pt;
		double w_1 = 1.0/mWrdPts.at<double>(3,i);

		pt.x = mWrdPts.at<double>(0,i)*w_1;
		pt.y = mWrdPts.at<double>(1,i)*w_1;
		pt.z = mWrdPts.at<double>(2,i)*w_1;

		if (pt.z>0)
		{
			n_pos++;
		}

		vWrdPts.push_back(pt);

		double dx0 = imgpts0_crct[i].x-imgpts0[i].x;
		double dy0 = imgpts0_crct[i].y-imgpts0[i].y;
		double dx1 = imgpts1_crct[i].x-imgpts1[i].x;
		double dy1 = imgpts1_crct[i].y-imgpts1[i].y;
		double d2 = dx0*dx0+dy0*dy0+dx1*dx1+dy1*dy1;
		sum_d2+=d2;
	}

	err_rpj = sqrt(sum_d2*0.5/n);

	wrdpts_all.push_back(vWrdPts);
	err_rpj_all.push_back(err_rpj);
	n_pos_all.push_back(n_pos);
	R_all.push_back(mR);
	t_all.push_back(mt);
	/////////////////////////////////////////////////////////////////////////////////

	// try fix bz = -1 //////////////////////////////////////////////////////////////////////////
	bz = -1.0;
	PIRO_X_Y_AXAYAZ_GN(nimgpts0,nimgpts1,0,0,0,0,0,X_optim,Y_optim,AX_optim,AY_optim,AZ_optim,bz,maxIter,xEps,fEps);
	mR = GenR_Euler_Radian_CV(AX_optim,AY_optim,AZ_optim,ZYX);
	C(0)=X_optim;
	C(1)=Y_optim;
	C(2)=bz;
	mt = -mR*C; // t=-RC
	mKR = mK1*mR;
	mKt = mK1*mt;
	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mP1(i,j)=mKR(i,j);
		}
	}
	mP1(0,3)=mKt(0);
	mP1(1,3)=mKt(1);
	mP1(2,3)=mKt(2);
	// get fundamental matrix
	mF = GetF_Stereo(mK0,mK1,mR,mt);
	correctMatches(mF,imgpts0,imgpts1,imgpts0_crct,imgpts1_crct);
	triangulatePoints(mP0, mP1, imgpts0_crct, imgpts1_crct, mWrdPts);

	vWrdPts.clear();
	sum_d2 = 0;
	n_pos = 0;

	for (i=0;i<n;i++)
	{
		Point3d pt;
		double w_1 = 1.0/mWrdPts.at<double>(3,i);

		pt.x = mWrdPts.at<double>(0,i)*w_1;
		pt.y = mWrdPts.at<double>(1,i)*w_1;
		pt.z = mWrdPts.at<double>(2,i)*w_1;

		if (pt.z>0)
		{
			n_pos++;
		}

		vWrdPts.push_back(pt);

		double dx0 = imgpts0_crct[i].x-imgpts0[i].x;
		double dy0 = imgpts0_crct[i].y-imgpts0[i].y;
		double dx1 = imgpts1_crct[i].x-imgpts1[i].x;
		double dy1 = imgpts1_crct[i].y-imgpts1[i].y;
		double d2 = dx0*dx0+dy0*dy0+dx1*dx1+dy1*dy1;
		sum_d2+=d2;
	}

	err_rpj = sqrt(sum_d2*0.5/n);

	wrdpts_all.push_back(vWrdPts);
	err_rpj_all.push_back(err_rpj);
	n_pos_all.push_back(n_pos);
	R_all.push_back(mR);
	t_all.push_back(mt);
	/////////////////////////////////////////////////////////////////////////////////

	// choose the best reasonable estimate
	vector <double>::iterator iterDouble = min_element(err_rpj_all.begin(), err_rpj_all.end());
	double min_err_rpj = *iterDouble;
	int idx_min_err_rpj = iterDouble - err_rpj_all.begin();

	// 
	if (n_pos_all[idx_min_err_rpj]<n_pos_all[idx_min_err_rpj+1])
	{
		idx_min_err_rpj++;
	}

	mR = R_all[idx_min_err_rpj];
	mt = t_all[idx_min_err_rpj];
	wrdpts = wrdpts_all[idx_min_err_rpj];

// 	for (i=0;i<wrdpts_all.size();i++)
// 	{
// 		CString str;
// 		str.Format("C:\\Users\\DeepVoid\\Desktop\\wrdpts %02d.txt",i);
// 		FILE * file = fopen(str,"w");
// 		for (j=0;j<n;j++)
// 		{
// 			fprintf(file, "%.12f;%.12f;%.12f\n", wrdpts_all[i][j].x, wrdpts_all[i][j].y, wrdpts_all[i][j].z);
// 		}
// 		fclose(file);
// 	}

	return err_rpj_all[idx_min_err_rpj];
}

bool DeepVoid::RelativeOrientation_RANSAC_Features_PIRO(const cam_data & cam1,				// input:	all the information about the image 1
														const cam_data & cam2,				// input:	all the information about the image 2
														int idx_cam1,						// input:	the index of the first camera
														int idx_cam2,						// input:	the index of the second camera
														CMatrix & mRT,						// output:	4*4 matrix, the relative orientation of these two images [R|t; 0 0 0 1]
														vector<CloudPoint> & clouds,		// output:	the reconstructed cloud points in reference camera frame, which is the first image
														double param1 /*= 3*/,				// input:	defining "good" matches (i.e. whose distance is less than param1*min_dist) in feature matching stage
														double param2 /*= 3*/,				// input:	the distance threshold between point and epiline, used in RANSAC stage
														double param3 /*= 0.99*/,			// input:	specifying a desirable level of confidence (probability) that the estimated matrix is correct
														double thresh_stdev_YZ /*= 0.08*/,	// input:	the threshold of standard deviation of Y and Z
														double thresh_reprojErr /*= 1*/,	// input:	the threshold of the reprojection error in pixels
														double thresh_pyErr /*= 0.001*/,	// input:	the threshold of the y-parallax error
														double thresh_ang /*= 30*/			// input:	the threshold of angle between optical axes
														)
{
	int i,j;

	int nFeat1 = cam1.m_feats.key_points.size();
	int nFeat2 = cam2.m_feats.key_points.size();

	CMatrix mK1(3, 3, 0), mK2(3, 3, 0);

	mK1(1,1) = cam1.fx; mK1(2,2) = cam1.fy;
	mK1(1,3) = cam1.cx; mK1(2,3) = cam1.cy;
	mK1(1,2) = cam1.s;  mK1(3,3) = 1;

	mK2(1,1) = cam2.fx; mK2(2,2) = cam2.fy;
	mK2(1,3) = cam2.cx; mK2(2,3) = cam2.cy;
	mK2(1,2) = cam2.s;  mK2(3,3) = 1;

	CMatrix mK1_ext = mK1.Clone();
	CMatrix mK2_ext = mK2.Clone();
	mK1_ext.AddOneCol(0);
	mK2_ext.AddOneCol(0);

	// it's preferable to first rectify the features' image coordinates if the distortion coefficients are not 0
	// this is not critical, but can improve the accuracy of Essential matrix a little bit
	// and it is preferable if the features are extracted from a whole rectified distortion free image too, because
	// the descriptors are generated from distortion free image
	Features feat1_rectified = cam1.m_feats;
	Features feat2_rectified = cam2.m_feats;

	for (i=0;i<nFeat1;i++)
	{
		double d_x, d_y, i_x, i_y;
		d_x = feat1_rectified.key_points[i].pt.x; d_y = feat1_rectified.key_points[i].pt.y;
		RemoveDistortion_DCBrown(cam1.cx, cam1.cy, cam1.fx, cam1.fy, cam1.k, d_x, d_y, i_x, i_y);
		feat1_rectified.key_points[i].pt.x = i_x; feat1_rectified.key_points[i].pt.y = i_y;
	}
	for (i=0;i<nFeat2;i++)
	{
		double d_x, d_y, i_x, i_y;
		d_x = feat2_rectified.key_points[i].pt.x; d_y = feat2_rectified.key_points[i].pt.y;
		RemoveDistortion_DCBrown(cam2.cx, cam2.cy, cam2.fx, cam2.fy, cam2.k, d_x, d_y, i_x, i_y);
		feat2_rectified.key_points[i].pt.x = i_x; feat2_rectified.key_points[i].pt.y = i_y;
	}

	// matching using rectified features and RANSAC
	vector<DMatch> matches;

	CalibFundamentalMat_RANSAC_Features(feat1_rectified, feat2_rectified, matches, param1, param2, param3);

	int n = matches.size();

	CMatrix mImgPts1(3, n, 1), mImgPts2(3, n, 1);
	for (i=0;i<n;i++)
	{
		mImgPts1(1, i+1) = feat1_rectified.key_points[matches[i].queryIdx].pt.x;
		mImgPts1(2, i+1) = feat1_rectified.key_points[matches[i].queryIdx].pt.y;

		mImgPts2(1, i+1) = feat2_rectified.key_points[matches[i].trainIdx].pt.x;
		mImgPts2(2, i+1) = feat2_rectified.key_points[matches[i].trainIdx].pt.y;
	}

	// get normalized image points
	CMatrix mImgPts1_norm = mK1.Inverse() * mImgPts1;
	CMatrix mImgPts2_norm = mK2.Inverse() * mImgPts2;

	double info[10]; CMatrix mCovar; int nIter;

	PIRO_Y_Z_AXAYAZ_levmar(mImgPts1_norm, mImgPts2_norm, mRT, 1, 1024, NULL, info, mCovar, &nIter);
	
	// record which points' Z coordinates are negative or 0
	int * status_neg = new int[n];
	memset(status_neg,0,n*sizeof(int));

	double * d1_reproj = new double [n];
	double * d2_reproj = new double [n];
	memset(d1_reproj,0,n*sizeof(double));
	memset(d2_reproj,0,n*sizeof(double));

	CMatrix mWrdPts(4, n, 1);
	
	double sumPY = 0;
	double sumReprojErr = 0;
	int nNeg = 0;

	for (i = 1; i <= n; i++)
	{
		double X,Y,Z,py;
		Triangulate_PIRO_py(mImgPts1_norm(1, i), mImgPts1_norm(2, i), 1, mImgPts2_norm(1, i), mImgPts2_norm(2, i), 1,
			mRT, X, Y, Z, py);

		mWrdPts(1,i) = X;
		mWrdPts(2,i) = Y;
		mWrdPts(3,i) = Z;

		sumPY += (py*py)/(Z*Z);

		CMatrix mImgPt_reproj = mK1_ext * GenI(4) * mWrdPts.GetCol(i);
		double dx1 = mImgPt_reproj(1) / mImgPt_reproj(3) - mImgPts1(1,i);
		double dy1 = mImgPt_reproj(2) / mImgPt_reproj(3) - mImgPts1(2,i);
		double d1d1 = dx1*dx1 + dy1*dy1;
		mImgPt_reproj = mK2_ext * mRT * mWrdPts.GetCol(i);
		double dx2 = mImgPt_reproj(1) / mImgPt_reproj(3) - mImgPts2(1,i);
		double dy2 = mImgPt_reproj(2) / mImgPt_reproj(3) - mImgPts2(2,i);
		double d2d2 = dx2*dx2 + dy2*dy2;

		sumReprojErr += (d1d1 + d2d2);

		d1_reproj[i-1] = sqrt(d1d1);
		d2_reproj[i-1] = sqrt(d2d2);

		if (Z<=0)
		{
			status_neg[i-1] = 1;
			nNeg++;
		}
	}

	// if the percentage of points behind images are more than certain threshold
	// it means the assumption that the other image is on the right of the reference
	// is violated, it should be on the left of the reference
	if (nNeg/double(n)>0.5)
	{
		PIRO_Y_Z_AXAYAZ_levmar(mImgPts1_norm, mImgPts2_norm, mRT, -1, 1024, NULL, info, mCovar, &nIter);

		memset(status_neg,0,n*sizeof(int));
		memset(d1_reproj,0,n*sizeof(double));
		memset(d2_reproj,0,n*sizeof(double));
		sumPY = 0;
		sumReprojErr = 0;
		nNeg = 0;

		for (i = 1; i <= n; i++)
		{
			double X,Y,Z,py;
			Triangulate_PIRO_py(mImgPts1_norm(1, i), mImgPts1_norm(2, i), 1, mImgPts2_norm(1, i), mImgPts2_norm(2, i), 1,
				mRT, X, Y, Z, py);

			mWrdPts(1,i) = X;
			mWrdPts(2,i) = Y;
			mWrdPts(3,i) = Z;

			sumPY += (py*py)/(Z*Z);

			CMatrix mImgPt_reproj = mK1_ext * GenI(4) * mWrdPts.GetCol(i);
			double dx1 = mImgPt_reproj(1) / mImgPt_reproj(3) - mImgPts1(1,i);
			double dy1 = mImgPt_reproj(2) / mImgPt_reproj(3) - mImgPts1(2,i);
			double d1d1 = dx1*dx1 + dy1*dy1;
			mImgPt_reproj = mK2_ext * mRT * mWrdPts.GetCol(i);
			double dx2 = mImgPt_reproj(1) / mImgPt_reproj(3) - mImgPts2(1,i);
			double dy2 = mImgPt_reproj(2) / mImgPt_reproj(3) - mImgPts2(2,i);
			double d2d2 = dx2*dx2 + dy2*dy2;

			sumReprojErr += (d1d1 + d2d2);

			d1_reproj[i-1] = sqrt(d1d1);
			d2_reproj[i-1] = sqrt(d2d2);

			if (Z<=0)
			{
				status_neg[i-1] = 1;
				nNeg++;
			}
		}
	}

	double pyErr = sqrt(sumPY/n);
	double reprojErr = sqrt(sumReprojErr*0.5/n);

	double Y_stdev_levmar = sqrt(mCovar(1,1));
	double Z_stdev_levmar = sqrt(mCovar(2,2));

	// compute the angle between the optical axes of these two images
	CMatrix mZ_axis(3,1); mZ_axis(3) = 1;
	CMatrix mZ_axis_other = mRT.GetRect(1,1,3,3) * mZ_axis;
	CMatrix mCos = mZ_axis_other.Transpose()*mZ_axis/(mZ_axis_other.Norm()*mZ_axis.Norm());
	double cosa = mCos(1);
	double ang = acos(cosa) * 180 / CV_PI;

	if (Y_stdev_levmar >= thresh_stdev_YZ || Z_stdev_levmar >= thresh_stdev_YZ || 
		pyErr >= thresh_pyErr || reprojErr >= thresh_reprojErr || ang < thresh_ang)
	{
		// release
		delete [] status_neg;
		delete [] d1_reproj;
		delete [] d2_reproj;

		return false;
	}
	else
	{
		for (i=0;i<n;i++)
		{
			if (!status_neg[i])
			{
				CloudPoint cldpt;
				cldpt.m_pt.x = mWrdPts(1,i+1);
				cldpt.m_pt.y = mWrdPts(2,i+1);
				cldpt.m_pt.z = mWrdPts(3,i+1);

				CloudPoint_ImgInfo cldpt_info;
				cldpt_info.m_idxImg = idx_cam1;
				cldpt_info.m_idxImgPt = matches[i].queryIdx;
				cldpt_info.m_rpjErr = d1_reproj[i];
				cldpt.m_vImgInfos.push_back(cldpt_info);

				cldpt_info.m_idxImg = idx_cam2;
				cldpt_info.m_idxImgPt = matches[i].trainIdx;
				cldpt_info.m_rpjErr = d2_reproj[i];
				cldpt.m_vImgInfos.push_back(cldpt_info);
				
				clouds.push_back(cldpt);
			}
		}

		// release
		delete [] status_neg;
		delete [] d1_reproj;
		delete [] d2_reproj;

		return true;
	}
}

// this PIRO func conduct ro with given matches
// and the feature points in both cam_data are supposed to be distortion free
bool DeepVoid::RelativeOrientation_RANSAC_Features_PIRO_givenMatches(const cam_data & cam1,				// input:	all the information about the image 1
																	 const cam_data & cam2,				// input:	all the information about the image 2
																	 int idx_cam1,						// input:	the index of the first camera
																	 int idx_cam2,						// input:	the index of the second camera
																	 const vector<DMatch> & matches,	// input:	the given matches
																	 CMatrix & mRT,						// output:	4*4 matrix, the relative orientation of these two images [R|t; 0 0 0 1]
																	 vector<CloudPoint> & clouds,		// output:	the reconstructed cloud points in reference camera frame, which is the first image	
																	 double thresh_stdev_YZ /*= 0.08*/,	// input:	the threshold of standard deviation of Y and Z
																	 double thresh_reprojErr /*= 1*/,	// input:	the threshold of the reprojection error in pixels
																	 double thresh_pyErr /*= 0.001*/,	// input:	the threshold of the y-parallax error
																	 double thresh_ang /*= 30*/			// input:	the threshold of angle between optical axes
																	 )
{
	int i,j;

	int nFeat1 = cam1.m_feats.key_points.size();
	int nFeat2 = cam2.m_feats.key_points.size();

	CMatrix mK1(3, 3, 0), mK2(3, 3, 0);

	mK1(1,1) = cam1.fx; mK1(2,2) = cam1.fy;
	mK1(1,3) = cam1.cx; mK1(2,3) = cam1.cy;
	mK1(1,2) = cam1.s;  mK1(3,3) = 1;

	mK2(1,1) = cam2.fx; mK2(2,2) = cam2.fy;
	mK2(1,3) = cam2.cx; mK2(2,3) = cam2.cy;
	mK2(1,2) = cam2.s;  mK2(3,3) = 1;

	CMatrix mK1_ext = mK1.Clone();
	CMatrix mK2_ext = mK2.Clone();
	mK1_ext.AddOneCol(0);
	mK2_ext.AddOneCol(0);

	// the feature points in both cam_data are supposed to be distortion free 
	Features feat1_rectified = cam1.m_feats;
	Features feat2_rectified = cam2.m_feats;

	int n = matches.size();
	// 20140831, make sure there are at least 3 matches
	if (n<3)
	{
		return false;
	}

	CMatrix mImgPts1(3, n, 1), mImgPts2(3, n, 1);
	for (i=0;i<n;i++)
	{
		mImgPts1(1, i+1) = feat1_rectified.key_points[matches[i].queryIdx].pt.x;
		mImgPts1(2, i+1) = feat1_rectified.key_points[matches[i].queryIdx].pt.y;

		mImgPts2(1, i+1) = feat2_rectified.key_points[matches[i].trainIdx].pt.x;
		mImgPts2(2, i+1) = feat2_rectified.key_points[matches[i].trainIdx].pt.y;
	}

	// get normalized image points
	CMatrix mImgPts1_norm = mK1.Inverse() * mImgPts1;
	CMatrix mImgPts2_norm = mK2.Inverse() * mImgPts2;

	//////////////////////////////////////////////////////////////////////////
// 	vector<Point2d> nimgpts0,nimgpts1,imgpts0,imgpts1;
// 	for (i=0;i<n;i++)
// 	{
// 		Point2d nimgpt0,nimgpt1;
// 		nimgpt0.x = mImgPts1_norm(1,i+1);
// 		nimgpt0.y = mImgPts1_norm(2,i+1);
// 
// 		nimgpt1.x = mImgPts2_norm(1,i+1);
// 		nimgpt1.y = mImgPts2_norm(2,i+1);
// 
// 		nimgpts0.push_back(nimgpt0);
// 		nimgpts1.push_back(nimgpt1);
// 
// 		Point2d imgpt0, imgpt1;
// 		imgpt0.x=mImgPts1(1,i+1);
// 		imgpt0.y=mImgPts1(2,i+1);
// 		imgpt1.x=mImgPts2(1,i+1);
// 		imgpt1.y=mImgPts2(2,i+1);
// 
// 		imgpts0.push_back(imgpt0);
// 		imgpts1.push_back(imgpt1);
// 	}
// 
// 	Matx33d mKK0, mKK1;
// 	for (i=0;i<3;i++)
// 	{
// 		for (j=0;j<3;j++)
// 		{
// 			mKK0(i,j)=mK1(i+1,j+1);
// 			mKK1(i,j)=mK2(i+1,j+1);
// 		}
// 	}
// 
// 	double X,Y,Z,AX,AY,AZ;
// 	PIRO_Y_Z_AXAYAZ_GN(nimgpts0,nimgpts1,0,0,0,0,0,Y,Z,AX,AY,AZ,1);
// 	PIRO_X_Z_AXAYAZ_GN(nimgpts0,nimgpts1,0,0,0,0,0,X,Z,AX,AY,AZ,1);
// 	PIRO_X_Z_AXAYAZ_GN(nimgpts0,nimgpts1,0,0,0,0,0,X,Z,AX,AY,AZ,-1);
// 	Matx33d mR;
// 	Matx31d mt;
// 	vector<Point3d> vwrdpts;
// 	double err_rpj = PIRO_GN(imgpts0,imgpts1,mKK0,mKK1,mR,mt,vwrdpts);
	//////////////////////////////////////////////////////////////////////////

	double info[10]; CMatrix mCovar; int nIter;

	PIRO_Y_Z_AXAYAZ_levmar(mImgPts1_norm, mImgPts2_norm, mRT, 1, 1024, NULL, info, mCovar, &nIter);

	// record which points' Z coordinates are negative or 0
	int * status_neg = new int[n];
	memset(status_neg,0,n*sizeof(int));

	double * d1_reproj = new double [n];
	double * d2_reproj = new double [n];
	memset(d1_reproj,0,n*sizeof(double));
	memset(d2_reproj,0,n*sizeof(double));

	CMatrix mWrdPts(4, n, 1);

	double sumPY = 0;
	double sumReprojErr = 0;
	int nNeg = 0;

	for (i = 1; i <= n; i++)
	{
		double X,Y,Z,py;
		Triangulate_PIRO_py(mImgPts1_norm(1, i), mImgPts1_norm(2, i), 1, mImgPts2_norm(1, i), mImgPts2_norm(2, i), 1,
			mRT, X, Y, Z, py);

		mWrdPts(1,i) = X;
		mWrdPts(2,i) = Y;
		mWrdPts(3,i) = Z;

		sumPY += (py*py)/(Z*Z);

		CMatrix mImgPt_reproj = mK1_ext * GenI(4) * mWrdPts.GetCol(i);
		double dx1 = mImgPt_reproj(1) / mImgPt_reproj(3) - mImgPts1(1,i);
		double dy1 = mImgPt_reproj(2) / mImgPt_reproj(3) - mImgPts1(2,i);
		double d1d1 = dx1*dx1 + dy1*dy1;
		mImgPt_reproj = mK2_ext * mRT * mWrdPts.GetCol(i);
		double dx2 = mImgPt_reproj(1) / mImgPt_reproj(3) - mImgPts2(1,i);
		double dy2 = mImgPt_reproj(2) / mImgPt_reproj(3) - mImgPts2(2,i);
		double d2d2 = dx2*dx2 + dy2*dy2;

		sumReprojErr += (d1d1 + d2d2);

		d1_reproj[i-1] = sqrt(d1d1);
		d2_reproj[i-1] = sqrt(d2d2);

		if (Z<=0)
		{
			status_neg[i-1] = 1;
			nNeg++;
		}
	}

	// if the percentage of points behind images are more than certain threshold
	// it means the assumption that the other image is on the right of the reference
	// is violated, it should be on the left of the reference
	if (nNeg/double(n)>0.5)
	{
		PIRO_Y_Z_AXAYAZ_levmar(mImgPts1_norm, mImgPts2_norm, mRT, -1, 1024, NULL, info, mCovar, &nIter);

		memset(status_neg,0,n*sizeof(int));
		memset(d1_reproj,0,n*sizeof(double));
		memset(d2_reproj,0,n*sizeof(double));
		sumPY = 0;
		sumReprojErr = 0;
		nNeg = 0;

		for (i = 1; i <= n; i++)
		{
			double X,Y,Z,py;
			Triangulate_PIRO_py(mImgPts1_norm(1, i), mImgPts1_norm(2, i), 1, mImgPts2_norm(1, i), mImgPts2_norm(2, i), 1,
				mRT, X, Y, Z, py);

			mWrdPts(1,i) = X;
			mWrdPts(2,i) = Y;
			mWrdPts(3,i) = Z;

			sumPY += (py*py)/(Z*Z);

			CMatrix mImgPt_reproj = mK1_ext * GenI(4) * mWrdPts.GetCol(i);
			double dx1 = mImgPt_reproj(1) / mImgPt_reproj(3) - mImgPts1(1,i);
			double dy1 = mImgPt_reproj(2) / mImgPt_reproj(3) - mImgPts1(2,i);
			double d1d1 = dx1*dx1 + dy1*dy1;
			mImgPt_reproj = mK2_ext * mRT * mWrdPts.GetCol(i);
			double dx2 = mImgPt_reproj(1) / mImgPt_reproj(3) - mImgPts2(1,i);
			double dy2 = mImgPt_reproj(2) / mImgPt_reproj(3) - mImgPts2(2,i);
			double d2d2 = dx2*dx2 + dy2*dy2;

			sumReprojErr += (d1d1 + d2d2);

			d1_reproj[i-1] = sqrt(d1d1);
			d2_reproj[i-1] = sqrt(d2d2);

			if (Z<=0)
			{
				status_neg[i-1] = 1;
				nNeg++;
			}
		}
	}

	double pyErr = sqrt(sumPY/n);
	double reprojErr = sqrt(sumReprojErr*0.5/n);

	double Y_stdev_levmar = sqrt(mCovar(1,1));
	double Z_stdev_levmar = sqrt(mCovar(2,2));

	// compute the angle between the optical axes of these two images
	CMatrix mZ_axis(3,1); mZ_axis(3) = 1;
	CMatrix mZ_axis_other = mRT.GetRect(1,1,3,3) * mZ_axis;
	CMatrix mCos = mZ_axis_other.Transpose()*mZ_axis/(mZ_axis_other.Norm()*mZ_axis.Norm());
	double cosa = mCos(1);
	double ang = acos(cosa) * 180 / CV_PI;

	if (Y_stdev_levmar >= thresh_stdev_YZ || Z_stdev_levmar >= thresh_stdev_YZ || 
		pyErr >= thresh_pyErr || reprojErr >= thresh_reprojErr || ang < thresh_ang)
	{
		// release
		delete [] status_neg;
		delete [] d1_reproj;
		delete [] d2_reproj;

		return false;
	}
	else
	{
		for (i=0;i<n;i++)
		{
			if (!status_neg[i])
			{
				if (cam1.m_feats.tracks[matches[i].queryIdx] == -1 || cam2.m_feats.tracks[matches[i].trainIdx] == -1 ||
					cam1.m_feats.tracks[matches[i].queryIdx] != cam2.m_feats.tracks[matches[i].trainIdx])
				{
					// if the matched features do not belong to the same track
					// the reconstructed object coordinates will not be accepted
					continue;
				}

				CloudPoint cldpt;
				cldpt.m_pt.x = mWrdPts(1,i+1);
				cldpt.m_pt.y = mWrdPts(2,i+1);
				cldpt.m_pt.z = mWrdPts(3,i+1);

				cldpt.m_idx = cam1.m_feats.tracks[matches[i].queryIdx];

				CloudPoint_ImgInfo cldpt_info;
				cldpt_info.m_idxImg = idx_cam1;
				cldpt_info.m_idxImgPt = matches[i].queryIdx;
				cldpt_info.m_rpjErr = d1_reproj[i];
				cldpt.m_vImgInfos.push_back(cldpt_info);

				cldpt_info.m_idxImg = idx_cam2;
				cldpt_info.m_idxImgPt = matches[i].trainIdx;
				cldpt_info.m_rpjErr = d2_reproj[i];
				cldpt.m_vImgInfos.push_back(cldpt_info);

				clouds.push_back(cldpt);
			}
		}

		// release
		delete [] status_neg;
		delete [] d1_reproj;
		delete [] d2_reproj;

		return true;
	}
}

// 20150115, zhaokunz, this PIRO func conduct ro with given matches
// and the feature points in both cam_data are supposed to be distortion free
bool DeepVoid::RelativeOrientation_Features_PIRO_givenMatches(const cam_data & cam1,			// input:	all the information about the image 1
															  const cam_data & cam2,			// input:	all the information about the image 2
															  int idx_cam1,						// input:	the index of the first camera
															  int idx_cam2,						// input:	the index of the second camera
															  const vector<DMatch> & matches,	// input:	the given matches
															  CMatrix & mRT,					// output:	4*4 matrix, the relative orientation of these two images [R|t; 0 0 0 1]
															  vector<CloudPoint> & clouds,		// output:	the reconstructed cloud points in reference camera frame, which is the first image
															  double thresh_reprojErr /*= 1*/	// input:	the threshold of the reprojection error in pixels
															  )
{
	int i,j;

	int nFeat1 = cam1.m_feats.key_points.size();
	int nFeat2 = cam2.m_feats.key_points.size();

	// the feature points in both cam_data are supposed to be distortion free 
	Features feat1_rectified = cam1.m_feats;
	Features feat2_rectified = cam2.m_feats;

	int n = matches.size();
	// 20140831, make sure there are at least 3 matches
	if (n<3)
	{
		return false;
	}

	vector<Point2d> imgpts0,imgpts1;
	for (i=0;i<n;i++)
	{
		Point2d imgpt0, imgpt1;
		imgpt0.x=feat1_rectified.key_points[matches[i].queryIdx].pt.x;
		imgpt0.y=feat1_rectified.key_points[matches[i].queryIdx].pt.y;
		imgpt1.x=feat2_rectified.key_points[matches[i].trainIdx].pt.x;
		imgpt1.y=feat2_rectified.key_points[matches[i].trainIdx].pt.y;

		imgpts0.push_back(imgpt0);
		imgpts1.push_back(imgpt1);
	}

	Matx33d mK0, mK1;
	
	mK0(0,0) = cam1.fx; mK0(1,1) = cam1.fy;
	mK0(0,2) = cam1.cx; mK0(1,2) = cam1.cy;
	mK0(0,1) = cam1.s;  mK0(2,2) = 1;

	mK1(0,0) = cam2.fx; mK1(1,1) = cam2.fy;
	mK1(0,2) = cam2.cx; mK1(1,2) = cam2.cy;
	mK1(0,1) = cam2.s;  mK1(2,2) = 1;

	Matx33d mR;
	Matx31d mt;
	vector<Point3d> vwrdpts;
	double err_rpj = PIRO_GN(imgpts0,imgpts1,mK0,mK1,mR,mt,vwrdpts);

	mRT = CMatrix(4,4,0);
	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mRT(i+1,j+1)=mR(i,j);
		}
	}
	mRT(1,4)=mt(0);
	mRT(2,4)=mt(1);
	mRT(3,4)=mt(2);
	mRT(4,4)=1;

	// record which points' Z coordinates are negative or 0
	vector<bool> status_neg(n);
	for (i=0;i<n;i++)
	{
		if (vwrdpts[i].z<=0)
		{
			status_neg[i]=true;
		}
	}

	if (err_rpj>=thresh_reprojErr)
	{
		return false;
	}
	else
	{
		for (i=0;i<n;i++)
		{
			if (!status_neg[i])
			{
				if (cam1.m_feats.tracks[matches[i].queryIdx] == -1 || cam2.m_feats.tracks[matches[i].trainIdx] == -1 ||
					cam1.m_feats.tracks[matches[i].queryIdx] != cam2.m_feats.tracks[matches[i].trainIdx])
				{
					// if the matched features do not belong to the same track
					// the reconstructed object coordinates will not be accepted
					continue;
				}

				Point3d pt = vwrdpts[i];

				CloudPoint cldpt;
				cldpt.m_pt.x = pt.x;
				cldpt.m_pt.y = pt.y;
				cldpt.m_pt.z = pt.z;

				cldpt.m_idx = cam1.m_feats.tracks[matches[i].queryIdx];

				CloudPoint_ImgInfo cldpt_info;
				cldpt_info.m_idxImg = idx_cam1;
				cldpt_info.m_idxImgPt = matches[i].queryIdx;
//				cldpt_info.m_rpjErr = d1_reproj[i];
				cldpt.m_vImgInfos.push_back(cldpt_info);

				cldpt_info.m_idxImg = idx_cam2;
				cldpt_info.m_idxImgPt = matches[i].trainIdx;
//				cldpt_info.m_rpjErr = d2_reproj[i];
				cldpt.m_vImgInfos.push_back(cldpt_info);

				clouds.push_back(cldpt);
			}
		}

		return true;
	}
}

void DeepVoid::Triangulate_PIRO_py(double nx1, double ny1, double nz1,	// input:	the normalized image coordinates in reference image
								   double nx2, double ny2, double nz2,	// input:	the normalized image coordinates in the other image
								   const CMatrix & mRT,					// input:	the relative orientation
								   double & X, double & Y, double & Z,	// output:	the reconstructed 3d coordinates
								   double & py							// output:	the y-parallax
								   )
{
	CMatrix mR = mRT.GetRect(1,1,3,3);
	CMatrix mOptCnt = -mR.Transpose() * mRT.GetRect(1,4,1,3);

	double bx = mOptCnt(1);
	double by = mOptCnt(2);
	double bz = mOptCnt(3);

	CMatrix mx2(3,1);
	mx2(1)=nx2;
	mx2(2)=ny2;
	mx2(3)=nz2;

	mx2 = mR.Transpose()*mx2;

	double nnx2 = mx2(1);
	double nny2 = mx2(2);
	double nnz2 = mx2(3);

	double de = nx1*nnz2-nz1*nnx2;

	double a = (bx*nnz2-bz*nnx2)/de;
	double b = (bx*nz1 -bz*nx1 )/de;

	X = a*nx1;
	Z = a*nz1;
	
	double Y1 = a*ny1;
	double Y2 = b*nny2+by;

	Y = (Y1+Y2)/2;

	py = Y2-Y1;
}


/*-----------------------------------------------------------*/
/* 求非线性优化各种目标函数相关的导数，即Jacobian matrix        */

// 图像重投影误差的目标函数 fi = ((xi - xi')^2 + (yi - yi')^2)^0.5，其中 i 表示第 i 个控制点
// dfi/dx = (xi - xi')/fi   dfi/dy = (yi - yi')/fi，函数输入n个控制点的话，函数就输入一个n×2的Jacobian matrix
// 其中每一行为(dfi/dx	dfi/dy)
// mImgPtReproj和mImgPtReal保证尺寸一致即可，齐次或非齐次都可，只要尺寸一致
CMatrix DeepVoid::Jacobian_Fi_xy(const CMatrix & mImgPtReproj, const CMatrix & mImgPtReal)
{
	if ((mImgPtReproj.m_nCol != mImgPtReal.m_nCol) || (mImgPtReproj.m_nRow != mImgPtReal.m_nRow))
	{
		// 两输入点集要是点数不一致则返回空矩阵
		return CMatrix(0); 
	}

	int ptNum = mImgPtReproj.m_nCol;

	CMatrix mJacob(ptNum, 2), mError(mImgPtReproj.m_nRow, 1);

	int i; double d;
	for (i = 1; i <= ptNum; i++)
	{
		mError = mImgPtReproj.GetCol(i) - mImgPtReal.GetCol(i);
		d = mError.Norm();

		mJacob(i, 1) = mError(1) / d;
		mJacob(i, 2) = mError(2) / d;
	}

	return mJacob;
}

// 归一化的像点坐标(nx, ny)对旋转矩阵每个元素ri，以及平移向量 (tx, ty, tz) 总共12个元素进行求导，输出 2×12 的Jacobian matrix
// mRT为4×4的矩阵，mWrdPt为一维列向量
CMatrix DeepVoid::Jacobian_nxny_RT(const CMatrix & mRT, const CMatrix & mWrdPt)
{
	double r1 = mRT(1, 1); double r2 = mRT(1, 2); double r3 = mRT(1, 3); double tx = mRT(1, 4);
	double r4 = mRT(2, 1); double r5 = mRT(2, 2); double r6 = mRT(2, 3); double ty = mRT(2, 4);
	double r7 = mRT(3, 1); double r8 = mRT(3, 2); double r9 = mRT(3, 3); double tz = mRT(3, 4);

	double X = mWrdPt(1, 1);
	double Y = mWrdPt(2, 1);
	double Z = mWrdPt(3, 1);

	double fx1 = r1 * X + r2 * Y + r3 * Z + tx;
	double fx2 = r4 * X + r5 * Y + r6 * Z + ty;
	double gx  = r7 * X + r8 * Y + r9 * Z + tz;

	CMatrix mJacob(2, 12);

	mJacob(1, 1)  = X / gx; // dnx/dr1
	mJacob(1, 2)  = Y / gx; // dnx/dr2
	mJacob(1, 3)  = Z / gx; // dnx/dr3
	mJacob(1, 7)  = (-X * fx1) / (gx * gx); // dnx/dr7
	mJacob(1, 8)  = (-Y * fx1) / (gx * gx); // dnx/dr8
	mJacob(1, 9)  = (-Z * fx1) / (gx * gx); // dnx/dr9
	mJacob(1, 10) = 1 / gx; // dnx/dtx
	mJacob(1, 12) = (-fx1) / (gx * gx); // dnx/dtz

	mJacob(2, 4)  = X / gx; // dny/dr4
	mJacob(2, 5)  = Y / gx; // dny/dr5
	mJacob(2, 6)  = Z / gx; // dny/dr6
	mJacob(2, 7)  = (-X * fx2) / (gx * gx); // dny/dr7
	mJacob(2, 8)  = (-Y * fx2) / (gx * gx); // dny/dr8
	mJacob(2, 9)  = (-Z * fx2) / (gx * gx); // dny/dr9
	mJacob(2, 11) = 1 / gx; // dny/dty
	mJacob(2, 12) = (-fx2) / (gx * gx); // dny/dtz

	return mJacob;
}

// 正常像点坐标(x, y)对旋转矩阵每个元素ri，以及平移向量 (tx, ty, tz) 总共12个元素进行求导，输出 2×12 的Jacobian matrix
// mRT为4×4的矩阵，mWrdPt为一维列向量，mK为像机内参数矩阵3×3或3×4的皆可
CMatrix DeepVoid::Jacobian_xy_RT(const CMatrix & mRT, const CMatrix & mK, const CMatrix & mWrdPt)
{
	double r1 = mRT(1, 1); double r2 = mRT(1, 2); double r3 = mRT(1, 3); double tx = mRT(1, 4);
	double r4 = mRT(2, 1); double r5 = mRT(2, 2); double r6 = mRT(2, 3); double ty = mRT(2, 4);
	double r7 = mRT(3, 1); double r8 = mRT(3, 2); double r9 = mRT(3, 3); double tz = mRT(3, 4);

	double fx = mK(1, 1);
	double fy = mK(2, 2);
	double cx = mK(1, 3);
	double cy = mK(2, 3);

	double X = mWrdPt(1, 1);
	double Y = mWrdPt(2, 1);
	double Z = mWrdPt(3, 1);

	double f1 = (r1 * X + r2 * Y + r3 * Z + tx) * fx;
	double f2 = (r4 * X + r5 * Y + r6 * Z + ty) * fy;
	double g  = r7 * X + r8 * Y + r9 * Z + tz;

	CMatrix mJacob(2, 12);

// 	mJacob(1, 1)  = (fx * X) / g; // dx/dr1
// 	mJacob(1, 2)  = (fx * Y) / g; // dx/dr2
// 	mJacob(1, 3)  = (fx * Z) / g; // dx/dr3
// 	mJacob(1, 7)  = (-X * f1) / (g * g); // dx/dr7
// 	mJacob(1, 8)  = (-Y * f1) / (g * g); // dx/dr8
// 	mJacob(1, 9)  = (-Z * f1) / (g * g); // dx/dr9
// 	mJacob(1, 10) = fx / g; // dx/dtx
// 	mJacob(1, 12) = (-f1) / (g * g); // dx/dtz
// 
// 	mJacob(2, 4)  = (fy * X) / g; // dy/dr4
// 	mJacob(2, 5)  = (fy * Y) / g; // dy/dr5
// 	mJacob(2, 6)  = (fy * Z) / g; // dy/dr6
// 	mJacob(2, 7)  = (-X * f2) / (g * g); // dy/dr7
// 	mJacob(2, 8)  = (-Y * f2) / (g * g); // dy/dr8
// 	mJacob(2, 9)  = (-Z * f2) / (g * g); // dy/dr9
// 	mJacob(2, 11) = fy / g; // dy/dty
// 	mJacob(2, 12) = (-f2) / (g * g); // dy/dtz

	double ginv = 1/g;
	double g2inv = ginv*ginv;

	mJacob(1, 1)  = (fx * X) * ginv; // dx/dr1
	mJacob(1, 2)  = (fx * Y) * ginv; // dx/dr2
	mJacob(1, 3)  = (fx * Z) * ginv; // dx/dr3
	mJacob(1, 7)  = (-X * f1) * g2inv; // dx/dr7
	mJacob(1, 8)  = (-Y * f1) * g2inv; // dx/dr8
	mJacob(1, 9)  = (-Z * f1) * g2inv; // dx/dr9
	mJacob(1, 10) = fx * ginv; // dx/dtx
	mJacob(1, 12) = (-f1) * g2inv; // dx/dtz

	mJacob(2, 4)  = (fy * X) * ginv; // dy/dr4
	mJacob(2, 5)  = (fy * Y) * ginv; // dy/dr5
	mJacob(2, 6)  = (fy * Z) * ginv; // dy/dr6
	mJacob(2, 7)  = (-X * f2) * g2inv; // dy/dr7
	mJacob(2, 8)  = (-Y * f2) * g2inv; // dy/dr8
	mJacob(2, 9)  = (-Z * f2) * g2inv; // dy/dr9
	mJacob(2, 11) = fy * ginv; // dy/dty
	mJacob(2, 12) = (-f2) * g2inv; // dy/dtz

	return mJacob;
}

// 正常像点坐标(x, y)对旋转矩阵每个元素ri，以及平移向量 (tx, ty, tz) 总共12个元素进行求导，输出 2×12 的Jacobian matrix
CMatrix DeepVoid::Jacobian_xy_RT(const CMatrix & mRT,        // 输入： 4×4 的像机外参数矩阵
								 const CMatrix & mK,         // 输入： 3×4 或者 3×3 的像机内参数矩阵
								 double X,                   // 输入： 该点的齐次空间坐标
								 double Y,                   // 输入： 该点的齐次空间坐标
								 double Z,                   // 输入： 该点的齐次空间坐标
								 double W                    // 输入： 该点的齐次空间坐标
								 )
{
	double r1 = mRT(1, 1); double r2 = mRT(1, 2); double r3 = mRT(1, 3); double tx = mRT(1, 4);
	double r4 = mRT(2, 1); double r5 = mRT(2, 2); double r6 = mRT(2, 3); double ty = mRT(2, 4);
	double r7 = mRT(3, 1); double r8 = mRT(3, 2); double r9 = mRT(3, 3); double tz = mRT(3, 4);

	double fx = mK(1, 1);
	double fy = mK(2, 2);
	double cx = mK(1, 3);
	double cy = mK(2, 3);

	double f1 = (r1 * X + r2 * Y + r3 * Z + tx * W) * fx;
	double f2 = (r4 * X + r5 * Y + r6 * Z + ty * W) * fy;
	double g  =  r7 * X + r8 * Y + r9 * Z + tz * W;

	CMatrix mJacob(2, 12, 0);

	mJacob(1, 1)  = (fx * X) / g; // dx/dr1
	mJacob(1, 2)  = (fx * Y) / g; // dx/dr2
	mJacob(1, 3)  = (fx * Z) / g; // dx/dr3
	mJacob(1, 7)  = (-X * f1) / (g * g); // dx/dr7
	mJacob(1, 8)  = (-Y * f1) / (g * g); // dx/dr8
	mJacob(1, 9)  = (-Z * f1) / (g * g); // dx/dr9
	mJacob(1, 10) = (fx * W) / g; // dx/dtx
	mJacob(1, 12) = (-f1 * W) / (g * g); // dx/dtz

	mJacob(2, 4)  = (fy * X) / g; // dy/dr4
	mJacob(2, 5)  = (fy * Y) / g; // dy/dr5
	mJacob(2, 6)  = (fy * Z) / g; // dy/dr6
	mJacob(2, 7)  = (-X * f2) / (g * g); // dy/dr7
	mJacob(2, 8)  = (-Y * f2) / (g * g); // dy/dr8
	mJacob(2, 9)  = (-Z * f2) / (g * g); // dy/dr9
	mJacob(2, 11) = (fy * W) / g; // dy/dty
	mJacob(2, 12) = (-f2 * W) / (g * g); // dy/dtz

	return mJacob;
}

// 正常像点坐标(x, y)对内参数fx, fy, cx, cy进行求导，输出2×4的Jacobian matrix
// mRT为4×4的矩阵，mWrdPt为一维列向量
CMatrix DeepVoid::Jacobian_xy_fxfycxcy(const CMatrix & mRT, const CMatrix & mWrdPt)
{
	double r1 = mRT(1, 1); double r2 = mRT(1, 2); double r3 = mRT(1, 3); double tx = mRT(1, 4);
	double r4 = mRT(2, 1); double r5 = mRT(2, 2); double r6 = mRT(2, 3); double ty = mRT(2, 4);
	double r7 = mRT(3, 1); double r8 = mRT(3, 2); double r9 = mRT(3, 3); double tz = mRT(3, 4);

	double X = mWrdPt(1, 1);
	double Y = mWrdPt(2, 1);
	double Z = mWrdPt(3, 1);

	double f1 = r1 * X + r2 * Y + r3 * Z + tx;
	double f2 = r4 * X + r5 * Y + r6 * Z + ty;
	double g  = r7 * X + r8 * Y + r9 * Z + tz;

	CMatrix mJacob(2, 4);

	mJacob(1, 1) = f1 / g;	mJacob(1, 2) = 0;		mJacob(1, 3) = 1;	mJacob(1, 4) = 0;
	mJacob(2, 1) =      0;	mJacob(2, 2) = f2 / g;	mJacob(2, 3) = 0;	mJacob(2, 4) = 1;

	return mJacob;
}

// Weng's像差(du, dv)对归一化像点坐标(nx, ny)进行求导，输出2×2的Jacobian matrix
// mImgPtNorm为一归一化像点坐标，mK为内参数矩阵，3×3或3×4皆可，mDist为Weng's像差系数
CMatrix DeepVoid::Jacobian_dudv_xyNorm_Weng(const CMatrix & mImgPtNorm, const CMatrix & mK, const CMatrix & mDist)
{
	double x = mImgPtNorm(1, 1);
	double y = mImgPtNorm(2, 1);

	double x2 = x * x;
	double y2 = y * y;
	double xy = x * y;

	double fx = mK(1, 1);
	double fy = mK(2, 2);

	double k1 = mDist(1);
	double k2 = mDist(2);
	double k3 = mDist(3);
	double k4 = mDist(4);
	double k5 = mDist(5);

	CMatrix mJacob(2, 2);

	mJacob(1, 1) = 3*k1*fx*x2  +    k1*fx*y2  +  2*k2*fx*x  +  2*k4*fx*x +   k5*fx*y; // α(du) / α(nx)
	mJacob(1, 2) = 2*k1*fx*xy  +  2*k2*fx*y   +    k5*fx*x;                           // α(du) / α(ny)

	mJacob(2, 1) = 2*k1*fy*xy  +  2*k3*fy*x   +    k4*fy*y;                           // α(dv) / α(nx)
	mJacob(2, 2) =   k1*fy*x2  +  3*k1*fy*y2  +  2*k3*fy*y  +    k4*fy*x + 2*k5*fy*y; // α(dv) / α(ny)

	return mJacob;
}


// Weng's像差(du, dv)对理想像点坐标(x, y)进行求导，输出2×2的Jacobian matrix
// mImgPt为一理想像点坐标，mK为内参数矩阵，3×3或3×4皆可，mDist为Weng's像差系数
CMatrix DeepVoid::Jacobian_dudv_xy_Weng(const CMatrix & mImgPt, const CMatrix & mK, const CMatrix & mDist)
{
	double x = mImgPt(1, 1);
	double y = mImgPt(2, 1);

	double fx = mK(1, 1);
	double fy = mK(2, 2);
	double cx = mK(1, 3);
	double cy = mK(2, 3);

	double nx = (x - cx) / fx;
	double ny = (y - cy) / fy;

	CMatrix mImgPtNorm(2, 1);
	mImgPtNorm(1) = nx;
	mImgPtNorm(2) = ny;

	CMatrix mJacob = Jacobian_dudv_xyNorm_Weng(mImgPtNorm, mK, mDist);

	CMatrix mTmp(2, 2, 0);
	mTmp(1, 1) = 1 / fx;
	mTmp(2, 2) = 1 / fy;

	mJacob = mJacob * mTmp;

	return mJacob;
}

// 带像差的重投影像点坐标对理想像点坐标(x, y)进行求导，输出2×2的Jacobian matrix
// mImgPt为一理想像点坐标，mK为内参数矩阵，3×3或3×4皆可，mDist为Weng's像差系数
CMatrix DeepVoid::Jacobian_distxy_xy_Weng(const CMatrix & mImgPt, const CMatrix & mK, const CMatrix & mDist)
{
	CMatrix mEye(2, 2, 0);
	mEye(1, 1) = 1;
	mEye(2, 2) = 1;

	CMatrix mJacob = mEye + Jacobian_dudv_xy_Weng(mImgPt, mK, mDist);

	return mJacob;
}

// 带像差的重投影像点坐标对5个weng's像差系数进行求导，输出2×5的Jacobian matrix
// mImgPt为线性重投影的理想像点坐标，mK为内参数矩阵，3×3或3×4皆可
CMatrix DeepVoid::Jacobian_distxy_ki_Weng(const CMatrix & mImgPt, const CMatrix & mK)
{
	// 取出线性重投影像点坐标
	double x = mImgPt(1, 1);
	double y = mImgPt(2, 1);

	// 取出像机内参数
	double fx = mK(1, 1);
	double fy = mK(2, 2);
	double cx = mK(1, 3);
	double cy = mK(2, 3);

	// 计算得到归一化线性重投影像点坐标
	double nx = (x - cx) / fx;
	double ny = (y - cy) / fy;

	// 生成Jacobian matrix
	CMatrix mJacob(2, 5);

	mJacob(1, 1) = fx*nx*nx*nx + fx*nx*ny*ny;	mJacob(1, 2) = fx*nx*nx + fx*ny*ny;	mJacob(1, 3) = 0;					mJacob(1, 4) = fx*nx*nx;	mJacob(1, 5) = fx*nx*ny;
	mJacob(2, 1) = fy*ny*nx*nx + fy*ny*ny*ny;	mJacob(2, 2) = 0;					mJacob(2, 3) = fy*nx*nx + fy*ny*ny; mJacob(2, 4) = fy*nx*ny;	mJacob(2, 5) = fy*ny*ny; 

	return mJacob;
}

// 外参矩阵的12个元素对6个外参数(yaw, pitch, roll, tx, ty, tz)进行求导，输出12×6的Jacobian matrix
// mExtPara为6维的列向量
CMatrix DeepVoid::Jacobian_RT_ExtPara(const CMatrix & mExtPara)
{
	double yaw   = mExtPara(1); // 偏航角
	double pitch = mExtPara(2); // 俯仰角
	double roll  = mExtPara(3); // 滚转角

	double sx = sind(roll);
	double cx = cosd(roll);
	double sy = sind(pitch);
	double cy = cosd(pitch);
	double sz = sind(yaw);
	double cz = cosd(yaw);

	CMatrix mJacob(12, 6);

	// 	mJacob(1, 1)  = -cy * sz;					mJacob(1, 2)  = -cz * sy;		mJacob(1, 3)  =        0;					mJacob(1, 4)  = 0;	mJacob(1, 5)  = 0;	mJacob(1, 6)  = 0;
	// 	mJacob(2, 1)  = -cy * cz;					mJacob(2, 2)  =  sy * sz;		mJacob(2, 3)  =        0;					mJacob(2, 4)  = 0;	mJacob(2, 5)  = 0;	mJacob(2, 6)  = 0;
	// 	mJacob(3, 1)  =        0;					mJacob(3, 2)  =       cy;		mJacob(3, 3)  =        0;					mJacob(3, 4)  = 0;	mJacob(3, 5)  = 0;	mJacob(3, 6)  = 0;
	// 	mJacob(4, 1)  =  cx * cz - sx * sy * sz;	mJacob(4, 2)  =  cy * cz * sx;	mJacob(4, 3)  =  cx * cz * sy - sx * sz;	mJacob(4, 4)  = 0;	mJacob(4, 5)  = 0;	mJacob(4, 6)  = 0;
	// 	mJacob(5, 1)  = -cx * sz - cz * sx * sy; 	mJacob(5, 2)  = -cy * sx * sz;  mJacob(5, 3)  = -cz * sx - cx * sy * sz; 	mJacob(5, 4)  = 0;	mJacob(5, 5)  = 0;	mJacob(5, 6)  = 0;
	// 	mJacob(6, 1)  =	       0;					mJacob(6, 2)  =  sx * sy;		mJacob(6, 3)  = -cx * cy;					mJacob(6, 4)  = 0;	mJacob(6, 5)  = 0;	mJacob(6, 6)  = 0;
	// 	mJacob(7, 1)  =  cz * sx + cx * sy * sz;	mJacob(7, 2)  = -cx * cy * cz;	mJacob(7, 3)  =  cx * sz + cz * sx * sy;	mJacob(7, 4)  = 0;	mJacob(7, 5)  = 0;	mJacob(7, 6)  = 0;
	// 	mJacob(8, 1)  =  cx * cz * sy - sx * sz;	mJacob(8, 2)  =  cx * cy * sz;	mJacob(8, 3)  =  cx * cz - sx * sy * sz;	mJacob(8, 4)  = 0;	mJacob(8, 5)  = 0;	mJacob(8, 6)  = 0;
	// 	mJacob(9, 1)  =        0;					mJacob(9, 2)  = -cx * sy;		mJacob(9, 3)  = -cy * sx;					mJacob(9, 4)  = 0;	mJacob(9, 5)  = 0;	mJacob(9, 6)  = 0;
	// 	mJacob(10, 1) =        0;					mJacob(10, 2) =        0;		mJacob(10, 3) =        0;					mJacob(10, 4) = 1;	mJacob(10, 5) = 0;	mJacob(10, 6) = 0;
	// 	mJacob(11, 1) =        0;					mJacob(11, 2) =        0;		mJacob(11, 3) =        0;					mJacob(11, 4) = 0;	mJacob(11, 5) = 1;	mJacob(11, 6) = 0;
	// 	mJacob(12, 1) =        0;					mJacob(12, 2) =        0;		mJacob(12, 3) =        0;					mJacob(12, 4) = 0;	mJacob(12, 5) = 0;	mJacob(12, 6) = 1;


	// 2012.11.06，若用角度表示而非弧度，则比方说函数 cos(a * pi/180) * sin(b * pi/180) 对角度 a 求偏导的话应该是 -pi/180 * sin(a * pi/180) * sin(b * pi/180)
	double pi_div_180 = CV_PI / 180.0;

	mJacob(1, 1)  = -pi_div_180 * cy * sz;					mJacob(1, 2)  = -pi_div_180 * cz * sy;		mJacob(1, 3)  =        0;								mJacob(1, 4)  = 0;	mJacob(1, 5)  = 0;	mJacob(1, 6)  = 0;
	mJacob(2, 1)  = -pi_div_180 * cy * cz;					mJacob(2, 2)  =  pi_div_180 * sy * sz;		mJacob(2, 3)  =        0;								mJacob(2, 4)  = 0;	mJacob(2, 5)  = 0;	mJacob(2, 6)  = 0;
	mJacob(3, 1)  =        0;								mJacob(3, 2)  =  pi_div_180 * cy;			mJacob(3, 3)  =        0;								mJacob(3, 4)  = 0;	mJacob(3, 5)  = 0;	mJacob(3, 6)  = 0;
	mJacob(4, 1)  =  pi_div_180 * (cx * cz - sx * sy * sz);	mJacob(4, 2)  =  pi_div_180 * cy * cz * sx;	mJacob(4, 3)  =  pi_div_180 * (cx * cz * sy - sx * sz);	mJacob(4, 4)  = 0;	mJacob(4, 5)  = 0;	mJacob(4, 6)  = 0;
	mJacob(5, 1)  =  pi_div_180 * (-cx * sz - cz * sx * sy);mJacob(5, 2)  = -pi_div_180 * cy * sx * sz; mJacob(5, 3)  =  pi_div_180 * (-cz * sx - cx * sy * sz);mJacob(5, 4)  = 0;	mJacob(5, 5)  = 0;	mJacob(5, 6)  = 0;
	mJacob(6, 1)  =	       0;								mJacob(6, 2)  =  pi_div_180 * sx * sy;		mJacob(6, 3)  = -pi_div_180 * cx * cy;					mJacob(6, 4)  = 0;	mJacob(6, 5)  = 0;	mJacob(6, 6)  = 0;
	mJacob(7, 1)  =  pi_div_180 * (cz * sx + cx * sy * sz);	mJacob(7, 2)  = -pi_div_180 * cx * cy * cz;	mJacob(7, 3)  =  pi_div_180 * (cx * sz + cz * sx * sy);	mJacob(7, 4)  = 0;	mJacob(7, 5)  = 0;	mJacob(7, 6)  = 0;
	mJacob(8, 1)  =  pi_div_180 * (cx * cz * sy - sx * sz);	mJacob(8, 2)  =  pi_div_180 * cx * cy * sz;	mJacob(8, 3)  =  pi_div_180 * (cx * cz - sx * sy * sz);	mJacob(8, 4)  = 0;	mJacob(8, 5)  = 0;	mJacob(8, 6)  = 0;
	mJacob(9, 1)  =        0;								mJacob(9, 2)  = -pi_div_180 * cx * sy;		mJacob(9, 3)  = -pi_div_180 * cy * sx;					mJacob(9, 4)  = 0;	mJacob(9, 5)  = 0;	mJacob(9, 6)  = 0;
	mJacob(10, 1) =        0;								mJacob(10, 2) =        0;					mJacob(10, 3) =        0;								mJacob(10, 4) = 1;	mJacob(10, 5) = 0;	mJacob(10, 6) = 0;
	mJacob(11, 1) =        0;								mJacob(11, 2) =        0;					mJacob(11, 3) =        0;								mJacob(11, 4) = 0;	mJacob(11, 5) = 1;	mJacob(11, 6) = 0;
	mJacob(12, 1) =        0;								mJacob(12, 2) =        0;					mJacob(12, 3) =        0;								mJacob(12, 4) = 0;	mJacob(12, 5) = 0;	mJacob(12, 6) = 1;

	return mJacob;
}

// 利用消隐线优化像机相对姿态角时，3个目标函数分别对旋转矩阵各元素求导生成的雅各比矩阵
CMatrix DeepVoid::Jacobian_Fi_R_VanishingLineOptimAngles(const CMatrix & mNorm)
{
	double nx = mNorm(1);
	double ny = mNorm(2);
	double nz = mNorm(3);

	CMatrix mJacob(3, 9, 0);

	mJacob(1, 1) = nx;	mJacob(1, 2) = ny;	mJacob(1, 3) = nz;	
	mJacob(2, 4) = nx;	mJacob(2, 5) = ny;	mJacob(2, 6) = nz;	
	mJacob(3, 7) = nx;	mJacob(3, 8) = ny;	mJacob(3, 9) = nz;	

	return mJacob;
}

// 利用 2 个以上的像机对 单个 物点空间坐标进行光束法平差时，每个像机上该物点的理想投影点对其空间坐标 (X, Y, Z) 分别求偏导形成的 Jacobian Matrix
// 因此若参与该 单个 物点空间坐标平差的目数为 n ，则输出即为一 2n×3 的 Jacobian Matrix
CMatrix DeepVoid::Jacobian_xy_XYZ(double X,                                 // 输入： 待优化的该物点空间坐标初值
								  double Y,                                 // 输入： 待优化的该物点空间坐标初值
								  double Z,                                 // 输入： 待优化的该物点空间坐标初值
								  const CMatrix & mKs,                      // 输入： 参与光束法平差优化物点空间坐标的各像机内参数矩阵，至少需要 2 个以上的像机参与该物点的光束法平差，每个像机的内参数矩阵皆应为 3×4 的矩阵，因此若有 n 个像机，则该输入应为 3×4n 的矩阵
								  const CMatrix & mRTs                      // 输入： 参与光束法平差优化物点空间坐标的各像机外参数矩阵，至少需要 2 个以上的像机参与该物点的光束法平差，每个像机的外参数矩阵皆应为 4×4 的矩阵，因此若有 n 个像机，则该输入应为 4×4n 的矩阵
								  )
{
	// 目数
	int num = mRTs.m_nCol / 4;

	// 生成返回矩阵
	CMatrix mJacob(2 * num, 3);

	// 生成中间变量	
	double fx, fy;
	double cx, cy;

	double r1, r2, r3;
	double r4, r5, r6;
	double r7, r8, r9;
	double tx, ty, tz;

	double f1, f2;
	double g;

	int i;
	for (i = 1; i <= num; i++)
	{
		fx = mKs(1, 4 * (i - 1) + 1);
		fy = mKs(2, 4 * (i - 1) + 2);
		cx = mKs(1, 4 * (i - 1) + 3);
		cy = mKs(2, 4 * (i - 1) + 3);

		r1 = mRTs(1, 4 * (i - 1) + 1);
		r2 = mRTs(1, 4 * (i - 1) + 2);
		r3 = mRTs(1, 4 * (i - 1) + 3);
		tx = mRTs(1, 4 * (i - 1) + 4);

		r4 = mRTs(2, 4 * (i - 1) + 1);
		r5 = mRTs(2, 4 * (i - 1) + 2);
		r6 = mRTs(2, 4 * (i - 1) + 3);
		ty = mRTs(2, 4 * (i - 1) + 4);

		r7 = mRTs(3, 4 * (i - 1) + 1);
		r8 = mRTs(3, 4 * (i - 1) + 2);
		r9 = mRTs(3, 4 * (i - 1) + 3);
		tz = mRTs(3, 4 * (i - 1) + 4);

		// 20120507，朱肇昆，屏蔽，完全错误的导数
		// 20120507，朱肇昆，重新恢复，该段求导代码并不是有错误，跟下面的那段是等效的
		// 只不过一开始除以 g*g 没有用括号框起来，等于是除了g后又乘了g，所以像点对空间坐标位置的导数非常大。。。
		f1 = fx * (X * r1 + Y * r2 + Z * r3 + tx);		
		f2 = fy * (X * r4 + Y * r5 + Z * r6 + ty);
		g  =       X * r7 + Y * r8 + Z * r9 + tz;

		double g2inv = 1 / (g * g);

// 		mJacob(2 * (i - 1) + 1, 1) = (fx * r1 * g - r7 * f1) / (g * g);
// 		mJacob(2 * (i - 1) + 1, 2) = (fx * r2 * g - r8 * f1) / (g * g);
// 		mJacob(2 * (i - 1) + 1, 3) = (fx * r3 * g - r9 * f1) / (g * g);
// 
// 		mJacob(2 * (i - 1) + 2, 1) = (fy * r4 * g - r7 * f2) / (g * g);
// 		mJacob(2 * (i - 1) + 2, 2) = (fy * r5 * g - r8 * f2) / (g * g);
// 		mJacob(2 * (i - 1) + 2, 3) = (fy * r6 * g - r9 * f2) / (g * g);

		mJacob(2 * (i - 1) + 1, 1) = (fx * r1 * g - r7 * f1) * g2inv;
		mJacob(2 * (i - 1) + 1, 2) = (fx * r2 * g - r8 * f1) * g2inv;
		mJacob(2 * (i - 1) + 1, 3) = (fx * r3 * g - r9 * f1) * g2inv;

		mJacob(2 * (i - 1) + 2, 1) = (fy * r4 * g - r7 * f2) * g2inv;
		mJacob(2 * (i - 1) + 2, 2) = (fy * r5 * g - r8 * f2) * g2inv;
		mJacob(2 * (i - 1) + 2, 3) = (fy * r6 * g - r9 * f2) * g2inv;

		// 20120507，朱肇昆，改正为正确的导数
		// 		g  =       X * r7 + Y * r8 + Z * r9 + tz;
		// 		f1 = fx * (X * r1 + Y * r2 + Z * r3 + tx) + cx * g;		
		// 		f2 = fy * (X * r4 + Y * r5 + Z * r6 + ty) + cy * g;
		// 
		// 		double xX = (fx * r1 * g + cx * r7 * g - r7 * f1) / (g * g);
		// 		double xY = (fx * r2 * g + cx * r8 * g - r8 * f1) / (g * g);
		// 		double xZ = (fx * r3 * g + cx * r9 * g - r9 * f1) / (g * g);
		// 
		// 		double yX = (fy * r4 * g + cy * r7 * g - r7 * f2) / (g * g);
		// 		double yY = (fy * r5 * g + cy * r8 * g - r8 * f2) / (g * g);
		// 		double yZ = (fy * r6 * g + cy * r9 * g - r9 * f2) / (g * g);
		// 
		// 		mJacob(2 * (i - 1) + 1, 1) = (fx * r1 * g + cx * r7 * g - r7 * f1) / (g * g);
		// 		mJacob(2 * (i - 1) + 1, 2) = (fx * r2 * g + cx * r8 * g - r8 * f1) / (g * g);
		// 		mJacob(2 * (i - 1) + 1, 3) = (fx * r3 * g + cx * r9 * g - r9 * f1) / (g * g);
		// 
		// 		mJacob(2 * (i - 1) + 2, 1) = (fy * r4 * g + cy * r7 * g - r7 * f2) / (g * g);
		// 		mJacob(2 * (i - 1) + 2, 2) = (fy * r5 * g + cy * r8 * g - r8 * f2) / (g * g);
		// 		mJacob(2 * (i - 1) + 2, 3) = (fy * r6 * g + cy * r9 * g - r9 * f2) / (g * g);
	}

	return mJacob;
}

// 投影像点坐标对对应的空间点世界坐标求导
Matx23d DeepVoid::Jacobian_xy_XYZ(const Matx33d & mKR,			
								  const Matx31d & mKt,
								  double X, double Y, double Z,
								  double & imgx, double & imgy
								  )
{
	Matx31d XYZ;
	XYZ(0) = X;
	XYZ(1) = Y;
	XYZ(2) = Z;

	Matx31d Proj = mKR*XYZ+mKt;

	double f1 = Proj(0);
	double f2 = Proj(1);
	double g =  Proj(2);
	double g_1  = 1.0/g;
	double g2_1 = g_1*g_1;

	imgx = f1*g_1;
	imgy = f2*g_1;

	Matx23d der;

	der(0,0) = (mKR(0,0)*g-mKR(2,0)*f1)*g2_1; // dx/dX
	der(0,1) = (mKR(0,1)*g-mKR(2,1)*f1)*g2_1; // dx/dY
	der(0,2) = (mKR(0,2)*g-mKR(2,2)*f1)*g2_1; // dx/dZ

	der(1,0) = (mKR(1,0)*g-mKR(2,0)*f2)*g2_1; // dy/dX
	der(1,1) = (mKR(1,1)*g-mKR(2,1)*f2)*g2_1; // dy/dY
	der(1,2) = (mKR(1,2)*g-mKR(2,2)*f2)*g2_1; // dy/dZ

	return der;
}

// zhaokunz, 20150108, 投影像点坐标对对应的空间点世界坐标求导
Matx23d DeepVoid::Jacobian_xy_XYZ(const Matx34d & mP,
								  double X, double Y, double Z
								  )
{
	Matx41d XYZW;

	XYZW(0)=X; XYZW(1)=Y; XYZW(2)=Z; XYZW(3)=1;

	Matx31d xyw = mP*XYZW;

	double f1 = xyw(0);
	double f2 = xyw(1);
	double g  = xyw(2);
	double g2 = g*g;
	double g2_1 = 1.0/g2;

	Matx23d der;
	
	der(0,0) = (mP(0,0)*g-mP(2,0)*f1)*g2_1; // dx/dX
	der(0,1) = (mP(0,1)*g-mP(2,1)*f1)*g2_1; // dx/dY
	der(0,2) = (mP(0,2)*g-mP(2,2)*f1)*g2_1; // dx/dZ

	der(1,0) = (mP(1,0)*g-mP(2,0)*f2)*g2_1; // dy/dX
	der(1,1) = (mP(1,1)*g-mP(2,1)*f2)*g2_1; // dy/dY
	der(1,2) = (mP(1,2)*g-mP(2,2)*f2)*g2_1; // dy/dZ

	return der;
}

// zhaokunz, 20150108, 投影像点坐标对camera matrix求导
Matx<double,2,12> DeepVoid::Jacobian_xy_P(const Matx34d & mP,
										  double X, double Y, double Z
										  )
{
	Matx<double,2,12> der;

	Matx41d XYZW;

	XYZW(0)=X; XYZW(1)=Y; XYZW(2)=Z; XYZW(3)=1;

	Matx31d xyw = mP*XYZW;

	double f1 = xyw(0);
	double f2 = xyw(1);
	double g  = xyw(2);
	double g_1 = 1.0/g;
	double g2_1 = g_1*g_1;
	double f1g2_1 = f1*g2_1;
	double f2g2_1 = f2*g2_1;

	der(0,0)  = X*g_1;		// dx/dP11
	der(0,1)  = Y*g_1;		// dx/dP12
	der(0,2)  = Z*g_1;		// dx/dP13
	der(0,3)  =   g_1;		// dx/dP14

	der(0,8)  = -X*f1g2_1;	// dx/dP31
	der(0,9)  = -Y*f1g2_1;	// dx/dP32
	der(0,10) = -Z*f1g2_1;	// dx/dP33
	der(0,11) =   -f1g2_1;	// dx/dP34

	der(1,4)  = der(0,0);	// dy/dP21
	der(1,5)  = der(0,1);	// dy/dP22
	der(1,6)  = der(0,2);	// dy/dP23
	der(1,7)  = der(0,3);	// dy/dP24

	der(1,8)  = -X*f2g2_1;	// dy/dP31
	der(1,9)  = -Y*f2g2_1;	// dy/dP32
	der(1,10) = -Z*f2g2_1;	// dy/dP33
	der(1,11) =   -f2g2_1;	// dy/dP34

	return der;
}

// 理想像点坐标对空间点的齐次空间坐标求导的 Jacobian Matrix，返回 2×4 的 Jacobian Matrix
CMatrix DeepVoid::Jacobian_xy_XYZW(double X,                                // 输入： 该空间点当前的空间位置
								   double Y,                                // 输入： 该空间点当前的空间位置
								   double Z,                                // 输入： 该空间点当前的空间位置
								   double W,                                // 输入： 该空间点当前的空间位置
								   const CMatrix & mK,                      // 输入： 像机的内参数矩阵，3×4 或者 3×3 的矩阵皆可
								   const CMatrix & mRT                      // 输入： 像机的外参数矩阵，4×4 的矩阵
								   )
{
	CMatrix mJacob(2, 4, 0);

	double fx = mK(1, 1);
	double fy = mK(2, 2);
	double cx = mK(1, 3);
	double cy = mK(2, 3);

	double r1 = mRT(1, 1);	double r2 = mRT(1, 2);	double r3 = mRT(1, 3);	double tx = mRT(1, 4);
	double r4 = mRT(2, 1);	double r5 = mRT(2, 2);	double r6 = mRT(2, 3);	double ty = mRT(2, 4);
	double r7 = mRT(3, 1);	double r8 = mRT(3, 2);	double r9 = mRT(3, 3);	double tz = mRT(3, 4);

	double f1 = fx * (r1 * X + r2 * Y + r3 * Z + tx * W);
	double f2 = fy * (r4 * X + r5 * Y + r6 * Z + ty * W);
	double g  =       r7 * X + r8 * Y + r9 * Z + tz * W;

	mJacob(1, 1) = (fx * r1 * g - r7 * f1) / (g * g);
	mJacob(1, 2) = (fx * r2 * g - r8 * f1) / (g * g);
	mJacob(1, 3) = (fx * r3 * g - r9 * f1) / (g * g);
	mJacob(1, 4) = (fx * tx * g - tz * f1) / (g * g);

	mJacob(2, 1) = (fy * r4 * g - r7 * f2) / (g * g);
	mJacob(2, 2) = (fy * r5 * g - r8 * f2) / (g * g);
	mJacob(2, 3) = (fy * r6 * g - r9 * f2) / (g * g);
	mJacob(2, 4) = (fy * ty * g - tz * f2) / (g * g);

	return mJacob;
}

// D.C.Brown's 像差 (du, dv) 对归一化像点坐标 (nx, ny) 进行求导，输出 2×2 的 Jacobian matrix
CMatrix DeepVoid::Jacobian_dudv_xyNorm_DCBrown(double x_n,                  // 输入： 该像点的归一化像点坐标
											   double y_n,                  // 输入： 该像点的归一化像点坐标
											   const CMatrix & mK,          // 输入： 像机的内参数矩阵 3×4 或 3×3 的矩阵皆可
											   const CMatrix & mDist        // 输入： 像机的 5 系数 D.C.Brown 像差系数
											   )
{
	double fx = mK(1, 1);
	double fy = mK(2, 2);

	double k1 = mDist(1);
	double k2 = mDist(2);
	double k3 = mDist(3);
	double k4 = mDist(4);
	double k5 = mDist(5);

	double r2 = x_n * x_n + y_n * y_n; // r^2 = nx^2 + ny^2
	double r4 = r2 * r2;               // r^4
	double r6 = r4 * r2;               // r^6

	double f = k1 * r2 + k2 * r4 + k5 * r6; // f = k1 r^2 + k2 r^4 + k5 r^6

	double tmp = 2 * k1 + 4 * k2 * r2 + 6 * k5 * r4; // tmp = 2 k1 + 4 k2 r^2 + 6 k5 r^4

	double dfdx = tmp * x_n;           // df/dnx = tmp * nx
	double dfdy = tmp * y_n;           // df/dny = tmp * ny

	double dr2dx = 2 * x_n;            // dr^2/dnx = 2 * nx
	double dr2dy = 2 * y_n;            // dr^2/dny = 2 * ny

	// 2×2 的 Jacobian Matrix
	CMatrix mJacob(2, 2);

	mJacob(1, 1) = x_n * fx * dfdx + fx * f + 2 * k3 * y_n * fx + k4 * fx * dr2dx + 4 * k4 * fx * x_n;  // du/dnx
	mJacob(1, 2) = x_n * fx * dfdy + 2 * k3 * x_n * fx + k4 * fx * dr2dy;                               // du/dny
	mJacob(2, 1) = y_n * fy * dfdx + k3 * fy * dr2dx + 2 * k4 * fy * y_n;                               // dv/dnx
	mJacob(2, 2) = y_n * fy * dfdy + fy * f + k3 * fy * dr2dy + 4 * k3 * fy * y_n + 2 * k4 * fy * x_n;  // dv/dny

	return mJacob;
}

// D.C.Brown's 像差 (du, dv) 对物点的线性重投影的理想像点 (x, y) 进行求导,输出 2×2 的 Jacobian matrix
CMatrix DeepVoid::Jacobian_dudv_xy_DCBrown(double x,                        // 输入： 线性重投影的理想像点坐标
										   double y,                        // 输入： 线性重投影的理想像点坐标
										   const CMatrix & mK,              // 输入： 像机的内参数矩阵 3×4 或 3×3 的矩阵皆可
										   const CMatrix & mDist            // 输入： 像机的 5 系数 D.C.Brown 像差系数
										   )
{
	double fx = mK(1, 1);
	double fy = mK(2, 2);
	double cx = mK(1, 3);
	double cy = mK(2, 3);

	double nx = (x - cx) / fx;
	double ny = (y - cy) / fy;

	CMatrix mJacob = Jacobian_dudv_xyNorm_DCBrown(nx, ny, mK, mDist);

	CMatrix mTmp(2, 2, 0);
	mTmp(1, 1) = 1 / fx;
	mTmp(2, 2) = 1 / fy;

	mJacob = mJacob * mTmp;

	return mJacob;
}

// 带 D.C.Brown's 像差的重投影像点坐标对理想像点坐标 (x, y) 进行求导，输出 2×2 的 Jacobian matrix
CMatrix DeepVoid::Jacobian_distxy_xy_DCBrown(double x,                        // 输入： 线性重投影的理想像点坐标
											 double y,                        // 输入： 线性重投影的理想像点坐标
											 const CMatrix & mK,              // 输入： 像机的内参数矩阵 3×4 或 3×3 的矩阵皆可
											 const CMatrix & mDist            // 输入： 像机的 5 系数 D.C.Brown 像差系数
											 )
{
	CMatrix mEye(2, 2, 0);
	mEye(1, 1) = 1;
	mEye(2, 2) = 1;

	CMatrix mJacob = mEye + Jacobian_dudv_xy_DCBrown(x, y, mK, mDist);

	return mJacob;
}

// 带像差的重投影像点坐标对 5 个 D.C.Brown's 像差系数进行求导，输出2×5的Jacobian matrix
CMatrix DeepVoid::Jacobian_distxy_ki_DCBrown(double x,                        // 输入： 线性重投影的理想像点坐标
											 double y,                        // 输入： 线性重投影的理想像点坐标
											 const CMatrix & mK               // 输入： 像机的内参数矩阵 3×4 或 3×3 的矩阵皆可
											 )
{
	double fx = mK(1, 1);
	double fy = mK(2, 2);
	double cx = mK(1, 3);
	double cy = mK(2, 3);

	double nx = (x - cx) / fx;
	double ny = (y - cy) / fy;

	double r2 = nx * nx + ny * ny;  // r^2 = nx^2 + ny^2
	double r4 = r2 * r2;            // r^4
	double r6 = r4 * r2;            // r^6

	CMatrix mJacob(2, 5);

	mJacob(1, 1) = r2 * nx * fx;	mJacob(1, 2) = r4 * nx * fx;	mJacob(1, 3) = 2 * nx * ny * fx;		mJacob(1, 4) = (r2 + 2 * nx * nx) * fx;	mJacob(1, 5) = r6 * nx * fx;
	mJacob(2, 1) = r2 * ny * fy;	mJacob(2, 2) = r4 * ny * fy;	mJacob(2, 3) = (r2 + 2 * ny * ny) * fy; mJacob(2, 4) = 2 * nx * ny * fy;		mJacob(2, 5) = r6 * ny * fy;

	return mJacob;
}

// 该函数是计算某点在坐标系 2 中的坐标对坐标系 1 和 2 刚体变换矩阵 H12 各元素求导的 Jacobian Matrix，X2 = H12 * X1，返回一 3×12 的矩阵
CMatrix DeepVoid::Jacobian_XYZ_RT(double X,                                 // 输入： 该点在坐标系 1 中的坐标
								  double Y,								  // 输入： 该点在坐标系 1 中的坐标
								  double Z                                  // 输入： 该点在坐标系 1 中的坐标
								  )
{
	CMatrix mJacob(3, 12, 0);

	mJacob(1, 1)  = mJacob(2, 4)  = mJacob(3, 7)  = X;
	mJacob(1, 2)  = mJacob(2, 5)  = mJacob(3, 8)  = Y;
	mJacob(1, 3)  = mJacob(2, 6)  = mJacob(3, 9)  = Z;
	mJacob(1, 10) = mJacob(2, 11) = mJacob(3, 12) = 1;

	return mJacob;
}

// 某点表征的三维点世界坐标对其沿视线方向的深度，也就是Zc坐标的导数
void DeepVoid::Jacobian_XYZ_depth(const Matx33d & mR,					// input: rotation matrix
								  double nimgx, double nimgy,			// input: normalized image points
								  double & dX_dd,						// output: dX/dd
								  double & dY_dd,						// output: dY/dd
								  double & dZ_dd						// output: dZ/dd
								  )
{
	Matx31d dir;

	dir(0) = nimgx;
	dir(1) = nimgy;
	dir(2) = 1;

	Matx31d der = mR.t() * dir;

	dX_dd = der(0);
	dY_dd = der(1);
	dZ_dd = der(2);
}

// support window中某像素表征的三维点世界坐标对该support window的dr hx hy求导
Matx33d DeepVoid::Jacobian_XYZ_drhxhy(const Matx33d & mR,				// input:	rotation matrix
									  double u, double v,				// input:	local offset coordinates of this pixel w.r.t central pixel
									  double nimgx, double nimgy		// input:	normalized image points representing the direction
									  )
{
	Matx31d dir;
	dir(0) = nimgx;
	dir(1) = nimgy;
	dir(2) = 1;

	Matx13d m1uv;
	m1uv(0) = 1;
	m1uv(1) = u;
	m1uv(2) = v;

	return mR.t()*dir*m1uv; // R'x[1 u v]
}

// support window中某像素表征的三维点世界坐标对该support window的dr hx hy求导
Matx33d DeepVoid::Jacobian_XYZ_drhxhy(const Matx31d & mRtx,			// input:	R'x(u,v), transpose of R * normalized image points of (u,v)
									  double u, double v				// input:	local offset coordinates of this pixel w.r.t central pixel
									  )
{
	Matx13d m1uv;
	m1uv(0) = 1;
	m1uv(1) = u;
	m1uv(2) = v;

	return mRtx*m1uv; // R'x[1 u v]
}

// 某刚体变换矩阵 RT 的逆 inv(RT) 对该矩阵的求导
CMatrix DeepVoid::Jacobian_invRT_RT(const CMatrix & mRT)                     // 输入： 当前的刚体变换矩阵						
{
	double r1 = mRT(1, 1);	double r2 = mRT(1, 2);	double r3 = mRT(1, 3);
	double r4 = mRT(2, 1);	double r5 = mRT(2, 2);	double r6 = mRT(2, 3);
	double r7 = mRT(3, 1);	double r8 = mRT(3, 2);	double r9 = mRT(3, 3);

	double tx = mRT(1, 4);	double ty = mRT(2, 4);	double tz = mRT(3, 4);

	CMatrix mJacob(12, 12, 0);

	mJacob(1, 1) = mJacob(2, 4) = mJacob(3, 7) = 1;
	mJacob(4, 2) = mJacob(5, 5) = mJacob(6, 8) = 1;
	mJacob(7, 3) = mJacob(8, 6) = mJacob(9, 9) = 1;

	mJacob(10, 1) = mJacob(11, 2) = mJacob(12, 3) = -tx;
	mJacob(10, 4) = mJacob(11, 5) = mJacob(12, 6) = -ty;
	mJacob(10, 7) = mJacob(11, 8) = mJacob(12, 9) = -tz;

	mJacob(10, 10) = -r1;	mJacob(10, 11) = -r4;	mJacob(10, 12) = -r7;
	mJacob(11, 10) = -r2;	mJacob(11, 11) = -r5;	mJacob(11, 12) = -r8;
	mJacob(12, 10) = -r3;	mJacob(12, 11) = -r6;	mJacob(12, 12) = -r9;

	return mJacob;
}

// 旋转平移矩阵 RT 对旋转向量 v 的导数阵
// 其中 R = I + [n]sin(a) + [n]^2(1 - cos(a))，其中 n 为单位的旋转轴向量，a 为绕旋转轴旋转的弧度
// 输出为 12×6 的 Jacobian Matrix
CMatrix DeepVoid::Jacobian_RT_ExtPara_RotVec(const CMatrix & mRotVec)       // 输入： 当前像机的 3 维的旋转向量 v，|v| 为旋转弧度大小，v 为旋转轴	
{
	double radian = mRotVec.Norm(); // 把当前的旋转弧度取出来

	double sina = sin(radian);
	double cosa = cos(radian);

	CMatrix mRotVec_unit = mRotVec / radian; // 得到单位的旋转轴向量

	double n1 = mRotVec_unit(1);
	double n2 = mRotVec_unit(2);
	double n3 = mRotVec_unit(3);

	double w1 = mRotVec(1);
	double w2 = mRotVec(2);
	double w3 = mRotVec(3);

	double g = sqrt(w1 * w1 + w2 * w2 + w3 * w3);
	double g2 = g * g;
	double g2_1 = 1/g2;
	double g_1 = 1.0/g;

	double w1w1 = w1 * w1;
	double w1w2 = w1 * w2;
	double w1w3 = w1 * w3;
	double w2w2 = w2 * w2;
	double w2w3 = w2 * w3;
	double w3w3 = w3 * w3;

	CMatrix mJacobian_R_n1n2n3a(9, 4), mJacobian_n1n2n3a_w1w2w3(4, 3);

	mJacobian_R_n1n2n3a(1, 1) =               0;		mJacobian_R_n1n2n3a(1, 2) = -2 * (1 - cosa) * n2;	mJacobian_R_n1n2n3a(1, 3) = -2 * (1 - cosa) * n3;	mJacobian_R_n1n2n3a(1, 4) = -(n3 * n3 + n2 * n2) * sina;
	mJacobian_R_n1n2n3a(2, 1) = (1 - cosa) * n2;		mJacobian_R_n1n2n3a(2, 2) =      (1 - cosa) * n1;	mJacobian_R_n1n2n3a(2, 3) =                -sina;	mJacobian_R_n1n2n3a(2, 4) = -n3 * cosa + n1 * n2 * sina;
	mJacobian_R_n1n2n3a(3, 1) = (1 - cosa) * n3;		mJacobian_R_n1n2n3a(3, 2) =                 sina;	mJacobian_R_n1n2n3a(3, 3) =      (1 - cosa) * n1;	mJacobian_R_n1n2n3a(3, 4) =  n2 * cosa + n1 * n3 * sina;
	mJacobian_R_n1n2n3a(4, 1) = (1 - cosa) * n2;		mJacobian_R_n1n2n3a(4, 2) =      (1 - cosa) * n1;	mJacobian_R_n1n2n3a(4, 3) =                 sina;	mJacobian_R_n1n2n3a(4, 4) =  n3 * cosa + n1 * n2 * sina;
	mJacobian_R_n1n2n3a(5, 1) = -2 * (1 - cosa) * n1;	mJacobian_R_n1n2n3a(5, 2) =                    0;	mJacobian_R_n1n2n3a(5, 3) = -2 * (1 - cosa) * n3;	mJacobian_R_n1n2n3a(5, 4) = -(n3 * n3 + n1 * n1) * sina;
	mJacobian_R_n1n2n3a(6, 1) =           -sina;		mJacobian_R_n1n2n3a(6, 2) =      (1 - cosa) * n3;	mJacobian_R_n1n2n3a(6, 3) =      (1 - cosa) * n2;	mJacobian_R_n1n2n3a(6, 4) = -n1 * cosa + n2 * n3 * sina;
	mJacobian_R_n1n2n3a(7, 1) = (1 - cosa) * n3;		mJacobian_R_n1n2n3a(7, 2) =                -sina;	mJacobian_R_n1n2n3a(7, 3) =      (1 - cosa) * n1;	mJacobian_R_n1n2n3a(7, 4) = -n2 * cosa + n1 * n3 * sina;
	mJacobian_R_n1n2n3a(8, 1) =            sina;		mJacobian_R_n1n2n3a(8, 2) =      (1 - cosa) * n3;	mJacobian_R_n1n2n3a(8, 3) =      (1 - cosa) * n2;	mJacobian_R_n1n2n3a(8, 4) =  n1 * cosa + n2 * n3 * sina;
	mJacobian_R_n1n2n3a(9, 1) = -2 * (1 - cosa) * n1;	mJacobian_R_n1n2n3a(9, 2) = -2 * (1 - cosa) * n2;	mJacobian_R_n1n2n3a(9, 3) =                    0;	mJacobian_R_n1n2n3a(9, 4) = -(n2 * n2 + n1 * n1) * sina;

	// 20121106，苑云改
	// 	mJacobian_R_n1n2n3a(1, 1) = 2 * (1 - cosa) * n1;	mJacobian_R_n1n2n3a(1, 2) = 0;						mJacobian_R_n1n2n3a(1, 3) = 0;						mJacobian_R_n1n2n3a(1, 4) = -(n3 * n3 + n2 * n2) * sina;
	// 	mJacobian_R_n1n2n3a(2, 1) = (1 - cosa) * n2;		mJacobian_R_n1n2n3a(2, 2) =      (1 - cosa) * n1;	mJacobian_R_n1n2n3a(2, 3) =                -sina;	mJacobian_R_n1n2n3a(2, 4) = -n3 * cosa + n1 * n2 * sina;
	// 	mJacobian_R_n1n2n3a(3, 1) = (1 - cosa) * n3;		mJacobian_R_n1n2n3a(3, 2) =                 sina;	mJacobian_R_n1n2n3a(3, 3) =      (1 - cosa) * n1;	mJacobian_R_n1n2n3a(3, 4) =  n2 * cosa + n1 * n3 * sina;
	// 	mJacobian_R_n1n2n3a(4, 1) = (1 - cosa) * n2;		mJacobian_R_n1n2n3a(4, 2) =      (1 - cosa) * n1;	mJacobian_R_n1n2n3a(4, 3) =                 sina;	mJacobian_R_n1n2n3a(4, 4) =  n3 * cosa + n1 * n2 * sina;
	// 	mJacobian_R_n1n2n3a(5, 1) =0;						mJacobian_R_n1n2n3a(5, 2) =    2 * (1 - cosa) * n2;	mJacobian_R_n1n2n3a(5, 3) = 0;						mJacobian_R_n1n2n3a(5, 4) = -(n3 * n3 + n1 * n1) * sina;
	// 	mJacobian_R_n1n2n3a(6, 1) =           -sina;		mJacobian_R_n1n2n3a(6, 2) =      (1 - cosa) * n3;	mJacobian_R_n1n2n3a(6, 3) =      (1 - cosa) * n2;	mJacobian_R_n1n2n3a(6, 4) = -n1 * cosa + n2 * n3 * sina;
	// 	mJacobian_R_n1n2n3a(7, 1) = (1 - cosa) * n3;		mJacobian_R_n1n2n3a(7, 2) =                -sina;	mJacobian_R_n1n2n3a(7, 3) =      (1 - cosa) * n1;	mJacobian_R_n1n2n3a(7, 4) = -n2 * cosa + n1 * n3 * sina;
	// 	mJacobian_R_n1n2n3a(8, 1) =            sina;		mJacobian_R_n1n2n3a(8, 2) =      (1 - cosa) * n3;	mJacobian_R_n1n2n3a(8, 3) =      (1 - cosa) * n2;	mJacobian_R_n1n2n3a(8, 4) =  n1 * cosa + n2 * n3 * sina;
	// 	mJacobian_R_n1n2n3a(9, 1) = 0;						mJacobian_R_n1n2n3a(9, 2) = 0;						mJacobian_R_n1n2n3a(9, 3) =  2 * (1 - cosa) * n3;	mJacobian_R_n1n2n3a(9, 4) = -(n2 * n2 + n1 * n1) * sina;

	mJacobian_n1n2n3a_w1w2w3(1, 1) = (g - w1w1 * g_1) * g2_1;		mJacobian_n1n2n3a_w1w2w3(1, 2) =   (- w1w2 * g_1) * g2_1;		mJacobian_n1n2n3a_w1w2w3(1, 3) =   (- w1w3 * g_1) * g2_1;
	mJacobian_n1n2n3a_w1w2w3(2, 1) =   (- w1w2 * g_1) * g2_1;		mJacobian_n1n2n3a_w1w2w3(2, 2) = (g - w2w2 * g_1) * g2_1;		mJacobian_n1n2n3a_w1w2w3(2, 3) =   (- w2w3 * g_1) * g2_1;
	mJacobian_n1n2n3a_w1w2w3(3, 1) =   (- w1w3 * g_1) * g2_1;		mJacobian_n1n2n3a_w1w2w3(3, 2) =   (- w2w3 * g_1) * g2_1;		mJacobian_n1n2n3a_w1w2w3(3, 3) = (g - w3w3 * g_1) * g2_1;
	mJacobian_n1n2n3a_w1w2w3(4, 1) =       g_1 * w1;				mJacobian_n1n2n3a_w1w2w3(4, 2) =       g_1 * w2;				mJacobian_n1n2n3a_w1w2w3(4, 3) =       g_1 * w3;

	CMatrix mJacobian_R_w1w2w3 = mJacobian_R_n1n2n3a * mJacobian_n1n2n3a_w1w2w3;

	CMatrix mJacob(12, 6, 0);

	mJacob.SetRect(1, 1, mJacobian_R_w1w2w3);
	mJacob.SetRect(10, 4, GenI(3));

	return mJacob;
}

// 当前的旋转平移矩阵 RT 对单位四元数的导数阵
// 输出为 12×7 的 Jacobian Matrix
CMatrix DeepVoid::Jacobian_RT_ExtPara_Quaternion(const CMatrix & q)       // 输入： 当前像机旋转的 4 维单位四元数
{
	double q0 = q(1);
	double q1 = q(2);
	double q2 = q(3);
	double q3 = q(4);

	double q0_2 = 2 * q0;
	double q1_2 = 2 * q1;
	double q2_2 = 2 * q2;
	double q3_2 = 2 * q3;

	CMatrix mJacob(12, 7, 0);

	mJacob(1, 1) =  q0_2;	mJacob(1, 2) =  q1_2;	mJacob(1, 3) = -q2_2;	mJacob(1, 4) = -q3_2;
	mJacob(2, 1) = -q3_2;	mJacob(2, 2) =  q2_2;	mJacob(2, 3) =  q1_2;	mJacob(2, 4) = -q0_2;
	mJacob(3, 1) =  q2_2;	mJacob(3, 2) =  q3_2;	mJacob(3, 3) =  q0_2;	mJacob(3, 4) =  q1_2;
	mJacob(4, 1) =  q3_2;	mJacob(4, 2) =  q2_2;	mJacob(4, 3) =  q1_2;	mJacob(4, 4) =  q0_2;
	mJacob(5, 1) =  q0_2;	mJacob(5, 2) = -q1_2;	mJacob(5, 3) =  q2_2;	mJacob(5, 4) = -q3_2;
	mJacob(6, 1) = -q1_2;	mJacob(6, 2) = -q0_2;	mJacob(6, 3) =  q3_2;	mJacob(6, 4) =  q2_2;
	mJacob(7, 1) = -q2_2;	mJacob(7, 2) =  q3_2;	mJacob(7, 3) = -q0_2;	mJacob(7, 4) =  q1_2;
	mJacob(8, 1) =  q1_2;	mJacob(8, 2) =  q0_2;	mJacob(8, 3) =  q3_2;	mJacob(8, 4) =  q2_2;
	mJacob(9, 1) =  q0_2;	mJacob(9, 2) = -q1_2;	mJacob(9, 3) = -q2_2;	mJacob(9, 4) =  q3_2;

	mJacob.SetRect(10, 5, GenI(3));

	return mJacob;
}

//////////////////////////////////////////////////////////////////////////


// Structure from Motion related //////////////////////////////////////////////////////////////////////////

void DeepVoid::FindAllMatchingTracks_with121mappingcheck(vector<cam_data> & allCams,
														 const vector<vector<DMatch>> & allMatches,
														 vector<vector<Point2i>> & allTracks								 
														 )
{
	int i,j,k,l,ii,jj;

	int nImg = (int)sqrt((double)allMatches.size());

	int nTracks = 0;

	for (i=0;i<nImg;i++)
	{
		for (j=i+1;j<nImg;j++)
		{
			CString strInfo;
			strInfo.Format("now checking matches between image %03d and %03d", i, j);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			vector<DMatch> matches = allMatches[i*nImg+j];
			for (k=0;k<matches.size();k++)
			{
// 				CString strInfo;
// 				strInfo.Format("now checking the %04d match between image %03d and %03d", k, i, j);
// 				theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

				vector<Point2i> track;

				DMatch match = matches[k];

				// check if this feature has already belong to some track
				if (allCams[i].m_feats.tracks[match.queryIdx]!=-1)
				{
					continue;
				}

				// breadth-first search
				deque<Point2i> queue;

				bool b121mapping = true;
				for (l=0;l<matches.size();l++)
				{
					if (l==k)
					{
						continue;
					}

					if (matches[l].queryIdx == match.queryIdx || matches[l].trainIdx == match.trainIdx)
					{
						theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(_T("not 121mapping, code: 1!"));
						b121mapping = false;
						break;
					}
				}

				if (b121mapping)
				{
					Point2i pt;
					pt.x = i; pt.y = match.queryIdx;
					queue.push_back(pt);
					track.push_back(pt);

					pt.x = j; pt.y = match.trainIdx;
					queue.push_back(pt);
					track.push_back(pt);
				} 
				else
				{
					continue;
				}

				bool * mCheck = new bool [nImg*nImg];
				memset(mCheck, 0, nImg*nImg*sizeof(bool));
				mCheck[i*nImg+j] = mCheck[j*nImg+i] = 1;

				Point2i pt;
				while (queue.size())
				{
					pt = queue.front();
					queue.pop_front();

					for (l=0;l<nImg;l++)
					{
						if (l==pt.x || mCheck[pt.x*nImg+l])
						{
							continue;
						}

						vector<DMatch> matches_inloop = allMatches[pt.x*nImg+l];

						int idx_ii;
						int n_q = 0;
						for (ii=0;ii<matches_inloop.size();ii++)
						{
							if (matches_inloop[ii].queryIdx == pt.y)
							{
								idx_ii = ii;
								n_q++;
							}
						}

						if (n_q != 1)
						{
							strInfo.Format("n_q: %02d, code: 2!", n_q);
							theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);
							continue;
						}

						b121mapping = true;
						for (ii=0;ii<matches_inloop.size();ii++)
						{
							if (idx_ii == ii)
							{
								continue;
							}
							
							if (matches_inloop[ii].trainIdx == matches_inloop[idx_ii].trainIdx)
							{
								theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(_T("not 121mapping, code: 3!"));
								b121mapping = false;
								break;
							}
						}

						if (b121mapping)
						{
							Point2i ptnew;
							ptnew.x = l;
							ptnew.y = matches_inloop[idx_ii].trainIdx;

							bool bExist = false;
							for (ii=0;ii<track.size();ii++)
							{
								if (track[ii].x == ptnew.x && track[ii].y == ptnew.y)
								{
									bExist = true;
								}
							}
							
							if (!bExist)
							{
								queue.push_back(ptnew);
								track.push_back(ptnew);
							}
						} 
						
						mCheck[pt.x*nImg+l] = mCheck[l*nImg+pt.x] = 1;
					}
				}

				bool bGood = true;
				for (ii=0;ii<track.size();ii++)
				{
					for (jj=ii+1;jj<track.size();jj++)
					{
						if (track[ii].x == track[jj].x)
						{
							bGood = false;
							break;
						}
					}
					if (!bGood)
					{
						break;
					}
				}

				if (bGood)
				{
					allTracks.push_back(track);

					for (ii=0;ii<track.size();ii++)
					{
						allCams[track[ii].x].m_feats.tracks[track[ii].y] = nTracks;
					}

					nTracks++;
				}
				
				delete [] mCheck;
			}
		}
	}
}

void DeepVoid::FindAllMatchingTracks(vector<cam_data> & allCams,
									 const vector<vector<DMatch>> & allMatches,
									 vector<vector<Point2i>> & allTracks
									 )
{
	int i,j,k,l,ii,jj;

	int nImg = (int)sqrt((double)allMatches.size());

	int nTracks = 0;

	for (i=0;i<nImg;i++)
	{
		for (j=i+1;j<nImg;j++)
		{
			CString strInfo;
			strInfo.Format("now checking matches between image %03d and %03d", i, j);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			vector<DMatch> matches = allMatches[i*nImg+j];
			for (k=0;k<matches.size();k++)
			{
				vector<Point2i> track;

				DMatch match = matches[k];

				// check if this feature has already belong to some track
				if (allCams[i].m_feats.tracks[match.queryIdx]!=-1)
				{
					continue;
				}

				// breadth-first search
				deque<Point2i> queue;

				Point2i pt;
				pt.x = i; pt.y = match.queryIdx;
				queue.push_back(pt);
				track.push_back(pt);

				pt.x = j; pt.y = match.trainIdx;
				queue.push_back(pt);
				track.push_back(pt);
				
				bool * mCheck = new bool [nImg*nImg];
				memset(mCheck, 0, nImg*nImg*sizeof(bool));
				mCheck[i*nImg+j] = mCheck[j*nImg+i] = 1;

				// we believe that this feature will expand a good track
				// unless something happens afterward change this assumption
				// like the track containing more than 1 feature in the same image
				bool bGood = true;

				while (queue.size())
				{
					pt = queue.front();
					queue.pop_front();

					for (l=0;l<nImg;l++)
					{
						if (l==pt.x || mCheck[pt.x*nImg+l])
						{
							continue;
						}

						vector<DMatch> matches_inloop = allMatches[pt.x*nImg+l];

						int idx_ii;
						bool bFound = false;
						for (ii=0;ii<matches_inloop.size();ii++)
						{
							if (matches_inloop[ii].queryIdx == pt.y)
							{
								idx_ii = ii;
								bFound = true;
								break;
							}
						}

						if (!bFound) // not found
						{
							continue;
						}

						// if the found feature has already been in the track
						Point2i ptnew;
						ptnew.x = l;
						ptnew.y = matches_inloop[idx_ii].trainIdx;

						bool bExist = false;
						for (ii=0;ii<track.size();ii++)
						{
							if (track[ii].x == ptnew.x)
							{
								if (track[ii].y != ptnew.y)
								{
									// found more than 1 feature in the same image
									bGood = false;
									break;
								} 
								else
								{
									bExist = true;
									break;
								}
							}
						}

						if (!bGood)
						{
							break;
						}

						if (!bExist)
						{
							queue.push_back(ptnew);
							track.push_back(ptnew);
						}
					
						mCheck[pt.x*nImg+l] = mCheck[l*nImg+pt.x] = 1;
					}

					if (!bGood)
					{
						break;
					}
				}

				if (bGood)
				{
					allTracks.push_back(track);

					for (ii=0;ii<track.size();ii++)
					{
						allCams[track[ii].x].m_feats.tracks[track[ii].y] = nTracks;
					}

					nTracks++;
				}

				delete [] mCheck;
			}
		}
	}
}

// return the index of the image observing the most reconstructed tracks
int DeepVoid::FindImgObservingMostTracks_traversal(const vector<cam_data> & allCams,	// input:	all images
												   const vector<CloudPoint> & clouds,	// input:	all reconstructed tracks
												   const vector<int> & status,		// input:	status[i]=1 means that image i is not considered
												   int & nPts							// output:	the maximum number of tracks observed by single image 
												   )
{
	int i,j,k;

	int nTracks = clouds.size();
	int nImgs = allCams.size();

	int idx_max = -1;
	nPts = 0;
	
	for (i=0;i<nImgs;i++)
	{
		if (status[i])
		{
			continue;
		}

		vector<int> tracks = allCams[i].m_feats.tracks;
		int n_feats = tracks.size();

		int nPts_oneImg = 0;
		for (j=0;j<n_feats;j++)
		{
			if (tracks[j]==-1)
			{
				continue;
			}

			for (k=0;k<nTracks;k++)
			{
				if (tracks[j] != clouds[k].m_idx)
				{
					continue;
				}

				nPts_oneImg++;
				break;
			}
		}

		if (nPts_oneImg>nPts)
		{
			nPts = nPts_oneImg;
			idx_max = i;
		}
	}

	return idx_max;
}

// return the index of the image observing the most reconstructed tracks
int DeepVoid::FindImgObservingMostTracks_binarySearch(const vector<cam_data> & allCams,	// input:	all images
													  const vector<CloudPoint> & clouds,	// input:	all reconstructed tracks
													  const vector<int> & status,			// input:	status[i]=1 means that image i is not considered
													  int & nPts							// output:	the maximum number of tracks observed by single image 
													  )
{
	int i,j,k;

	int nTracks = clouds.size();
	int nImgs = allCams.size();

	// sort tracks first
	vector<int> allTracks(nTracks);
	for (i=0;i<nTracks;i++)
	{
		allTracks[i] = clouds[i].m_idx;
	}
	sort(allTracks.begin(), allTracks.end());

	int idx_max = -1;
	nPts = 0;

	for (i=0;i<nImgs;i++)
	{
		if (status[i])
		{
			continue;
		}

		vector<int> tracks = allCams[i].m_feats.tracks;
		int n_feats = tracks.size();

		int nPts_oneImg = 0;
		for (j=0;j<n_feats;j++)
		{
			if (tracks[j]==-1)
			{
				continue;
			}

			if (binary_search(allTracks.begin(), allTracks.end(), tracks[j]))
			{
				nPts_oneImg++;
			}
		}

		if (nPts_oneImg>nPts)
		{
			nPts = nPts_oneImg;
			idx_max = i;
		}
	}

	return idx_max;
}

// return the index of the image observing the most reconstructed tracks
int DeepVoid::FindImgObservingMostTracks_hashSet(const vector<cam_data> & allCams,	// input:	all images
												 const vector<CloudPoint> & clouds,	// input:	all reconstructed tracks
												 const vector<int> & status,			// input:	status[i]=1 means that image i is not considered
												 int & nPts							// output:	the maximum number of tracks observed by single image 
												 )
{
	int i,j,k;

	int nTracks = clouds.size();
	int nImgs = allCams.size();

	// initial hash_set
	hash_set<int> allTracks;
	for (i=0;i<nTracks;i++)
	{
		allTracks.insert(clouds[i].m_idx);
	}

	int idx_max = -1;
	nPts = 0;

	for (i=0;i<nImgs;i++)
	{
		if (status[i])
		{
			continue;
		}

		vector<int> tracks = allCams[i].m_feats.tracks;
		int n_feats = tracks.size();

		int nPts_oneImg = 0;
		for (j=0;j<n_feats;j++)
		{
			if (tracks[j]==-1)
			{
				continue;
			}

			if (allTracks.find(tracks[j]) != allTracks.end()) // found
			{
				nPts_oneImg++;
			}
		}

		if (nPts_oneImg>nPts)
		{
			nPts = nPts_oneImg;
			idx_max = i;
		}
	}

	return idx_max;
}

// 20150127, zhaokunz, return the index of the image observing the most reconstructed tracks
void DeepVoid::GetReconstructedTrackNum(const vector<cam_data> & allCams,	// input:	all images
									    const vector<CloudPoint> & clouds,	// input:	all reconstructed tracks
									    const vector<int> & status,			// input:	status[i]=1 means that image i is not considered
									    vector<Point2i> & pairs				// output:	the maximum number of tracks observed by single image 
									    )
{
	int i,j,k;

	pairs.clear();

	int nTracks = clouds.size();
	int nImgs = allCams.size();

	// initial hash_set
	hash_set<int> allTracks;
	for (i=0;i<nTracks;i++)
	{
		allTracks.insert(clouds[i].m_idx);
	}

	for (i=0;i<nImgs;i++)
	{
		if (status[i])
		{
			continue;
		}

		vector<int> tracks = allCams[i].m_feats.tracks;
		int n_feats = tracks.size();

		int nPts_oneImg = 0;
		for (j=0;j<n_feats;j++)
		{
			if (tracks[j]==-1)
			{
				continue;
			}

			if (allTracks.find(tracks[j]) != allTracks.end()) // found
			{
				nPts_oneImg++;
			}
		}

		Point2i p;
		p.x = i;
		p.y = nPts_oneImg;

		pairs.push_back(p);
	}

	sort(pairs.begin(), pairs.end(), [](const Point2i & a, const Point2i & b){return a.y>b.y;});
}

// 20150127, zhaokunz, find image pair good for RO
void DeepVoid::FindPairObservingMostCommonTracks(const vector<cam_data> & allCams,			// input:	all images
											     const vector<vector<Point2i>> & allTracks,	// input:	all feature tracks
												 vector<Point2i> & pairs					// output:	the found pairs in descendent ordering
											     )
{
	int i,j,k;

	int n = allCams.size(); // number of cameras
	int m = allTracks.size(); // number of tracks

	pairs.clear();

	vector<Point2i> pairs_tmp;
	vector<int> score;
	vector<int> indices;

	int idx = 0;

	for (i=0;i<n;i++)
	{
		for (j=i+1;j<n;j++)
		{
			int N = 0;

			for (k=0;k<m;k++)
			{
				vector<Point2i> oneTrack = allTracks[k];

				auto iter = find_if(oneTrack.begin(),oneTrack.end(),[i](const Point2i & t){return t.x==i;});

				if (iter==oneTrack.end())
				{
					continue;
				}

				iter = find_if(oneTrack.begin(),oneTrack.end(),[j](const Point2i & t){return t.x==j;});

				if (iter==oneTrack.end())
				{
					continue;
				}

				N+=oneTrack.size();
			}

			Point2i p;
			p.x = i;
			p.y = j;

			pairs_tmp.push_back(p);
			score.push_back(N);
			indices.push_back(idx);

			idx++;
		}
	}

	sort(indices.begin(), indices.end(), [&score](int a, int b){return score[a]>score[b];}); // > is descendent, < is increasing

	for (i=0;i<indices.size();i++)
	{
		pairs.push_back(pairs_tmp[indices[i]]);
	}
}

// 20150203, zhaokunz, try to rank all other oriented images for dense matching with designated reference image based on certain measure
void DeepVoid::RankMatchingImages(const vector<cam_data> & allCams,	// input:	all images
								  const vector<CloudPoint> & clouds,// input:	all reconstructed tracks
								  int idxRefImg,					// input:	the index of the reference image
								  vector<int> & matchingImgs		// output:	the indices of all other matching images, in descending ordering 
								  )
{
	int i,j;

	matchingImgs.clear();

	if (allCams[idxRefImg].R[0]<-90)
	{
		// the reference image has not been oriented yet
		return;
	}

	// first, compute the optical centers of all images
	vector<Matx31d> vCs;
	for (auto iter=allCams.begin();iter!=allCams.end();++iter)
	{
		if (iter->R[0]<-90)
		{
			Matx31d C;
			vCs.push_back(C);
			continue;
		}

		Matx33d mR;
		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR(i,j)=iter->R[i*3+j];
			}
		}

		Matx31d mt;
		mt(0) = iter->t[0];
		mt(1) = iter->t[1];
		mt(2) = iter->t[2];

		Matx31d mC = -mR.t()*mt;

		vCs.push_back(mC);
	}
	
	vector<double> angs_sum(allCams.size());
	vector<int> nums(allCams.size());

	for (auto iter=clouds.begin();iter!=clouds.end();++iter)
	{
		auto iter_found = find_if(iter->m_vImgInfos.begin(),iter->m_vImgInfos.end(),
			[idxRefImg](const CloudPoint_ImgInfo & a){return a.m_idxImg==idxRefImg;});

		if (iter_found==iter->m_vImgInfos.end())
		{
			// not found in the reference image
			continue;
		}

		Matx31d XYZ;
		XYZ(0) = iter->m_pt.x;
		XYZ(1) = iter->m_pt.y;
		XYZ(2) = iter->m_pt.z;

		// the reference line vector
		Matx31d vec_ref = XYZ-vCs[idxRefImg];
		double nVec_ref = norm(vec_ref);

		for (auto iter_j=iter->m_vImgInfos.begin();iter_j!=iter->m_vImgInfos.end();++iter_j)
		{
			if (iter_j==iter_found)
			{
				continue;
			}

			Matx31d vec_j = XYZ-vCs[iter_j->m_idxImg];

			double nVec_j = norm(vec_j);

			Matx<double,1,1> cosa = vec_ref.t() * vec_j;
			double tmp = cosa(0)/(nVec_ref*nVec_j);
			if (tmp>1)
			{
				tmp=1;
			}
			if (tmp<-1)
			{
				tmp=-1;
			}
			double ang = acos(tmp)*180/CV_PI; // 0-180

			++nums[iter_j->m_idxImg];
			angs_sum[iter_j->m_idxImg] += ang;
		}
	}
}

// 20150204, zhaokunz, try to score all other oriented images for dense matching with designated reference image based on certain measure
void DeepVoid::ScoreMatchingImages(const vector<cam_data> & allCams,			// input:	all images
								   const vector<CloudPoint> & clouds,			// input:	all reconstructed tracks
								   const vector<vector<DMatch>> & allMatches,	// input:	all pair-wise matches
								   int idxRefImg,								// input:	the index of the reference image
								   vector<Point2d> & scores,					// output:	scores of all other images, with x being the index, and y being the score, in descending order
								   double ang_desired /*= 15*/					// input:	the desired triangulation angle
								   )
{
	int i,j;

	int nCam = allCams.size();

	double ang_sigma = ang_desired/3.0;

	scores.clear();

	if (allCams[idxRefImg].R[0]<-90)
	{
		// the reference image has not been oriented yet
		return;
	}

	// first, compute the optical centers of all images
	vector<Matx31d> vCs;
	for (auto iter=allCams.begin();iter!=allCams.end();++iter)
	{
		if (iter->R[0]<-90)
		{
			Matx31d C;
			vCs.push_back(C);
			continue;
		}

		Matx33d mR;
		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR(i,j)=iter->R[i*3+j];
			}
		}

		Matx31d mt;
		mt(0) = iter->t[0];
		mt(1) = iter->t[1];
		mt(2) = iter->t[2];

		Matx31d mC = -mR.t()*mt;

		vCs.push_back(mC);
	}

	for (i=0;i<nCam;i++)
	{
		if (allCams[i].R[0]<-90||i==idxRefImg)
		{
			Point2d pt;
			pt.x = i;
			pt.y = -1;
			scores.push_back(pt);
			continue;
		}

		double sum_w = 0;

		vector<DMatch> matches = allMatches[idxRefImg*nCam+i];

		for (auto iter_match=matches.begin();iter_match!=matches.end();++iter_match)
		{
			int idxTrack = allCams[idxRefImg].m_feats.tracks[iter_match->queryIdx];

			auto iter_find_cloud = find_if(clouds.begin(),clouds.end(),[idxTrack](const CloudPoint & a){return a.m_idx==idxTrack;});

			if (iter_find_cloud==clouds.end())
			{
				// this track has not been reconstructed yet
				continue;
			}

			auto iter_find_imgpt_ref = find_if(iter_find_cloud->m_vImgInfos.begin(),iter_find_cloud->m_vImgInfos.end(),
				[idxRefImg](const CloudPoint_ImgInfo & a){return a.m_idxImg==idxRefImg;});
			auto iter_find_imgpt_i   = find_if(iter_find_cloud->m_vImgInfos.begin(),iter_find_cloud->m_vImgInfos.end(),
				[i](const CloudPoint_ImgInfo & a){return a.m_idxImg==i;});

			if (iter_find_imgpt_ref==iter_find_cloud->m_vImgInfos.end()||iter_find_imgpt_i==iter_find_cloud->m_vImgInfos.end())
			{
				// at least one of the matching features is not associated with the reconstructed cloud point
				continue;
			}

			// here, we confirm that we found a valid reconstructed matching feature
			Matx31d XYZ;
			XYZ(0) = iter_find_cloud->m_pt.x;
			XYZ(1) = iter_find_cloud->m_pt.y;
			XYZ(2) = iter_find_cloud->m_pt.z;

			Matx31d vec_ref = XYZ-vCs[idxRefImg];
			double nVec_ref = norm(vec_ref);

			Matx31d vec_i = XYZ-vCs[i];
			double nVec_i = norm(vec_i);

			Matx<double,1,1> cosa = vec_ref.t() * vec_i;
			double tmp = cosa(0)/(nVec_ref*nVec_i);
			if (tmp>1)
			{
				tmp=1;
			}
			if (tmp<-1)
			{
				tmp=-1;
			}
			double ang = acos(tmp)*R2D; // 0-180

			double w = exp_miu_sigma(ang,ang_desired,ang_sigma); // compute the weight

			sum_w+=w;
		}

		Point2d pt;
		pt.x = i;
		pt.y = sum_w;

		scores.push_back(pt);
	}

	sort(scores.begin(), scores.end(), [](const Point2d & a, const Point2d & b){return a.y>b.y;});
}

// feature points in all images are supposed to be distortion free
bool DeepVoid::ExteriorOrientation_PnP_RANSAC(vector<cam_data> & vCams,						// input&output:	all the images
											  int idx_cam,									// input:	the index of the image to be oriented
											  vector<CloudPoint> & clouds,					// input&output:	the reconstructed cloud points in reference camera frame, which is the first image
											  const vector<vector<Point2i>> & allTracks,	// input:	all the tracks
											  double thresh_rpj_inlier/* = 1*/,				// input:	the allowed level of reprojection error, used for RANSAC to determine outlier
											  double thresh_ratio_inlier/* = 0.5*/			// input:	the allowed minimum ratio of inliers within all reconstructed matches
											  )
{
	cam_data cam = vCams[idx_cam];
	vector<int> tracks = cam.m_feats.tracks;

	int i,j,k;

	int n_allCldPts = clouds.size();

	int nFeat = tracks.size();
	
	Matx33d mK;
	mK(0,0) = cam.fx;
	mK(1,1) = cam.fy;
	mK(0,1) = cam.s;
	mK(0,2) = cam.cx;
	mK(1,2) = cam.cy;
	mK(2,2) = 1;

	// check how many tracks have already been reconstructed
	vector<Point3f> objectPoints;
	vector<Point2f> imagePoints;

	// the idx of image points in image that has already been reconstructed
	vector<Point2i> vIdxTrack_exist;

	vector<int> vIdxTrack_nonExist;

	for (i=0;i<nFeat;i++)
	{
		if (tracks[i] == -1)
		{
			continue;
		}

		bool bExist = false;
		for (j=0;j<n_allCldPts;j++)
		{
			if (tracks[i] != clouds[j].m_idx)
			{
				continue;
			}

			Point2i idx;
			idx.x = j; // the corresponding object index
			idx.y = i; // the corresponding image point index
			vIdxTrack_exist.push_back(idx);

			Point3f pt3d;
			pt3d.x = clouds[j].m_pt.x;
			pt3d.y = clouds[j].m_pt.y;
			pt3d.z = clouds[j].m_pt.z;
			objectPoints.push_back(pt3d);

			Point2f pt2d;
			pt2d.x = cam.m_feats.key_points[i].pt.x;
			pt2d.y = cam.m_feats.key_points[i].pt.y;
			imagePoints.push_back(pt2d);

			bExist = true;
			break;
		}

		if (!bExist)
		{
			vIdxTrack_nonExist.push_back(i);
		}
	}

	int n_exist = objectPoints.size();			// the number of observed tracks already been reconstructed
	int n_nonExist = vIdxTrack_nonExist.size(); // the number of observed tracks haven't been reconstructed yet

	if (n_exist < 6)
	{
		return false;
	}

	Mat distCoeffs;
	Matx31d rvec, mt;
	vector<int> vInliers;

	try
	{
		solvePnPRansac(objectPoints, imagePoints, mK, distCoeffs, rvec, mt, false, 256, thresh_rpj_inlier, n_exist, vInliers, CV_ITERATIVE);
	}
	catch (cv::Exception & e)
	{
		CString str;
		str = e.msg.c_str();
		AfxMessageBox(str);
	}

	int n_inliers = vInliers.size();

	double ratio_inliers = n_inliers/(double)n_exist;

	// if the ratio of inliers is not big enough then this eo is considered failure
	if (ratio_inliers < thresh_ratio_inlier || n_inliers < 6)
	{
		return false;
	}

	for (i=0;i<n_inliers;i++)
	{
		int idx_obj = vIdxTrack_exist[vInliers[i]].x;
		int idx_img = vIdxTrack_exist[vInliers[i]].y;

		CloudPoint_ImgInfo imgInfo;
		imgInfo.m_idxImg = idx_cam;
		imgInfo.m_idxImgPt = idx_img;

		clouds[idx_obj].m_vImgInfos.push_back(imgInfo);
	}

	Matx33d mR;

	try
	{
		Rodrigues(rvec, mR);
	}
	catch (cv::Exception & e)
	{
		CString str;
		str = e.msg.c_str();
		AfxMessageBox(str);
	}

	// check all reproj err //////////////////////////////////////////////////
	FILE * file = fopen("D:\\outliers.txt", "a");
	vector<double> vRpjErr;
	for (i=0;i<n_exist;i++)
	{
		Matx33d mKR = mK*mR;
		Matx31d mKt = mK*mt;

		Matx31d pt3d;
		pt3d(0) = objectPoints[i].x; pt3d(1) = objectPoints[i].y; pt3d(2) = objectPoints[i].z;

		Matx31d pt2d = mKR*pt3d+mKt;

		pt2d(0) /= pt2d(2);	pt2d(1) /= pt2d(2);
		double dx = pt2d(0) - imagePoints[i].x;
		double dy = pt2d(1) - imagePoints[i].y;
		double d = sqrt(dx*dx+dy*dy);
		vRpjErr.push_back(d);

		if (d>thresh_rpj_inlier)
		{
			fprintf(file, "outliers obj point: %04d track: %04d	%lf	%lf	%lf	%lf\n", vIdxTrack_exist[i].x, clouds[vIdxTrack_exist[i].x].m_idx, pt3d(0), pt3d(1), pt3d(2), d);
		}
	}
	fclose(file);
	//////////////////////////////////////////////////////////////////////////

	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			vCams[idx_cam].R[i*3+j] = mR(i,j);
		}
	}
	vCams[idx_cam].t[0] = mt(0);
	vCams[idx_cam].t[1] = mt(1);
	vCams[idx_cam].t[2] = mt(2);

	// add new consistent tracks
	for (i=0;i<n_nonExist;i++)
	{
		vector<Point2i> oneNewTrack = allTracks[tracks[vIdxTrack_nonExist[i]]];

		double rprErr; CMatrix mWrdPt;
		int code = Intersect_oneTrack(oneNewTrack, vCams, mWrdPt, &rprErr);

		// if 0, it's because there are no more than one calibrated images
		if (code == 1)
		{
			continue;
		}
		else if (code == 2)
		{
			// cut off the connection between all features and the track
			// because the reconstructed point is behind some of the images
			// this track definitely contain some mismatches
			for (j=0;j<oneNewTrack.size();j++)
			{
				Point2i indices = oneNewTrack[j];
				vCams[indices.x].m_feats.tracks[indices.y] = -1;
			}
		}
		else // code == 0
		{
			if (rprErr < 3)
			{
				// this track is added
				CloudPoint cldpt;
				cldpt.m_idx = tracks[vIdxTrack_nonExist[i]];

				cldpt.m_pt.x = mWrdPt(1);
				cldpt.m_pt.y = mWrdPt(2);
				cldpt.m_pt.z = mWrdPt(3);

				for (j=0;j<oneNewTrack.size();j++)
				{
					Point2i indices = oneNewTrack[j];
					if (vCams[indices.x].R[0]<-90)
					{
						continue;
					}
					CloudPoint_ImgInfo cldpt_imginfo;
					cldpt_imginfo.m_idxImg = indices.x;
					cldpt_imginfo.m_idxImgPt = indices.y;
					cldpt.m_vImgInfos.push_back(cldpt_imginfo);
				}
				
				clouds.push_back(cldpt);
			} 
			else
			{
				// cut off the connection between all features and the track
				// because the reprojection error is too big, this track could be a potential mismatch
				for (j=0;j<oneNewTrack.size();j++)
				{
					Point2i indices = oneNewTrack[j];
					vCams[indices.x].m_feats.tracks[indices.y] = -1;
				}
			}
		}
	}

	return true;
}

// feature points in all images are supposed to be distortion free
// detach all the outliers found in PnP RANSAC with corresponding tracks 
bool DeepVoid::ExteriorOrientation_PnP_RANSAC_detachOutliers(vector<cam_data> & vCams,					// input&output:	all the images
															 int idx_cam,								// input:	the index of the image to be oriented
															 vector<CloudPoint> & clouds,				// input&output:	the reconstructed cloud points in reference camera frame, which is the first image
															 const vector<vector<Point2i>> & allTracks,	// input:	all the tracks
															 double thresh_rpj_inlier /*= 1*/,			// input:	the allowed level of reprojection error, used for RANSAC to determine outlier
															 double thresh_ratio_inlier /*= 0.5*/		// input:	the allowed minimum ratio of inliers within all reconstructed matches
															 )
{
	cam_data cam = vCams[idx_cam];
	vector<int> tracks = cam.m_feats.tracks;

	int i,j,k;

	int n_allCldPts = clouds.size();

	int nFeat = tracks.size();

	Matx33d mK;
	mK(0,0) = cam.fx;
	mK(1,1) = cam.fy;
	mK(0,1) = cam.s;
	mK(0,2) = cam.cx;
	mK(1,2) = cam.cy;
	mK(2,2) = 1;

	// check how many tracks have already been reconstructed
	vector<Point3f> objectPoints;
	vector<Point2f> imagePoints;

	// the idx of image points in image that has already been reconstructed
	vector<Point3i> vIdxTrack_exist;

	vector<int> vIdxTrack_nonExist;

	for (i=0;i<nFeat;i++)
	{
		if (tracks[i] == -1)
		{
			continue;
		}

		bool bExist = false;
		for (j=0;j<n_allCldPts;j++)
		{
			if (tracks[i] != clouds[j].m_idx)
			{
				continue;
			}

			Point3i idx;
			idx.x = j; // the corresponding object index
			idx.y = i; // the corresponding image point index
			idx.z = clouds[j].m_idx; // the corresponding track index of object point
			vIdxTrack_exist.push_back(idx);

			Point3f pt3d;
			pt3d.x = clouds[j].m_pt.x;
			pt3d.y = clouds[j].m_pt.y;
			pt3d.z = clouds[j].m_pt.z;
			objectPoints.push_back(pt3d);

			Point2f pt2d;
			pt2d.x = cam.m_feats.key_points[i].pt.x;
			pt2d.y = cam.m_feats.key_points[i].pt.y;
			imagePoints.push_back(pt2d);

			bExist = true;
			break;
		}

		if (!bExist)
		{
			vIdxTrack_nonExist.push_back(i);
		}
	}

	int n_exist = objectPoints.size();			// the number of observed tracks already been reconstructed
	int n_nonExist = vIdxTrack_nonExist.size(); // the number of observed tracks haven't been reconstructed yet

	if (n_exist < 6)
	{
		return false;
	}

	Mat distCoeffs;
	Matx31d rvec, mt;
	vector<int> vInliers;

	try
	{
		solvePnPRansac(objectPoints, imagePoints, mK, distCoeffs, rvec, mt, false, 256, thresh_rpj_inlier, n_exist, vInliers, CV_ITERATIVE);
	}
	catch (cv::Exception & e)
	{
		CString str;
		str = e.msg.c_str();
		AfxMessageBox(str);
	}

	int n_inliers = vInliers.size();

	double ratio_inliers = n_inliers/(double)n_exist;

	// if the ratio of inliers is not big enough then this eo is considered failure
	if (ratio_inliers < thresh_ratio_inlier || n_inliers < 6)
	{
		return false;
	}
	
	hash_set<int> hInliers;
	for (i=0;i<n_inliers;i++)
	{
		int idx_obj = vIdxTrack_exist[vInliers[i]].x;
		int idx_img = vIdxTrack_exist[vInliers[i]].y;

		CloudPoint_ImgInfo imgInfo;
		imgInfo.m_idxImg = idx_cam;
		imgInfo.m_idxImgPt = idx_img;

		clouds[idx_obj].m_vImgInfos.push_back(imgInfo);

		hInliers.insert(vInliers[i]);
	}

	// detach all the outliers found in PnP RANSAC with corresponding tracks ////
	for (i=0;i<n_exist;i++)
	{
		if (hInliers.find(i) == hInliers.end()) // found an outlier
		{
			// get the track index of this outlier
			int idx_track = vIdxTrack_exist[i].z;

			// first delete the object point from clouds
			vector <CloudPoint>::iterator iter;
			for (iter = clouds.begin(); iter != clouds.end(); iter++)
			{
				if (iter->m_idx == idx_track)
				{
					clouds.erase(iter);
					break;
				}
			}

			// then detach all the features from this track
			vector<Point2i> oneTrack = allTracks[idx_track];
			for (j=0;j<oneTrack.size();j++)
			{
				Point2i indices = oneTrack[j];
				vCams[indices.x].m_feats.tracks[indices.y] = -1;
			}
		}
	}
	/////////////////////////////////////////////////////////////////////////////

	Matx33d mR;

	try
	{
		Rodrigues(rvec, mR);
	}
	catch (cv::Exception & e)
	{
		CString str;
		str = e.msg.c_str();
		AfxMessageBox(str);
	}

	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			vCams[idx_cam].R[i*3+j] = mR(i,j);
		}
	}
	vCams[idx_cam].t[0] = mt(0);
	vCams[idx_cam].t[1] = mt(1);
	vCams[idx_cam].t[2] = mt(2);

	// add new consistent tracks
	for (i=0;i<n_nonExist;i++)
	{
		vector<Point2i> oneNewTrack = allTracks[tracks[vIdxTrack_nonExist[i]]];

		double rprErr; CMatrix mWrdPt;
		int code = Intersect_oneTrack(oneNewTrack, vCams, mWrdPt, &rprErr);

		// if 0, it's because there are no more than one calibrated images
		if (code == 1)
		{
			continue;
		}
		else if (code == 2)
		{
			// cut off the connection between all features and the track
			// because the reconstructed point is behind some of the images
			// this track definitely contain some mismatches
			for (j=0;j<oneNewTrack.size();j++)
			{
				Point2i indices = oneNewTrack[j];
				vCams[indices.x].m_feats.tracks[indices.y] = -1;
			}
		}
		else // code == 0
		{
			if (rprErr < thresh_rpj_inlier)
			{
				// this track is added
				CloudPoint cldpt;
				cldpt.m_idx = tracks[vIdxTrack_nonExist[i]];

				cldpt.m_pt.x = mWrdPt(1);
				cldpt.m_pt.y = mWrdPt(2);
				cldpt.m_pt.z = mWrdPt(3);

				for (j=0;j<oneNewTrack.size();j++)
				{
					Point2i indices = oneNewTrack[j];
					if (vCams[indices.x].R[0]<-90)
					{
						continue;
					}
					CloudPoint_ImgInfo cldpt_imginfo;
					cldpt_imginfo.m_idxImg = indices.x;
					cldpt_imginfo.m_idxImgPt = indices.y;
					cldpt.m_vImgInfos.push_back(cldpt_imginfo);
				}

				clouds.push_back(cldpt);
			} 
			else
			{
				// cut off the connection between all features and the track
				// because the reprojection error is too big, this track could be a potential mismatch
				for (j=0;j<oneNewTrack.size();j++)
				{
					Point2i indices = oneNewTrack[j];
					vCams[indices.x].m_feats.tracks[indices.y] = -1;
				}
			}
		}
	}

	return true;
}

// 20150124, zhaokunz, feature points in all images are supposed to be distortion free
bool DeepVoid::EO_PnP_RANSAC(vector<cam_data> & vCams,					// input&output:	all the images
							 int idx_refimg,							// input:	the reference image, whose R=I and t = [0,0,0]'
						     int idx_cam,								// input:	the index of the image to be oriented
						     vector<CloudPoint> & clouds,				// input&output:	the reconstructed cloud points in reference camera frame, which is the first image
						     const vector<vector<Point2i>> & allTracks,	// input:	all the tracks
						     double thresh_rpj_inlier/* = 1*/,			// input:	the allowed level of reprojection error, used for RANSAC to determine outlier
						     double thresh_ratio_inlier /*= 0.5*/		// input:	the allowed minimum ratio of inliers within all reconstructed matches
						     )
{
	cam_data cam = vCams[idx_cam];
	vector<int> tracks = cam.m_feats.tracks;

	int i,j,k;

	int nImg = vCams.size();

	int n_allCldPts = clouds.size();

	int nFeat = tracks.size();

	Matx33d mK;
	mK(0,0) = cam.fx;
	mK(1,1) = cam.fy;
	mK(0,1) = cam.s;
	mK(0,2) = cam.cx;
	mK(1,2) = cam.cy;
	mK(2,2) = 1;

	// check how many tracks have already been reconstructed
	vector<Point3f> objectPoints;
	vector<Point2f> imagePoints;

	// the idx of image points in image that has already been reconstructed
	vector<Point3i> vIdxTrack_exist;

	vector<int> vIdxTrack_nonExist;

	for (i=0;i<nFeat;i++)
	{
		if (tracks[i] == -1)
		{
			continue;
		}

		bool bExist = false;
		for (j=0;j<n_allCldPts;j++)
		{
			if (tracks[i] != clouds[j].m_idx)
			{
				continue;
			}

			Point3i idx;
			idx.x = j; // the corresponding object index
			idx.y = i; // the corresponding image point index
			idx.z = clouds[j].m_idx; // the corresponding track index of object point
			vIdxTrack_exist.push_back(idx);

			Point3f pt3d;
			pt3d.x = clouds[j].m_pt.x;
			pt3d.y = clouds[j].m_pt.y;
			pt3d.z = clouds[j].m_pt.z;
			objectPoints.push_back(pt3d);

			Point2f pt2d;
			pt2d.x = cam.m_feats.key_points[i].pt.x;
			pt2d.y = cam.m_feats.key_points[i].pt.y;
			imagePoints.push_back(pt2d);

			bExist = true;
			break;
		}

		if (!bExist)
		{
			vIdxTrack_nonExist.push_back(i);
		}
	}

	int n_exist = objectPoints.size();			// the number of observed tracks already been reconstructed
	int n_nonExist = vIdxTrack_nonExist.size(); // the number of observed tracks haven't been reconstructed yet

	if (n_exist < 6)
	{
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("no more than 6 exist points");

		return false;
	}

	Mat distCoeffs;
	Matx31d rvec, mt;
	vector<int> vInliers;

	try
	{
		solvePnPRansac(objectPoints, imagePoints, mK, distCoeffs, rvec, mt, false, 256, thresh_rpj_inlier, n_exist, vInliers, CV_ITERATIVE);
	}
	catch (cv::Exception & e)
	{
		CString str;
		str = e.msg.c_str();
		AfxMessageBox(str);
	}

	int n_inliers = vInliers.size();

	double ratio_inliers = n_inliers/(double)n_exist;

	// if the ratio of inliers is not big enough then this eo is considered failure
	if (ratio_inliers < thresh_ratio_inlier || n_inliers < 6)
	{
		CString strInfo;
		strInfo.Format("ratio_inliers: %lf, n_inliers: %d", ratio_inliers, n_inliers);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		return false;
	}

	// update the EO //////////////////////////////////////////////////////////////////////////
	Matx33d mR;

	Rodrigues(rvec, mR);
	
	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			vCams[idx_cam].R[i*3+j] = mR(i,j);
		}
	}
	vCams[idx_cam].t[0] = mt(0);
	vCams[idx_cam].t[1] = mt(1);
	vCams[idx_cam].t[2] = mt(2);
	///////////////////////////////////////////////////////////////////////////////////////////

	vector<uchar> vbools(n_exist);
	for (i=0;i<n_inliers;i++)
	{
		vbools[vInliers[i]] = 1;
	}

	for (i=0;i<n_exist;i++)
	{
		int idx_obj = vIdxTrack_exist[i].x;
		int idx_img = vIdxTrack_exist[i].y;

		CloudPoint_ImgInfo imgInfo;
		imgInfo.m_idxImg = idx_cam;
		imgInfo.m_idxImgPt = idx_img;

		vector<CloudPoint_ImgInfo>::iterator iter = find(clouds[idx_obj].m_vImgInfos.begin(),clouds[idx_obj].m_vImgInfos.end(),imgInfo);

		if (vbools[i]) // inlier
		{
			if (iter == clouds[idx_obj].m_vImgInfos.end())
			{
				// the inlier image point is not associated with a object point yet
				// then associate them
				clouds[idx_obj].m_vImgInfos.push_back(imgInfo);
			}
		} 
		else // outlier
		{
			if (iter != clouds[idx_obj].m_vImgInfos.end())
			{
				// if the outlier image point already exist, then erase it
				clouds[idx_obj].m_vImgInfos.erase(iter);
			}
		}
	}

	// using current inliers to do sba
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(_T("SBA in EO starts"));
	double opts[5];
	opts[0] = 1.0E-3;	// levmar 优化方法中要用到的参数 u 的初始尺度因子，默认为 1.0E-3
	opts[1] = 1.0E-8;	// 当目标函数对各待优化参数的最大导数小于等于该值时优化结束，默认为 1.0E-12
	opts[2] = 1.0E-8;	// 当待优化参数 2 范数的变化量小于该阈值时优化结束，默认为 1.0E-12
	opts[3] = 1.0E-12;	// 当误差矢量的 2 范数小于该阈值时优化结束，默认为 1.0E-12
	opts[4] = 0;		// 当误差矢量的 2 范数的相对变化量小于该阈值时优化结束，默认为 0

	double info[10];

// 	int nnn = optim_sba_levmar_XYZ_ext_rotvec(clouds, vCams, idx_refimg, 1024, opts, info);
// 	double rrr = sqrt(info[1]/nnn);
// 	CString strInfo;
// 	strInfo.Format("SBA in EO ends, err: %lf, iter: %04.0f, code: %01.0f", rrr, info[5], info[6]);

	int nnn = optim_sba_levmar_XYZ_ext_rotvec_own(clouds, vCams, idx_refimg, 1024, opts, info);
	double rrr = info[1];
	CString strInfo;
	strInfo.Format("SBA in EO ends, err: %lf, iter: %04.0f, code: %01.0f", rrr, info[3], info[4]);

	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

	// check if the inliers change after sba
	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mR(i,j) = vCams[idx_cam].R[i*3+j];
		}
	}
	mt(0) = vCams[idx_cam].t[0];
	mt(1) = vCams[idx_cam].t[1];
	mt(2) = vCams[idx_cam].t[2];

	Matx33d mKR = mK*mR;
	Matx31d mKt = mK*mt;

	vector<uchar> vbools_new(n_exist);

	for (i=0;i<n_exist;i++)
	{
		int idx_obj = vIdxTrack_exist[i].x;

		Matx31d XYZ;
		XYZ(0) = clouds[idx_obj].m_pt.x;
		XYZ(1) = clouds[idx_obj].m_pt.y;
		XYZ(2) = clouds[idx_obj].m_pt.z;

		Matx31d xyw = mKR*XYZ+mKt;

		double dx = xyw(0)/xyw(2)-imagePoints[i].x;
		double dy = xyw(1)/xyw(2)-imagePoints[i].y;

		double d = sqrt(dx*dx+dy*dy);

		if (d<thresh_rpj_inlier)
		{
			vbools_new[i] = 1;
		} 
	}

//	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("001");

	// update the inliers, maybe there are more inliers after sba
	for (i=0;i<n_exist;i++)
	{
		int idx_obj = vIdxTrack_exist[i].x;
		int idx_img = vIdxTrack_exist[i].y;

		CloudPoint_ImgInfo imgInfo;
		imgInfo.m_idxImg = idx_cam;
		imgInfo.m_idxImgPt = idx_img;

//		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("004");

		vector<CloudPoint_ImgInfo>::iterator iter = find(clouds[idx_obj].m_vImgInfos.begin(),clouds[idx_obj].m_vImgInfos.end(),imgInfo);

//		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("005");

		if (vbools_new[i]) // inlier
		{
			if (iter == clouds[idx_obj].m_vImgInfos.end())
			{
//				theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("006");

				// the inlier image point is not associated with a object point yet
				// then associate them
				clouds[idx_obj].m_vImgInfos.push_back(imgInfo);
			}
		} 
		else // outlier
		{
			if (iter != clouds[idx_obj].m_vImgInfos.end())
			{
// 				strInfo.Format("007 idx_obj: %d", idx_obj);
// 				theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

				// if the outlier image point already exist, then erase it
				clouds[idx_obj].m_vImgInfos.erase(iter);
			}
		}
	}
	
//	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("002");

	// finally, we have to triangulate 
	// first, identify which images have already been oriented
	vector<int> vIdxOrientedImg;
	for (i=0;i<nImg;i++)
	{
		if (vCams[i].R[0]<-90 || i == idx_cam)
		{
			continue;
		}
		vIdxOrientedImg.push_back(i);
	}

	vector<Matx33d> vKs_oriented;
	vector<Matx33d> vRs_oriented;
	vector<Matx31d> vts_oriented;

	vector<vector<Point3d>> wrdpts_new(n_nonExist);

	// tiangulate points with each oriented image
	for (k=0;k<vIdxOrientedImg.size();k++)
	{
		int idx = vIdxOrientedImg[k];

		Matx33d mK_other, mR_other;
		Matx31d mt_other;

		cam_data cam_other = vCams[idx];
		
		mK_other(0,0) = cam_other.fx;
		mK_other(1,1) = cam_other.fy;
		mK_other(0,1) = cam_other.s;
		mK_other(0,2) = cam_other.cx;
		mK_other(1,2) = cam_other.cy;
		mK_other(2,2) = 1;

		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR_other(i,j) = cam_other.R[i*3+j];
			}
		}

		mt_other(0) = cam_other.t[0];
		mt_other(1) = cam_other.t[1];
		mt_other(2) = cam_other.t[2];

		vKs_oriented.push_back(mK_other);
		vRs_oriented.push_back(mR_other);
		vts_oriented.push_back(mt_other);

		vector<int> idxFeat_k;

		vector<Point2d> imgpts, imgpts_other;
		for (i=0;i<n_nonExist;i++)
		{
			int idxTrack = tracks[vIdxTrack_nonExist[i]];
			vector<Point2i> track = allTracks[idxTrack];

			auto iter = find_if(track.begin(), track.end(), [idx](const Point2i & pt){return pt.x == idx;}); // Lambda Expressions in C++

			if (iter!=track.end()) // found one
			{
				Point2d pt_other;
				pt_other.x = cam_other.m_feats.key_points[iter->y].pt.x;
				pt_other.y = cam_other.m_feats.key_points[iter->y].pt.y;
				imgpts_other.push_back(pt_other);

				iter = find_if(track.begin(), track.end(), [idx_cam](const Point2i & pt){return pt.x == idx_cam;});

				Point2d pt;
				pt.x = cam.m_feats.key_points[iter->y].pt.x;
				pt.y = cam.m_feats.key_points[iter->y].pt.y;
				imgpts.push_back(pt);

				idxFeat_k.push_back(i);
			}
		}

		// there are no common track needs to be triangulated between current image and the kth image
		if (imgpts.size()<1)
		{
			continue;
		}

		vector<Point3d> wrdpts;
		vector<Point2d> errs;
		double rpj_err = Triangulate_Optimal(imgpts_other, mK_other, mR_other, mt_other, imgpts, mK, mR, mt, wrdpts, errs);

		for (i=0;i<imgpts.size();i++)
		{
			if (errs[i].x >= 1.5 || errs[i].y >= 1.5)
			{
				continue;
			}

			wrdpts_new[idxFeat_k[i]].push_back(wrdpts[i]);
		}
	}

//	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("003");

	vIdxOrientedImg.push_back(idx_cam);
	vKs_oriented.push_back(mK);
	vRs_oriented.push_back(mR);
	vts_oriented.push_back(mt);

	// 
	for (i=0;i<n_nonExist;i++)
	{
		vector<Point3d> pts = wrdpts_new[i];

		int nCand = pts.size();

		if (nCand<1) // there should be at least 1 candidate 3d coordinates
		{
			continue;
		}

		int idxTrack = tracks[vIdxTrack_nonExist[i]];
		vector<Point2i> track = allTracks[idxTrack];

		vector<int> vNs;
		vector<double> vrpjerrs;
		vector<vector<Point2i>> vVisis;

		// check each candidate
		for (j=0;j<nCand;j++)
		{
			Point3d pt = pts[j];
			Matx31d XYZ;
			XYZ(0)=pt.x;
			XYZ(1)=pt.y;
			XYZ(2)=pt.z;

			int N = 0;
			double sum2 = 0;
			vector<Point2i> visi;

			for (k=0;k<vIdxOrientedImg.size();k++)
			{
				int idxImg = vIdxOrientedImg[k];

				auto iter = find_if(track.begin(), track.end(), [idxImg](const Point2i & pt){return pt.x == idxImg;});

				if (iter == track.end())
				{
					continue;
				}

				cam_data cam_other = vCams[idxImg];

				double x0 = cam_other.m_feats.key_points[iter->y].pt.x;
				double y0 = cam_other.m_feats.key_points[iter->y].pt.y;

				// project
				Matx31d xyw = vKs_oriented[k]*vRs_oriented[k]*XYZ+vKs_oriented[k]*vts_oriented[k];
				double x = xyw(0)/xyw(2);
				double y = xyw(1)/xyw(2);

				double dx = x-x0;
				double dy = y-y0;

				double d2 = dx*dx+dy*dy;

				double d = sqrt(d2);

				if (d>=1.5)
				{
					continue;
				}

				N++;
				sum2+=d2;

				visi.push_back(*iter);
			}

			double rpjerr = sqrt(sum2/N);

			vNs.push_back(N);
			vrpjerrs.push_back(rpjerr);
			vVisis.push_back(visi);
		}

		// find the coordinate that delivers the maximum matched images
		auto iter = max_element(vNs.begin(), vNs.end());
		int max_imgs = *iter;

		if (max_imgs < 2)
		{
			continue;
		}
		
		vector<int> idxMax;
		vector<double> rpjMax;

		for (j=0;j<nCand;j++)
		{
			if (vNs[j]==max_imgs)
			{
				idxMax.push_back(j);
				rpjMax.push_back(vrpjerrs[j]);
			}
		}

		auto iter2 = min_element(rpjMax.begin(), rpjMax.end());
		int idx = iter2 - rpjMax.begin();
		int idx_final = idxMax[idx];

		Point3d pt = pts[idx_final];
		vector<Point2i> visi_track = vVisis[idx_final];

		// this track is added
		CloudPoint cldpt;
		cldpt.m_idx = tracks[vIdxTrack_nonExist[i]];

		cldpt.m_pt.x = pt.x;
		cldpt.m_pt.y = pt.y;
		cldpt.m_pt.z = pt.z;

		for (j=0;j<visi_track.size();j++)
		{
			Point2i indices = visi_track[j];
			
			CloudPoint_ImgInfo cldpt_imginfo;
			cldpt_imginfo.m_idxImg = indices.x;
			cldpt_imginfo.m_idxImgPt = indices.y;
			cldpt.m_vImgInfos.push_back(cldpt_imginfo);
		}

		clouds.push_back(cldpt);
	}

	return true;
}

// 利用匹配路径中的所有点来进行交会得到其空间坐标，返回其 4 维的其次空间坐标
// feature points in all images are supposed to be distortion free
int DeepVoid::Intersect_oneTrack(const vector<Point2i> & track,		// 输入：匹配路径，里面包含每个匹配点所在的视图索引号以及像点索引号
								 const vector<cam_data> & allCams,	// 输入：所有视图的所有信息
								 CMatrix & mWrdPt,					// output: the reconstructed point
								 double * reprojErr /*= NULL*/		// 输出：交会的点在参与交会各视图上的重投影残差的统计量				
								 )
{
	int i,j,k;

	vector<Point2i> vCalibed;

	// find calibrated images
	for (i=0;i<track.size();i++)
	{
		if (allCams[track[i].x].R[0]<-90)
		{
			continue;
		}
		vCalibed.push_back(track[i]);
	}

	int n_pts = vCalibed.size();

	if (n_pts>2)
	{
		double shit = 0;
	}

	// at least 2 images should be calibrated
	if (n_pts<2)
	{
		return 1;
	}

	CMatrix mK(3, 4, 0), mRT(4, 4, 0);
	mK(3, 3) = 1; mRT(4, 4) = 1;
	CMatrix mImgPts(3, n_pts, 1), mProjs(3, 4*n_pts), mImgPt(3, 1, 1);

	for (i=0;i<n_pts;i++)
	{
		int i0 = vCalibed[i].x;
		int j0 = vCalibed[i].y;

		cam_data cam = allCams[i0];

		mImgPt(1) = cam.m_feats.key_points[j0].pt.x;
		mImgPt(2) = cam.m_feats.key_points[j0].pt.y;

		mImgPts(1, i+1) = mImgPt(1);
		mImgPts(2, i+1) = mImgPt(2);

		mK(1, 1) = cam.fx;	mK(2, 2) = cam.fy;
		mK(1, 3) = cam.cx;	mK(2, 3) = cam.cy;
		mK(1, 2) = cam.s;

		for (j=0;j<3;j++)
		{
			for (k=0;k<3;k++)
			{
				mRT(j+1,k+1) = cam.R[j*3+k];
			}
		}

		mRT(1, 4) = cam.t[0];
		mRT(2, 4) = cam.t[1];
		mRT(3, 4) = cam.t[2];

		mProjs.SetRect(1, i*4+1, mK * mRT);
	}

	// 得到交会出来的空间点坐标
	mWrdPt = Intersect(mImgPts, mProjs);

	// 接下来计算该空间点在各参与交会的视图的像面上的重投影残差
	CMatrix mImgPt_reproj;

	double sum_d2 = 0;

	for (i=0;i<n_pts;i++)
	{
		int i0 = vCalibed[i].x;
		int j0 = vCalibed[i].y;

		cam_data cam = allCams[i0];

		mImgPt(1) = cam.m_feats.key_points[j0].pt.x;
		mImgPt(2) = cam.m_feats.key_points[j0].pt.y;

		mK(1, 1) = cam.fx;	mK(2, 2) = cam.fy;
		mK(1, 3) = cam.cx;	mK(2, 3) = cam.cy;
		mK(1, 2) = cam.s;

		for (j=0;j<3;j++)
		{
			for (k=0;k<3;k++)
			{
				mRT(j+1,k+1) = cam.R[j*3+k];
			}
		}

		mRT(1, 4) = cam.t[0];
		mRT(2, 4) = cam.t[1];
		mRT(3, 4) = cam.t[2];

		// 线性重投影
		CMatrix mWrdPt_inCam = mRT * mWrdPt; // the coordinates of reconstructed point in camera coordinate system
		if (mWrdPt_inCam(3)<=0)
		{
			// if the reconstructed point is behind one of the image then quit directly
			// and return 2
			return 2;
		}

		mImgPt_reproj = mK * mWrdPt_inCam;
		mImgPt_reproj(1) = mImgPt_reproj(1) / mImgPt_reproj(3);
		mImgPt_reproj(2) = mImgPt_reproj(2) / mImgPt_reproj(3);
		mImgPt_reproj(3) = mImgPt_reproj(3) / mImgPt_reproj(3);

		double dx = mImgPt_reproj(1) - mImgPt(1);
		double dy = mImgPt_reproj(2) - mImgPt(2);

		sum_d2 += dx * dx + dy * dy; // sum_d2 += dx*dx + dy*dy
	}

	if (reprojErr != NULL)
	{
		*reprojErr = sqrt(sum_d2 / n_pts);
	}

	return 0;
}

void DeepVoid::FillCloudPoints_RBG_RpjErr(const vector<cam_data> & vCams,	// input:	all image data
										  vector<CloudPoint> & clouds		// input&output:	all the existing cloud points
										  )			
{
	Matx33d mK, mR, mKR;
	Matx31d mt, mKt, mWrdPt, mImgPt;

	mK(2,2) = 1;
	mK(1,0) = mK(2,0) = mK(2,1) = 0;

	int i,j,k,ii;

	int nImg = vCams.size();
	int nClouds = clouds.size();

	for (i=0;i<nImg;i++)
	{
		cam_data cam = vCams[i];

		int nFeat = cam.m_feats.key_points.size();

		for (j=0;j<3;j++)
		{
			for (k=0;k<3;k++)
			{
				mR(j,k)=cam.R[j*3+k];
			}
		}

		mt(0) = cam.t[0]; mt(1) = cam.t[1]; mt(2) = cam.t[2];

		mK(0,0) = cam.fx; mK(1,1) = cam.fy;
		mK(0,2) = cam.cx; mK(1,2) = cam.cy;
		mK(0,1) = cam.s;

		mKR = mK*mR;
		mKt = mK*mt;

		// read corresponding image data into memory first
		char * pDir = (char *)theApp.m_pMainFrame->m_wndImgThumbnailPane.m_wndImgListCtrl.GetItemData(i);

		CString strDir;
		strDir.Format(_T("%s"), pDir);
		strDir.Trim();

		Mat img = imread(strDir.GetBuffer(), CV_LOAD_IMAGE_UNCHANGED);

		for (j=0;j<nFeat;j++)
		{
			int idxTrack = cam.m_feats.tracks[j];

			double img_x = cam.m_feats.key_points[j].pt.x;
			double img_y = cam.m_feats.key_points[j].pt.y;

			if (idxTrack == -1)
			{
				continue;
			}

			for (k=0;k<nClouds;k++)
			{
				if (clouds[k].m_idx != idxTrack)
				{
					continue;
				}

				mWrdPt(0) = clouds[k].m_pt.x;
				mWrdPt(1) = clouds[k].m_pt.y;
				mWrdPt(2) = clouds[k].m_pt.z;

				// first interpolate RGB
				uchar r,g,b;
				BilinearInterp(img, img_x, img_y, r, g, b);

				// then compute the rpj error
				mImgPt = mKR * mWrdPt + mKt;

				// linear reprojection
				double imgpt_rpj_linear_x = mImgPt(0)/mImgPt(2);
				double imgpt_rpj_linear_y = mImgPt(1)/mImgPt(2);

				double imgpt_rpj_dist_x, imgpt_rpj_dist_y;

				CalcuDistedImgPt_DCBrown(cam.cx, cam.cy, cam.fx, cam.fy, cam.k,
					imgpt_rpj_linear_x, imgpt_rpj_linear_y, imgpt_rpj_dist_x, imgpt_rpj_dist_y);

				double dx = imgpt_rpj_dist_x - img_x;
				double dy = imgpt_rpj_dist_y - img_y;
				double d = sqrt(dx*dx+dy*dy);

				// locate the CloudPoint_ImgInfo and write the RGB and rpjerror
				bool bFound = false;
				for (ii=0;ii<clouds[k].m_vImgInfos.size();ii++)
				{
					if (clouds[k].m_vImgInfos[ii].m_idxImg != i || clouds[k].m_vImgInfos[ii].m_idxImgPt != j)
					{
						continue;
					}
					clouds[k].m_vImgInfos[ii].m_rpjErr = d;
					clouds[k].m_vImgInfos[ii].m_rgb.val[0] = b;
					clouds[k].m_vImgInfos[ii].m_rgb.val[1] = g;
					clouds[k].m_vImgInfos[ii].m_rgb.val[2] = r;
					bFound = true;
					break;
				}

// 				if (!bFound)
// 				{
// 					CString strInfo;
// 					strInfo.Format("found one incomplete track: %04d", idxTrack);
// 					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);
// 				}

				break;
			}
		}
	}
}

double DeepVoid::MeanMinDistance_3D(const vector<CloudPoint> & clouds)
{
	int i,j;

	int n_pts = clouds.size();

	double d_sum = 0;
	for (i=0;i<n_pts;i++)
	{
		Point3d pti = clouds[i].m_pt;

		double d_min = -1;
		for (j=0;j<n_pts;j++)
		{
			if (j==i)
			{
				continue;
			}

			Point3d ptj = clouds[j].m_pt;

			double dX = pti.x - ptj.x;
			double dY = pti.y - ptj.y;
			double dZ = pti.z - ptj.z;

			double d = sqrt(dX*dX+dY*dY+dZ*dZ);

			if (d_min<0)
			{
				d_min = d;
				continue;
			}

			if (d<d_min)
			{
				if (d<1.0E-12)
				{
					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(_T("found one identical 3d point"));
				}

				d_min = d;
			}
		}

		d_sum += d_min;
	}

	return d_sum/n_pts;
}

void DeepVoid::Clustering_3D_byDistance(const vector<CloudPoint> & clouds,	// input:	cloud points
										vector<vector<int>> & clusters,		// output:	all clusters
										double thresh_distance				// input:	the distance threshold, if distance between two 3d points is smaller than this threshold, they belong to the same cluster
										)
{
	int i,j,k;

	int n_pts = clouds.size();

	clusters.clear();

	vector<int> vStatus(n_pts, 0);

	for (i=0;i<n_pts;i++)
	{
		if (vStatus[i] != 0)
		{
			// indicates that i point has already belong to some cluster
			continue;
		}

		vStatus[i] = 1;

		vector<int> cluster;
		cluster.push_back(i);

		deque<int> q;
		q.push_back(i);

		while (q.size() != 0)
		{
			int idx_cur = q.front();
			q.pop_front();

			CloudPoint pt1 = clouds[idx_cur];

			for (j=0;j<n_pts;j++)
			{
				if (idx_cur == j || vStatus[j] != 0)
				{
					// j = idx_cur or j already belongs to some clusters
					continue;
				}

				CloudPoint pt2 = clouds[j];

				double dX = pt2.m_pt.x - pt1.m_pt.x;
				double dY = pt2.m_pt.y - pt1.m_pt.y;
				double dZ = pt2.m_pt.z - pt1.m_pt.z;

				double d = sqrt(dX*dX+dY*dY+dZ*dZ);

				if (d<thresh_distance)
				{
					vStatus[j] = 1;
					cluster.push_back(j);
					q.push_back(j);
				}
			}
		}

		clusters.push_back(cluster);
	}
}

void DeepVoid::FindAllGoodImagePairs(const vector<cam_data> & vCams,
	                                 vector<Point2i> & pairs
									 )
{
	pairs.clear();

	int i,j,ii,jj;

	int n_imgs = vCams.size();

	bool * mCheck = new bool [n_imgs*n_imgs];
	memset(mCheck, 0, n_imgs*n_imgs*sizeof(bool));

	Matx33d mRw1,mRw2,mR12;
	Matx31d mtw1,mtw2,mt12;

	for (i=0;i<n_imgs;i++)
	{
		cam_data cam1 = vCams[i];

		if (cam1.R[0]<-90)
		{
			continue;
		}

		for (ii=0;ii<3;ii++)
		{
			for (jj=0;jj<3;jj++)
			{
				mRw1(ii,jj) = cam1.R[ii*3+jj];
			}
		}
		mtw1(0) = cam1.t[0]; mtw1(1) = cam1.t[1]; mtw1(2) = cam1.t[2]; 

		int idx_ang_min = -1;
		int idx_dis_min = -1;

		double ang_min, dis_min;

		for (j=0;j<n_imgs;j++)
		{
			if (j==i)
			{
				continue;
			}

			cam_data cam2 = vCams[j];

			if (cam2.R[0]<-90)
			{
				continue;
			}

			for (ii=0;ii<3;ii++)
			{
				for (jj=0;jj<3;jj++)
				{
					mRw2(ii,jj) = cam2.R[ii*3+jj];
				}
			}
			mtw2(0) = cam2.t[0]; mtw2(1) = cam2.t[1]; mtw2(2) = cam2.t[2];

			// compute the relative pose
			mR12 = mRw1*mRw2.t();
			mt12 = -mR12*mtw2+mtw1;

			// compute the angle between optical axes and the distance between optical centers
			double radian = GetAngleBetweenOpticalAxes_Radian(mR12);
			double dist = sqrt(mt12(0)*mt12(0)+mt12(1)*mt12(1)+mt12(2)*mt12(2));

			if (idx_ang_min == -1 && idx_dis_min == -1)
			{
				idx_ang_min = j;
				idx_dis_min = j;

				ang_min = radian;
				dis_min = dist;

				continue;
			}

			if (radian < ang_min)
			{
				idx_ang_min = j;
				ang_min = radian;
			}
			if (dist < dis_min)
			{
				idx_dis_min = j;
				dis_min = dist;
			}
		}

		if (idx_ang_min == idx_dis_min && !mCheck[i*n_imgs+idx_ang_min])
		{
			mCheck[i*n_imgs+idx_ang_min] = mCheck[idx_ang_min*n_imgs+i] = 1;

			Point2i pair;
			pair.x = i;
			pair.y = idx_ang_min;
			pairs.push_back(pair);
		}
	}

	delete [] mCheck;
}

///////////////////////////////////////////////////////////////////////////////////////////////////////////
RNG rng_initRndField(0xffffffff);
void DeepVoid::InitRndField(const Matx33d & mK,					// input:	the camera matrix
							const Matx33d & mR,					// input:	the rotation matrix
							const Matx31d & mt,					// input:	the translation vector
							const vector<CloudPoint> & clouds,	// input:	the cloud points
							double angLimit,					// input:	the angular range limit of the normal of every object point, in angle, not radian
							int imgWidth, int imgHeight,		// input:	the size of the image
							Mat & rndField_depth,				// output:	the 32FC1 matrix with the same size of the image, the initial depth
							Mat & rndField_incre_x,				// output:	the 32FC1 matrix with the same size of the image, the initial hx
							Mat & rndField_incre_y				// output:	the 32FC1 matrix with the same size of the image, the initial hy
							)
{
	int i,j;

	int n_cloud = clouds.size();
	
	double f=(mK(0,0)+mK(1,1))/2;
	double tana = tan(angLimit*CV_PI/180);
	double tana_f = tana/f;

	Matx31d mX;
	Matx31d mx;

	double depth_min;
	double depth_max;

	vector<Point2i> vFeatImgPts;
	vector<double> vFeatDepths;
	for (i=0;i<n_cloud;i++)
	{
		mX(0) = clouds[i].m_pt.x;
		mX(1) = clouds[i].m_pt.y;
		mX(2) = clouds[i].m_pt.z;

		mX = mR*mX+mt;

		double depth = mX(2);

		if (vFeatDepths.size() == 0)
		{
			depth_min = depth;
			depth_max = depth;
		} 
		else
		{
			if (depth<depth_min)
			{
				depth_min = depth;
			}
			if (depth>depth_max)
			{
				depth_max = depth;
			}
		}

		vFeatDepths.push_back(depth);

		mx = mK*mX;
		double z_1 = 1/mx(2);
		double x = mx(0)*z_1;
		double y = mx(1)*z_1;

		Point2i pt2d;
		pt2d.x = FTOI(x);
		pt2d.y = FTOI(y);
		vFeatImgPts.push_back(pt2d);
	}

	double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

	double depth_ext = (depth_max-depth_min)*ratio_ext;

	depth_max += depth_ext;

	double tmp = depth_min - depth_ext;

	if (tmp<0)
	{
		depth_min = 0;
	} 
	else
	{
		depth_min = tmp;
	}

	// initialize the random depth field first
	rndField_depth = Mat(imgHeight, imgWidth, CV_32FC1);
	rndField_incre_x = Mat(imgHeight, imgWidth, CV_32FC1);
	rndField_incre_y = Mat(imgHeight, imgWidth, CV_32FC1);

	rng_initRndField.fill(rndField_depth, RNG::UNIFORM, depth_min, depth_max);

	// then
	for (i=0;i<imgHeight;i++)
	{
		for (j=0;j<imgWidth;j++)
		{
			double Z = rndField_depth.at<float>(i,j);
			double dX_incre = tana_f*Z;
			rndField_incre_x.at<float>(i,j) = rng_initRndField.uniform(-dX_incre, dX_incre);
			rndField_incre_y.at<float>(i,j) = rng_initRndField.uniform(-dX_incre, dX_incre);
		}
	}
}

// 20140914, self-contained version
void DeepVoid::InitRndField(const Matx33d & mK,		// input:	the camera matrix
						    const Matx33d & mR,		// input:	the rotation matrix
						    const Matx31d & mt,		// input:	the translation vector
						    double depth_min,		// input:	the minimal depth
						    double depth_max,		// input:	the maximal depth
						    double angLimit,		// input:	the angular range limit of the normal of every object point, in angle, not radian
						    int width, int height,	// input:	the size of the image
						    Mat & mDepth,			// output:	the 32FC1 matrix with the same size of the image, the initial depth
						    Mat & mHx,				// output:	the 32FC1 matrix with the same size of the image, the initial hx
						    Mat & mHy				// output:	the 32FC1 matrix with the same size of the image, the initial hy
						    )
{
	int i,j;

	double f=(mK(0,0)+mK(1,1))*0.5;
	double tana = tan(angLimit*D2R);
	double tana_f = tana/f;

	// initialize the random depth field first
	mDepth = Mat(height, width, CV_32FC1);
	mHx = Mat(height, width, CV_32FC1);
	mHy = Mat(height, width, CV_32FC1);

	rng_initRndField.fill(mDepth, RNG::UNIFORM, depth_min, depth_max);

	// then
	for (i=0;i<height;i++)
	{
		for (j=0;j<width;j++)
		{
			double Z = mDepth.at<float>(i,j);
			double dX_incre = tana_f*Z;
			mHx.at<float>(i,j) = rng_initRndField.uniform(-dX_incre, dX_incre);
			mHy.at<float>(i,j) = rng_initRndField.uniform(-dX_incre, dX_incre);
		}
	}
}

void DeepVoid::Scan_Update_rndField(const vector<cam_data> & vCams,	// input:	all camera data
									const vector<CloudPoint> & clouds,// input:	the cloud points
									double angLimit,				// input:	the angular range limit of the normal of every object point, in angle, not radian
									int idx_refimg,					// input:	the index of the reference image
									Mat & mDepth,					// input&output:	the 32FC1 matrix with the same size of the image, the initial depth
									Mat & mIncre_x,					// input&output:	the 32FC1 matrix with the same size of the image, the initial hx
									Mat & mIncre_y,					// input&output:	the 32FC1 matrix with the same size of the image, the initial hy
									Mat & mScore,					// input&output:	the score matrix corresponding to the 3 parameter state matrix, it's updated as output
									int iter,						// input:	iteration
									int size /*= 5*/,				// input:	the window size of the image patch, should be odd number
									double thresh_ncc /*= 0.8*/		// input:	the threshold within which to be considered as a successful ncc
									)
{
	int i,j,ii,jj;

	int wndSizeHalf = (size-1)/2;
	int imgWidth = mDepth.cols;
	int imgHeight = mDepth.rows;

	cam_data cam_ref = vCams[idx_refimg];

	// extract camera matrix
	Matx33d mK_ref, mR_ref;
	Matx31d mt_ref;

	for (ii=0;ii<3;ii++)
	{
		for (jj=0;jj<3;jj++)
		{
			mR_ref(ii,jj) = cam_ref.R[ii*3+jj];
		}
	}
	mK_ref(0,0) = cam_ref.fx;	mK_ref(0,1) = cam_ref.s;  mK_ref(0,2) = cam_ref.cx;
	mK_ref(1,1) = cam_ref.fy;	mK_ref(1,2) = cam_ref.cy; mK_ref(2,2) = 1;
	mt_ref(0) = cam_ref.t[0];	mt_ref(1) = cam_ref.t[1]; mt_ref(2) = cam_ref.t[2];

	// generate new random parameter sets for every pixel
	vector<Mat> vRndFields(3);
	InitRndField(mK_ref, mR_ref, mt_ref, clouds, angLimit, imgWidth, imgHeight, vRndFields[0], vRndFields[1], vRndFields[2]);

	CString strInfo;
	
	// now start scanning and updating
	if (iter%2 == 0) // even iterations, from left to right, from top to bottom
	{
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("evaluate row %04d", i);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				int i_real, j_real;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
				vector<double> vScores_candidates;

				// first check out current random parameter set
				double depth_random = vRndFields[0].at<float>(i,j);
				double hx_random = vRndFields[1].at<float>(i,j);
				double hy_random = vRndFields[2].at<float>(i,j);

				vector<double> vScores_random;
				CheckOnePixel_givenOneParamSet(vCams,idx_refimg,j_real,i_real,depth_random,hx_random,hy_random,vScores_random,size);
				vScores_candidates.push_back(GetScore(vScores_random, thresh_ncc, 3));
				vDepths_candidates.push_back(depth_random);
				vHx_candidates.push_back(hx_random);
				vHy_candidates.push_back(hy_random);

				if (j-1>=0) // means that there is a left neighbor
				{
					double depth_left = mDepth.at<float>(i,j-1);
					double hx_left = mIncre_x.at<float>(i,j-1);
					double hy_left = mIncre_y.at<float>(i,j-1);

					vector<double> vScores_left;
					CheckOnePixel_givenOneParamSet(vCams,idx_refimg,j_real,i_real,depth_left,hx_left,hy_left,vScores_left,size);
					vScores_candidates.push_back(GetScore(vScores_left, thresh_ncc, 3));
					vDepths_candidates.push_back(depth_left);
					vHx_candidates.push_back(hx_left);
					vHy_candidates.push_back(hy_left);
				}

				if (i-1>=0) // means that there is a upper neighbor
				{
					double depth_upper = mDepth.at<float>(i-1,j);
					double hx_upper = mIncre_x.at<float>(i-1,j);
					double hy_upper = mIncre_y.at<float>(i-1,j);

					vector<double> vScores_upper;
					CheckOnePixel_givenOneParamSet(vCams,idx_refimg,j_real,i_real,depth_upper,hx_upper,hy_upper,vScores_upper,size);
					vScores_candidates.push_back(GetScore(vScores_upper, thresh_ncc, 3));
					vDepths_candidates.push_back(depth_upper);
					vHx_candidates.push_back(hx_upper);
					vHy_candidates.push_back(hy_upper);
				}

				vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				double max_score = *iterDouble;
				int idx_max_score = iterDouble - vScores_candidates.begin();

				if (max_score > mScore.at<float>(i,j))
				{
					// if a better score is obtained then update the pixel with better parameter set
					mDepth.at<float>(i,j) = vDepths_candidates[idx_max_score];
					mIncre_x.at<float>(i,j) = vHx_candidates[idx_max_score];
					mIncre_y.at<float>(i,j) = vHy_candidates[idx_max_score];
					mScore.at<float>(i,j) = max_score;
				}
			}
		}
	} 
	else // odd iterations, from right to left, from bottom to top
	{
		for (i=imgHeight-1;i>=0;i--)
		{
			strInfo.Format("evaluate row %04d", i);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=imgWidth-1;j>=0;j--)
			{
				int i_real, j_real;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
				vector<double> vScores_candidates;

				// first check out current random parameter set
				double depth_random = vRndFields[0].at<float>(i,j);
				double hx_random = vRndFields[1].at<float>(i,j);
				double hy_random = vRndFields[2].at<float>(i,j);

				vector<double> vScores_random;
				CheckOnePixel_givenOneParamSet(vCams,idx_refimg,j_real,i_real,depth_random,hx_random,hy_random,vScores_random,size);
				vScores_candidates.push_back(GetScore(vScores_random, thresh_ncc, 3));
				vDepths_candidates.push_back(depth_random);
				vHx_candidates.push_back(hx_random);
				vHy_candidates.push_back(hy_random);

				if (j+1<imgWidth) // means that there is a right neighbor
				{
					double depth_right = mDepth.at<float>(i,j+1);
					double hx_right = mIncre_x.at<float>(i,j+1);
					double hy_right = mIncre_y.at<float>(i,j+1);

					vector<double> vScores_right;
					CheckOnePixel_givenOneParamSet(vCams,idx_refimg,j_real,i_real,depth_right,hx_right,hy_right,vScores_right,size);
					vScores_candidates.push_back(GetScore(vScores_right, thresh_ncc, 3));
					vDepths_candidates.push_back(depth_right);
					vHx_candidates.push_back(hx_right);
					vHy_candidates.push_back(hy_right);
				}

				if (i+1<imgHeight) // means that there is a lower neighbor
				{
					double depth_lower = mDepth.at<float>(i+1,j);
					double hx_lower = mIncre_x.at<float>(i+1,j);
					double hy_lower = mIncre_y.at<float>(i+1,j);

					vector<double> vScores_lower;
					CheckOnePixel_givenOneParamSet(vCams,idx_refimg,j_real,i_real,depth_lower,hx_lower,hy_lower,vScores_lower,size);
					vScores_candidates.push_back(GetScore(vScores_lower, thresh_ncc, 3));
					vDepths_candidates.push_back(depth_lower);
					vHx_candidates.push_back(hx_lower);
					vHy_candidates.push_back(hy_lower);
				}

				vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				double max_score = *iterDouble;
				int idx_max_score = iterDouble - vScores_candidates.begin();

				if (max_score > mScore.at<float>(i,j))
				{
					// if a better score is obtained then update the pixel with better parameter set
					mDepth.at<float>(i,j) = vDepths_candidates[idx_max_score];
					mIncre_x.at<float>(i,j) = vHx_candidates[idx_max_score];
					mIncre_y.at<float>(i,j) = vHy_candidates[idx_max_score];
					mScore.at<float>(i,j) = max_score;
				}
			}
		}
	}
}

void DeepVoid::Scan_Update_rndField(const vector<cam_data> & vCams,		// input:	all camera data
									const vector<Mat> & vImgs,			// input:	all images
									const vector<CloudPoint> & clouds,	// input:	the cloud points
									double angLimit,					// input:	the angular range limit of the normal of every object point, in angle, not radian
									int idx_refimg,						// input:	the index of the reference image
									Mat & mDepth,						// input&output:	the 32FC1 matrix with the same size of the image, the initial depth, it's updated as output
									Mat & mIncre_x,						// input&output:	the 32FC1 matrix with the same size of the image, the initial hx, it's updated as output
									Mat & mIncre_y,						// input&output:	the 32FC1 matrix with the same size of the image, the initial hy, it's updated as output
									Mat & mScore,						// input&output:	the score matrix corresponding to the 3 parameter state matrix, it's updated as output
									int iter,							// input:	iteration
									int size /*= 5*/,					// input:	the window size of the image patch, should be odd number
									double thresh_ncc /*= 0.8*/			// input:	the threshold within which to be considered as a successful ncc
									)
{
	int i,j,ii,jj;

	int wndSizeHalf = (size-1)/2;
	int imgWidth = mDepth.cols;
	int imgHeight = mDepth.rows;

	cam_data cam_ref = vCams[idx_refimg];

	// extract camera matrix
	Matx33d mK_ref, mR_ref;
	Matx31d mt_ref;

	for (ii=0;ii<3;ii++)
	{
		for (jj=0;jj<3;jj++)
		{
			mR_ref(ii,jj) = cam_ref.R[ii*3+jj];
		}
	}
	mK_ref(0,0) = cam_ref.fx;	mK_ref(0,1) = cam_ref.s;  mK_ref(0,2) = cam_ref.cx;
	mK_ref(1,1) = cam_ref.fy;	mK_ref(1,2) = cam_ref.cy; mK_ref(2,2) = 1;
	mt_ref(0) = cam_ref.t[0];	mt_ref(1) = cam_ref.t[1]; mt_ref(2) = cam_ref.t[2];

	// generate new random parameter sets for every pixel
	vector<Mat> vRndFields(3);
	InitRndField(mK_ref, mR_ref, mt_ref, clouds, angLimit, imgWidth, imgHeight, vRndFields[0], vRndFields[1], vRndFields[2]);

	CString strInfo;

	// now start scanning and updating
	if (iter%2 == 0) // even iterations, from left to right, from top to bottom
	{
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("evaluate row %04d", i);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				int i_real, j_real;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
				vector<double> vScores_candidates;

				// first check out current random parameter set
				double depth_random = vRndFields[0].at<float>(i,j);
				double hx_random = vRndFields[1].at<float>(i,j);
				double hy_random = vRndFields[2].at<float>(i,j);

				vector<double> vScores_random;
				CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_random,hx_random,hy_random,vScores_random,size);
				vScores_candidates.push_back(GetScore(vScores_random, thresh_ncc, 3));
				vDepths_candidates.push_back(depth_random);
				vHx_candidates.push_back(hx_random);
				vHy_candidates.push_back(hy_random);

				if (j-1>=0) // means that there is a left neighbor
				{
					double depth_left = mDepth.at<float>(i,j-1);
					double hx_left = mIncre_x.at<float>(i,j-1);
					double hy_left = mIncre_y.at<float>(i,j-1);

					vector<double> vScores_left;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_left,hx_left,hy_left,vScores_left,size);
					vScores_candidates.push_back(GetScore(vScores_left, thresh_ncc, 3));
					vDepths_candidates.push_back(depth_left);
					vHx_candidates.push_back(hx_left);
					vHy_candidates.push_back(hy_left);
				}

				if (i-1>=0) // means that there is a upper neighbor
				{
					double depth_upper = mDepth.at<float>(i-1,j);
					double hx_upper = mIncre_x.at<float>(i-1,j);
					double hy_upper = mIncre_y.at<float>(i-1,j);

					vector<double> vScores_upper;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_upper,hx_upper,hy_upper,vScores_upper,size);
					vScores_candidates.push_back(GetScore(vScores_upper, thresh_ncc, 3));
					vDepths_candidates.push_back(depth_upper);
					vHx_candidates.push_back(hx_upper);
					vHy_candidates.push_back(hy_upper);
				}

				vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				double max_score = *iterDouble;
				int idx_max_score = iterDouble - vScores_candidates.begin();

				if (max_score > mScore.at<float>(i,j))
				{
					// if a better score is obtained then update the pixel with better parameter set
					mDepth.at<float>(i,j) = vDepths_candidates[idx_max_score];
					mIncre_x.at<float>(i,j) = vHx_candidates[idx_max_score];
					mIncre_y.at<float>(i,j) = vHy_candidates[idx_max_score];
					mScore.at<float>(i,j) = max_score;
				}
			}
		}
	} 
	else // odd iterations, from right to left, from bottom to top
	{
		for (i=imgHeight-1;i>=0;i--)
		{
			strInfo.Format("evaluate row %04d", i);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=imgWidth-1;j>=0;j--)
			{
				int i_real, j_real;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
				vector<double> vScores_candidates;

				// first check out current random parameter set
				double depth_random = vRndFields[0].at<float>(i,j);
				double hx_random = vRndFields[1].at<float>(i,j);
				double hy_random = vRndFields[2].at<float>(i,j);

				vector<double> vScores_random;
				CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_random,hx_random,hy_random,vScores_random,size);
				vScores_candidates.push_back(GetScore(vScores_random, thresh_ncc, 3));
				vDepths_candidates.push_back(depth_random);
				vHx_candidates.push_back(hx_random);
				vHy_candidates.push_back(hy_random);

				if (j+1<imgWidth) // means that there is a right neighbor
				{
					double depth_right = mDepth.at<float>(i,j+1);
					double hx_right = mIncre_x.at<float>(i,j+1);
					double hy_right = mIncre_y.at<float>(i,j+1);

					vector<double> vScores_right;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_right,hx_right,hy_right,vScores_right,size);
					vScores_candidates.push_back(GetScore(vScores_right, thresh_ncc, 3));
					vDepths_candidates.push_back(depth_right);
					vHx_candidates.push_back(hx_right);
					vHy_candidates.push_back(hy_right);
				}

				if (i+1<imgHeight) // means that there is a lower neighbor
				{
					double depth_lower = mDepth.at<float>(i+1,j);
					double hx_lower = mIncre_x.at<float>(i+1,j);
					double hy_lower = mIncre_y.at<float>(i+1,j);

					vector<double> vScores_lower;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_lower,hx_lower,hy_lower,vScores_lower,size);
					vScores_candidates.push_back(GetScore(vScores_lower, thresh_ncc, 3));
					vDepths_candidates.push_back(depth_lower);
					vHx_candidates.push_back(hx_lower);
					vHy_candidates.push_back(hy_lower);
				}

				vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				double max_score = *iterDouble;
				int idx_max_score = iterDouble - vScores_candidates.begin();

				if (max_score > mScore.at<float>(i,j))
				{
					// if a better score is obtained then update the pixel with better parameter set
					mDepth.at<float>(i,j) = vDepths_candidates[idx_max_score];
					mIncre_x.at<float>(i,j) = vHx_candidates[idx_max_score];
					mIncre_y.at<float>(i,j) = vHy_candidates[idx_max_score];
					mScore.at<float>(i,j) = max_score;
				}
			}
		}
	}
}

void DeepVoid::Scan_Update_rndField_original(const vector<cam_data> & vCams,	// input:	all camera data
											 const vector<Mat> & vImgs,			// input:	all images
											 const vector<CloudPoint> & clouds,	// input:	the cloud points
											 double angLimit,					// input:	the angular range limit of the normal of every object point, in angle, not radian
											 int idx_refimg,					// input:	the index of the reference image
											 Mat & mDepth,						// input&output:	the 32FC1 matrix with the same size of the image, the initial depth, it's updated as output
											 Mat & mIncre_x,					// input&output:	the 32FC1 matrix with the same size of the image, the initial hx, it's updated as output
											 Mat & mIncre_y,					// input&output:	the 32FC1 matrix with the same size of the image, the initial hy, it's updated as output
											 Mat & mScore,						// input&output:	the score matrix corresponding to the 3 parameter state matrix, it's updated as output
											 int iter,							// input:	iteration
											 int mincams /*= 1*/,
											 double factor /*= 0.5*/,
											 int nRandSamp /*= 6*/,
											 int size/* = 5*/,					// input:	the window size of the image patch, should be odd number
											 double thresh_ncc /*= 0.8*/		// input:	the threshold within which to be considered as a successful ncc
											 )
{
	int i,j,ii,jj,k;

	int wndSizeHalf = (size-1)/2;
	int imgWidth = mDepth.cols;
	int imgHeight = mDepth.rows;

	int w_interval = imgWidth/5;
	int h_interval = imgHeight/5;

	cam_data cam_ref = vCams[idx_refimg];

	// extract camera matrix
	Matx33d mK_ref, mR_ref;
	Matx31d mt_ref;

	for (ii=0;ii<3;ii++)
	{
		for (jj=0;jj<3;jj++)
		{
			mR_ref(ii,jj) = cam_ref.R[ii*3+jj];
		}
	}
	mK_ref(0,0) = cam_ref.fx;	mK_ref(0,1) = cam_ref.s;  mK_ref(0,2) = cam_ref.cx;
	mK_ref(1,1) = cam_ref.fy;	mK_ref(1,2) = cam_ref.cy; mK_ref(2,2) = 1;
	mt_ref(0) = cam_ref.t[0];	mt_ref(1) = cam_ref.t[1]; mt_ref(2) = cam_ref.t[2];

	// determine the boundary of parameters
	int n_cloud = clouds.size();

	double f=(mK_ref(0,0)+mK_ref(1,1))/2;
	double tana = tan(angLimit*CV_PI/180);
	double tana_f = tana/f;

	double depth_min;
	double depth_max;

	for (i=0;i<n_cloud;i++)
	{
		Matx31d mX;

		mX(0) = clouds[i].m_pt.x;
		mX(1) = clouds[i].m_pt.y;
		mX(2) = clouds[i].m_pt.z;

		mX = mR_ref*mX+mt_ref;

		double depth = mX(2);

		if (i == 0)
		{
			depth_min = depth;
			depth_max = depth;
		} 
		else
		{
			if (depth<depth_min)
			{
				depth_min = depth;
			}
			if (depth>depth_max)
			{
				depth_max = depth;
			}
		}
	}

	double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

	double depth_ext = (depth_max-depth_min)*ratio_ext;

	depth_max += depth_ext;

	double tmp = depth_min - depth_ext;

	if (tmp<0)
	{
		depth_min = 0;
	} 
	else
	{
		depth_min = tmp;
	}

	double d_range = depth_max - depth_min;
	double hx_max = tana_f * depth_max;
	double h_range = 2*hx_max;

	CString strInfo;

	// now start scanning and updating
	if (iter%2 == 0) // even iterations, from left to right, from top to bottom
	{
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("evaluate row %04d", i);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

// 			bool bRow = false;
// 			if (i%h_interval == 0)
// 			{
// 				bRow = true;
// 			}

			for (j=0;j<imgWidth;j++)
			{
// 				bool bCol = false;
// 				if (j%w_interval == 0)
// 				{
// 					bCol = true;
// 				}

				int i_real, j_real;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
				vector<double> vScores_candidates;

				// first evaluate current parameter set for (i,j)
				double depth0 = mDepth.at<float>(i,j);
				double hx0 = mIncre_x.at<float>(i,j);
				double hy0 = mIncre_y.at<float>(i,j);

				vector<double> vScores0;
				CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth0,hx0,hy0,vScores0,size);
				vScores_candidates.push_back(GetScore(vScores0, thresh_ncc, mincams));
				vDepths_candidates.push_back(depth0);
				vHx_candidates.push_back(hx0);
				vHy_candidates.push_back(hy0);

				if (j-1>=0) // means that there is a left neighbor
				{
					double depth_left = mDepth.at<float>(i,j-1);
					double hx_left = mIncre_x.at<float>(i,j-1);
					double hy_left = mIncre_y.at<float>(i,j-1);

					vector<double> vScores_left;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_left,hx_left,hy_left,vScores_left,size);
					vScores_candidates.push_back(GetScore(vScores_left, thresh_ncc, mincams));
					vDepths_candidates.push_back(depth_left);
					vHx_candidates.push_back(hx_left);
					vHy_candidates.push_back(hy_left);
				}

				if (i-1>=0) // means that there is a upper neighbor
				{
					double depth_upper = mDepth.at<float>(i-1,j);
					double hx_upper = mIncre_x.at<float>(i-1,j);
					double hy_upper = mIncre_y.at<float>(i-1,j);

					vector<double> vScores_upper;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_upper,hx_upper,hy_upper,vScores_upper,size);
					vScores_candidates.push_back(GetScore(vScores_upper, thresh_ncc, mincams));
					vDepths_candidates.push_back(depth_upper);
					vHx_candidates.push_back(hx_upper);
					vHy_candidates.push_back(hy_upper);
				}

				vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				double max_score = *iterDouble;
				int idx_max_score = iterDouble - vScores_candidates.begin();

				double depth_possible = vDepths_candidates[idx_max_score];
				double hx_possible = vHx_candidates[idx_max_score];
				double hy_possible = vHy_candidates[idx_max_score];
				double score_possible = max_score;

				vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();
				
				vScores_candidates.push_back(score_possible);
				vDepths_candidates.push_back(depth_possible);
				vHx_candidates.push_back(hx_possible);
				vHy_candidates.push_back(hy_possible);

				for (k=0;k<nRandSamp;k++)
				{
					double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
					if (k==0)
					{
						d_max_k = depth_max;
						d_min_k = depth_min;
						hx_max_k = hx_max;
						hx_min_k = -hx_max;
						hy_max_k = hx_max;
						hy_min_k = -hx_max;
					}
					else
					{
						double factor_k = pow(factor, k);
						double d_r = factor_k*d_range;
						double h_r = factor_k*h_range;
						DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
						DetermineInterval(hx_max, -hx_max, hx_possible, h_r, hx_max_k, hx_min_k);
						DetermineInterval(hx_max, -hx_max, hy_possible, h_r, hy_max_k, hy_min_k);
					}

					// generate current parameter set
					double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
					double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
					double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

					vector<double> vScores_k;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size);
					vScores_candidates.push_back(GetScore(vScores_k, thresh_ncc, mincams));
					vDepths_candidates.push_back(depth_k);
					vHx_candidates.push_back(hx_k);
					vHy_candidates.push_back(hy_k);
				}

				iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				max_score = *iterDouble;
				idx_max_score = iterDouble - vScores_candidates.begin();

				mDepth.at<float>(i,j) = vDepths_candidates[idx_max_score];
				mIncre_x.at<float>(i,j) = vHx_candidates[idx_max_score];
				mIncre_y.at<float>(i,j) = vHy_candidates[idx_max_score];
				mScore.at<float>(i,j) = max_score;

				// write the runtime image into file
// 				if (bRow && bCol)
// 				{
// 					double minncc = thresh_ncc*mincams/(vCams.size()-1);
// 					double maxncc_minncc_1 = 1/(1-minncc);
// 
// 					double max_depth,min_depth,max_incre_x,min_incre_x,max_incre_y,min_incre_y,max_score,min_score;
// 
// 					minMaxIdx(mDepth, &min_depth, &max_depth);
// 					minMaxIdx(mIncre_x, &min_incre_x, &max_incre_x);
// 					minMaxIdx(mIncre_y, &min_incre_y, &max_incre_y);
// 					minMaxIdx(mScore, &min_score, &max_score);
// 
// 					vector<Mat> vRndFields_normed(3);
// 
// 					Mat mScores_normed_color(mScore.rows, mScore.cols, CV_8UC3);
// 
// 					mDepth.convertTo(vRndFields_normed[0], CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
// 					mIncre_x.convertTo(vRndFields_normed[1], CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
// 					mIncre_y.convertTo(vRndFields_normed[2], CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));
// 
// 					for (ii=0;ii<mScore.rows;ii++)
// 					{
// 						for (jj=0;jj<mScore.cols;jj++)
// 						{
// 							if (mScore.at<float>(ii,jj)<0)
// 							{
// 								mScores_normed_color.at<Vec3b>(ii,jj).val[0] = 0;
// 								mScores_normed_color.at<Vec3b>(ii,jj).val[1] = 0;
// 								mScores_normed_color.at<Vec3b>(ii,jj).val[2] = 255;
// 							}
// 							else
// 							{
// 								mScores_normed_color.at<Vec3b>(ii,jj).val[0] = 0;
// 								mScores_normed_color.at<Vec3b>(ii,jj).val[1] = FTOI(255*(mScore.at<float>(ii,jj)-minncc)*maxncc_minncc_1);
// 								mScores_normed_color.at<Vec3b>(ii,jj).val[2] = 0;
// 							}
// 						}
// 					}
// 
// 					strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\runtime info\\depth map (%03d,%03d) iter %d.bmp", i, j, iter);
// 					imwrite(strInfo.GetBuffer(), vRndFields_normed[0]);
// 					strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\runtime info\\hx map (%03d,%03d) iter %d.bmp", i, j, iter);
// 					imwrite(strInfo.GetBuffer(), vRndFields_normed[1]);
// 					strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\runtime info\\hy map (%03d,%03d) iter %d.bmp", i, j, iter);
// 					imwrite(strInfo.GetBuffer(), vRndFields_normed[2]);
// 					strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\runtime info\\score map (%03d,%03d) iter %d.bmp", i, j, iter);
// 					imwrite(strInfo.GetBuffer(), mScores_normed_color);
// 				}
			}
		}
	} 
	else // odd iterations, from right to left, from bottom to top
	{
		for (i=imgHeight-1;i>=0;i--)
		{
			strInfo.Format("evaluate row %04d", i);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

// 			bool bRow = false;
// 			if (i%h_interval == 0)
// 			{
// 				bRow = true;
// 			}

			for (j=imgWidth-1;j>=0;j--)
			{
// 				bool bCol = false;
// 				if (j%w_interval == 0)
// 				{
// 					bCol = true;
// 				}

				int i_real, j_real;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
				vector<double> vScores_candidates;

				// first evaluate current parameter set for (i,j)
				double depth0 = mDepth.at<float>(i,j);
				double hx0 = mIncre_x.at<float>(i,j);
				double hy0 = mIncre_y.at<float>(i,j);

				vector<double> vScores0;
				CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth0,hx0,hy0,vScores0,size);
				vScores_candidates.push_back(GetScore(vScores0, thresh_ncc, mincams));
				vDepths_candidates.push_back(depth0);
				vHx_candidates.push_back(hx0);
				vHy_candidates.push_back(hy0);

				if (j+1<imgWidth) // means that there is a right neighbor
				{
					double depth_right = mDepth.at<float>(i,j+1);
					double hx_right = mIncre_x.at<float>(i,j+1);
					double hy_right = mIncre_y.at<float>(i,j+1);

					vector<double> vScores_right;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_right,hx_right,hy_right,vScores_right,size);
					vScores_candidates.push_back(GetScore(vScores_right, thresh_ncc, mincams));
					vDepths_candidates.push_back(depth_right);
					vHx_candidates.push_back(hx_right);
					vHy_candidates.push_back(hy_right);
				}

				if (i+1<imgHeight) // means that there is a lower neighbor
				{
					double depth_lower = mDepth.at<float>(i+1,j);
					double hx_lower = mIncre_x.at<float>(i+1,j);
					double hy_lower = mIncre_y.at<float>(i+1,j);

					vector<double> vScores_lower;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_lower,hx_lower,hy_lower,vScores_lower,size);
					vScores_candidates.push_back(GetScore(vScores_lower, thresh_ncc, mincams));
					vDepths_candidates.push_back(depth_lower);
					vHx_candidates.push_back(hx_lower);
					vHy_candidates.push_back(hy_lower);
				}

				vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				double max_score = *iterDouble;
				int idx_max_score = iterDouble - vScores_candidates.begin();

				double depth_possible = vDepths_candidates[idx_max_score];
				double hx_possible = vHx_candidates[idx_max_score];
				double hy_possible = vHy_candidates[idx_max_score];
				double score_possible = max_score;

				vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

				vScores_candidates.push_back(score_possible);
				vDepths_candidates.push_back(depth_possible);
				vHx_candidates.push_back(hx_possible);
				vHy_candidates.push_back(hy_possible);

				for (k=0;k<nRandSamp;k++)
				{
					double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
					if (k==0)
					{
						d_max_k = depth_max;
						d_min_k = depth_min;
						hx_max_k = hx_max;
						hx_min_k = -hx_max;
						hy_max_k = hx_max;
						hy_min_k = -hx_max;
					}
					else
					{
						double factor_k = pow(factor, k);
						double d_r = factor_k*d_range;
						double h_r = factor_k*h_range;
						DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
						DetermineInterval(hx_max, -hx_max, hx_possible, h_r, hx_max_k, hx_min_k);
						DetermineInterval(hx_max, -hx_max, hy_possible, h_r, hy_max_k, hy_min_k);
					}

					// generate current parameter set
					double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
					double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
					double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

					vector<double> vScores_k;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size);
					vScores_candidates.push_back(GetScore(vScores_k, thresh_ncc, mincams));
					vDepths_candidates.push_back(depth_k);
					vHx_candidates.push_back(hx_k);
					vHy_candidates.push_back(hy_k);
				}

				iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				max_score = *iterDouble;
				idx_max_score = iterDouble - vScores_candidates.begin();

				mDepth.at<float>(i,j) = vDepths_candidates[idx_max_score];
				mIncre_x.at<float>(i,j) = vHx_candidates[idx_max_score];
				mIncre_y.at<float>(i,j) = vHy_candidates[idx_max_score];
				mScore.at<float>(i,j) = max_score;


				// write the runtime image into file
// 				if (bRow && bCol)
// 				{
// 					double minncc = thresh_ncc*mincams/(vCams.size()-1);
// 					double maxncc_minncc_1 = 1/(1-minncc);
// 
// 					double max_depth,min_depth,max_incre_x,min_incre_x,max_incre_y,min_incre_y,max_score,min_score;
// 
// 					minMaxIdx(mDepth, &min_depth, &max_depth);
// 					minMaxIdx(mIncre_x, &min_incre_x, &max_incre_x);
// 					minMaxIdx(mIncre_y, &min_incre_y, &max_incre_y);
// 					minMaxIdx(mScore, &min_score, &max_score);
// 
// 					vector<Mat> vRndFields_normed(3);
// 
// 					Mat mScores_normed_color(mScore.rows, mScore.cols, CV_8UC3);
// 
// 					mDepth.convertTo(vRndFields_normed[0], CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
// 					mIncre_x.convertTo(vRndFields_normed[1], CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
// 					mIncre_y.convertTo(vRndFields_normed[2], CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));
// 
// 					for (ii=0;ii<mScore.rows;ii++)
// 					{
// 						for (jj=0;jj<mScore.cols;jj++)
// 						{
// 							if (mScore.at<float>(ii,jj)<0)
// 							{
// 								mScores_normed_color.at<Vec3b>(ii,jj).val[0] = 0;
// 								mScores_normed_color.at<Vec3b>(ii,jj).val[1] = 0;
// 								mScores_normed_color.at<Vec3b>(ii,jj).val[2] = 255;
// 							}
// 							else
// 							{
// 								mScores_normed_color.at<Vec3b>(ii,jj).val[0] = 0;
// 								mScores_normed_color.at<Vec3b>(ii,jj).val[1] = FTOI(255*(mScore.at<float>(ii,jj)-minncc)*maxncc_minncc_1);
// 								mScores_normed_color.at<Vec3b>(ii,jj).val[2] = 0;
// 							}
// 						}
// 					}
// 
// 					strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\runtime info\\depth map (%03d,%03d) iter %d.bmp", i, j, iter);
// 					imwrite(strInfo.GetBuffer(), vRndFields_normed[0]);
// 					strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\runtime info\\hx map (%03d,%03d) iter %d.bmp", i, j, iter);
// 					imwrite(strInfo.GetBuffer(), vRndFields_normed[1]);
// 					strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\runtime info\\hy map (%03d,%03d) iter %d.bmp", i, j, iter);
// 					imwrite(strInfo.GetBuffer(), vRndFields_normed[2]);
// 					strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\runtime info\\score map (%03d,%03d) iter %d.bmp", i, j, iter);
// 					imwrite(strInfo.GetBuffer(), mScores_normed_color);
// 				}
			}
		}
	}
}

void DeepVoid::Scan_Update_rndField_original_visi(const vector<cam_data> & vCams,	// input:	all camera data
												  const vector<Mat> & vImgs,		// input:	all images
												  const vector<CloudPoint> & clouds,// input:	the cloud points
												  double angLimit,					// input:	the angular range limit of the normal of every object point, in angle, not radian
												  int idx_refimg,					// input:	the index of the reference image
												  Mat & mDepth,					// input&output:	the 32FC1 matrix with the same size of the image, the initial depth, it's updated as output
												  Mat & mIncre_x,				// input&output:	the 32FC1 matrix with the same size of the image, the initial hx, it's updated as output
												  Mat & mIncre_y,				// input&output:	the 32FC1 matrix with the same size of the image, the initial hy, it's updated as output
												  Mat & mScore,					// input&output:	the score matrix corresponding to the 3 parameter state matrix, it's updated as output
												  Mat & mVisi,					// output:	the 8UC1 matrix with the same size of the image
												  Mat & mVisiN,					// output:	the 8UC1 matrix with the same size of the image
												  int iter,						// input:	iteration
												  int mincams/* = 1*/,
												  double factor /*= 0.5*/,
												  int nRandSamp /*= 6*/,
												  int size /*= 5*/,				// input:	the window size of the image patch, should be odd number
												  double thresh_ncc /*= 0.8*/	// input:	the threshold within which to be considered as a successful ncc
												  )
{
	int i,j,ii,jj,k;

	int wndSizeHalf = (size-1)/2;
	int imgWidth = mDepth.cols;
	int imgHeight = mDepth.rows;

	int w_interval = imgWidth/5;
	int h_interval = imgHeight/5;

	cam_data cam_ref = vCams[idx_refimg];

	// extract camera matrix
	Matx33d mK_ref, mR_ref;
	Matx31d mt_ref;

	for (ii=0;ii<3;ii++)
	{
		for (jj=0;jj<3;jj++)
		{
			mR_ref(ii,jj) = cam_ref.R[ii*3+jj];
		}
	}
	mK_ref(0,0) = cam_ref.fx;	mK_ref(0,1) = cam_ref.s;  mK_ref(0,2) = cam_ref.cx;
	mK_ref(1,1) = cam_ref.fy;	mK_ref(1,2) = cam_ref.cy; mK_ref(2,2) = 1;
	mt_ref(0) = cam_ref.t[0];	mt_ref(1) = cam_ref.t[1]; mt_ref(2) = cam_ref.t[2];

	// determine the boundary of parameters
	int n_cloud = clouds.size();

	double f=(mK_ref(0,0)+mK_ref(1,1))/2;
	double tana = tan(angLimit*CV_PI/180);
	double tana_f = tana/f;

	double depth_min;
	double depth_max;

	for (i=0;i<n_cloud;i++)
	{
		Matx31d mX;

		mX(0) = clouds[i].m_pt.x;
		mX(1) = clouds[i].m_pt.y;
		mX(2) = clouds[i].m_pt.z;

		mX = mR_ref*mX+mt_ref;

		double depth = mX(2);

		if (i == 0)
		{
			depth_min = depth;
			depth_max = depth;
		} 
		else
		{
			if (depth<depth_min)
			{
				depth_min = depth;
			}
			if (depth>depth_max)
			{
				depth_max = depth;
			}
		}
	}

	double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

	double depth_ext = (depth_max-depth_min)*ratio_ext;

	depth_max += depth_ext;

	double tmp = depth_min - depth_ext;

	if (tmp<0)
	{
		depth_min = 0;
	} 
	else
	{
		depth_min = tmp;
	}

	double d_range = depth_max - depth_min;
	double hx_max = tana_f * depth_max;
	double h_range = 2*hx_max;

	CString strInfo;

	// now start scanning and updating
	if (iter%2 == 0) // even iterations, from left to right, from top to bottom
	{
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("evaluate row %04d", i);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				int i_real, j_real, nVisi;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
				vector<double> vScores_candidates;
				vector<uchar> vVisi_candidates;
				vector<int> vVisiN_candidates;

				// first evaluate current parameter set for (i,j)
				double depth0 = mDepth.at<float>(i,j);
				double hx0 = mIncre_x.at<float>(i,j);
				double hy0 = mIncre_y.at<float>(i,j);

				vector<double> vScores0;
				CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth0,hx0,hy0,vScores0,size);
				vScores_candidates.push_back(GetScore(vScores0, thresh_ncc, mincams, &nVisi));
				vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores0, thresh_ncc));
				vVisiN_candidates.push_back(nVisi);
				vDepths_candidates.push_back(depth0);
				vHx_candidates.push_back(hx0);
				vHy_candidates.push_back(hy0);

				if (j-1>=0) // means that there is a left neighbor
				{
					double depth_left = mDepth.at<float>(i,j-1);
					double hx_left = mIncre_x.at<float>(i,j-1);
					double hy_left = mIncre_y.at<float>(i,j-1);

					vector<double> vScores_left;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_left,hx_left,hy_left,vScores_left,size);
					vScores_candidates.push_back(GetScore(vScores_left, thresh_ncc, mincams, &nVisi));
					vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_left, thresh_ncc));
					vVisiN_candidates.push_back(nVisi);
					vDepths_candidates.push_back(depth_left);
					vHx_candidates.push_back(hx_left);
					vHy_candidates.push_back(hy_left);
				}

				if (i-1>=0) // means that there is a upper neighbor
				{
					double depth_upper = mDepth.at<float>(i-1,j);
					double hx_upper = mIncre_x.at<float>(i-1,j);
					double hy_upper = mIncre_y.at<float>(i-1,j);

					vector<double> vScores_upper;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_upper,hx_upper,hy_upper,vScores_upper,size);
					vScores_candidates.push_back(GetScore(vScores_upper, thresh_ncc, mincams, &nVisi));
					vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_upper, thresh_ncc));
					vVisiN_candidates.push_back(nVisi);
					vDepths_candidates.push_back(depth_upper);
					vHx_candidates.push_back(hx_upper);
					vHy_candidates.push_back(hy_upper);
				}

				vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				double max_score = *iterDouble;
				int idx_max_score = iterDouble - vScores_candidates.begin();

				double depth_possible = vDepths_candidates[idx_max_score];
				double hx_possible = vHx_candidates[idx_max_score];
				double hy_possible = vHy_candidates[idx_max_score];
				uchar visi_possible = vVisi_candidates[idx_max_score];
				int visiN_possible = vVisiN_candidates[idx_max_score];
				double score_possible = max_score;

				vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear(); vVisi_candidates.clear(); vVisiN_candidates.clear();

				vScores_candidates.push_back(score_possible);
				vVisi_candidates.push_back(visi_possible);
				vVisiN_candidates.push_back(visiN_possible);
				vDepths_candidates.push_back(depth_possible);
				vHx_candidates.push_back(hx_possible);
				vHy_candidates.push_back(hy_possible);

				for (k=0;k<nRandSamp;k++)
				{
					double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
					if (k==0)
					{
						d_max_k = depth_max;
						d_min_k = depth_min;
						hx_max_k = hx_max;
						hx_min_k = -hx_max;
						hy_max_k = hx_max;
						hy_min_k = -hx_max;
					}
					else
					{
						double factor_k = pow(factor, k);
						double d_r = factor_k*d_range;
						double h_r = factor_k*h_range;
						DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
						DetermineInterval(hx_max, -hx_max, hx_possible, h_r, hx_max_k, hx_min_k);
						DetermineInterval(hx_max, -hx_max, hy_possible, h_r, hy_max_k, hy_min_k);
					}

					// generate current parameter set
					double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
					double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
					double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

					vector<double> vScores_k;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size);
					vScores_candidates.push_back(GetScore(vScores_k, thresh_ncc, mincams, &nVisi));
					vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_k, thresh_ncc));
					vVisiN_candidates.push_back(nVisi);
					vDepths_candidates.push_back(depth_k);
					vHx_candidates.push_back(hx_k);
					vHy_candidates.push_back(hy_k);
				}

				iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				max_score = *iterDouble;
				idx_max_score = iterDouble - vScores_candidates.begin();

				mDepth.at<float>(i,j) = vDepths_candidates[idx_max_score];
				mIncre_x.at<float>(i,j) = vHx_candidates[idx_max_score];
				mIncre_y.at<float>(i,j) = vHy_candidates[idx_max_score];
				mVisi.at<uchar>(i,j) = vVisi_candidates[idx_max_score];
				mVisiN.at<uchar>(i,j) = (uchar)vVisiN_candidates[idx_max_score];
				mScore.at<float>(i,j) = max_score;
			}
		}
	} 
	else // odd iterations, from right to left, from bottom to top
	{
		for (i=imgHeight-1;i>=0;i--)
		{
			strInfo.Format("evaluate row %04d", i);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=imgWidth-1;j>=0;j--)
			{
				int i_real, j_real, nVisi;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
				vector<double> vScores_candidates;
				vector<uchar> vVisi_candidates;
				vector<int> vVisiN_candidates;

				// first evaluate current parameter set for (i,j)
				double depth0 = mDepth.at<float>(i,j);
				double hx0 = mIncre_x.at<float>(i,j);
				double hy0 = mIncre_y.at<float>(i,j);

				vector<double> vScores0;
				CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth0,hx0,hy0,vScores0,size);
				vScores_candidates.push_back(GetScore(vScores0, thresh_ncc, mincams, &nVisi));
				vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores0, thresh_ncc));
				vVisiN_candidates.push_back(nVisi);
				vDepths_candidates.push_back(depth0);
				vHx_candidates.push_back(hx0);
				vHy_candidates.push_back(hy0);

				if (j+1<imgWidth) // means that there is a right neighbor
				{
					double depth_right = mDepth.at<float>(i,j+1);
					double hx_right = mIncre_x.at<float>(i,j+1);
					double hy_right = mIncre_y.at<float>(i,j+1);

					vector<double> vScores_right;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_right,hx_right,hy_right,vScores_right,size);
					vScores_candidates.push_back(GetScore(vScores_right, thresh_ncc, mincams, &nVisi));
					vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_right, thresh_ncc));
					vVisiN_candidates.push_back(nVisi);
					vDepths_candidates.push_back(depth_right);
					vHx_candidates.push_back(hx_right);
					vHy_candidates.push_back(hy_right);
				}

				if (i+1<imgHeight) // means that there is a lower neighbor
				{
					double depth_lower = mDepth.at<float>(i+1,j);
					double hx_lower = mIncre_x.at<float>(i+1,j);
					double hy_lower = mIncre_y.at<float>(i+1,j);

					vector<double> vScores_lower;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_lower,hx_lower,hy_lower,vScores_lower,size);
					vScores_candidates.push_back(GetScore(vScores_lower, thresh_ncc, mincams, &nVisi));
					vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_lower, thresh_ncc));
					vVisiN_candidates.push_back(nVisi);
					vDepths_candidates.push_back(depth_lower);
					vHx_candidates.push_back(hx_lower);
					vHy_candidates.push_back(hy_lower);
				}

				vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				double max_score = *iterDouble;
				int idx_max_score = iterDouble - vScores_candidates.begin();

				double depth_possible = vDepths_candidates[idx_max_score];
				double hx_possible = vHx_candidates[idx_max_score];
				double hy_possible = vHy_candidates[idx_max_score];
				uchar visi_possible = vVisi_candidates[idx_max_score];
				int visiN_possible = vVisiN_candidates[idx_max_score];
				double score_possible = max_score;

				vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear(); vVisi_candidates.clear(); vVisiN_candidates.clear();

				vScores_candidates.push_back(score_possible);
				vVisi_candidates.push_back(visi_possible);
				vVisiN_candidates.push_back(visiN_possible);
				vDepths_candidates.push_back(depth_possible);
				vHx_candidates.push_back(hx_possible);
				vHy_candidates.push_back(hy_possible);

				for (k=0;k<nRandSamp;k++)
				{
					double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
					if (k==0)
					{
						d_max_k = depth_max;
						d_min_k = depth_min;
						hx_max_k = hx_max;
						hx_min_k = -hx_max;
						hy_max_k = hx_max;
						hy_min_k = -hx_max;
					}
					else
					{
						double factor_k = pow(factor, k);
						double d_r = factor_k*d_range;
						double h_r = factor_k*h_range;
						DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
						DetermineInterval(hx_max, -hx_max, hx_possible, h_r, hx_max_k, hx_min_k);
						DetermineInterval(hx_max, -hx_max, hy_possible, h_r, hy_max_k, hy_min_k);
					}

					// generate current parameter set
					double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
					double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
					double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

					vector<double> vScores_k;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size);
					vScores_candidates.push_back(GetScore(vScores_k, thresh_ncc, mincams, &nVisi));
					vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_k, thresh_ncc));
					vVisiN_candidates.push_back(nVisi);
					vDepths_candidates.push_back(depth_k);
					vHx_candidates.push_back(hx_k);
					vHy_candidates.push_back(hy_k);
				}

				iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				max_score = *iterDouble;
				idx_max_score = iterDouble - vScores_candidates.begin();

				mDepth.at<float>(i,j) = vDepths_candidates[idx_max_score];
				mIncre_x.at<float>(i,j) = vHx_candidates[idx_max_score];
				mIncre_y.at<float>(i,j) = vHy_candidates[idx_max_score];
				mVisi.at<uchar>(i,j) = vVisi_candidates[idx_max_score];
				mVisiN.at<uchar>(i,j) = (uchar)vVisiN_candidates[idx_max_score];
				mScore.at<float>(i,j) = max_score;
			}
		}
	}
}

void DeepVoid::Scan_Update_rndField_original_fixedvisi(const vector<cam_data> & vCams,	// input:	all camera data
													   const vector<Mat> & vImgs,		// input:	all images
													   const vector<CloudPoint> & clouds,	// input:	the cloud points
													   double angLimit,					// input:	the angular range limit of the normal of every object point, in angle, not radian
													   int idx_refimg,					// input:	the index of the reference image
													   Mat & mDepth,					// input&output:	the 32FC1 matrix with the same size of the image, the initial depth, it's updated as output
													   Mat & mIncre_x,					// input&output:	the 32FC1 matrix with the same size of the image, the initial hx, it's updated as output
													   Mat & mIncre_y,					// input&output:	the 32FC1 matrix with the same size of the image, the initial hy, it's updated as output
													   Mat & mScore,					// input&output:	the score matrix corresponding to the 3 parameter state matrix, it's updated as output
													   const Mat & mVisi,				// input:	the 8UC1 matrix with the same size of the image, fixed visibility
													   int iter,						// input:	iteration
													   int mincams /*= 1*/,
													   double factor /*= 0.5*/,
													   int nRandSamp /*= 6*/,
													   int size /*= 5*/					// input:	the window size of the image patch, should be odd number
													   )
{
	int i,j,ii,jj,k,kk;

	int wndSizeHalf = (size-1)/2;
	int imgWidth = mDepth.cols;
	int imgHeight = mDepth.rows;

	int w_interval = imgWidth/5;
	int h_interval = imgHeight/5;

	cam_data cam_ref = vCams[idx_refimg];

	// extract camera matrix
	Matx33d mK_ref, mR_ref;
	Matx31d mt_ref;

	for (ii=0;ii<3;ii++)
	{
		for (jj=0;jj<3;jj++)
		{
			mR_ref(ii,jj) = cam_ref.R[ii*3+jj];
		}
	}
	mK_ref(0,0) = cam_ref.fx;	mK_ref(0,1) = cam_ref.s;  mK_ref(0,2) = cam_ref.cx;
	mK_ref(1,1) = cam_ref.fy;	mK_ref(1,2) = cam_ref.cy; mK_ref(2,2) = 1;
	mt_ref(0) = cam_ref.t[0];	mt_ref(1) = cam_ref.t[1]; mt_ref(2) = cam_ref.t[2];

	// determine the boundary of parameters
	int n_cloud = clouds.size();

	double f=(mK_ref(0,0)+mK_ref(1,1))/2;
	double tana = tan(angLimit*CV_PI/180);
	double tana_f = tana/f;

	double depth_min;
	double depth_max;

	for (i=0;i<n_cloud;i++)
	{
		Matx31d mX;

		mX(0) = clouds[i].m_pt.x;
		mX(1) = clouds[i].m_pt.y;
		mX(2) = clouds[i].m_pt.z;

		mX = mR_ref*mX+mt_ref;

		double depth = mX(2);

		if (i == 0)
		{
			depth_min = depth;
			depth_max = depth;
		} 
		else
		{
			if (depth<depth_min)
			{
				depth_min = depth;
			}
			if (depth>depth_max)
			{
				depth_max = depth;
			}
		}
	}

	double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

	double depth_ext = (depth_max-depth_min)*ratio_ext;

	depth_max += depth_ext;

	double tmp = depth_min - depth_ext;

	if (tmp<0)
	{
		depth_min = 0;
	} 
	else
	{
		depth_min = tmp;
	}

	double d_range = depth_max - depth_min;
	double hx_max = tana_f * depth_max;
	double h_range = 2*hx_max;

	CString strInfo;

	// now start scanning and updating
	if (iter%2 == 0) // even iterations, from left to right, from top to bottom
	{
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("evaluate row %04d", i);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				int i_real, j_real, nVisi;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				uchar visi = mVisi.at<uchar>(i,j);
				if (visi==0)
				{
					mScore.at<float>(i,j) = -1;
					continue;
				}
				vector<bool> vbools;
				InterpVisiVector_uchar(visi, vbools, &nVisi);

				vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
				vector<double> vScores_candidates;

				// first evaluate current parameter set for (i,j)
				double depth0 = mDepth.at<float>(i,j);
				double hx0 = mIncre_x.at<float>(i,j);
				double hy0 = mIncre_y.at<float>(i,j);

				vector<double> vScores0;
				CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth0,hx0,hy0,vScores0,size);
// 				for (kk=0;kk<vCams.size();kk++)
// 				{
// 					if (!vbools[kk]) {vScores0[kk]=-1;}
// 				}
// 				vScores_candidates.push_back(GetScore(vScores0, 0, mincams));
				double sum = 0;
				for (kk=0;kk<vCams.size();kk++){if (vbools[kk]){sum += vScores0[kk];}}
				double score = sum/nVisi;
				vScores_candidates.push_back(score);
				vDepths_candidates.push_back(depth0);
				vHx_candidates.push_back(hx0);
				vHy_candidates.push_back(hy0);

				if (j-1>=0) // means that there is a left neighbor
				{
					double depth_left = mDepth.at<float>(i,j-1);
					double hx_left = mIncre_x.at<float>(i,j-1);
					double hy_left = mIncre_y.at<float>(i,j-1);

					vector<double> vScores_left;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_left,hx_left,hy_left,vScores_left,size);
// 					for (kk=0;kk<vCams.size();kk++)
// 					{
// 						if (!vbools[kk]) {vScores_left[kk]=-1;}
// 					}
// 					vScores_candidates.push_back(GetScore(vScores_left, 0, mincams));
					sum = 0;
					for (kk=0;kk<vCams.size();kk++){if (vbools[kk]){sum += vScores_left[kk];}}
					score = sum/nVisi;
					vScores_candidates.push_back(score);
					vDepths_candidates.push_back(depth_left);
					vHx_candidates.push_back(hx_left);
					vHy_candidates.push_back(hy_left);
				}

				if (i-1>=0) // means that there is a upper neighbor
				{
					double depth_upper = mDepth.at<float>(i-1,j);
					double hx_upper = mIncre_x.at<float>(i-1,j);
					double hy_upper = mIncre_y.at<float>(i-1,j);

					vector<double> vScores_upper;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_upper,hx_upper,hy_upper,vScores_upper,size);
// 					for (kk=0;kk<vCams.size();kk++)
// 					{
// 						if (!vbools[kk]) {vScores_upper[kk]=-1;}
// 					}
// 					vScores_candidates.push_back(GetScore(vScores_upper, 0, mincams));
					sum = 0;
					for (kk=0;kk<vCams.size();kk++){if (vbools[kk]){sum += vScores_upper[kk];}}
					score = sum/nVisi;
					vScores_candidates.push_back(score);
					vDepths_candidates.push_back(depth_upper);
					vHx_candidates.push_back(hx_upper);
					vHy_candidates.push_back(hy_upper);
				}

				vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				double max_score = *iterDouble;
				int idx_max_score = iterDouble - vScores_candidates.begin();

				double depth_possible = vDepths_candidates[idx_max_score];
				double hx_possible = vHx_candidates[idx_max_score];
				double hy_possible = vHy_candidates[idx_max_score];
				double score_possible = max_score;

				vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

				vScores_candidates.push_back(score_possible);
				vDepths_candidates.push_back(depth_possible);
				vHx_candidates.push_back(hx_possible);
				vHy_candidates.push_back(hy_possible);

				for (k=0;k<nRandSamp;k++)
				{
					double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
					if (k==0)
					{
						d_max_k = depth_max;
						d_min_k = depth_min;
						hx_max_k = hx_max;
						hx_min_k = -hx_max;
						hy_max_k = hx_max;
						hy_min_k = -hx_max;
					}
					else
					{
						double factor_k = pow(factor, k);
						double d_r = factor_k*d_range;
						double h_r = factor_k*h_range;
						DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
						DetermineInterval(hx_max, -hx_max, hx_possible, h_r, hx_max_k, hx_min_k);
						DetermineInterval(hx_max, -hx_max, hy_possible, h_r, hy_max_k, hy_min_k);
					}

					// generate current parameter set
					double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
					double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
					double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

					vector<double> vScores_k;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size);
// 					for (kk=0;kk<vCams.size();kk++)
// 					{
// 						if (!vbools[kk]) {vScores_k[kk]=-1;}
// 					}
// 					vScores_candidates.push_back(GetScore(vScores_k, 0, mincams));
					sum = 0;
					for (kk=0;kk<vCams.size();kk++){if (vbools[kk]){sum += vScores_k[kk];}}
					score = sum/nVisi;
					vScores_candidates.push_back(score);
					vDepths_candidates.push_back(depth_k);
					vHx_candidates.push_back(hx_k);
					vHy_candidates.push_back(hy_k);
				}

				iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				max_score = *iterDouble;
				idx_max_score = iterDouble - vScores_candidates.begin();

				mDepth.at<float>(i,j) = vDepths_candidates[idx_max_score];
				mIncre_x.at<float>(i,j) = vHx_candidates[idx_max_score];
				mIncre_y.at<float>(i,j) = vHy_candidates[idx_max_score];
				mScore.at<float>(i,j) = max_score;
			}
		}
	} 
	else // odd iterations, from right to left, from bottom to top
	{
		for (i=imgHeight-1;i>=0;i--)
		{
			strInfo.Format("evaluate row %04d", i);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=imgWidth-1;j>=0;j--)
			{
				int i_real, j_real, nVisi;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				uchar visi = mVisi.at<uchar>(i,j);
				if (visi==0)
				{
					mScore.at<float>(i,j) = -1;
					continue;
				}
				vector<bool> vbools;
				InterpVisiVector_uchar(visi, vbools, &nVisi);

				vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
				vector<double> vScores_candidates;

				// first evaluate current parameter set for (i,j)
				double depth0 = mDepth.at<float>(i,j);
				double hx0 = mIncre_x.at<float>(i,j);
				double hy0 = mIncre_y.at<float>(i,j);

				vector<double> vScores0;
				CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth0,hx0,hy0,vScores0,size);
// 				for (kk=0;kk<vCams.size();kk++)
// 				{
// 					if (!vbools[kk]) {vScores0[kk]=-1;}
// 				}
// 				vScores_candidates.push_back(GetScore(vScores0, 0, mincams));
				double sum = 0;
				for (kk=0;kk<vCams.size();kk++){if (vbools[kk]){sum += vScores0[kk];}}
				double score = sum/nVisi;
				vScores_candidates.push_back(score);
				vDepths_candidates.push_back(depth0);
				vHx_candidates.push_back(hx0);
				vHy_candidates.push_back(hy0);

				if (j+1<imgWidth) // means that there is a right neighbor
				{
					double depth_right = mDepth.at<float>(i,j+1);
					double hx_right = mIncre_x.at<float>(i,j+1);
					double hy_right = mIncre_y.at<float>(i,j+1);

					vector<double> vScores_right;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_right,hx_right,hy_right,vScores_right,size);
// 					for (kk=0;kk<vCams.size();kk++)
// 					{
// 						if (!vbools[kk]) {vScores_right[kk]=-1;}
// 					}
// 					vScores_candidates.push_back(GetScore(vScores_right, 0, mincams));
					sum = 0;
					for (kk=0;kk<vCams.size();kk++){if (vbools[kk]){sum += vScores_right[kk];}}
					score = sum/nVisi;
					vScores_candidates.push_back(score);
					vDepths_candidates.push_back(depth_right);
					vHx_candidates.push_back(hx_right);
					vHy_candidates.push_back(hy_right);
				}

				if (i+1<imgHeight) // means that there is a lower neighbor
				{
					double depth_lower = mDepth.at<float>(i+1,j);
					double hx_lower = mIncre_x.at<float>(i+1,j);
					double hy_lower = mIncre_y.at<float>(i+1,j);

					vector<double> vScores_lower;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_lower,hx_lower,hy_lower,vScores_lower,size);
// 					for (kk=0;kk<vCams.size();kk++)
// 					{
// 						if (!vbools[kk]) {vScores_lower[kk]=-1;}
// 					}
// 					vScores_candidates.push_back(GetScore(vScores_lower, 0, mincams));
					sum = 0;
					for (kk=0;kk<vCams.size();kk++){if (vbools[kk]){sum += vScores_lower[kk];}}
					score = sum/nVisi;
					vScores_candidates.push_back(score);
					vDepths_candidates.push_back(depth_lower);
					vHx_candidates.push_back(hx_lower);
					vHy_candidates.push_back(hy_lower);
				}

				vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				double max_score = *iterDouble;
				int idx_max_score = iterDouble - vScores_candidates.begin();

				double depth_possible = vDepths_candidates[idx_max_score];
				double hx_possible = vHx_candidates[idx_max_score];
				double hy_possible = vHy_candidates[idx_max_score];
				double score_possible = max_score;

				vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

				vScores_candidates.push_back(score_possible);
				vDepths_candidates.push_back(depth_possible);
				vHx_candidates.push_back(hx_possible);
				vHy_candidates.push_back(hy_possible);

				for (k=0;k<nRandSamp;k++)
				{
					double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
					if (k==0)
					{
						d_max_k = depth_max;
						d_min_k = depth_min;
						hx_max_k = hx_max;
						hx_min_k = -hx_max;
						hy_max_k = hx_max;
						hy_min_k = -hx_max;
					}
					else
					{
						double factor_k = pow(factor, k);
						double d_r = factor_k*d_range;
						double h_r = factor_k*h_range;
						DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
						DetermineInterval(hx_max, -hx_max, hx_possible, h_r, hx_max_k, hx_min_k);
						DetermineInterval(hx_max, -hx_max, hy_possible, h_r, hy_max_k, hy_min_k);
					}

					// generate current parameter set
					double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
					double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
					double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

					vector<double> vScores_k;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size);
// 					for (kk=0;kk<vCams.size();kk++)
// 					{
// 						if (!vbools[kk]) {vScores_k[kk]=-1;}
// 					}
// 					vScores_candidates.push_back(GetScore(vScores_k, 0, mincams));
					sum = 0;
					for (kk=0;kk<vCams.size();kk++){if (vbools[kk]){sum += vScores_k[kk];}}
					score = sum/nVisi;
					vScores_candidates.push_back(score);
					vDepths_candidates.push_back(depth_k);
					vHx_candidates.push_back(hx_k);
					vHy_candidates.push_back(hy_k);
				}

				iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				max_score = *iterDouble;
				idx_max_score = iterDouble - vScores_candidates.begin();

				mDepth.at<float>(i,j) = vDepths_candidates[idx_max_score];
				mIncre_x.at<float>(i,j) = vHx_candidates[idx_max_score];
				mIncre_y.at<float>(i,j) = vHy_candidates[idx_max_score];
				mScore.at<float>(i,j) = max_score;
			}
		}
	}
}

void DeepVoid::Scan_Update_rndField_original_visi_new(const vector<cam_data> & vCams,	// input:	all camera data
													  const vector<Mat> & vImgs,		// input:	all images
													  const vector<CloudPoint> & clouds,// input:	the cloud points
													  double angLimit,					// input:	the angular range limit of the normal of every object point, in angle, not radian
													  int idx_refimg,					// input:	the index of the reference image
													  Mat & mDepth,						// input&output:	the 32FC1 matrix with the same size of the image, the initial depth, it's updated as output
													  Mat & mIncre_x,					// input&output:	the 32FC1 matrix with the same size of the image, the initial hx, it's updated as output
													  Mat & mIncre_y,					// input&output:	the 32FC1 matrix with the same size of the image, the initial hy, it's updated as output
													  Mat & mScore,						// input&output:	the score matrix corresponding to the 3 parameter state matrix, it's updated as output
													  Mat & mVisi,						// output:	the 8UC1 matrix with the same size of the image
													  Mat & mVisiN,						// output:	the 8UC1 matrix with the same size of the image
													  int iter,							// input:	iteration
													  int mincams /*= 1*/,
													  double factor /*= 0.5*/,
													  int nRandSamp /*= 6*/,
													  int size /*= 5*/,					// input:	the window size of the image patch, should be odd number
													  double thresh_ncc /*= 0.8*/,		// input:	the threshold within which to be considered as a successful ncc
													  double ratio_2ndto1st /*= 0.05*/
													  )
{
	int i,j,ii,jj,k;

	double ratio_2ndto1st_1 = 1-ratio_2ndto1st;

	int wndSizeHalf = (size-1)/2;
	int imgWidth = mDepth.cols;
	int imgHeight = mDepth.rows;

	int w_interval = imgWidth/5;
	int h_interval = imgHeight/5;

	cam_data cam_ref = vCams[idx_refimg];

	// extract camera matrix
	Matx33d mK_ref, mR_ref;
	Matx31d mt_ref;

	for (ii=0;ii<3;ii++)
	{
		for (jj=0;jj<3;jj++)
		{
			mR_ref(ii,jj) = cam_ref.R[ii*3+jj];
		}
	}
	mK_ref(0,0) = cam_ref.fx;	mK_ref(0,1) = cam_ref.s;  mK_ref(0,2) = cam_ref.cx;
	mK_ref(1,1) = cam_ref.fy;	mK_ref(1,2) = cam_ref.cy; mK_ref(2,2) = 1;
	mt_ref(0) = cam_ref.t[0];	mt_ref(1) = cam_ref.t[1]; mt_ref(2) = cam_ref.t[2];

	// determine the boundary of parameters
	int n_cloud = clouds.size();

	double f=(mK_ref(0,0)+mK_ref(1,1))/2;
	double tana = tan(angLimit*CV_PI/180);
	double tana_f = tana/f;

	double depth_min;
	double depth_max;

	for (i=0;i<n_cloud;i++)
	{
		Matx31d mX;

		mX(0) = clouds[i].m_pt.x;
		mX(1) = clouds[i].m_pt.y;
		mX(2) = clouds[i].m_pt.z;

		mX = mR_ref*mX+mt_ref;

		double depth = mX(2);

		if (i == 0)
		{
			depth_min = depth;
			depth_max = depth;
		} 
		else
		{
			if (depth<depth_min)
			{
				depth_min = depth;
			}
			if (depth>depth_max)
			{
				depth_max = depth;
			}
		}
	}

	double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

	double depth_ext = (depth_max-depth_min)*ratio_ext;

	depth_max += depth_ext;

	double tmp = depth_min - depth_ext;

	if (tmp<0)
	{
		depth_min = 0;
	} 
	else
	{
		depth_min = tmp;
	}

	double d_range = depth_max - depth_min;
	double hx_max = tana_f * depth_max;
	double h_range = 2*hx_max;

	CString strInfo;

	// now start scanning and updating
	if (iter%2 == 0) // even iterations, from left to right, from top to bottom
	{
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("evaluate row %04d", i);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				int i_real, j_real, nVisi;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
				vector<double> vScores_candidates;
				vector<uchar> vVisi_candidates;
				vector<int> vVisiN_candidates;

				// first evaluate current parameter set for (i,j)
				double depth0 = mDepth.at<float>(i,j);
				double hx0 = mIncre_x.at<float>(i,j);
				double hy0 = mIncre_y.at<float>(i,j);

				vector<double> vScores0;
				CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth0,hx0,hy0,vScores0,size);
				vScores_candidates.push_back(GetScore(vScores0, thresh_ncc, mincams, &nVisi));
				vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores0, thresh_ncc));
				vVisiN_candidates.push_back(nVisi);
				vDepths_candidates.push_back(depth0);
				vHx_candidates.push_back(hx0);
				vHy_candidates.push_back(hy0);

				if (j-1>=0) // means that there is a left neighbor
				{
					double depth_left = mDepth.at<float>(i,j-1);
					double hx_left = mIncre_x.at<float>(i,j-1);
					double hy_left = mIncre_y.at<float>(i,j-1);

					vector<double> vScores_left;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_left,hx_left,hy_left,vScores_left,size);
					vScores_candidates.push_back(GetScore(vScores_left, thresh_ncc, mincams, &nVisi));
					vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_left, thresh_ncc));
					vVisiN_candidates.push_back(nVisi);
					vDepths_candidates.push_back(depth_left);
					vHx_candidates.push_back(hx_left);
					vHy_candidates.push_back(hy_left);
				}

				if (i-1>=0) // means that there is a upper neighbor
				{
					double depth_upper = mDepth.at<float>(i-1,j);
					double hx_upper = mIncre_x.at<float>(i-1,j);
					double hy_upper = mIncre_y.at<float>(i-1,j);

					vector<double> vScores_upper;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_upper,hx_upper,hy_upper,vScores_upper,size);
					vScores_candidates.push_back(GetScore(vScores_upper, thresh_ncc, mincams, &nVisi));
					vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_upper, thresh_ncc));
					vVisiN_candidates.push_back(nVisi);
					vDepths_candidates.push_back(depth_upper);
					vHx_candidates.push_back(hx_upper);
					vHy_candidates.push_back(hy_upper);
				}

				vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				double max_score = *iterDouble;
				int idx_max_score = iterDouble - vScores_candidates.begin();

				if (vScores_candidates.size()>1)
				{
					vScores_candidates[idx_max_score] = -1;
					iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
					double max_2nd_score = *iterDouble;
					int idx_max_2nd_score = iterDouble - vScores_candidates.begin();

					if (max_2nd_score>(max_score*ratio_2ndto1st_1) && vVisiN_candidates[idx_max_2nd_score]>vVisiN_candidates[idx_max_score])
					{
						idx_max_score = idx_max_2nd_score;
						max_score = max_2nd_score;
					}
				}

				double depth_possible = vDepths_candidates[idx_max_score];
				double hx_possible = vHx_candidates[idx_max_score];
				double hy_possible = vHy_candidates[idx_max_score];
				uchar visi_possible = vVisi_candidates[idx_max_score];
				int nVisi_possible = vVisiN_candidates[idx_max_score];
				double score_possible = max_score;

				vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear(); vVisi_candidates.clear(); vVisiN_candidates.clear();

				vScores_candidates.push_back(score_possible);
				vVisi_candidates.push_back(visi_possible);
				vVisiN_candidates.push_back(nVisi_possible);
				vDepths_candidates.push_back(depth_possible);
				vHx_candidates.push_back(hx_possible);
				vHy_candidates.push_back(hy_possible);

				for (k=0;k<nRandSamp;k++)
				{
					double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
					if (k==0)
					{
						d_max_k = depth_max;
						d_min_k = depth_min;
						hx_max_k = hx_max;
						hx_min_k = -hx_max;
						hy_max_k = hx_max;
						hy_min_k = -hx_max;
					}
					else
					{
						double factor_k = pow(factor, k);
						double d_r = factor_k*d_range;
						double h_r = factor_k*h_range;
						DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
						DetermineInterval(hx_max, -hx_max, hx_possible, h_r, hx_max_k, hx_min_k);
						DetermineInterval(hx_max, -hx_max, hy_possible, h_r, hy_max_k, hy_min_k);
					}

					// generate current parameter set
					double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
					double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
					double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

					vector<double> vScores_k;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size);
					vScores_candidates.push_back(GetScore(vScores_k, thresh_ncc, mincams, &nVisi));
					vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_k, thresh_ncc));
					vVisiN_candidates.push_back(nVisi);
					vDepths_candidates.push_back(depth_k);
					vHx_candidates.push_back(hx_k);
					vHy_candidates.push_back(hy_k);
				}

				iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				max_score = *iterDouble;
				idx_max_score = iterDouble - vScores_candidates.begin();

				vScores_candidates[idx_max_score] = -1;
				iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				double max_2nd_score = *iterDouble;
				int idx_max_2nd_score = iterDouble - vScores_candidates.begin();

				if (max_2nd_score>(max_score*ratio_2ndto1st_1) && vVisiN_candidates[idx_max_2nd_score]>vVisiN_candidates[idx_max_score])
				{
					idx_max_score = idx_max_2nd_score;
					max_score = max_2nd_score;
				}

				mDepth.at<float>(i,j) = vDepths_candidates[idx_max_score];
				mIncre_x.at<float>(i,j) = vHx_candidates[idx_max_score];
				mIncre_y.at<float>(i,j) = vHy_candidates[idx_max_score];
				mVisi.at<uchar>(i,j) = vVisi_candidates[idx_max_score];
				mVisiN.at<uchar>(i,j) = (uchar)vVisiN_candidates[idx_max_score];
				mScore.at<float>(i,j) = max_score;
			}
		}
	} 
	else // odd iterations, from right to left, from bottom to top
	{
		for (i=imgHeight-1;i>=0;i--)
		{
			strInfo.Format("evaluate row %04d", i);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=imgWidth-1;j>=0;j--)
			{
				int i_real, j_real, nVisi;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
				vector<double> vScores_candidates;
				vector<uchar> vVisi_candidates;
				vector<int> vVisiN_candidates;

				// first evaluate current parameter set for (i,j)
				double depth0 = mDepth.at<float>(i,j);
				double hx0 = mIncre_x.at<float>(i,j);
				double hy0 = mIncre_y.at<float>(i,j);

				vector<double> vScores0;
				CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth0,hx0,hy0,vScores0,size);
				vScores_candidates.push_back(GetScore(vScores0, thresh_ncc, mincams, &nVisi));
				vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores0, thresh_ncc));
				vVisiN_candidates.push_back(nVisi);
				vDepths_candidates.push_back(depth0);
				vHx_candidates.push_back(hx0);
				vHy_candidates.push_back(hy0);

				if (j+1<imgWidth) // means that there is a right neighbor
				{
					double depth_right = mDepth.at<float>(i,j+1);
					double hx_right = mIncre_x.at<float>(i,j+1);
					double hy_right = mIncre_y.at<float>(i,j+1);

					vector<double> vScores_right;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_right,hx_right,hy_right,vScores_right,size);
					vScores_candidates.push_back(GetScore(vScores_right, thresh_ncc, mincams, &nVisi));
					vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_right, thresh_ncc));
					vVisiN_candidates.push_back(nVisi);
					vDepths_candidates.push_back(depth_right);
					vHx_candidates.push_back(hx_right);
					vHy_candidates.push_back(hy_right);
				}

				if (i+1<imgHeight) // means that there is a lower neighbor
				{
					double depth_lower = mDepth.at<float>(i+1,j);
					double hx_lower = mIncre_x.at<float>(i+1,j);
					double hy_lower = mIncre_y.at<float>(i+1,j);

					vector<double> vScores_lower;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_lower,hx_lower,hy_lower,vScores_lower,size);
					vScores_candidates.push_back(GetScore(vScores_lower, thresh_ncc, mincams, &nVisi));
					vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_lower, thresh_ncc));
					vVisiN_candidates.push_back(nVisi);
					vDepths_candidates.push_back(depth_lower);
					vHx_candidates.push_back(hx_lower);
					vHy_candidates.push_back(hy_lower);
				}

				vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				double max_score = *iterDouble;
				int idx_max_score = iterDouble - vScores_candidates.begin();

				if (vScores_candidates.size()>1)
				{
					vScores_candidates[idx_max_score] = -1;
					iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
					double max_2nd_score = *iterDouble;
					int idx_max_2nd_score = iterDouble - vScores_candidates.begin();

					if (max_2nd_score>(max_score*ratio_2ndto1st_1) && vVisiN_candidates[idx_max_2nd_score]>vVisiN_candidates[idx_max_score])
					{
						idx_max_score = idx_max_2nd_score;
						max_score = max_2nd_score;
					}
				}

				double depth_possible = vDepths_candidates[idx_max_score];
				double hx_possible = vHx_candidates[idx_max_score];
				double hy_possible = vHy_candidates[idx_max_score];
				uchar visi_possible = vVisi_candidates[idx_max_score];
				int nVisi_possible = vVisiN_candidates[idx_max_score];
				double score_possible = max_score;

				vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear(); vVisi_candidates.clear(); vVisiN_candidates.clear();

				vScores_candidates.push_back(score_possible);
				vVisi_candidates.push_back(visi_possible);
				vVisiN_candidates.push_back(nVisi_possible);
				vDepths_candidates.push_back(depth_possible);
				vHx_candidates.push_back(hx_possible);
				vHy_candidates.push_back(hy_possible);

				for (k=0;k<nRandSamp;k++)
				{
					double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
					if (k==0)
					{
						d_max_k = depth_max;
						d_min_k = depth_min;
						hx_max_k = hx_max;
						hx_min_k = -hx_max;
						hy_max_k = hx_max;
						hy_min_k = -hx_max;
					}
					else
					{
						double factor_k = pow(factor, k);
						double d_r = factor_k*d_range;
						double h_r = factor_k*h_range;
						DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
						DetermineInterval(hx_max, -hx_max, hx_possible, h_r, hx_max_k, hx_min_k);
						DetermineInterval(hx_max, -hx_max, hy_possible, h_r, hy_max_k, hy_min_k);
					}

					// generate current parameter set
					double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
					double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
					double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

					vector<double> vScores_k;
					CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size);
					vScores_candidates.push_back(GetScore(vScores_k, thresh_ncc, mincams, &nVisi));
					vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_k, thresh_ncc));
					vVisiN_candidates.push_back(nVisi);
					vDepths_candidates.push_back(depth_k);
					vHx_candidates.push_back(hx_k);
					vHy_candidates.push_back(hy_k);
				}

				iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				max_score = *iterDouble;
				idx_max_score = iterDouble - vScores_candidates.begin();

				vScores_candidates[idx_max_score] = -1;
				iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
				double max_2nd_score = *iterDouble;
				int idx_max_2nd_score = iterDouble - vScores_candidates.begin();

				if (max_2nd_score>(max_score*ratio_2ndto1st_1) && vVisiN_candidates[idx_max_2nd_score]>vVisiN_candidates[idx_max_score])
				{
					idx_max_score = idx_max_2nd_score;
					max_score = max_2nd_score;
				}

				mDepth.at<float>(i,j) = vDepths_candidates[idx_max_score];
				mIncre_x.at<float>(i,j) = vHx_candidates[idx_max_score];
				mIncre_y.at<float>(i,j) = vHy_candidates[idx_max_score];
				mVisi.at<uchar>(i,j) = vVisi_candidates[idx_max_score];
				mVisiN.at<uchar>(i,j) = (uchar)vVisiN_candidates[idx_max_score];
				mScore.at<float>(i,j) = max_score;
			}
		}
	}
}

void DeepVoid::PatchMatch_withViewPropagation(const vector<cam_data> & vCams,		// input:	all camera data
											  const vector<Mat> & vImgs,			// input:	all images
											  const vector<CloudPoint> & clouds,	// input:	the cloud points
											  vector<Mat> & vDepths,				// output:	all the depth maps
											  vector<Mat> & vHxs,					// output:	all the hx maps
											  vector<Mat> & vHys,					// output:	all the hy maps
											  vector<Mat> & vScores,				// output:	all the score maps
											  vector<Mat> & vVisis,					// output:	all the visibility maps
											  vector<Mat> & vVisiNs,				// output:	all the visible image number maps
											  int size /*= 5*/,						// input:	the window size of the image patch, should be odd number
											  double thresh_ncc /*= 0.8*/,			// input:	the threshold within which to be considered as a successful ncc
											  double angLimit /*= 80*/,				// input:	the angular range limit of the normal of every object point, in angle, not radian
											  int maxIter /*= 4*/,					// input:	maximum iteration
											  int mincams /*= 1*/,
											  double factor /*= 0.5*/,
											  int nRandSamp /*= 6*/
											  )
{
	int i,j,k,ii,jj,kk,rk;

	vDepths.clear(); vHxs.clear(); vHys.clear(); vScores.clear(); vVisis.clear(); vVisiNs.clear();

	double thresh_angle = 75;

	int nImg = vCams.size();
	int n_cloud = clouds.size();
	int imgWidth = vImgs[0].cols;
	int imgHeight = vImgs[0].rows;
	int wndSizeHalf = (size-1)/2;
	double tana = tan(angLimit*D2R);

	vector<Matx33d> vRs,vKs; vector<Matx31d> vts;
	vector<double> vfx_1, vfy_1;

	for (k=0;k<nImg;k++)
	{
		Matx33d mR,mK; Matx31d mt;

		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR(i,j) = vCams[k].R[i*3+j];
			}
		}
		mK(0,0) = vCams[k].fx;	mK(0,1) = vCams[k].s;  mK(0,2) = vCams[k].cx;
		mK(1,1) = vCams[k].fy;	mK(1,2) = vCams[k].cy; mK(2,2) = 1;
		mt(0) = vCams[k].t[0];	mt(1) = vCams[k].t[1]; mt(2) = vCams[k].t[2];

		vRs.push_back(mR);
		vKs.push_back(mK);
		vts.push_back(mt);
		vfx_1.push_back(1/vCams[k].fx);
		vfy_1.push_back(1/vCams[k].fy);
	}
	
	CString strInfo;

	// initialize all depth, hx, hy maps randomly
	for (k=0;k<nImg;k++)
	{
		Mat mDepth, mHx, mHy, mScore(imgHeight, imgWidth, CV_32FC1), mVisi(imgHeight, imgWidth, CV_8UC1),  mVisiN(imgHeight, imgWidth, CV_8UC1);
		InitRndField(vKs[k], vRs[k], vts[k], clouds, angLimit, imgWidth, imgHeight, mDepth, mHx, mHy);
		vDepths.push_back(mDepth);
		vHxs.push_back(mHx);
		vHys.push_back(mHy);

		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial depth map ref %02d.txt", k);
		FILE * file_depth = fopen(strInfo, "w");
		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial hx map ref %02d.txt", k);
		FILE * file_hx = fopen(strInfo, "w");
		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial hy map ref %02d.txt", k);
		FILE * file_hy = fopen(strInfo, "w");
		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial score map ref %02d.txt", k);
		FILE * file_score = fopen(strInfo, "w");
		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial visi map ref %02d.txt", k);
		FILE * file_visi = fopen(strInfo, "w");
		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial visiN map ref %02d.txt", k);
		FILE * file_visiN = fopen(strInfo, "w");	

		// at the same time evaluate all parameters
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("evaluate row %04d of image %02d", i, k);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				int i_real, j_real, nVisi;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				double depth = vDepths[k].at<float>(i,j);
				double hx = vHxs[k].at<float>(i,j);
				double hy = vHys[k].at<float>(i,j);

				vector<double> vnccs;
				CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth,hx,hy,vnccs,size, thresh_angle);

				mScore.at<float>(i,j) = GetScore(vnccs, thresh_ncc, mincams, &nVisi);
				mVisi.at<uchar>(i,j) = GetVisibilityVector_uchar(vnccs, thresh_ncc);
				mVisiN.at<uchar>(i,j) = (uchar)nVisi;

				fprintf(file_depth, "%.12f	", mDepth.at<float>(i,j));
				fprintf(file_hx, "%.12f	", mHx.at<float>(i,j));
				fprintf(file_hy, "%.12f	", mHy.at<float>(i,j));
				fprintf(file_score, "%.12f	", mScore.at<float>(i,j));
				fprintf(file_visi, "%d	", mVisi.at<uchar>(i,j));
				fprintf(file_visiN, "%d	", mVisiN.at<uchar>(i,j));
			}
			fprintf(file_depth, "\n");
			fprintf(file_hx, "\n");
			fprintf(file_hy, "\n");
			fprintf(file_score, "\n");
			fprintf(file_visi, "\n");
			fprintf(file_visiN, "\n");
		}

		vScores.push_back(mScore);
		vVisis.push_back(mVisi);
		vVisiNs.push_back(mVisiN);

		fclose(file_depth);
		fclose(file_hx);
		fclose(file_hy);
		fclose(file_score);
		fclose(file_visi);
		fclose(file_visiN);

// 		Mat mDepth(imgHeight, imgWidth, CV_32FC1), mHx(imgHeight, imgWidth, CV_32FC1), mHy(imgHeight, imgWidth, CV_32FC1), mScore(imgHeight, imgWidth, CV_32FC1),
// 			mVisi(imgHeight, imgWidth, CV_8UC1),  mVisiN(imgHeight, imgWidth, CV_8UC1);
// 		
// 		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial depth map ref %02d.txt", k);
// //		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\final PatchMatch depth map ref %02d.txt", k);
// 		FILE * file_depth = fopen(strInfo, "r");
// 		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial hx map ref %02d.txt", k);
// //		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\final PatchMatch hx map ref %02d.txt", k);
// 		FILE * file_hx = fopen(strInfo, "r");
// 		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial hy map ref %02d.txt", k);
// //		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\final PatchMatch hy map ref %02d.txt", k);
// 		FILE * file_hy = fopen(strInfo, "r");
// 		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial score map ref %02d.txt", k);
// //		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\final PatchMatch score map ref %02d.txt", k);
// 		FILE * file_score = fopen(strInfo, "r");
// 		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial visi map ref %02d.txt", k);
// //		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\final PatchMatch visi map ref %02d.txt", k);
// 		FILE * file_visi = fopen(strInfo, "r");
// 		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial visiN map ref %02d.txt", k);
// //		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\final PatchMatch visiN map ref %02d.txt", k);
// 		FILE * file_visiN = fopen(strInfo, "r");	
// 
// 		// at the same time evaluate all parameters
// 		for (i=0;i<imgHeight;i++)
// 		{
// 			for (j=0;j<imgWidth;j++)
// 			{
// 				double depth,hx,hy,score;
// 				int tmp;
// 				fscanf(file_depth, "%lf	", &depth);
// 				fscanf(file_hx, "%lf	", &hx);
// 				fscanf(file_hy, "%lf	", &hy);
// 				fscanf(file_score, "%lf	", &score);
// 
// 				mDepth.at<float>(i,j) = depth;
// 				mHx.at<float>(i,j) = hx;
// 				mHy.at<float>(i,j) = hy;
// 				mScore.at<float>(i,j) = score;
// 
// 				fscanf(file_visi, "%d	", &tmp);
// 				mVisi.at<uchar>(i,j) = (uchar)tmp;
// 				fscanf(file_visiN, "%d	", &tmp);
// 				mVisiN.at<uchar>(i,j) = (uchar)tmp;
// 			}
// 		}
// 		fclose(file_depth);
// 		fclose(file_hx);
// 		fclose(file_hy);
// 		fclose(file_score);
// 		fclose(file_visi);
// 		fclose(file_visiN);
// 
// 		vDepths.push_back(mDepth);
// 		vHxs.push_back(mHx);
// 		vHys.push_back(mHy);
// 		vScores.push_back(mScore);
// 		vVisis.push_back(mVisi);
// 		vVisiNs.push_back(mVisiN);
	}

	// start propagation
	for (ii=0;ii<maxIter;ii++)
	{
		if (ii%2 == 0)
		{
			for (k=0;k<nImg;k++)
			{
				// determine the sampling ranges of all parameters //////////////////////////////////////////////////////////////////////////
				double fx = vKs[k](0,0);
				double fy = vKs[k](1,1);
				double cx = vKs[k](0,2);
				double cy = vKs[k](1,2);
				double fx_1 = vfx_1[k];
				double fy_1 = vfy_1[k];
				double f=(fx+fy)*0.5;
				double tana_f = tana/f;

				double depth_min;
				double depth_max;

				for (jj=0;jj<n_cloud;jj++)
				{
					Matx31d mX;

					mX(0) = clouds[jj].m_pt.x;
					mX(1) = clouds[jj].m_pt.y;
					mX(2) = clouds[jj].m_pt.z;

					mX = vRs[k]*mX+vts[k];

					double depth = mX(2);

					if (jj == 0)
					{
						depth_min = depth;
						depth_max = depth;
					} 
					else
					{
						if (depth<depth_min)
						{
							depth_min = depth;
						}
						if (depth>depth_max)
						{
							depth_max = depth;
						}
					}
				}

				double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

				double depth_ext = (depth_max-depth_min)*ratio_ext;

				depth_max += depth_ext;

				double tmp = depth_min - depth_ext;

				if (tmp<0)
				{
					depth_min = 0;
				} 
				else
				{
					depth_min = tmp;
				}

				double d_range = depth_max - depth_min;
				double hx_max = tana_f * depth_max;
				double h_range = 2*hx_max;
				//////////////////////////////////////////////////////////////////////////


				for (i=0;i<imgHeight;i++)
				{
					strInfo.Format("evaluate row %04d of image %02d in iteration %02d", i, k, ii);
					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

					double nimgy = (i-cy)*fy_1;

					for (j=0;j<imgWidth;j++)
					{
						int i_real, j_real, nVisi;
						MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

						// normalized image point, i.e. the direction
						double nimgx = (j-cx)*fx_1;

						vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
						vector<double> vScores_candidates;
						vector<uchar> vVisi_candidates;
						vector<int> vVisiN_candidates;

						// first evaluate current parameter set for (i,j)
						double depth0 = vDepths[k].at<float>(i,j);
						double hx0 = vHxs[k].at<float>(i,j);
						double hy0 = vHys[k].at<float>(i,j);
						double score0 = vScores[k].at<float>(i,j);
						uchar visi0 = vVisis[k].at<uchar>(i,j);
						uchar visiN0 = vVisiNs[k].at<uchar>(i,j);

						vScores_candidates.push_back(score0);
						vVisi_candidates.push_back(visi0);
						vVisiN_candidates.push_back(visiN0);
						vDepths_candidates.push_back(depth0);
						vHx_candidates.push_back(hx0);
						vHy_candidates.push_back(hy0);

						if (j-1>=0) // means that there is a left neighbor
						{
							double depth_left = vDepths[k].at<float>(i,j-1);
							double hx_left = vHxs[k].at<float>(i,j-1);
							double hy_left = vHys[k].at<float>(i,j-1);

							vector<double> vScores_left;
//							CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, k, j_real,i_real,depth_left,hx_left,hy_left,vScores_left,size);
							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_left,hx_left,hy_left,vScores_left,size,thresh_angle);
							vScores_candidates.push_back(GetScore(vScores_left, thresh_ncc, mincams, &nVisi));
							vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_left, thresh_ncc));
							vVisiN_candidates.push_back(nVisi);
							vDepths_candidates.push_back(depth_left);
							vHx_candidates.push_back(hx_left);
							vHy_candidates.push_back(hy_left);
						}

						if (i-1>=0) // means that there is a upper neighbor
						{
							double depth_upper = vDepths[k].at<float>(i-1,j);
							double hx_upper = vHxs[k].at<float>(i-1,j);
							double hy_upper = vHys[k].at<float>(i-1,j);

							vector<double> vScores_upper;
//							CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, k, j_real,i_real,depth_upper,hx_upper,hy_upper,vScores_upper,size);
							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_upper,hx_upper,hy_upper,vScores_upper,size,thresh_angle);
							vScores_candidates.push_back(GetScore(vScores_upper, thresh_ncc, mincams, &nVisi));
							vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_upper, thresh_ncc));
							vVisiN_candidates.push_back(nVisi);
							vDepths_candidates.push_back(depth_upper);
							vHx_candidates.push_back(hx_upper);
							vHy_candidates.push_back(hy_upper);
						}

						vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						double max_score = *iterDouble;
						int idx_max_score = iterDouble - vScores_candidates.begin();

						double depth_possible = vDepths_candidates[idx_max_score];
						double hx_possible = vHx_candidates[idx_max_score];
						double hy_possible = vHy_candidates[idx_max_score];
						uchar visi_possible = vVisi_candidates[idx_max_score];
						int visiN_possible = vVisiN_candidates[idx_max_score];
						double score_possible = max_score;

						vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear(); vVisi_candidates.clear(); vVisiN_candidates.clear();

						vScores_candidates.push_back(score_possible);
						vVisi_candidates.push_back(visi_possible);
						vVisiN_candidates.push_back(visiN_possible);
						vDepths_candidates.push_back(depth_possible);
						vHx_candidates.push_back(hx_possible);
						vHy_candidates.push_back(hy_possible);

						for (rk=0;rk<nRandSamp;rk++)
						{
							double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
							if (rk==0)
							{
								d_max_k = depth_max;
								d_min_k = depth_min;
								hx_max_k = hx_max;
								hx_min_k = -hx_max;
								hy_max_k = hx_max;
								hy_min_k = -hx_max;
							}
							else
							{
								double factor_k = pow(factor, rk);
								double d_r = factor_k*d_range*0.5;
								double h_r = factor_k*h_range*0.5;
								DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
								DetermineInterval(hx_max, -hx_max, hx_possible, h_r, hx_max_k, hx_min_k);
								DetermineInterval(hx_max, -hx_max, hy_possible, h_r, hy_max_k, hy_min_k);
							}

							// generate current parameter set
							double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
							double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
							double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

							vector<double> vScores_k;
//							CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, k, j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size);
							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size,thresh_angle);
							vScores_candidates.push_back(GetScore(vScores_k, thresh_ncc, mincams, &nVisi));
							vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_k, thresh_ncc));
							vVisiN_candidates.push_back(nVisi);
							vDepths_candidates.push_back(depth_k);
							vHx_candidates.push_back(hx_k);
							vHy_candidates.push_back(hy_k);
						}

						iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						max_score = *iterDouble;
						idx_max_score = iterDouble - vScores_candidates.begin();

						double d   = vDepths[k].at<float>(i,j) = vDepths_candidates[idx_max_score];
						double hx  = vHxs[k].at<float>(i,j) = vHx_candidates[idx_max_score];
						double hy  = vHys[k].at<float>(i,j) = vHy_candidates[idx_max_score];
						uchar visi = vVisis[k].at<uchar>(i,j) = vVisi_candidates[idx_max_score];
						vVisiNs[k].at<uchar>(i,j) = (uchar)vVisiN_candidates[idx_max_score];
						vScores[k].at<float>(i,j) = max_score;

						// propagate current parameters to all matched pixels in other images, if they are better than their current guess then adopt it.
						// get the 3D coordinates of the point associated with current pixel
						Matx31d pt3d = GetXYZ_givenDepth(vRs[k], vts[k], nimgx, nimgy, d);
						// get the normal of current obtained parameters
						Matx31d mn0; mn0(2)=1;
						get_normal_givendrhxhy(fx, fy, nimgx, nimgy, d, hx, hy, mn0(0), mn0(1));
						Matx31d mnw = vRs[k].t()*mn0; // convert the normal into world coordinate system
						vector<bool> vbools;
						InterpVisiVector_uchar(visi, vbools);
						for (kk=0;kk<nImg;kk++)
						{
							if (!vbools[kk]){continue;}

							double fx_kk = vKs[kk](0,0); double fy_kk = vKs[kk](1,1); 
							double cx_kk = vKs[kk](0,2); double cy_kk = vKs[kk](1,2); 
							double fx_kk_1 = vfx_1[kk];  double fy_kk_1 = vfy_1[kk];

							// get the patch normal in kk image
							Matx31d mnkk = vRs[kk]*mnw;

							Matx31d pt3d_proj = vRs[kk]*pt3d+vts[kk];

							Matx31d imgpt = vKs[kk]*pt3d_proj;
							double zk_1 = 1/imgpt(2);
							double xk = imgpt(0)*zk_1;
							double yk = imgpt(1)*zk_1;

							if (xk<0||xk>(imgWidth-1)||yk<0||yk>(imgHeight-1)){continue;}

							int xk_int = int(xk+0.5);
							int yk_int = int(yk+0.5);

							int xk_real, yk_real;
							MakeSureNotOutBorder(xk_int,yk_int,xk_real,yk_real,wndSizeHalf,imgWidth,imgHeight);

							double u_kk = 0; double v_kk = 0; double d_kk = pt3d_proj(2);
							optim_gn_uvrou_initialdk(vKs[k], vRs[k], vts[k], vKs[kk], vRs[kk], vts[kk], d, hx, hy, j, i, xk_int, yk_int, u_kk, v_kk, d_kk);

							double nimgx_kk = (xk_int-cx_kk)*fx_kk_1;
							double nimgy_kk = (yk_int-cy_kk)*fy_kk_1;

							double hx_kk, hy_kk;
							get_hxhy_givendrnormal(fx_kk, fy_kk, nimgx_kk, nimgy_kk, d_kk, mnkk, hx_kk, hy_kk);

							vector<double> vScores_kk;
//							CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, kk, xk_real, yk_real, d_kk, hx_kk, hy_kk, vScores_kk, size);
							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs,kk,xk_real,yk_real,d_kk,hx_kk,hy_kk,vScores_kk,size,thresh_angle);
							double score_new = GetScore(vScores_kk, thresh_ncc, mincams, &nVisi);
							double score_old = vScores[kk].at<float>(yk_int,xk_int);
							if (score_new>score_old)
							{
								vDepths[kk].at<float>(yk_int,xk_int) = d_kk;
								vHxs[kk].at<float>(yk_int,xk_int) = hx_kk;
								vHys[kk].at<float>(yk_int,xk_int) = hy_kk;
								vVisis[kk].at<uchar>(yk_int,xk_int) = GetVisibilityVector_uchar(vScores_kk, thresh_ncc);
								vVisiNs[kk].at<uchar>(yk_int,xk_int) = (uchar)nVisi;
								vScores[kk].at<float>(yk_int,xk_int) = score_new;
							}
						}
					}
				}

				double maxncc_minncc_1 = 1/(1-thresh_ncc);
				// output runtime info
				for (kk=0;kk<nImg;kk++)
				{
					Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3), mVisiN_map(imgHeight, imgWidth, CV_8UC3);

					double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

					minMaxIdx(vDepths[kk], &min_depth, &max_depth);
					minMaxIdx(vHxs[kk], &min_incre_x, &max_incre_x);
					minMaxIdx(vHys[kk], &min_incre_y, &max_incre_y);

					vDepths[kk].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
					vHxs[kk].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
					vHys[kk].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

					for (i=0;i<imgHeight;i++)
					{
						for (j=0;j<imgWidth;j++)
						{
							if (vScores[kk].at<float>(i,j)<0)
							{
								mScore_map.at<Vec3b>(i,j).val[0] = 0;
								mScore_map.at<Vec3b>(i,j).val[1] = 0;
								mScore_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else
							{
								mScore_map.at<Vec3b>(i,j).val[0] = 0;
								mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*(vScores[kk].at<float>(i,j)-thresh_ncc)*maxncc_minncc_1);
								mScore_map.at<Vec3b>(i,j).val[2] = 0;
							}

							uchar nnn = vVisiNs[kk].at<uchar>(i,j);

							if (nnn==0)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==1)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==2)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==3)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
							}
							else
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
							}
						}
					}

					strInfo.Format("D:\\all\\depth map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mDepth_map);
					strInfo.Format("D:\\all\\hx map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mHx_map);
					strInfo.Format("D:\\all\\hy map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mHy_map);
					strInfo.Format("D:\\all\\score map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mScore_map);
					strInfo.Format("D:\\all\\visi map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), vVisis[kk]);
					strInfo.Format("D:\\all\\visiN map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mVisiN_map);
					strInfo.Format("D:\\all\\cloud points iteration %02d ref %02d img %02d.txt", ii, k, kk);
					/*WriteDepthMap(strInfo,vCams[kk],vImgs[kk],vDepths[kk],vScores[kk]);*/
					OutputPointCloud(strInfo,vCams[kk],vImgs[kk],vDepths[kk],vHxs[kk],vHys[kk],vScores[kk]);
				}

// 				if (ii==0&&k==1)
// 				{
// 					break;
// 				}
			}
		} 
		else
		{
			for (k=(nImg-1);k>=0;k--)
			{
				// determine the sampling ranges of all parameters //////////////////////////////////////////////////////////////////////////
				double fx = vKs[k](0,0);
				double fy = vKs[k](1,1);
				double cx = vKs[k](0,2);
				double cy = vKs[k](1,2);
				double fx_1 = vfx_1[k];
				double fy_1 = vfy_1[k];
				double f=(fx+fy)*0.5;
				double tana_f = tana/f;

				double depth_min;
				double depth_max;

				for (jj=0;jj<n_cloud;jj++)
				{
					Matx31d mX;

					mX(0) = clouds[jj].m_pt.x;
					mX(1) = clouds[jj].m_pt.y;
					mX(2) = clouds[jj].m_pt.z;

					mX = vRs[k]*mX+vts[k];

					double depth = mX(2);

					if (jj == 0)
					{
						depth_min = depth;
						depth_max = depth;
					} 
					else
					{
						if (depth<depth_min)
						{
							depth_min = depth;
						}
						if (depth>depth_max)
						{
							depth_max = depth;
						}
					}
				}

				double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

				double depth_ext = (depth_max-depth_min)*ratio_ext;

				depth_max += depth_ext;

				double tmp = depth_min - depth_ext;

				if (tmp<0)
				{
					depth_min = 0;
				} 
				else
				{
					depth_min = tmp;
				}

				double d_range = depth_max - depth_min;
				double hx_max = tana_f * depth_max;
				double h_range = 2*hx_max;
				//////////////////////////////////////////////////////////////////////////


				for (i=imgHeight-1;i>=0;i--)
				{
					strInfo.Format("evaluate row %04d of image %02d in iteration %02d", i, k, ii);
					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

					double nimgy = (i-cy)*fy_1;

					for (j=imgWidth-1;j>=0;j--)
					{
						int i_real, j_real, nVisi;
						MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

						// normalized image point, i.e. the direction
						double nimgx = (j-cx)*fx_1;
						
						vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
						vector<double> vScores_candidates;
						vector<uchar> vVisi_candidates;
						vector<int> vVisiN_candidates;

						// first evaluate current parameter set for (i,j)
						double depth0 = vDepths[k].at<float>(i,j);
						double hx0 = vHxs[k].at<float>(i,j);
						double hy0 = vHys[k].at<float>(i,j);
						double score0 = vScores[k].at<float>(i,j);
						uchar visi0 = vVisis[k].at<uchar>(i,j);
						uchar visiN0 = vVisiNs[k].at<uchar>(i,j);

						vScores_candidates.push_back(score0);
						vVisi_candidates.push_back(visi0);
						vVisiN_candidates.push_back(visiN0);
						vDepths_candidates.push_back(depth0);
						vHx_candidates.push_back(hx0);
						vHy_candidates.push_back(hy0);

						if (j+1<imgWidth) // means that there is a right neighbor
						{
							double depth_right = vDepths[k].at<float>(i,j+1);
							double hx_right = vHxs[k].at<float>(i,j+1);
							double hy_right = vHys[k].at<float>(i,j+1);

							vector<double> vScores_right;
//							CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, k, j_real,i_real,depth_right,hx_right,hy_right,vScores_right,size);
							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_right,hx_right,hy_right,vScores_right,size,thresh_angle);
							vScores_candidates.push_back(GetScore(vScores_right, thresh_ncc, mincams, &nVisi));
							vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_right, thresh_ncc));
							vVisiN_candidates.push_back(nVisi);
							vDepths_candidates.push_back(depth_right);
							vHx_candidates.push_back(hx_right);
							vHy_candidates.push_back(hy_right);
						}

						if (i+1<imgHeight) // means that there is a lower neighbor
						{
							double depth_lower = vDepths[k].at<float>(i+1,j);
							double hx_lower = vHxs[k].at<float>(i+1,j);
							double hy_lower = vHys[k].at<float>(i+1,j);

							vector<double> vScores_lower;
//							CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, k, j_real,i_real,depth_lower,hx_lower,hy_lower,vScores_lower,size);
							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_lower,hx_lower,hy_lower,vScores_lower,size,thresh_angle);
							vScores_candidates.push_back(GetScore(vScores_lower, thresh_ncc, mincams, &nVisi));
							vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_lower, thresh_ncc));
							vVisiN_candidates.push_back(nVisi);
							vDepths_candidates.push_back(depth_lower);
							vHx_candidates.push_back(hx_lower);
							vHy_candidates.push_back(hy_lower);
						}

						vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						double max_score = *iterDouble;
						int idx_max_score = iterDouble - vScores_candidates.begin();

						double depth_possible = vDepths_candidates[idx_max_score];
						double hx_possible = vHx_candidates[idx_max_score];
						double hy_possible = vHy_candidates[idx_max_score];
						uchar visi_possible = vVisi_candidates[idx_max_score];
						int visiN_possible = vVisiN_candidates[idx_max_score];
						double score_possible = max_score;

						vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear(); vVisi_candidates.clear(); vVisiN_candidates.clear();

						vScores_candidates.push_back(score_possible);
						vVisi_candidates.push_back(visi_possible);
						vVisiN_candidates.push_back(visiN_possible);
						vDepths_candidates.push_back(depth_possible);
						vHx_candidates.push_back(hx_possible);
						vHy_candidates.push_back(hy_possible);

						for (rk=0;rk<nRandSamp;rk++)
						{
							double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
							if (rk==0)
							{
								d_max_k = depth_max;
								d_min_k = depth_min;
								hx_max_k = hx_max;
								hx_min_k = -hx_max;
								hy_max_k = hx_max;
								hy_min_k = -hx_max;
							}
							else
							{
								double factor_k = pow(factor, rk);
								double d_r = factor_k*d_range*0.5;
								double h_r = factor_k*h_range*0.5;
								DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
								DetermineInterval(hx_max, -hx_max, hx_possible, h_r, hx_max_k, hx_min_k);
								DetermineInterval(hx_max, -hx_max, hy_possible, h_r, hy_max_k, hy_min_k);
							}

							// generate current parameter set
							double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
							double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
							double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

							vector<double> vScores_k;
//							CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, k, j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size);
							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size,thresh_angle);
							vScores_candidates.push_back(GetScore(vScores_k, thresh_ncc, mincams, &nVisi));
							vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_k, thresh_ncc));
							vVisiN_candidates.push_back(nVisi);
							vDepths_candidates.push_back(depth_k);
							vHx_candidates.push_back(hx_k);
							vHy_candidates.push_back(hy_k);
						}

						iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						max_score = *iterDouble;
						idx_max_score = iterDouble - vScores_candidates.begin();

						double d   = vDepths[k].at<float>(i,j) = vDepths_candidates[idx_max_score];
						double hx  = vHxs[k].at<float>(i,j) = vHx_candidates[idx_max_score];
						double hy  = vHys[k].at<float>(i,j) = vHy_candidates[idx_max_score];
						uchar visi = vVisis[k].at<uchar>(i,j) = vVisi_candidates[idx_max_score];
						vVisiNs[k].at<uchar>(i,j) = (uchar)vVisiN_candidates[idx_max_score];
						vScores[k].at<float>(i,j) = max_score;

						// propagate current parameters to all matched pixels in other images, if they are better than their current guess then adopt it.
						// get the 3D coordinates of the point associated with current pixel
						Matx31d pt3d = GetXYZ_givenDepth(vRs[k], vts[k], nimgx, nimgy, d);
						// get the normal of current obtained parameters
						Matx31d mn0; mn0(2)=1;
						get_normal_givendrhxhy(fx, fy, nimgx, nimgy, d, hx, hy, mn0(0), mn0(1));
						Matx31d mnw = vRs[k].t()*mn0; // convert the normal into world coordinate system
						vector<bool> vbools;
						InterpVisiVector_uchar(visi, vbools);
						for (kk=0;kk<nImg;kk++)
						{
							if (!vbools[kk]){continue;}

							double fx_kk = vKs[kk](0,0); double fy_kk = vKs[kk](1,1); 
							double cx_kk = vKs[kk](0,2); double cy_kk = vKs[kk](1,2); 
							double fx_kk_1 = vfx_1[kk];  double fy_kk_1 = vfy_1[kk];

							// get the patch normal in kk image
							Matx31d mnkk = vRs[kk]*mnw;

							Matx31d pt3d_proj = vRs[kk]*pt3d+vts[kk];

							Matx31d imgpt = vKs[kk]*pt3d_proj;
							double zk_1 = 1/imgpt(2);
							double xk = imgpt(0)*zk_1;
							double yk = imgpt(1)*zk_1;

							if (xk<0||xk>(imgWidth-1)||yk<0||yk>(imgHeight-1)){continue;}

							int xk_int = int(xk+0.5);
							int yk_int = int(yk+0.5);

							int xk_real, yk_real;
							MakeSureNotOutBorder(xk_int,yk_int,xk_real,yk_real,wndSizeHalf,imgWidth,imgHeight);

							double u_kk = 0; double v_kk = 0; double d_kk = pt3d_proj(2);
							optim_gn_uvrou_initialdk(vKs[k], vRs[k], vts[k], vKs[kk], vRs[kk], vts[kk], d, hx, hy, j, i, xk_int, yk_int, u_kk, v_kk, d_kk);

							double nimgx_kk = (xk_int-cx_kk)*fx_kk_1;
							double nimgy_kk = (yk_int-cy_kk)*fy_kk_1;

							double hx_kk, hy_kk;
							get_hxhy_givendrnormal(fx_kk, fy_kk, nimgx_kk, nimgy_kk, d_kk, mnkk, hx_kk, hy_kk);

							vector<double> vScores_kk;
//							CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, kk, xk_real, yk_real, d_kk, hx_kk, hy_kk, vScores_kk, size);
							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, kk, xk_real, yk_real, d_kk, hx_kk, hy_kk, vScores_kk, size, thresh_angle);
							double score_new = GetScore(vScores_kk, thresh_ncc, mincams, &nVisi);
							double score_old = vScores[kk].at<float>(yk_int,xk_int);
							if (score_new>score_old)
							{
								vDepths[kk].at<float>(yk_int,xk_int) = d_kk;
								vHxs[kk].at<float>(yk_int,xk_int) = hx_kk;
								vHys[kk].at<float>(yk_int,xk_int) = hy_kk;
								vVisis[kk].at<uchar>(yk_int,xk_int) = GetVisibilityVector_uchar(vScores_kk, thresh_ncc);
								vVisiNs[kk].at<uchar>(yk_int,xk_int) = (uchar)nVisi;
								vScores[kk].at<float>(yk_int,xk_int) = score_new;
							}
						}
					}
				}

				double maxncc_minncc_1 = 1/(1-thresh_ncc);
				// output runtime info
				for (kk=0;kk<nImg;kk++)
				{
					Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3), mVisiN_map(imgHeight, imgWidth, CV_8UC3);

					double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

					minMaxIdx(vDepths[kk], &min_depth, &max_depth);
					minMaxIdx(vHxs[kk], &min_incre_x, &max_incre_x);
					minMaxIdx(vHys[kk], &min_incre_y, &max_incre_y);

					vDepths[kk].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
					vHxs[kk].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
					vHys[kk].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

					for (i=0;i<imgHeight;i++)
					{
						for (j=0;j<imgWidth;j++)
						{
							if (vScores[kk].at<float>(i,j)<0)
							{
								mScore_map.at<Vec3b>(i,j).val[0] = 0;
								mScore_map.at<Vec3b>(i,j).val[1] = 0;
								mScore_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else
							{
								mScore_map.at<Vec3b>(i,j).val[0] = 0;
								mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*(vScores[kk].at<float>(i,j)-thresh_ncc)*maxncc_minncc_1);
								mScore_map.at<Vec3b>(i,j).val[2] = 0;
							}

							uchar nnn = vVisiNs[kk].at<uchar>(i,j);

							if (nnn==0)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==1)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==2)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==3)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
							}
							else
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
							}
						}
					}

					strInfo.Format("D:\\all\\depth map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mDepth_map);
					strInfo.Format("D:\\all\\hx map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mHx_map);
					strInfo.Format("D:\\all\\hy map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mHy_map);
					strInfo.Format("D:\\all\\score map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mScore_map);
					strInfo.Format("D:\\all\\visi map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), vVisis[kk]);
					strInfo.Format("D:\\all\\visiN map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mVisiN_map);
					strInfo.Format("D:\\all\\cloud points iteration %02d ref %02d img %02d.txt", ii, k, kk);
					/*WriteDepthMap(strInfo,vCams[kk],vImgs[kk],vDepths[kk],vScores[kk]);*/
					OutputPointCloud(strInfo,vCams[kk],vImgs[kk],vDepths[kk],vHxs[kk],vHys[kk],vScores[kk]);
				}
			}
		}

// 		if (ii==0&&k==1)
// 		{
// 			break;
// 		}
	}

	for (k=0;k<nImg;k++)
	{
		strInfo.Format("D:\\all\\final PatchMatch depth map ref %02d.txt", k);
		FILE * file_depth = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch hx map ref %02d.txt", k);
		FILE * file_hx = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch hy map ref %02d.txt", k);
		FILE * file_hy = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch score map ref %02d.txt", k);
		FILE * file_score = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch visi map ref %02d.txt", k);
		FILE * file_visi = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch visiN map ref %02d.txt", k);
		FILE * file_visiN = fopen(strInfo, "w");	

		// at the same time evaluate all parameters
		for (i=0;i<imgHeight;i++)
		{
			for (j=0;j<imgWidth;j++)
			{
				fprintf(file_depth, "%.12f	", vDepths[k].at<float>(i,j));
				fprintf(file_hx, "%.12f	", vHxs[k].at<float>(i,j));
				fprintf(file_hy, "%.12f	", vHys[k].at<float>(i,j));
				fprintf(file_score, "%.12f	", vScores[k].at<float>(i,j));
				fprintf(file_visi, "%d	", vVisis[k].at<uchar>(i,j));
				fprintf(file_visiN, "%d	", vVisiNs[k].at<uchar>(i,j));
			}
			fprintf(file_depth, "\n");
			fprintf(file_hx, "\n");
			fprintf(file_hy, "\n");
			fprintf(file_score, "\n");
			fprintf(file_visi, "\n");
			fprintf(file_visiN, "\n");
		}
		fclose(file_depth);
		fclose(file_hx);
		fclose(file_hy);
		fclose(file_score);
		fclose(file_visi);
		fclose(file_visiN);
	}
}

// 20140728, propagate depth according to depth gradients of previous pixels
void DeepVoid::PatchMatch_withViewPropagation_140728(const vector<cam_data> & vCams,		// input:	all camera data
												     const vector<Mat> & vImgs,			// input:	all images
												     const vector<CloudPoint> & clouds,	// input:	the cloud points
												     vector<Mat> & vDepths,				// output:	all the depth maps
												     vector<Mat> & vHxs,					// output:	all the hx maps
												     vector<Mat> & vHys,					// output:	all the hy maps
												     vector<Mat> & vScores,				// output:	all the score maps
												     vector<Mat> & vVisis,				// output:	all the visibility maps
												     vector<Mat> & vVisiNs,				// output:	all the visible image number maps
												     int size /*= 5*/,					// input:	the window size of the image patch, should be odd number
												     double thresh_ncc /*= 0.8*/,			// input:	the threshold within which to be considered as a successful ncc
												     double angLimit /*= 80*/,			// input:	the angular range limit of the normal of every object point, in angle, not radian
												     int maxIter /*= 4*/,					// input:	maximum iteration
												     int mincams /*= 1*/,
												     double factor /*= 0.5*/,
												     int nRandSamp /*= 6*/
												     )
{
	int i,j,k,ii,jj,kk,rk;

	vDepths.clear(); vHxs.clear(); vHys.clear(); vScores.clear(); vVisis.clear(); vVisiNs.clear();

	double thresh_angle = 720;
	double miu_angle = 0;
	double sigma_angle = 10;

	int nImg = vCams.size();
	int n_cloud = clouds.size();
	int imgWidth = vImgs[0].cols;
	int imgHeight = vImgs[0].rows;
	int wndSizeHalf = (size-1)/2;
	double tana = tan(angLimit*D2R);

	vector<Matx33d> vRs,vKs; vector<Matx31d> vts;
	vector<double> vfx_1, vfy_1;

	vector<double> vDepth_max, vDepth_min; // max depths and min depths for every image
	vector<double> vH_max; // max hx and hy for every image

	for (k=0;k<nImg;k++)
	{
		Matx33d mR,mK; Matx31d mt;

		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR(i,j) = vCams[k].R[i*3+j];
			}
		}
		mK(0,0) = vCams[k].fx;	mK(0,1) = vCams[k].s;  mK(0,2) = vCams[k].cx;
		mK(1,1) = vCams[k].fy;	mK(1,2) = vCams[k].cy; mK(2,2) = 1;
		mt(0) = vCams[k].t[0];	mt(1) = vCams[k].t[1]; mt(2) = vCams[k].t[2];

		vRs.push_back(mR);
		vKs.push_back(mK);
		vts.push_back(mt);
		vfx_1.push_back(1/vCams[k].fx);
		vfy_1.push_back(1/vCams[k].fy);

		double fx = vCams[k].fx;
		double fy = vCams[k].fy;
		double cx = vCams[k].cx;
		double cy = vCams[k].cy;
		double fx_1 = vfx_1[k];
		double fy_1 = vfy_1[k];
		double f=(fx+fy)*0.5;
		double tana_f = tana/f;

		double depth_min;
		double depth_max;

		for (jj=0;jj<n_cloud;jj++)
		{
			Matx31d mX;

			mX(0) = clouds[jj].m_pt.x;
			mX(1) = clouds[jj].m_pt.y;
			mX(2) = clouds[jj].m_pt.z;

			mX = mR*mX+mt;

			double depth = mX(2);

			if (jj == 0)
			{
				depth_min = depth;
				depth_max = depth;
			} 
			else
			{
				if (depth<depth_min)
				{
					depth_min = depth;
				}
				if (depth>depth_max)
				{
					depth_max = depth;
				}
			}
		}

		double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

		double depth_ext = (depth_max-depth_min)*ratio_ext;

		depth_max += depth_ext;

		double tmp = depth_min - depth_ext;

		if (tmp<0)
		{
			depth_min = 0;
		} 
		else
		{
			depth_min = tmp;
		}

		double hx_max = tana_f * depth_max;

		vDepth_max.push_back(depth_max);
		vDepth_min.push_back(depth_min);
		vH_max.push_back(hx_max);
	}

	// 20140728, calculate the angle weights between every image pair
	vector<vector<double>> mWeights;
	for (i=0;i<nImg;i++)
	{
		vector<double> vw;

		Matx33d mRi = vRs[i];
		
		for (j=0;j<nImg;j++)
		{
			if (i==j)
			{
				vw.push_back(0);
				continue;
			}
			if (i>j)
			{
				vw.push_back(mWeights[j][i]);
			}
			else
			{
				Matx33d mRj = vRs[j];

				// compute the relative pose
				Matx33d mRij = mRi*mRj.t();
				// compute the angle between optical axes and the distance between optical centers
				double angle = GetAngleBetweenOpticalAxes_Angle(mRij);

				vw.push_back(exp_miu_sigma(angle, miu_angle, sigma_angle));
			}
		}

		mWeights.push_back(vw);
	}

	CString strInfo;

	// initialize all depth, hx, hy maps randomly
	for (k=0;k<nImg;k++)
	{
		Mat mDepth, mHx, mHy, mScore(imgHeight, imgWidth, CV_32FC1), mVisi(imgHeight, imgWidth, CV_8UC1),  mVisiN(imgHeight, imgWidth, CV_8UC1);
		InitRndField(vKs[k], vRs[k], vts[k], clouds, angLimit, imgWidth, imgHeight, mDepth, mHx, mHy);
		vDepths.push_back(mDepth);
		vHxs.push_back(mHx);
		vHys.push_back(mHy);

		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial depth map ref %02d.txt", k);
		FILE * file_depth = fopen(strInfo, "w");
		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial hx map ref %02d.txt", k);
		FILE * file_hx = fopen(strInfo, "w");
		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial hy map ref %02d.txt", k);
		FILE * file_hy = fopen(strInfo, "w");
		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial score map ref %02d.txt", k);
		FILE * file_score = fopen(strInfo, "w");
		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial visi map ref %02d.txt", k);
		FILE * file_visi = fopen(strInfo, "w");
		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial visiN map ref %02d.txt", k);
		FILE * file_visiN = fopen(strInfo, "w");	

		// at the same time evaluate all parameters
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("evaluate row %04d of image %02d", i, k);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				int i_real, j_real, nVisi;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				double depth = vDepths[k].at<float>(i,j);
				double hx = vHxs[k].at<float>(i,j);
				double hy = vHys[k].at<float>(i,j);

				vector<double> vnccs,vangs;
//				CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth,hx,hy,vnccs,size, thresh_angle);
				CheckOnePixel_givenOneParamSet_outputAngles(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth,hx,hy,vnccs,vangs,size);

//				mScore.at<float>(i,j) = GetScore(vnccs, thresh_ncc, mincams, &nVisi);
//				mScore.at<float>(i,j) = GetScore_angleWeighted(vnccs, mWeights[k], thresh_ncc, mincams, &nVisi);
//				mScore.at<float>(i,j) = GetScore_allWeighted(vnccs, vangs, mWeights[k], thresh_ncc, thresh_angle, &nVisi);
				vector<double> vtmp;
				mScore.at<float>(i,j) = GetScore_allWeighted(vnccs, vangs, mWeights[k], vtmp, thresh_ncc, thresh_angle, &nVisi);

				mVisi.at<uchar>(i,j) = GetVisibilityVector_uchar(vnccs, thresh_ncc);
				mVisiN.at<uchar>(i,j) = (uchar)nVisi;

				fprintf(file_depth, "%.12f	", mDepth.at<float>(i,j));
				fprintf(file_hx, "%.12f	", mHx.at<float>(i,j));
				fprintf(file_hy, "%.12f	", mHy.at<float>(i,j));
				fprintf(file_score, "%.12f	", mScore.at<float>(i,j));
				fprintf(file_visi, "%d	", mVisi.at<uchar>(i,j));
				fprintf(file_visiN, "%d	", mVisiN.at<uchar>(i,j));
			}
			fprintf(file_depth, "\n");
			fprintf(file_hx, "\n");
			fprintf(file_hy, "\n");
			fprintf(file_score, "\n");
			fprintf(file_visi, "\n");
			fprintf(file_visiN, "\n");
		}

		vScores.push_back(mScore);
		vVisis.push_back(mVisi);
		vVisiNs.push_back(mVisiN);

		fclose(file_depth);
		fclose(file_hx);
		fclose(file_hy);
		fclose(file_score);
		fclose(file_visi);
		fclose(file_visiN);

		// 		Mat mDepth(imgHeight, imgWidth, CV_32FC1), mHx(imgHeight, imgWidth, CV_32FC1), mHy(imgHeight, imgWidth, CV_32FC1), mScore(imgHeight, imgWidth, CV_32FC1),
		// 			mVisi(imgHeight, imgWidth, CV_8UC1),  mVisiN(imgHeight, imgWidth, CV_8UC1);
		// 		
		// 		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial depth map ref %02d.txt", k);
		// //		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\final PatchMatch depth map ref %02d.txt", k);
		// 		FILE * file_depth = fopen(strInfo, "r");
		// 		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial hx map ref %02d.txt", k);
		// //		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\final PatchMatch hx map ref %02d.txt", k);
		// 		FILE * file_hx = fopen(strInfo, "r");
		// 		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial hy map ref %02d.txt", k);
		// //		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\final PatchMatch hy map ref %02d.txt", k);
		// 		FILE * file_hy = fopen(strInfo, "r");
		// 		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial score map ref %02d.txt", k);
		// //		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\final PatchMatch score map ref %02d.txt", k);
		// 		FILE * file_score = fopen(strInfo, "r");
		// 		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial visi map ref %02d.txt", k);
		// //		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\final PatchMatch visi map ref %02d.txt", k);
		// 		FILE * file_visi = fopen(strInfo, "r");
		// 		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial visiN map ref %02d.txt", k);
		// //		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\final PatchMatch visiN map ref %02d.txt", k);
		// 		FILE * file_visiN = fopen(strInfo, "r");	
		// 
		// 		// at the same time evaluate all parameters
		// 		for (i=0;i<imgHeight;i++)
		// 		{
		// 			for (j=0;j<imgWidth;j++)
		// 			{
		// 				double depth,hx,hy,score;
		// 				int tmp;
		// 				fscanf(file_depth, "%lf	", &depth);
		// 				fscanf(file_hx, "%lf	", &hx);
		// 				fscanf(file_hy, "%lf	", &hy);
		// 				fscanf(file_score, "%lf	", &score);
		// 
		// 				mDepth.at<float>(i,j) = depth;
		// 				mHx.at<float>(i,j) = hx;
		// 				mHy.at<float>(i,j) = hy;
		// 				mScore.at<float>(i,j) = score;
		// 
		// 				fscanf(file_visi, "%d	", &tmp);
		// 				mVisi.at<uchar>(i,j) = (uchar)tmp;
		// 				fscanf(file_visiN, "%d	", &tmp);
		// 				mVisiN.at<uchar>(i,j) = (uchar)tmp;
		// 			}
		// 		}
		// 		fclose(file_depth);
		// 		fclose(file_hx);
		// 		fclose(file_hy);
		// 		fclose(file_score);
		// 		fclose(file_visi);
		// 		fclose(file_visiN);
		// 
		// 		vDepths.push_back(mDepth);
		// 		vHxs.push_back(mHx);
		// 		vHys.push_back(mHy);
		// 		vScores.push_back(mScore);
		// 		vVisis.push_back(mVisi);
		// 		vVisiNs.push_back(mVisiN);
	}

	// start propagation
	for (ii=0;ii<maxIter;ii++)
	{
		if (ii%2 == 0)
		{
			for (k=0;k<nImg;k++)
			{
				// determine the sampling ranges of all parameters //////////////////////////////////////////////////////////////////////////
				double fx = vKs[k](0,0);
				double fy = vKs[k](1,1);
				double cx = vKs[k](0,2);
				double cy = vKs[k](1,2);
				double fx_1 = vfx_1[k];
				double fy_1 = vfy_1[k];
				double f=(fx+fy)*0.5;
				double tana_f = tana/f;

				double depth_max = vDepth_max[k];
				double depth_min = vDepth_min[k];
				double hx_max = vH_max[k];

				double d_range = depth_max - depth_min;
				double h_range = 2*hx_max;
				//////////////////////////////////////////////////////////////////////////


				for (i=0;i<imgHeight;i++)
				{
					strInfo.Format("evaluate row %04d of image %02d in iteration %02d", i, k, ii);
					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

					double nimgy = (i-cy)*fy_1;

					for (j=0;j<imgWidth;j++)
					{
						int i_real, j_real, nVisi;
						MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

						// normalized image point, i.e. the direction
						double nimgx = (j-cx)*fx_1;

						vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
						vector<double> vScores_candidates;
						vector<uchar> vVisi_candidates;
						vector<int> vVisiN_candidates;

						// first evaluate current parameter set for (i,j)
						double depth0 = vDepths[k].at<float>(i,j);
						double hx0 = vHxs[k].at<float>(i,j);
						double hy0 = vHys[k].at<float>(i,j);
						double score0 = vScores[k].at<float>(i,j);
						uchar visi0 = vVisis[k].at<uchar>(i,j);
						uchar visiN0 = vVisiNs[k].at<uchar>(i,j);

						vScores_candidates.push_back(score0);
						vVisi_candidates.push_back(visi0);
						vVisiN_candidates.push_back(visiN0);
						vDepths_candidates.push_back(depth0);
						vHx_candidates.push_back(hx0);
						vHy_candidates.push_back(hy0);

						if (j-1>=0) // means that there is a left neighbor
						{
							double hx_left = vHxs[k].at<float>(i,j-1);
							double hy_left = vHys[k].at<float>(i,j-1);
							double depth_left = vDepths[k].at<float>(i,j-1)/*+hx_left*/; // add the corresponding depth gradient of the left pixel

							vector<double> vScores_left,vAngs_left;
							//							CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, k, j_real,i_real,depth_left,hx_left,hy_left,vScores_left,size);
//							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_left,hx_left,hy_left,vScores_left,size,thresh_angle);
							CheckOnePixel_givenOneParamSet_outputAngles(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_left,hx_left,hy_left,vScores_left,vAngs_left,size);

//							vScores_candidates.push_back(GetScore(vScores_left, thresh_ncc, mincams, &nVisi));
//							vScores_candidates.push_back(GetScore_angleWeighted(vScores_left, mWeights[k], thresh_ncc, mincams, &nVisi));
							vScores_candidates.push_back(GetScore_allWeighted(vScores_left, vAngs_left, mWeights[k], thresh_ncc, thresh_angle, &nVisi));

							vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_left, thresh_ncc));
							vVisiN_candidates.push_back(nVisi);
							vDepths_candidates.push_back(depth_left);
							vHx_candidates.push_back(hx_left);
							vHy_candidates.push_back(hy_left);
						}

						if (i-1>=0) // means that there is a upper neighbor
						{
							double hx_upper = vHxs[k].at<float>(i-1,j);
							double hy_upper = vHys[k].at<float>(i-1,j);
							double depth_upper = vDepths[k].at<float>(i-1,j)/*+hy_upper*/;

							vector<double> vScores_upper,vAngs_upper;
							//							CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, k, j_real,i_real,depth_upper,hx_upper,hy_upper,vScores_upper,size);
//							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_upper,hx_upper,hy_upper,vScores_upper,size,thresh_angle);
							CheckOnePixel_givenOneParamSet_outputAngles(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_upper,hx_upper,hy_upper,vScores_upper,vAngs_upper,size);

//							vScores_candidates.push_back(GetScore(vScores_upper, thresh_ncc, mincams, &nVisi));
//							vScores_candidates.push_back(GetScore_angleWeighted(vScores_upper, mWeights[k], thresh_ncc, mincams, &nVisi));
							vScores_candidates.push_back(GetScore_allWeighted(vScores_upper, vAngs_upper, mWeights[k], thresh_ncc, thresh_angle, &nVisi));

							vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_upper, thresh_ncc));
							vVisiN_candidates.push_back(nVisi);
							vDepths_candidates.push_back(depth_upper);
							vHx_candidates.push_back(hx_upper);
							vHy_candidates.push_back(hy_upper);
						}

						vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						double max_score = *iterDouble;
						int idx_max_score = iterDouble - vScores_candidates.begin();

						double depth_possible = vDepths_candidates[idx_max_score];
						double hx_possible = vHx_candidates[idx_max_score];
						double hy_possible = vHy_candidates[idx_max_score];
						uchar visi_possible = vVisi_candidates[idx_max_score];
						int visiN_possible = vVisiN_candidates[idx_max_score];
						double score_possible = max_score;

						vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear(); vVisi_candidates.clear(); vVisiN_candidates.clear();

						vScores_candidates.push_back(score_possible);
						vVisi_candidates.push_back(visi_possible);
						vVisiN_candidates.push_back(visiN_possible);
						vDepths_candidates.push_back(depth_possible);
						vHx_candidates.push_back(hx_possible);
						vHy_candidates.push_back(hy_possible);

						for (rk=0;rk<nRandSamp;rk++)
						{
							double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
							if (rk==0)
							{
								d_max_k = depth_max;
								d_min_k = depth_min;
								hx_max_k = hx_max;
								hx_min_k = -hx_max;
								hy_max_k = hx_max;
								hy_min_k = -hx_max;
							}
							else
							{
								double factor_k = pow(factor, rk);
								double d_r = factor_k*d_range*0.5;
								double h_r = factor_k*h_range*0.5;
								DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
								DetermineInterval(hx_max, -hx_max, hx_possible, h_r, hx_max_k, hx_min_k);
								DetermineInterval(hx_max, -hx_max, hy_possible, h_r, hy_max_k, hy_min_k);
							}

							// generate current parameter set
							double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
							double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
							double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

							vector<double> vScores_k,vAngs_k;
							//							CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, k, j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size);
//							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size,thresh_angle);
							CheckOnePixel_givenOneParamSet_outputAngles(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_k,hx_k,hy_k,vScores_k,vAngs_k,size);

//							vScores_candidates.push_back(GetScore(vScores_k, thresh_ncc, mincams, &nVisi));
//							vScores_candidates.push_back(GetScore_angleWeighted(vScores_k, mWeights[k], thresh_ncc, mincams, &nVisi));
							vScores_candidates.push_back(GetScore_allWeighted(vScores_k, vAngs_k, mWeights[k], thresh_ncc, thresh_angle, &nVisi));

							vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_k, thresh_ncc));
							vVisiN_candidates.push_back(nVisi);
							vDepths_candidates.push_back(depth_k);
							vHx_candidates.push_back(hx_k);
							vHy_candidates.push_back(hy_k);
						}

						iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						max_score = *iterDouble;
						idx_max_score = iterDouble - vScores_candidates.begin();

						double d   = vDepths[k].at<float>(i,j) = vDepths_candidates[idx_max_score];
						double hx  = vHxs[k].at<float>(i,j) = vHx_candidates[idx_max_score];
						double hy  = vHys[k].at<float>(i,j) = vHy_candidates[idx_max_score];
						uchar visi = vVisis[k].at<uchar>(i,j) = vVisi_candidates[idx_max_score];
						vVisiNs[k].at<uchar>(i,j) = (uchar)vVisiN_candidates[idx_max_score];
						vScores[k].at<float>(i,j) = max_score;

						// propagate current parameters to all matched pixels in other images, if they are better than their current guess then adopt it.
						// get the 3D coordinates of the point associated with current pixel
						Matx31d pt3d = GetXYZ_givenDepth(vRs[k], vts[k], nimgx, nimgy, d);
						// get the normal of current obtained parameters
						Matx31d mn0; mn0(2)=1;
						get_normal_givendrhxhy(fx, fy, nimgx, nimgy, d, hx, hy, mn0(0), mn0(1));
						Matx31d mnw = vRs[k].t()*mn0; // convert the normal into world coordinate system
						vector<bool> vbools;
						InterpVisiVector_uchar(visi, vbools);
						for (kk=0;kk<nImg;kk++)
						{
							if (!vbools[kk]){continue;}

							double fx_kk = vKs[kk](0,0); double fy_kk = vKs[kk](1,1); 
							double cx_kk = vKs[kk](0,2); double cy_kk = vKs[kk](1,2); 
							double fx_kk_1 = vfx_1[kk];  double fy_kk_1 = vfy_1[kk];

							// get the patch normal in kk image
							Matx31d mnkk = vRs[kk]*mnw;

							Matx31d pt3d_proj = vRs[kk]*pt3d+vts[kk];

							Matx31d imgpt = vKs[kk]*pt3d_proj;
							double zk_1 = 1/imgpt(2);
							double xk = imgpt(0)*zk_1;
							double yk = imgpt(1)*zk_1;

							if (xk<0||xk>(imgWidth-1)||yk<0||yk>(imgHeight-1)){continue;}

							int xk_int = int(xk+0.5);
							int yk_int = int(yk+0.5);

							int xk_real, yk_real;
							MakeSureNotOutBorder(xk_int,yk_int,xk_real,yk_real,wndSizeHalf,imgWidth,imgHeight);

							double u_kk = 0; double v_kk = 0; double d_kk = pt3d_proj(2);
							optim_gn_uvrou_initialdk(vKs[k], vRs[k], vts[k], vKs[kk], vRs[kk], vts[kk], d, hx, hy, j, i, xk_int, yk_int, u_kk, v_kk, d_kk);

							// if the propagated d_kk is out of range then continue
							if (d_kk<vDepth_min[kk]||d_kk>vDepth_max[kk]){continue;}

							double nimgx_kk = (xk_int-cx_kk)*fx_kk_1;
							double nimgy_kk = (yk_int-cy_kk)*fy_kk_1;

							double hx_kk, hy_kk;
							get_hxhy_givendrnormal(fx_kk, fy_kk, nimgx_kk, nimgy_kk, d_kk, mnkk, hx_kk, hy_kk);

							// if the propagated hx_kk hy_kk is out of range then continue
							if (fabs(hx_kk)>vH_max[kk]||fabs(hy_kk)>vH_max[kk]){continue;}

							vector<double> vScores_kk,vAngs_kk;
							//							CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, kk, xk_real, yk_real, d_kk, hx_kk, hy_kk, vScores_kk, size);
//							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs,kk,xk_real,yk_real,d_kk,hx_kk,hy_kk,vScores_kk,size,thresh_angle);
							CheckOnePixel_givenOneParamSet_outputAngles(vKs, vRs, vts, vfx_1, vfy_1, vImgs,kk,xk_real,yk_real,d_kk,hx_kk,hy_kk,vScores_kk,vAngs_kk,size);

//							double score_new = GetScore(vScores_kk, thresh_ncc, mincams, &nVisi);
//							double score_new = GetScore_angleWeighted(vScores_kk, mWeights[kk], thresh_ncc, mincams, &nVisi);
							double score_new = GetScore_allWeighted(vScores_kk, vAngs_kk, mWeights[kk], thresh_ncc, thresh_angle, &nVisi);

							double score_old = vScores[kk].at<float>(yk_int,xk_int);
							if (score_new>score_old)
							{
								vDepths[kk].at<float>(yk_int,xk_int) = d_kk;
								vHxs[kk].at<float>(yk_int,xk_int) = hx_kk;
								vHys[kk].at<float>(yk_int,xk_int) = hy_kk;
								vVisis[kk].at<uchar>(yk_int,xk_int) = GetVisibilityVector_uchar(vScores_kk, thresh_ncc);
								vVisiNs[kk].at<uchar>(yk_int,xk_int) = (uchar)nVisi;
								vScores[kk].at<float>(yk_int,xk_int) = score_new;
							}
						}
					}
				}

				double maxncc_minncc_1 = 1/(1-thresh_ncc);
				// output runtime info
				for (kk=0;kk<nImg;kk++)
				{
					Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3), mVisiN_map(imgHeight, imgWidth, CV_8UC3);

					double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

					minMaxIdx(vDepths[kk], &min_depth, &max_depth);
					minMaxIdx(vHxs[kk], &min_incre_x, &max_incre_x);
					minMaxIdx(vHys[kk], &min_incre_y, &max_incre_y);

					vDepths[kk].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
					vHxs[kk].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
					vHys[kk].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

					for (i=0;i<imgHeight;i++)
					{
						for (j=0;j<imgWidth;j++)
						{
							if (vScores[kk].at<float>(i,j)<0)
							{
								mScore_map.at<Vec3b>(i,j).val[0] = 0;
								mScore_map.at<Vec3b>(i,j).val[1] = 0;
								mScore_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else
							{
								mScore_map.at<Vec3b>(i,j).val[0] = 0;
								mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*(vScores[kk].at<float>(i,j)-thresh_ncc)*maxncc_minncc_1);
								mScore_map.at<Vec3b>(i,j).val[2] = 0;
							}

							uchar nnn = vVisiNs[kk].at<uchar>(i,j);

							if (nnn==0)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==1)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==2)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==3)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
							}
							else
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
							}
						}
					}

					strInfo.Format("D:\\all\\depth map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mDepth_map);
					strInfo.Format("D:\\all\\hx map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mHx_map);
					strInfo.Format("D:\\all\\hy map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mHy_map);
					strInfo.Format("D:\\all\\score map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mScore_map);
					strInfo.Format("D:\\all\\visi map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), vVisis[kk]);
					strInfo.Format("D:\\all\\visiN map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mVisiN_map);

					Mat mNormColor;
					GetNormColorField(vCams[kk], vDepths[kk], vHxs[kk], vHys[kk], mNormColor);
					strInfo.Format("D:\\all\\normcolor map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mNormColor);

					strInfo.Format("D:\\all\\cloud points iteration %02d ref %02d img %02d.txt", ii, k, kk);
					/*WriteDepthMap(strInfo,vCams[kk],vImgs[kk],vDepths[kk],vScores[kk]);*/
					OutputPointCloud(strInfo,vCams[kk],vImgs[kk],vDepths[kk],vHxs[kk],vHys[kk],vScores[kk]);
				}

				// 				if (ii==0&&k==1)
				// 				{
				// 					break;
				// 				}
			}
		} 
		else
		{
			for (k=(nImg-1);k>=0;k--)
			{
				// determine the sampling ranges of all parameters //////////////////////////////////////////////////////////////////////////
				double fx = vKs[k](0,0);
				double fy = vKs[k](1,1);
				double cx = vKs[k](0,2);
				double cy = vKs[k](1,2);
				double fx_1 = vfx_1[k];
				double fy_1 = vfy_1[k];
				double f=(fx+fy)*0.5;
				double tana_f = tana/f;

				double depth_max = vDepth_max[k];
				double depth_min = vDepth_min[k];
				double hx_max = vH_max[k];

				double d_range = depth_max - depth_min;
				double h_range = 2*hx_max;
				//////////////////////////////////////////////////////////////////////////


				for (i=imgHeight-1;i>=0;i--)
				{
					strInfo.Format("evaluate row %04d of image %02d in iteration %02d", i, k, ii);
					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

					double nimgy = (i-cy)*fy_1;

					for (j=imgWidth-1;j>=0;j--)
					{
						int i_real, j_real, nVisi;
						MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

						// normalized image point, i.e. the direction
						double nimgx = (j-cx)*fx_1;

						vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
						vector<double> vScores_candidates;
						vector<uchar> vVisi_candidates;
						vector<int> vVisiN_candidates;

						// first evaluate current parameter set for (i,j)
						double depth0 = vDepths[k].at<float>(i,j);
						double hx0 = vHxs[k].at<float>(i,j);
						double hy0 = vHys[k].at<float>(i,j);
						double score0 = vScores[k].at<float>(i,j);
						uchar visi0 = vVisis[k].at<uchar>(i,j);
						uchar visiN0 = vVisiNs[k].at<uchar>(i,j);

						vScores_candidates.push_back(score0);
						vVisi_candidates.push_back(visi0);
						vVisiN_candidates.push_back(visiN0);
						vDepths_candidates.push_back(depth0);
						vHx_candidates.push_back(hx0);
						vHy_candidates.push_back(hy0);

						if (j+1<imgWidth) // means that there is a right neighbor
						{
							double hx_right = vHxs[k].at<float>(i,j+1);
							double hy_right = vHys[k].at<float>(i,j+1);
							double depth_right = vDepths[k].at<float>(i,j+1)/*-hx_right*/;

							vector<double> vScores_right,vAngs_right;
							//							CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, k, j_real,i_real,depth_right,hx_right,hy_right,vScores_right,size);
//							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_right,hx_right,hy_right,vScores_right,size,thresh_angle);
							CheckOnePixel_givenOneParamSet_outputAngles(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_right,hx_right,hy_right,vScores_right,vAngs_right,size);

//							vScores_candidates.push_back(GetScore(vScores_right, thresh_ncc, mincams, &nVisi));
//							vScores_candidates.push_back(GetScore_angleWeighted(vScores_right, mWeights[k], thresh_ncc, mincams, &nVisi));
							vScores_candidates.push_back(GetScore_allWeighted(vScores_right, vAngs_right, mWeights[k], thresh_ncc, thresh_angle, &nVisi));

							vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_right, thresh_ncc));
							vVisiN_candidates.push_back(nVisi);
							vDepths_candidates.push_back(depth_right);
							vHx_candidates.push_back(hx_right);
							vHy_candidates.push_back(hy_right);
						}

						if (i+1<imgHeight) // means that there is a lower neighbor
						{
							double hx_lower = vHxs[k].at<float>(i+1,j);
							double hy_lower = vHys[k].at<float>(i+1,j);
							double depth_lower = vDepths[k].at<float>(i+1,j)/*-hy_lower*/;

							vector<double> vScores_lower,vAngs_lower;
							//							CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, k, j_real,i_real,depth_lower,hx_lower,hy_lower,vScores_lower,size);
//							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_lower,hx_lower,hy_lower,vScores_lower,size,thresh_angle);
							CheckOnePixel_givenOneParamSet_outputAngles(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_lower,hx_lower,hy_lower,vScores_lower,vAngs_lower,size);

//							vScores_candidates.push_back(GetScore(vScores_lower, thresh_ncc, mincams, &nVisi));
//							vScores_candidates.push_back(GetScore_angleWeighted(vScores_lower, mWeights[k], thresh_ncc, mincams, &nVisi));
							vScores_candidates.push_back(GetScore_allWeighted(vScores_lower, vAngs_lower, mWeights[k], thresh_ncc, thresh_angle, &nVisi));

							vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_lower, thresh_ncc));
							vVisiN_candidates.push_back(nVisi);
							vDepths_candidates.push_back(depth_lower);
							vHx_candidates.push_back(hx_lower);
							vHy_candidates.push_back(hy_lower);
						}

						vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						double max_score = *iterDouble;
						int idx_max_score = iterDouble - vScores_candidates.begin();

						double depth_possible = vDepths_candidates[idx_max_score];
						double hx_possible = vHx_candidates[idx_max_score];
						double hy_possible = vHy_candidates[idx_max_score];
						uchar visi_possible = vVisi_candidates[idx_max_score];
						int visiN_possible = vVisiN_candidates[idx_max_score];
						double score_possible = max_score;

						vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear(); vVisi_candidates.clear(); vVisiN_candidates.clear();

						vScores_candidates.push_back(score_possible);
						vVisi_candidates.push_back(visi_possible);
						vVisiN_candidates.push_back(visiN_possible);
						vDepths_candidates.push_back(depth_possible);
						vHx_candidates.push_back(hx_possible);
						vHy_candidates.push_back(hy_possible);

						for (rk=0;rk<nRandSamp;rk++)
						{
							double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
							if (rk==0)
							{
								d_max_k = depth_max;
								d_min_k = depth_min;
								hx_max_k = hx_max;
								hx_min_k = -hx_max;
								hy_max_k = hx_max;
								hy_min_k = -hx_max;
							}
							else
							{
								double factor_k = pow(factor, rk);
								double d_r = factor_k*d_range*0.5;
								double h_r = factor_k*h_range*0.5;
								DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
								DetermineInterval(hx_max, -hx_max, hx_possible, h_r, hx_max_k, hx_min_k);
								DetermineInterval(hx_max, -hx_max, hy_possible, h_r, hy_max_k, hy_min_k);
							}

							// generate current parameter set
							double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
							double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
							double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

							vector<double> vScores_k,vAngs_k;
							//							CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, k, j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size);
//							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size,thresh_angle);
							CheckOnePixel_givenOneParamSet_outputAngles(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_k,hx_k,hy_k,vScores_k,vAngs_k,size);

//							vScores_candidates.push_back(GetScore(vScores_k, thresh_ncc, mincams, &nVisi));
//							vScores_candidates.push_back(GetScore_angleWeighted(vScores_k, mWeights[k], thresh_ncc, mincams, &nVisi));
							vScores_candidates.push_back(GetScore_allWeighted(vScores_k, vAngs_k, mWeights[k], thresh_ncc, thresh_angle, &nVisi));

							vVisi_candidates.push_back(GetVisibilityVector_uchar(vScores_k, thresh_ncc));
							vVisiN_candidates.push_back(nVisi);
							vDepths_candidates.push_back(depth_k);
							vHx_candidates.push_back(hx_k);
							vHy_candidates.push_back(hy_k);
						}

						iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						max_score = *iterDouble;
						idx_max_score = iterDouble - vScores_candidates.begin();

						double d   = vDepths[k].at<float>(i,j) = vDepths_candidates[idx_max_score];
						double hx  = vHxs[k].at<float>(i,j) = vHx_candidates[idx_max_score];
						double hy  = vHys[k].at<float>(i,j) = vHy_candidates[idx_max_score];
						uchar visi = vVisis[k].at<uchar>(i,j) = vVisi_candidates[idx_max_score];
						vVisiNs[k].at<uchar>(i,j) = (uchar)vVisiN_candidates[idx_max_score];
						vScores[k].at<float>(i,j) = max_score;

						// propagate current parameters to all matched pixels in other images, if they are better than their current guess then adopt it.
						// get the 3D coordinates of the point associated with current pixel
						Matx31d pt3d = GetXYZ_givenDepth(vRs[k], vts[k], nimgx, nimgy, d);
						// get the normal of current obtained parameters
						Matx31d mn0; mn0(2)=1;
						get_normal_givendrhxhy(fx, fy, nimgx, nimgy, d, hx, hy, mn0(0), mn0(1));
						Matx31d mnw = vRs[k].t()*mn0; // convert the normal into world coordinate system
						vector<bool> vbools;
						InterpVisiVector_uchar(visi, vbools);
						for (kk=0;kk<nImg;kk++)
						{
							if (!vbools[kk]){continue;}

							double fx_kk = vKs[kk](0,0); double fy_kk = vKs[kk](1,1); 
							double cx_kk = vKs[kk](0,2); double cy_kk = vKs[kk](1,2); 
							double fx_kk_1 = vfx_1[kk];  double fy_kk_1 = vfy_1[kk];

							// get the patch normal in kk image
							Matx31d mnkk = vRs[kk]*mnw;

							Matx31d pt3d_proj = vRs[kk]*pt3d+vts[kk];

							Matx31d imgpt = vKs[kk]*pt3d_proj;
							double zk_1 = 1/imgpt(2);
							double xk = imgpt(0)*zk_1;
							double yk = imgpt(1)*zk_1;

							if (xk<0||xk>(imgWidth-1)||yk<0||yk>(imgHeight-1)){continue;}

							int xk_int = int(xk+0.5);
							int yk_int = int(yk+0.5);

							int xk_real, yk_real;
							MakeSureNotOutBorder(xk_int,yk_int,xk_real,yk_real,wndSizeHalf,imgWidth,imgHeight);

							double u_kk = 0; double v_kk = 0; double d_kk = pt3d_proj(2);
							optim_gn_uvrou_initialdk(vKs[k], vRs[k], vts[k], vKs[kk], vRs[kk], vts[kk], d, hx, hy, j, i, xk_int, yk_int, u_kk, v_kk, d_kk);

							// if the propagated d_kk is out of range then continue
							if (d_kk<vDepth_min[kk]||d_kk>vDepth_max[kk]){continue;}

							double nimgx_kk = (xk_int-cx_kk)*fx_kk_1;
							double nimgy_kk = (yk_int-cy_kk)*fy_kk_1;

							double hx_kk, hy_kk;
							get_hxhy_givendrnormal(fx_kk, fy_kk, nimgx_kk, nimgy_kk, d_kk, mnkk, hx_kk, hy_kk);

							// if the propagated hx_kk hy_kk is out of range then continue
							if (fabs(hx_kk)>vH_max[kk]||fabs(hy_kk)>vH_max[kk]){continue;}

							vector<double> vScores_kk,vAngs_kk;
							//							CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, kk, xk_real, yk_real, d_kk, hx_kk, hy_kk, vScores_kk, size);
//							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, kk, xk_real, yk_real, d_kk, hx_kk, hy_kk, vScores_kk, size, thresh_angle);
							CheckOnePixel_givenOneParamSet_outputAngles(vKs, vRs, vts, vfx_1, vfy_1, vImgs, kk, xk_real, yk_real, d_kk, hx_kk, hy_kk, vScores_kk, vAngs_kk, size);

//							double score_new = GetScore(vScores_kk, thresh_ncc, mincams, &nVisi);
//							double score_new = GetScore_angleWeighted(vScores_kk, mWeights[kk], thresh_ncc, mincams, &nVisi);
							double score_new = GetScore_allWeighted(vScores_kk, vAngs_kk, mWeights[kk], thresh_ncc, thresh_angle, &nVisi);

							double score_old = vScores[kk].at<float>(yk_int,xk_int);
							if (score_new>score_old)
							{
								vDepths[kk].at<float>(yk_int,xk_int) = d_kk;
								vHxs[kk].at<float>(yk_int,xk_int) = hx_kk;
								vHys[kk].at<float>(yk_int,xk_int) = hy_kk;
								vVisis[kk].at<uchar>(yk_int,xk_int) = GetVisibilityVector_uchar(vScores_kk, thresh_ncc);
								vVisiNs[kk].at<uchar>(yk_int,xk_int) = (uchar)nVisi;
								vScores[kk].at<float>(yk_int,xk_int) = score_new;
							}
						}
					}
				}

				double maxncc_minncc_1 = 1/(1-thresh_ncc);
				// output runtime info
				for (kk=0;kk<nImg;kk++)
				{
					Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3), mVisiN_map(imgHeight, imgWidth, CV_8UC3);

					double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

					minMaxIdx(vDepths[kk], &min_depth, &max_depth);
					minMaxIdx(vHxs[kk], &min_incre_x, &max_incre_x);
					minMaxIdx(vHys[kk], &min_incre_y, &max_incre_y);

					vDepths[kk].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
					vHxs[kk].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
					vHys[kk].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

					for (i=0;i<imgHeight;i++)
					{
						for (j=0;j<imgWidth;j++)
						{
							if (vScores[kk].at<float>(i,j)<0)
							{
								mScore_map.at<Vec3b>(i,j).val[0] = 0;
								mScore_map.at<Vec3b>(i,j).val[1] = 0;
								mScore_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else
							{
								mScore_map.at<Vec3b>(i,j).val[0] = 0;
								mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*(vScores[kk].at<float>(i,j)-thresh_ncc)*maxncc_minncc_1);
								mScore_map.at<Vec3b>(i,j).val[2] = 0;
							}

							uchar nnn = vVisiNs[kk].at<uchar>(i,j);

							if (nnn==0)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==1)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==2)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==3)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
							}
							else
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
							}
						}
					}

					strInfo.Format("D:\\all\\depth map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mDepth_map);
					strInfo.Format("D:\\all\\hx map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mHx_map);
					strInfo.Format("D:\\all\\hy map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mHy_map);
					strInfo.Format("D:\\all\\score map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mScore_map);
					strInfo.Format("D:\\all\\visi map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), vVisis[kk]);
					strInfo.Format("D:\\all\\visiN map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mVisiN_map);

					Mat mNormColor;
					GetNormColorField(vCams[kk], vDepths[kk], vHxs[kk], vHys[kk], mNormColor);
					strInfo.Format("D:\\all\\normcolor map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mNormColor);

					strInfo.Format("D:\\all\\cloud points iteration %02d ref %02d img %02d.txt", ii, k, kk);
					/*WriteDepthMap(strInfo,vCams[kk],vImgs[kk],vDepths[kk],vScores[kk]);*/
					OutputPointCloud(strInfo,vCams[kk],vImgs[kk],vDepths[kk],vHxs[kk],vHys[kk],vScores[kk]);
				}
			}
		}

		// 		if (ii==0&&k==1)
		// 		{
		// 			break;
		// 		}
	}

	for (k=0;k<nImg;k++)
	{
		strInfo.Format("D:\\all\\final PatchMatch depth map ref %02d.txt", k);
		FILE * file_depth = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch hx map ref %02d.txt", k);
		FILE * file_hx = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch hy map ref %02d.txt", k);
		FILE * file_hy = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch score map ref %02d.txt", k);
		FILE * file_score = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch visi map ref %02d.txt", k);
		FILE * file_visi = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch visiN map ref %02d.txt", k);
		FILE * file_visiN = fopen(strInfo, "w");	

		// at the same time evaluate all parameters
		for (i=0;i<imgHeight;i++)
		{
			for (j=0;j<imgWidth;j++)
			{
				fprintf(file_depth, "%.12f	", vDepths[k].at<float>(i,j));
				fprintf(file_hx, "%.12f	", vHxs[k].at<float>(i,j));
				fprintf(file_hy, "%.12f	", vHys[k].at<float>(i,j));
				fprintf(file_score, "%.12f	", vScores[k].at<float>(i,j));
				fprintf(file_visi, "%d	", vVisis[k].at<uchar>(i,j));
				fprintf(file_visiN, "%d	", vVisiNs[k].at<uchar>(i,j));
			}
			fprintf(file_depth, "\n");
			fprintf(file_hx, "\n");
			fprintf(file_hy, "\n");
			fprintf(file_score, "\n");
			fprintf(file_visi, "\n");
			fprintf(file_visiN, "\n");
		}
		fclose(file_depth);
		fclose(file_hx);
		fclose(file_hy);
		fclose(file_score);
		fclose(file_visi);
		fclose(file_visiN);
	}
}

// 20140802, conduct patchmatch for reference image with every support image at each time
void DeepVoid::PatchMatch_140802(const cam_data & cam0,				// input:	reference image
							     const vector<cam_data> & vCams,	// input:	all support images
							     const Mat & img0,					// input:	reference image
							     const vector<Mat> & vImgs,			// input:	all support images
							     const vector<CloudPoint> & clouds,	// input:	the cloud points
							     vector<Mat> & vDepths,				// output:	all the depth maps
							     vector<Mat> & vHxs,				// output:	all the hx maps
							     vector<Mat> & vHys,				// output:	all the hy maps
							     vector<Mat> & vScores,				// output:	all the score maps
							     int size /*= 5*/,					// input:	the window size of the image patch, should be odd number
							     double thresh_ncc /*= 0.8*/,		// input:	the threshold within which to be considered as a successful ncc
							     double angLimit/* = 80*/,			// input:	the angular range limit of the normal of every object point, in angle, not radian
							     int maxIter/* = 4*/,				// input:	maximum iteration
							     int mincams /*= 1*/,
							     double factor /*= 0.5*/,
							     int nRandSamp /*= 6*/
							     )
{
	int i,j,k,ii,jj,rk;

	vDepths.clear(); vHxs.clear(); vHys.clear(); vScores.clear();

	int nImg = vCams.size(); // the number of support images
	int n_cloud = clouds.size();
	int imgWidth = img0.cols;
	int imgHeight = img0.rows;
	int wndSizeHalf = (size-1)/2;
	double tana = tan(angLimit*D2R);

	Matx33d mR0,mK0; Matx31d mt0;

	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mR0(i,j) = cam0.R[i*3+j];
		}
	}
	mK0(0,0) = cam0.fx;	mK0(0,1) = cam0.s;  mK0(0,2) = cam0.cx;
	mK0(1,1) = cam0.fy;	mK0(1,2) = cam0.cy; mK0(2,2) = 1;
	mt0(0) = cam0.t[0];	mt0(1) = cam0.t[1]; mt0(2) = cam0.t[2];

	double fx0_1 = 1/cam0.fx;
	double fy0_1 = 1/cam0.fy;

	double f=(cam0.fx+cam0.fy)*0.5;
	double tana_f = tana/f;

	double depth_min;
	double depth_max;

	for (jj=0;jj<n_cloud;jj++)
	{
		Matx31d mX;

		mX(0) = clouds[jj].m_pt.x;
		mX(1) = clouds[jj].m_pt.y;
		mX(2) = clouds[jj].m_pt.z;

		mX = mR0*mX+mt0;

		double depth = mX(2);

		if (jj == 0)
		{
			depth_min = depth;
			depth_max = depth;
		} 
		else
		{
			if (depth<depth_min)
			{
				depth_min = depth;
			}
			if (depth>depth_max)
			{
				depth_max = depth;
			}
		}
	}

	double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

	double depth_ext = (depth_max-depth_min)*ratio_ext;

	depth_max += depth_ext;

	double tmp = depth_min - depth_ext;

	if (tmp<0)
	{
		depth_min = 0;
	} 
	else
	{
		depth_min = tmp;
	}

	double hx_max = tana_f * depth_max;

	double d_range = depth_max - depth_min;
	double h_range = 2*hx_max;

	//////////////////////////////////////////////////////////////////////////
	vector<Matx33d> vRs,vKs; vector<Matx31d> vts; // for all support images
	vector<double> vfx_1, vfy_1; // for all support images

	for (k=0;k<nImg;k++)
	{
		Matx33d mR,mK; Matx31d mt;

		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR(i,j) = vCams[k].R[i*3+j];
			}
		}
		mK(0,0) = vCams[k].fx;	mK(0,1) = vCams[k].s;  mK(0,2) = vCams[k].cx;
		mK(1,1) = vCams[k].fy;	mK(1,2) = vCams[k].cy; mK(2,2) = 1;
		mt(0) = vCams[k].t[0];	mt(1) = vCams[k].t[1]; mt(2) = vCams[k].t[2];

		vRs.push_back(mR);
		vKs.push_back(mK);
		vts.push_back(mt);
		vfx_1.push_back(1/vCams[k].fx);
		vfy_1.push_back(1/vCams[k].fy);
	}
	//////////////////////////////////////////////////////////////////////////

	CString strInfo;
	// initialize all depth, hx, hy maps randomly
	for (k=0;k<nImg;k++)
	{
		Mat mDepth, mHx, mHy, mScore(imgHeight, imgWidth, CV_32FC1);
		InitRndField(mK0, mR0, mt0, clouds, angLimit, imgWidth, imgHeight, mDepth, mHx, mHy);
		vDepths.push_back(mDepth);
		vHxs.push_back(mHx);
		vHys.push_back(mHy);

		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial depth map with image %02d.txt", k);
		FILE * file_depth = fopen(strInfo, "w");
		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial hx map with image %02d.txt", k);
		FILE * file_hx = fopen(strInfo, "w");
		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial hy map with image %02d.txt", k);
		FILE * file_hy = fopen(strInfo, "w");
		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial score map with image %02d.txt", k);
		FILE * file_score = fopen(strInfo, "w");

		// at the same time evaluate all parameters
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("evaluate row %04d with image %02d", i, k);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				int i_real, j_real, nVisi;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				double depth = vDepths[k].at<float>(i,j);
				double hx = vHxs[k].at<float>(i,j);
				double hy = vHys[k].at<float>(i,j);

				double score, angle;
				CheckOnePixel_givenOneParamSet_oneImg(mK0,vKs[k],mR0,vRs[k],mt0,vts[k],fx0_1,vfx_1[k],fy0_1,vfy_1[k],img0,vImgs[k],j_real,i_real,depth,hx,hy,score,angle,size);

				mScore.at<float>(i,j) = score;

				fprintf(file_depth, "%.12f	", mDepth.at<float>(i,j));
				fprintf(file_hx, "%.12f	", mHx.at<float>(i,j));
				fprintf(file_hy, "%.12f	", mHy.at<float>(i,j));
				fprintf(file_score, "%.12f	", mScore.at<float>(i,j));
			}
			fprintf(file_depth, "\n");
			fprintf(file_hx, "\n");
			fprintf(file_hy, "\n");
			fprintf(file_score, "\n");
		}

		vScores.push_back(mScore);

		fclose(file_depth);
		fclose(file_hx);
		fclose(file_hy);
		fclose(file_score);

// 		Mat mDepth(imgHeight, imgWidth, CV_32FC1), mHx(imgHeight, imgWidth, CV_32FC1), mHy(imgHeight, imgWidth, CV_32FC1), mScore(imgHeight, imgWidth, CV_32FC1);
//  		
// 		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial depth map with image %02d.txt", k);
//  		FILE * file_depth = fopen(strInfo, "r");
//  		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial hx map with image %02d.txt", k);
//  		FILE * file_hx = fopen(strInfo, "r");
//  		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial hy map with image %02d.txt", k);
//  		FILE * file_hy = fopen(strInfo, "r");
//  		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial score map with image %02d.txt", k);
//  		FILE * file_score = fopen(strInfo, "r");
//  
//  		// at the same time evaluate all parameters
//  		for (i=0;i<imgHeight;i++)
//  		{
//  			for (j=0;j<imgWidth;j++)
//  			{
//  				double depth,hx,hy,score;
//  				int tmp;
//  				fscanf(file_depth, "%lf	", &depth);
//  				fscanf(file_hx, "%lf	", &hx);
//  				fscanf(file_hy, "%lf	", &hy);
//  				fscanf(file_score, "%lf	", &score);
//  
//  				mDepth.at<float>(i,j) = depth;
//  				mHx.at<float>(i,j) = hx;
//  				mHy.at<float>(i,j) = hy;
//  				mScore.at<float>(i,j) = score;
//  			}
//  		}
//  		fclose(file_depth);
//  		fclose(file_hx);
//  		fclose(file_hy);
//  		fclose(file_score);
//  
//  		vDepths.push_back(mDepth);
//  		vHxs.push_back(mHx);
//  		vHys.push_back(mHy);
//  		vScores.push_back(mScore);
	}

	// start propagation
	for (ii=0;ii<maxIter;ii++)
	{
		if (ii%2 == 0)
		{
			for (k=0;k<nImg;k++)
			{
				for (i=0;i<imgHeight;i++)
				{
					strInfo.Format("evaluate row %04d with image %02d in iteration %02d", i, k, ii);
					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

					for (j=0;j<imgWidth;j++)
					{
						int i_real, j_real, nVisi;
						MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

						vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
						vector<double> vScores_candidates;

						// first evaluate current parameter set for (i,j)
						double depth0 = vDepths[k].at<float>(i,j);
						double hx0 = vHxs[k].at<float>(i,j);
						double hy0 = vHys[k].at<float>(i,j);
						double score0 = vScores[k].at<float>(i,j);

						vScores_candidates.push_back(score0);
						vDepths_candidates.push_back(depth0);
						vHx_candidates.push_back(hx0);
						vHy_candidates.push_back(hy0);

						if (j-1>=0) // means that there is a left neighbor
						{
							double hx_left = vHxs[k].at<float>(i,j-1);
							double hy_left = vHys[k].at<float>(i,j-1);
							double depth_left = vDepths[k].at<float>(i,j-1)/*+hx_left*/; // add the corresponding depth gradient of the left pixel

							double score_left, angle_left;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,vKs[k],mR0,vRs[k],mt0,vts[k],fx0_1,vfx_1[k],fy0_1,vfy_1[k],img0,vImgs[k],j_real,i_real,depth_left,hx_left,hy_left,score_left,angle_left,size);

							vScores_candidates.push_back(score_left);

							vDepths_candidates.push_back(depth_left);
							vHx_candidates.push_back(hx_left);
							vHy_candidates.push_back(hy_left);
						}

						if (i-1>=0) // means that there is a upper neighbor
						{
							double hx_upper = vHxs[k].at<float>(i-1,j);
							double hy_upper = vHys[k].at<float>(i-1,j);
							double depth_upper = vDepths[k].at<float>(i-1,j)/*+hy_upper*/;

							double score_upper,angle_upper;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,vKs[k],mR0,vRs[k],mt0,vts[k],fx0_1,vfx_1[k],fy0_1,vfy_1[k],img0,vImgs[k],j_real,i_real,depth_upper,hx_upper,hy_upper,score_upper,angle_upper,size);

							vScores_candidates.push_back(score_upper);

							vDepths_candidates.push_back(depth_upper);
							vHx_candidates.push_back(hx_upper);
							vHy_candidates.push_back(hy_upper);
						}

						vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						double max_score = *iterDouble;
						int idx_max_score = iterDouble - vScores_candidates.begin();

						double depth_possible = vDepths_candidates[idx_max_score];
						double hx_possible = vHx_candidates[idx_max_score];
						double hy_possible = vHy_candidates[idx_max_score];
						double score_possible = max_score;

						vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

						vScores_candidates.push_back(score_possible);
						vDepths_candidates.push_back(depth_possible);
						vHx_candidates.push_back(hx_possible);
						vHy_candidates.push_back(hy_possible);

						for (rk=0;rk<nRandSamp;rk++)
						{
							double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
							if (rk==0)
							{
								d_max_k = depth_max;
								d_min_k = depth_min;
								hx_max_k = hx_max;
								hx_min_k = -hx_max;
								hy_max_k = hx_max;
								hy_min_k = -hx_max;
							}
							else
							{
								double factor_k = pow(factor, rk);
								double d_r = factor_k*d_range*0.5;
								double h_r = factor_k*h_range*0.5;
								DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
								DetermineInterval(hx_max, -hx_max, hx_possible, h_r, hx_max_k, hx_min_k);
								DetermineInterval(hx_max, -hx_max, hy_possible, h_r, hy_max_k, hy_min_k);
							}

							// generate current parameter set
							double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
							double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
							double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

							double score_k,angle_k;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,vKs[k],mR0,vRs[k],mt0,vts[k],fx0_1,vfx_1[k],fy0_1,vfy_1[k],img0,vImgs[k],j_real,i_real,depth_k,hx_k,hy_k,score_k,angle_k,size);

							vScores_candidates.push_back(score_k);

							vDepths_candidates.push_back(depth_k);
							vHx_candidates.push_back(hx_k);
							vHy_candidates.push_back(hy_k);
						}

						iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						max_score = *iterDouble;
						idx_max_score = iterDouble - vScores_candidates.begin();

						vDepths[k].at<float>(i,j) = vDepths_candidates[idx_max_score];
						vHxs[k].at<float>(i,j) = vHx_candidates[idx_max_score];
						vHys[k].at<float>(i,j) = vHy_candidates[idx_max_score];
						vScores[k].at<float>(i,j) = max_score;
					}
				}

				Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3);

				double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

				minMaxIdx(vDepths[k], &min_depth, &max_depth);
				minMaxIdx(vHxs[k], &min_incre_x, &max_incre_x);
				minMaxIdx(vHys[k], &min_incre_y, &max_incre_y);

				vDepths[k].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
				vHxs[k].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
				vHys[k].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

				for (i=0;i<imgHeight;i++)
				{
					for (j=0;j<imgWidth;j++)
					{
						if (vScores[k].at<float>(i,j)<0)
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = 0;
							mScore_map.at<Vec3b>(i,j).val[2] = 255;
						}
						else
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*vScores[k].at<float>(i,j));
							mScore_map.at<Vec3b>(i,j).val[2] = 0;
						}
					}
				}

				strInfo.Format("D:\\all\\depth map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mDepth_map);
				strInfo.Format("D:\\all\\hx map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mHx_map);
				strInfo.Format("D:\\all\\hy map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mHy_map);
				strInfo.Format("D:\\all\\score map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mScore_map);

				Mat mNormColor;
				GetNormColorField(cam0, vDepths[k], vHxs[k], vHys[k], mNormColor);
				strInfo.Format("D:\\all\\normcolor map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mNormColor);

				strInfo.Format("D:\\all\\cloud points iteration %02d with image %02d.txt", ii, k);
				OutputPointCloud(strInfo,cam0,img0,vDepths[k],vHxs[k],vHys[k],vScores[k]);
			}
		} 
		else
		{
			for (k=(nImg-1);k>=0;k--)
			{
				for (i=imgHeight-1;i>=0;i--)
				{
					strInfo.Format("evaluate row %04d with image %02d in iteration %02d", i, k, ii);
					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

					for (j=imgWidth-1;j>=0;j--)
					{
						int i_real, j_real, nVisi;
						MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

						vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
						vector<double> vScores_candidates;

						// first evaluate current parameter set for (i,j)
						double depth0 = vDepths[k].at<float>(i,j);
						double hx0 = vHxs[k].at<float>(i,j);
						double hy0 = vHys[k].at<float>(i,j);
						double score0 = vScores[k].at<float>(i,j);

						vScores_candidates.push_back(score0);
						vDepths_candidates.push_back(depth0);
						vHx_candidates.push_back(hx0);
						vHy_candidates.push_back(hy0);

						if (j+1<imgWidth) // means that there is a right neighbor
						{
							double hx_right = vHxs[k].at<float>(i,j+1);
							double hy_right = vHys[k].at<float>(i,j+1);
							double depth_right = vDepths[k].at<float>(i,j+1)/*-hx_right*/;

							double score_right,angle_right;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,vKs[k],mR0,vRs[k],mt0,vts[k],fx0_1,vfx_1[k],fy0_1,vfy_1[k],img0,vImgs[k],j_real,i_real,depth_right,hx_right,hy_right,score_right,angle_right,size);
							
							vScores_candidates.push_back(score_right);

							vDepths_candidates.push_back(depth_right);
							vHx_candidates.push_back(hx_right);
							vHy_candidates.push_back(hy_right);
						}

						if (i+1<imgHeight) // means that there is a lower neighbor
						{
							double hx_lower = vHxs[k].at<float>(i+1,j);
							double hy_lower = vHys[k].at<float>(i+1,j);
							double depth_lower = vDepths[k].at<float>(i+1,j)/*-hy_lower*/;

							double score_lower,angle_lower;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,vKs[k],mR0,vRs[k],mt0,vts[k],fx0_1,vfx_1[k],fy0_1,vfy_1[k],img0,vImgs[k],j_real,i_real,depth_lower,hx_lower,hy_lower,score_lower,angle_lower,size);

							vScores_candidates.push_back(score_lower);

							vDepths_candidates.push_back(depth_lower);
							vHx_candidates.push_back(hx_lower);
							vHy_candidates.push_back(hy_lower);
						}

						vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						double max_score = *iterDouble;
						int idx_max_score = iterDouble - vScores_candidates.begin();

						double depth_possible = vDepths_candidates[idx_max_score];
						double hx_possible = vHx_candidates[idx_max_score];
						double hy_possible = vHy_candidates[idx_max_score];
						double score_possible = max_score;

						vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

						vScores_candidates.push_back(score_possible);
						vDepths_candidates.push_back(depth_possible);
						vHx_candidates.push_back(hx_possible);
						vHy_candidates.push_back(hy_possible);

						for (rk=0;rk<nRandSamp;rk++)
						{
							double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
							if (rk==0)
							{
								d_max_k = depth_max;
								d_min_k = depth_min;
								hx_max_k = hx_max;
								hx_min_k = -hx_max;
								hy_max_k = hx_max;
								hy_min_k = -hx_max;
							}
							else
							{
								double factor_k = pow(factor, rk);
								double d_r = factor_k*d_range*0.5;
								double h_r = factor_k*h_range*0.5;
								DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
								DetermineInterval(hx_max, -hx_max, hx_possible, h_r, hx_max_k, hx_min_k);
								DetermineInterval(hx_max, -hx_max, hy_possible, h_r, hy_max_k, hy_min_k);
							}

							// generate current parameter set
							double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
							double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
							double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

							double score_k,angle_k;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,vKs[k],mR0,vRs[k],mt0,vts[k],fx0_1,vfx_1[k],fy0_1,vfy_1[k],img0,vImgs[k],j_real,i_real,depth_k,hx_k,hy_k,score_k,angle_k,size);

							vScores_candidates.push_back(score_k);

							vDepths_candidates.push_back(depth_k);
							vHx_candidates.push_back(hx_k);
							vHy_candidates.push_back(hy_k);
						}

						iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						max_score = *iterDouble;
						idx_max_score = iterDouble - vScores_candidates.begin();

						vDepths[k].at<float>(i,j) = vDepths_candidates[idx_max_score];
						vHxs[k].at<float>(i,j) = vHx_candidates[idx_max_score];
						vHys[k].at<float>(i,j) = vHy_candidates[idx_max_score];
						vScores[k].at<float>(i,j) = max_score;
					}
				}

				Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3);

				double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

				minMaxIdx(vDepths[k], &min_depth, &max_depth);
				minMaxIdx(vHxs[k], &min_incre_x, &max_incre_x);
				minMaxIdx(vHys[k], &min_incre_y, &max_incre_y);

				vDepths[k].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
				vHxs[k].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
				vHys[k].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

				for (i=0;i<imgHeight;i++)
				{
					for (j=0;j<imgWidth;j++)
					{
						if (vScores[k].at<float>(i,j)<0)
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = 0;
							mScore_map.at<Vec3b>(i,j).val[2] = 255;
						}
						else
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*vScores[k].at<float>(i,j));
							mScore_map.at<Vec3b>(i,j).val[2] = 0;
						}
					}
				}

				strInfo.Format("D:\\all\\depth map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mDepth_map);
				strInfo.Format("D:\\all\\hx map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mHx_map);
				strInfo.Format("D:\\all\\hy map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mHy_map);
				strInfo.Format("D:\\all\\score map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mScore_map);

				Mat mNormColor;
				GetNormColorField(cam0, vDepths[k], vHxs[k], vHys[k], mNormColor);
				strInfo.Format("D:\\all\\normcolor map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mNormColor);

				strInfo.Format("D:\\all\\cloud points iteration %02d with image %02d.txt", ii, k);
				OutputPointCloud(strInfo,cam0,img0,vDepths[k],vHxs[k],vHys[k],vScores[k]);
			}
		}
	}

	for (k=0;k<nImg;k++)
	{
		strInfo.Format("D:\\all\\final PatchMatch depth map ref %02d.txt", k);
		FILE * file_depth = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch hx map ref %02d.txt", k);
		FILE * file_hx = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch hy map ref %02d.txt", k);
		FILE * file_hy = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch score map ref %02d.txt", k);
		FILE * file_score = fopen(strInfo, "w");

		// at the same time evaluate all parameters
		for (i=0;i<imgHeight;i++)
		{
			for (j=0;j<imgWidth;j++)
			{
				fprintf(file_depth, "%.12f	", vDepths[k].at<float>(i,j));
				fprintf(file_hx, "%.12f	", vHxs[k].at<float>(i,j));
				fprintf(file_hy, "%.12f	", vHys[k].at<float>(i,j));
				fprintf(file_score, "%.12f	", vScores[k].at<float>(i,j));
			}
			fprintf(file_depth, "\n");
			fprintf(file_hx, "\n");
			fprintf(file_hy, "\n");
			fprintf(file_score, "\n");
		}
		fclose(file_depth);
		fclose(file_hx);
		fclose(file_hy);
		fclose(file_score);
	}
}

// 20140805, conduct patchmatch for reference image with certain designated visible support images
void DeepVoid::PatchMatch_140805(const cam_data & cam0,				// input:	reference image
							     const vector<cam_data> & vCams,	// input:	all support images
							     const Mat & img0,					// input:	reference image
							     const vector<Mat> & vImgs,			// input:	all support images
							     const vector<CloudPoint> & clouds,	// input:	the cloud points
							     Mat & mDepth,						// in&output:	initial depth map of reference image as input, and optimized as output
							     Mat & mHx,							// in&output:	initial hx map of reference image as input, and optimized as output
							     Mat & mHy,							// in&output:	initial hy map of reference image as input, and optimized as output
							     Mat & mScore,						// in&output:	initial score map of reference image as input, and optimized as output
								 const Mat & mVisi,					// input:	the visibility map
							     int size /*= 5*/,					// input:	the window size of the image patch, should be odd number
							     double thresh_ncc /*= 0.8*/,		// input:	the threshold within which to be considered as a successful ncc
							     double angLimit /*= 80*/,			// input:	the angular range limit of the normal of every object point, in angle, not radian
							     int maxIter /*= 4*/,				// input:	maximum iteration
							     int mincams /*= 1*/,
							     double factor /*= 0.5*/,
							     int nRandSamp /*= 6*/
							     )
{
	int i,j,k,ii,jj,rk;

	int nImg = vCams.size(); // the number of support images
	int n_cloud = clouds.size();
	int imgWidth = img0.cols;
	int imgHeight = img0.rows;
	int wndSizeHalf = (size-1)/2;
	double tana = tan(angLimit*D2R);

	Matx33d mR0,mK0; Matx31d mt0;

	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mR0(i,j) = cam0.R[i*3+j];
		}
	}
	mK0(0,0) = cam0.fx;	mK0(0,1) = cam0.s;  mK0(0,2) = cam0.cx;
	mK0(1,1) = cam0.fy;	mK0(1,2) = cam0.cy; mK0(2,2) = 1;
	mt0(0) = cam0.t[0];	mt0(1) = cam0.t[1]; mt0(2) = cam0.t[2];

	double fx0_1 = 1/cam0.fx;
	double fy0_1 = 1/cam0.fy;

	double f=(cam0.fx+cam0.fy)*0.5;
	double tana_f = tana/f;

	double depth_min;
	double depth_max;

	for (jj=0;jj<n_cloud;jj++)
	{
		Matx31d mX;

		mX(0) = clouds[jj].m_pt.x;
		mX(1) = clouds[jj].m_pt.y;
		mX(2) = clouds[jj].m_pt.z;

		mX = mR0*mX+mt0;

		double depth = mX(2);

		if (jj == 0)
		{
			depth_min = depth;
			depth_max = depth;
		} 
		else
		{
			if (depth<depth_min)
			{
				depth_min = depth;
			}
			if (depth>depth_max)
			{
				depth_max = depth;
			}
		}
	}

	double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

	double depth_ext = (depth_max-depth_min)*ratio_ext;

	depth_max += depth_ext;

	double tmp = depth_min - depth_ext;

	if (tmp<0)
	{
		depth_min = 0;
	} 
	else
	{
		depth_min = tmp;
	}

	double hx_max = tana_f * depth_max;

	double d_range = depth_max - depth_min;
	double h_range = 2*hx_max;

	//////////////////////////////////////////////////////////////////////////
	vector<Matx33d> vRs,vKs; vector<Matx31d> vts; // for all support images
	vector<double> vfx_1, vfy_1; // for all support images

	for (k=0;k<nImg;k++)
	{
		Matx33d mR,mK; Matx31d mt;

		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR(i,j) = vCams[k].R[i*3+j];
			}
		}
		mK(0,0) = vCams[k].fx;	mK(0,1) = vCams[k].s;  mK(0,2) = vCams[k].cx;
		mK(1,1) = vCams[k].fy;	mK(1,2) = vCams[k].cy; mK(2,2) = 1;
		mt(0) = vCams[k].t[0];	mt(1) = vCams[k].t[1]; mt(2) = vCams[k].t[2];

		vRs.push_back(mR);
		vKs.push_back(mK);
		vts.push_back(mt);
		vfx_1.push_back(1/vCams[k].fx);
		vfy_1.push_back(1/vCams[k].fy);
	}
	//////////////////////////////////////////////////////////////////////////

	CString strInfo;
	// evaluate all parameters
	for (i=0;i<imgHeight;i++)
	{
		strInfo.Format("evaluate row %04d", i);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		for (j=0;j<imgWidth;j++)
		{
			double score_old = mScore.at<float>(i,j);

			if (score_old<0){continue;} // this pixel is not valid, no need to evaluate it

			int i_real, j_real, nVisi;
			MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

			double depth = mDepth.at<float>(i,j);
			double hx = mHx.at<float>(i,j);
			double hy = mHy.at<float>(i,j);
			uchar visi = mVisi.at<uchar>(i,j);

			double score;
			CheckOnePixel_givenOneParamSet_mulImg(mK0,vKs,mR0,vRs,mt0,vts,fx0_1,vfx_1,fy0_1,vfy_1,img0,vImgs,j_real,i_real,depth,hx,hy,visi,score,size);

			mScore.at<float>(i,j) = score;
		}
	}	

	// start propagation
	for (ii=0;ii<maxIter;ii++)
	{
		if (ii%2 == 0)
		{
			for (i=0;i<imgHeight;i++)
			{
				strInfo.Format("evaluate row %04d in iteration %02d", i, ii);
				theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

				for (j=0;j<imgWidth;j++)
				{
					uchar visi = mVisi.at<uchar>(i,j);

					int i_real, j_real, nVisi;
					MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

					vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
					vector<double> vScores_candidates;

					// first evaluate current parameter set for (i,j)
					double depth0 = mDepth.at<float>(i,j);
					double hx0 = mHx.at<float>(i,j);
					double hy0 = mHy.at<float>(i,j);
					double score0 = mScore.at<float>(i,j);
					
					if (score0<0){continue;} // if score is 0 then no need

					vScores_candidates.push_back(score0);
					vDepths_candidates.push_back(depth0);
					vHx_candidates.push_back(hx0);
					vHy_candidates.push_back(hy0);

					if (j-1>=0) // means that there is a left neighbor
					{
						double hx_left = mHx.at<float>(i,j-1);
						double hy_left = mHy.at<float>(i,j-1);
						double depth_left = mDepth.at<float>(i,j-1)/*+hx_left*/; // add the corresponding depth gradient of the left pixel

						double score_left;
						CheckOnePixel_givenOneParamSet_mulImg(mK0,vKs,mR0,vRs,mt0,vts,fx0_1,vfx_1,fy0_1,vfy_1,img0,vImgs,j_real,i_real,depth_left,hx_left,hy_left,visi,score_left,size);

						vScores_candidates.push_back(score_left);

						vDepths_candidates.push_back(depth_left);
						vHx_candidates.push_back(hx_left);
						vHy_candidates.push_back(hy_left);
					}

					if (i-1>=0) // means that there is a upper neighbor
					{
						double hx_upper = mHx.at<float>(i-1,j);
						double hy_upper = mHy.at<float>(i-1,j);
						double depth_upper = mDepth.at<float>(i-1,j)/*+hy_upper*/;

						double score_upper;
						CheckOnePixel_givenOneParamSet_mulImg(mK0,vKs,mR0,vRs,mt0,vts,fx0_1,vfx_1,fy0_1,vfy_1,img0,vImgs,j_real,i_real,depth_upper,hx_upper,hy_upper,visi,score_upper,size);

						vScores_candidates.push_back(score_upper);

						vDepths_candidates.push_back(depth_upper);
						vHx_candidates.push_back(hx_upper);
						vHy_candidates.push_back(hy_upper);
					}

					vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
					double max_score = *iterDouble;
					int idx_max_score = iterDouble - vScores_candidates.begin();

					double depth_possible = vDepths_candidates[idx_max_score];
					double hx_possible = vHx_candidates[idx_max_score];
					double hy_possible = vHy_candidates[idx_max_score];
					double score_possible = max_score;

					vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

					vScores_candidates.push_back(score_possible);
					vDepths_candidates.push_back(depth_possible);
					vHx_candidates.push_back(hx_possible);
					vHy_candidates.push_back(hy_possible);

					for (rk=0;rk<nRandSamp;rk++)
					{
						double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
						if (rk==0)
						{
							d_max_k = depth_max;
							d_min_k = depth_min;
							hx_max_k = hx_max;
							hx_min_k = -hx_max;
							hy_max_k = hx_max;
							hy_min_k = -hx_max;
						}
						else
						{
							double factor_k = pow(factor, rk);
							double d_r = factor_k*d_range*0.5;
							double h_r = factor_k*h_range*0.5;
							DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
							DetermineInterval(hx_max, -hx_max, hx_possible, h_r, hx_max_k, hx_min_k);
							DetermineInterval(hx_max, -hx_max, hy_possible, h_r, hy_max_k, hy_min_k);
						}

// 						double factor_k = pow(factor, rk)*0.1; double factor_min = 1-factor_k; double factor_max = 1+factor_k;
// 						d_min_k = depth_possible*factor_min; d_max_k = depth_possible*factor_max;
// 						hx_min_k = hx_possible*factor_min; hx_max_k = hx_possible*factor_max;
// 						hy_min_k = hy_possible*factor_min; hy_max_k = hy_possible*factor_max;

						// generate current parameter set
						double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
//						double depth_k = depth_possible; // 20140822, random sample only normals
						double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
						double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

						double score_k;
						CheckOnePixel_givenOneParamSet_mulImg(mK0,vKs,mR0,vRs,mt0,vts,fx0_1,vfx_1,fy0_1,vfy_1,img0,vImgs,j_real,i_real,depth_k,hx_k,hy_k,visi,score_k,size);

						vScores_candidates.push_back(score_k);

						vDepths_candidates.push_back(depth_k);
						vHx_candidates.push_back(hx_k);
						vHy_candidates.push_back(hy_k);
					}

					iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
					max_score = *iterDouble;
					idx_max_score = iterDouble - vScores_candidates.begin();

					mDepth.at<float>(i,j) = vDepths_candidates[idx_max_score];
					mHx.at<float>(i,j) = vHx_candidates[idx_max_score];
					mHy.at<float>(i,j) = vHy_candidates[idx_max_score];
					mScore.at<float>(i,j) = max_score;
				}
			}

			Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3);

			double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

			minMaxIdx(mDepth, &min_depth, &max_depth);
			minMaxIdx(mHx, &min_incre_x, &max_incre_x);
			minMaxIdx(mHy, &min_incre_y, &max_incre_y);

			mDepth.convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
			mHx.convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
			mHy.convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

			for (i=0;i<imgHeight;i++)
			{
				for (j=0;j<imgWidth;j++)
				{
					if (mScore.at<float>(i,j)<0)
					{
						mScore_map.at<Vec3b>(i,j).val[0] = 0;
						mScore_map.at<Vec3b>(i,j).val[1] = 0;
						mScore_map.at<Vec3b>(i,j).val[2] = 255;
					}
					else
					{
						mScore_map.at<Vec3b>(i,j).val[0] = 0;
						mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
						mScore_map.at<Vec3b>(i,j).val[2] = 0;
					}
				}
			}

			strInfo.Format("D:\\all\\depth map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mDepth_map);
			strInfo.Format("D:\\all\\hx map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mHx_map);
			strInfo.Format("D:\\all\\hy map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mHy_map);
			strInfo.Format("D:\\all\\score map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mScore_map);

			Mat mNormColor;
			GetNormColorField(cam0, mDepth, mHx, mHy, mNormColor);
			strInfo.Format("D:\\all\\normcolor map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mNormColor);

			strInfo.Format("D:\\all\\cloud points iteration %02d.txt", ii);
			OutputPointCloud(strInfo,cam0,img0,mDepth,mHx,mHy,mScore);
		} 
		else
		{
			for (i=imgHeight-1;i>=0;i--)
			{
				strInfo.Format("evaluate row %04d in iteration %02d", i, ii);
				theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

				for (j=imgWidth-1;j>=0;j--)
				{
					uchar visi = mVisi.at<uchar>(i,j);

					int i_real, j_real, nVisi;
					MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

					vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
					vector<double> vScores_candidates;

					// first evaluate current parameter set for (i,j)
					double depth0 = mDepth.at<float>(i,j);
					double hx0 = mHx.at<float>(i,j);
					double hy0 = mHy.at<float>(i,j);
					double score0 = mScore.at<float>(i,j);

					if (score0<0){continue;} // if score is 0 then no need

					vScores_candidates.push_back(score0);
					vDepths_candidates.push_back(depth0);
					vHx_candidates.push_back(hx0);
					vHy_candidates.push_back(hy0);

					if (j+1<imgWidth) // means that there is a right neighbor
					{
						double hx_right = mHx.at<float>(i,j+1);
						double hy_right = mHy.at<float>(i,j+1);
						double depth_right = mDepth.at<float>(i,j+1)/*-hx_right*/;

						double score_right;
						CheckOnePixel_givenOneParamSet_mulImg(mK0,vKs,mR0,vRs,mt0,vts,fx0_1,vfx_1,fy0_1,vfy_1,img0,vImgs,j_real,i_real,depth_right,hx_right,hy_right,visi,score_right,size);

						vScores_candidates.push_back(score_right);

						vDepths_candidates.push_back(depth_right);
						vHx_candidates.push_back(hx_right);
						vHy_candidates.push_back(hy_right);
					}

					if (i+1<imgHeight) // means that there is a lower neighbor
					{
						double hx_lower = mHx.at<float>(i+1,j);
						double hy_lower = mHy.at<float>(i+1,j);
						double depth_lower = mDepth.at<float>(i+1,j)/*-hy_lower*/;

						double score_lower;
						CheckOnePixel_givenOneParamSet_mulImg(mK0,vKs,mR0,vRs,mt0,vts,fx0_1,vfx_1,fy0_1,vfy_1,img0,vImgs,j_real,i_real,depth_lower,hx_lower,hy_lower,visi,score_lower,size);

						vScores_candidates.push_back(score_lower);

						vDepths_candidates.push_back(depth_lower);
						vHx_candidates.push_back(hx_lower);
						vHy_candidates.push_back(hy_lower);
					}

					vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
					double max_score = *iterDouble;
					int idx_max_score = iterDouble - vScores_candidates.begin();

					double depth_possible = vDepths_candidates[idx_max_score];
					double hx_possible = vHx_candidates[idx_max_score];
					double hy_possible = vHy_candidates[idx_max_score];
					double score_possible = max_score;

					vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

					vScores_candidates.push_back(score_possible);
					vDepths_candidates.push_back(depth_possible);
					vHx_candidates.push_back(hx_possible);
					vHy_candidates.push_back(hy_possible);

					for (rk=0;rk<nRandSamp;rk++)
					{
						double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
						if (rk==0)
						{
							d_max_k = depth_max;
							d_min_k = depth_min;
							hx_max_k = hx_max;
							hx_min_k = -hx_max;
							hy_max_k = hx_max;
							hy_min_k = -hx_max;
						}
						else
						{
							double factor_k = pow(factor, rk);
							double d_r = factor_k*d_range*0.5;
							double h_r = factor_k*h_range*0.5;
							DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
							DetermineInterval(hx_max, -hx_max, hx_possible, h_r, hx_max_k, hx_min_k);
							DetermineInterval(hx_max, -hx_max, hy_possible, h_r, hy_max_k, hy_min_k);
						}

// 						double factor_k = pow(factor, rk)*0.1; double factor_min = 1-factor_k; double factor_max = 1+factor_k;
// 						d_min_k = depth_possible*factor_min; d_max_k = depth_possible*factor_max;
// 						hx_min_k = hx_possible*factor_min; hx_max_k = hx_possible*factor_max;
// 						hy_min_k = hy_possible*factor_min; hy_max_k = hy_possible*factor_max;

						// generate current parameter set
						double depth_k = rng_initRndField.uniform(d_min_k, d_max_k); // 20140822, random sample only depth
//						double depth_k = depth_possible;
						double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
						double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);
//						double hx_k = hx_possible;
//						double hy_k = hy_possible;

						double score_k;
						CheckOnePixel_givenOneParamSet_mulImg(mK0,vKs,mR0,vRs,mt0,vts,fx0_1,vfx_1,fy0_1,vfy_1,img0,vImgs,j_real,i_real,depth_k,hx_k,hy_k,visi,score_k,size);

						vScores_candidates.push_back(score_k);

						vDepths_candidates.push_back(depth_k);
						vHx_candidates.push_back(hx_k);
						vHy_candidates.push_back(hy_k);
					}

					iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
					max_score = *iterDouble;
					idx_max_score = iterDouble - vScores_candidates.begin();

					mDepth.at<float>(i,j) = vDepths_candidates[idx_max_score];
					mHx.at<float>(i,j) = vHx_candidates[idx_max_score];
					mHy.at<float>(i,j) = vHy_candidates[idx_max_score];
					mScore.at<float>(i,j) = max_score;
				}
			}

			Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3);

			double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

			minMaxIdx(mDepth, &min_depth, &max_depth);
			minMaxIdx(mHx, &min_incre_x, &max_incre_x);
			minMaxIdx(mHy, &min_incre_y, &max_incre_y);

			mDepth.convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
			mHx.convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
			mHy.convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

			for (i=0;i<imgHeight;i++)
			{
				for (j=0;j<imgWidth;j++)
				{
					if (mScore.at<float>(i,j)<0)
					{
						mScore_map.at<Vec3b>(i,j).val[0] = 0;
						mScore_map.at<Vec3b>(i,j).val[1] = 0;
						mScore_map.at<Vec3b>(i,j).val[2] = 255;
					}
					else
					{
						mScore_map.at<Vec3b>(i,j).val[0] = 0;
						mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
						mScore_map.at<Vec3b>(i,j).val[2] = 0;
					}
				}
			}

			strInfo.Format("D:\\all\\depth map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mDepth_map);
			strInfo.Format("D:\\all\\hx map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mHx_map);
			strInfo.Format("D:\\all\\hy map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mHy_map);
			strInfo.Format("D:\\all\\score map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mScore_map);

			Mat mNormColor;
			GetNormColorField(cam0, mDepth, mHx, mHy, mNormColor);
			strInfo.Format("D:\\all\\normcolor map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mNormColor);

			strInfo.Format("D:\\all\\cloud points iteration %02d.txt", ii);
			OutputPointCloud(strInfo,cam0,img0,mDepth,mHx,mHy,mScore);
		}
	}

	strInfo.Format("D:\\all\\final PatchMatch depth map.txt");
	FILE * file_depth = fopen(strInfo, "w");
	strInfo.Format("D:\\all\\final PatchMatch hx map.txt");
	FILE * file_hx = fopen(strInfo, "w");
	strInfo.Format("D:\\all\\final PatchMatch hy map.txt");
	FILE * file_hy = fopen(strInfo, "w");
	strInfo.Format("D:\\all\\final PatchMatch score map.txt");
	FILE * file_score = fopen(strInfo, "w");

	// at the same time evaluate all parameters
	for (i=0;i<imgHeight;i++)
	{
		for (j=0;j<imgWidth;j++)
		{
			fprintf(file_depth, "%.12f	", mDepth.at<float>(i,j));
			fprintf(file_hx, "%.12f	", mHx.at<float>(i,j));
			fprintf(file_hy, "%.12f	", mHy.at<float>(i,j));
			fprintf(file_score, "%.12f	", mScore.at<float>(i,j));
		}
		fprintf(file_depth, "\n");
		fprintf(file_hx, "\n");
		fprintf(file_hy, "\n");
		fprintf(file_score, "\n");
	}
	fclose(file_depth);
	fclose(file_hx);
	fclose(file_hy);
	fclose(file_score);
}

// back to the original multi-view patchmatch version, with the visibility determined according to certain ncc threshold
void DeepVoid::PatchMatch_141209(const Matx33d & mK0,				// input:	interior matrix of the reference image
							     const Matx33d & mR0,				// input:	rotation matrix of the reference image
							     const Matx31d & mt0,				// input:	translation vectors of the reference image
							     const Mat & img0,					// input:	the reference image
							     const vector<Matx33d> & vKs,		// input:	interior matrix of all support images
							     const vector<Matx33d> & vRs,		// input:	rotation matrix of all support images
							     const vector<Matx31d> & vts,		// input:	translation vectors of all support images
							     const vector<Mat> & vImgs,			// input:	all support images
							     const vector<CloudPoint> & clouds,	// input:	the given sparse cloud points
							     Mat & mDepth,						// output:	the depth map
							     Mat & mHx,							// output:	the hx map
							     Mat & mHy,							// output:	the hy map
							     Mat & mScore,						// output:	the score map
								 Mat & mVisi,						// output:	the visi map
							     int size /*= 5*/,					// input:	the window size of the image patch, should be odd number
							     double thresh_ncc /*= 0.8*/,		// input:	the threshold within which to be considered as a successful ncc
							     double angLimit /*= 80*/,			// input:	the angular range limit of the normal of every object point, in angle, not radian
							     int maxIter /*= 4*/,				// input:	maximum iteration
							     double factor /*= 0.5*/,
							     int nRandSamp /*= 6*/
							     )
{
	int i,j,k,ii,jj,kk,rk;

	int n_spt = vKs.size();
	int n_cloud = clouds.size();

	int imgWidth = img0.cols;
	int imgHeight = img0.rows;
	int wndSizeHalf = (size-1)/2;

	double fx0_1 = 1/mK0(0,0);
	double fy0_1 = 1/mK0(1,1);

	vector<double> vfx_1, vfy_1;
	for (k=0;k<n_spt;k++)
	{
		double fx_1 = 1/vKs[k](0,0);
		double fy_1 = 1/vKs[k](1,1);

		vfx_1.push_back(fx_1);
		vfy_1.push_back(fy_1);
	}

	// determine maximal and minimal parameters //////////////////////////////////////////////////////////////////////////
	double tana = tan(angLimit*D2R);

	double fx0 = mK0(0,0); double fy0 = mK0(1,1);

	double f=(fx0+fy0)*0.5;
	double tana_f = tana/f;

	double depth_min;
	double depth_max;

	for (jj=0;jj<n_cloud;jj++)
	{
		Matx31d mX;

		mX(0) = clouds[jj].m_pt.x;
		mX(1) = clouds[jj].m_pt.y;
		mX(2) = clouds[jj].m_pt.z;

		mX = mR0*mX+mt0;

		double depth = mX(2);

		if (jj == 0)
		{
			depth_min = depth;
			depth_max = depth;
		} 
		else
		{
			if (depth<depth_min)
			{
				depth_min = depth;
			}
			if (depth>depth_max)
			{
				depth_max = depth;
			}
		}
	}

	double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

	double depth_ext = (depth_max-depth_min)*ratio_ext;

	depth_max += depth_ext;

	double tmp = depth_min - depth_ext;

	if (tmp<0)
	{
		depth_min = 0;
	} 
	else
	{
		depth_min = tmp;
	}

	double h_max = tana_f * depth_max;
	double h_min = -h_max;

	double d_range = depth_max-depth_min;
	double h_range = h_max-h_min;
	//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

	CString strInfo;
	// initialize depth, hx, hy maps randomly
	mScore = Mat(imgHeight, imgWidth, CV_32FC1);
	mVisi = Mat(imgHeight, imgWidth, CV_8UC1);

	InitRndField(mK0,mR0,mt0,depth_min,depth_max,angLimit,imgWidth,imgHeight,mDepth,mHx,mHy);

	// at the same time evaluate all parameters
	for (i=0;i<imgHeight;i++)
	{
		strInfo.Format("evaluate row %04d", i);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		for (j=0;j<imgWidth;j++)
		{
			int i_real, j_real;
			MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

			double depth = mDepth.at<float>(i,j);
			double hx = mHx.at<float>(i,j);
			double hy = mHy.at<float>(i,j);

			vector<double> vScores, vAngs;
			CheckOnePixel_givenOneParamSet_allSptImgs(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs,vRs,vts,vImgs,vfx_1,vfy_1,
				j_real,i_real,depth,hx,hy,vScores,vAngs,size);

			double score = GetScore(vScores,thresh_ncc,1);
			uchar visi = GetVisibilityVector_uchar(vScores,thresh_ncc);

			mScore.at<float>(i,j) = score;
			mVisi.at<uchar>(i,j) = visi;
		}
	}

	// start propagation
	for (ii=0;ii<maxIter;ii++)
	{
		if (ii%2 == 0)
		{
			for (i=0;i<imgHeight;i++)
			{
				strInfo.Format("evaluate row %04d in iteration %02d", i, ii);
				theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

				for (j=0;j<imgWidth;j++)
				{
					int i_real, j_real;
					MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

					vector<double> vDepths_candidates, vHx_candidates, vHy_candidates, vScores_candidates;
					vector<uchar> vVisi_candidates;

					// first evaluate current parameter set for (i,j)
					double depth0 = mDepth.at<float>(i,j);
					double hx0 = mHx.at<float>(i,j);
					double hy0 = mHy.at<float>(i,j);
					double score0 = mScore.at<float>(i,j);
					uchar visi0 = mVisi.at<uchar>(i,j);

					vScores_candidates.push_back(score0);
					vDepths_candidates.push_back(depth0);
					vHx_candidates.push_back(hx0);
					vHy_candidates.push_back(hy0);
					vVisi_candidates.push_back(visi0);

					if (j-1>=0) // means that there is a left neighbor
					{
						double hx_left = mHx.at<float>(i,j-1);
						double hy_left = mHy.at<float>(i,j-1);
						double depth_left = mDepth.at<float>(i,j-1);

						vector<double> vScores, vAngs;
						CheckOnePixel_givenOneParamSet_allSptImgs(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs,vRs,vts,vImgs,vfx_1,vfy_1,
							j_real,i_real,depth_left,hx_left,hy_left,vScores,vAngs,size);

						double score_left = GetScore(vScores,thresh_ncc,1);
						uchar visi_left = GetVisibilityVector_uchar(vScores,thresh_ncc);

						vScores_candidates.push_back(score_left);
						vDepths_candidates.push_back(depth_left);
						vHx_candidates.push_back(hx_left);
						vHy_candidates.push_back(hy_left);
						vVisi_candidates.push_back(visi_left);
					}

					if (i-1>=0) // means that there is a upper neighbor
					{
						double hx_upper = mHx.at<float>(i-1,j);
						double hy_upper = mHy.at<float>(i-1,j);
						double depth_upper = mDepth.at<float>(i-1,j);

						vector<double> vScores, vAngs;
						CheckOnePixel_givenOneParamSet_allSptImgs(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs,vRs,vts,vImgs,vfx_1,vfy_1,
							j_real,i_real,depth_upper,hx_upper,hy_upper,vScores,vAngs,size);

						double score_upper = GetScore(vScores,thresh_ncc,1);
						uchar visi_upper = GetVisibilityVector_uchar(vScores,thresh_ncc);

						vScores_candidates.push_back(score_upper);
						vDepths_candidates.push_back(depth_upper);
						vHx_candidates.push_back(hx_upper);
						vHy_candidates.push_back(hy_upper);
						vVisi_candidates.push_back(visi_upper);
					}

					vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
					double max_score = *iterDouble;
					int idx_max_score = iterDouble - vScores_candidates.begin();

					double depth_possible = vDepths_candidates[idx_max_score];
					double hx_possible = vHx_candidates[idx_max_score];
					double hy_possible = vHy_candidates[idx_max_score];
					double score_possible = max_score;
					uchar visi_possible = vVisi_candidates[idx_max_score];

					vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear(); vVisi_candidates.clear();

					vScores_candidates.push_back(score_possible);
					vDepths_candidates.push_back(depth_possible);
					vHx_candidates.push_back(hx_possible);
					vHy_candidates.push_back(hy_possible);
					vVisi_candidates.push_back(visi_possible);

					for (rk=0;rk<nRandSamp;rk++)
					{
						double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
						if (rk==0)
						{
							d_max_k = depth_max;
							d_min_k = depth_min;
							hx_max_k = h_max;
							hx_min_k = h_min;
							hy_max_k = h_max;
							hy_min_k = h_min;
						}
						else
						{
							double factor_k = pow(factor, rk);
							double d_r = factor_k*d_range*0.5;
							double h_r = factor_k*h_range*0.5;
							DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
							DetermineInterval(h_max, h_min, hx_possible, h_r, hx_max_k, hx_min_k);
							DetermineInterval(h_max, h_min, hy_possible, h_r, hy_max_k, hy_min_k);
						}

						// generate current parameter set
						double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
						double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
						double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

						vector<double> vScores, vAngs;
						CheckOnePixel_givenOneParamSet_allSptImgs(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs,vRs,vts,vImgs,vfx_1,vfy_1,
							j_real,i_real,depth_k,hx_k,hy_k,vScores,vAngs,size);

						double score_k = GetScore(vScores,thresh_ncc,1);
						uchar visi_k = GetVisibilityVector_uchar(vScores,thresh_ncc);

						vScores_candidates.push_back(score_k);
						vDepths_candidates.push_back(depth_k);
						vHx_candidates.push_back(hx_k);
						vHy_candidates.push_back(hy_k);
						vVisi_candidates.push_back(visi_k);
					}

					iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
					max_score = *iterDouble;
					idx_max_score = iterDouble - vScores_candidates.begin();

					mDepth.at<float>(i,j) = vDepths_candidates[idx_max_score];
					mHx.at<float>(i,j) = vHx_candidates[idx_max_score];
					mHy.at<float>(i,j) = vHy_candidates[idx_max_score];
					mScore.at<float>(i,j) = max_score;
					mVisi.at<uchar>(i,j) = vVisi_candidates[idx_max_score];
				}
			}

			Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3);

			double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

			minMaxIdx(mDepth, &min_depth, &max_depth);
			minMaxIdx(mHx, &min_incre_x, &max_incre_x);
			minMaxIdx(mHy, &min_incre_y, &max_incre_y);

			mDepth.convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
			mHx.convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
			mHy.convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

			for (i=0;i<imgHeight;i++)
			{
				for (j=0;j<imgWidth;j++)
				{
					if (mScore.at<float>(i,j)<0)
					{
						mScore_map.at<Vec3b>(i,j).val[0] = 0;
						mScore_map.at<Vec3b>(i,j).val[1] = 0;
						mScore_map.at<Vec3b>(i,j).val[2] = 255;
					}
					else
					{
						mScore_map.at<Vec3b>(i,j).val[0] = 0;
						mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
						mScore_map.at<Vec3b>(i,j).val[2] = 0;
					}
				}
			}

			strInfo.Format("D:\\all\\depth map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mDepth_map);
			strInfo.Format("D:\\all\\hx map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mHx_map);
			strInfo.Format("D:\\all\\hy map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mHy_map);
			strInfo.Format("D:\\all\\score map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mScore_map);

			Mat mNormColor;
			GetNormColorField(mK0, mR0, mt0, fx0_1, fy0_1, mDepth, mHx, mHy, mNormColor);
			strInfo.Format("D:\\all\\normcolor map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mNormColor);

			strInfo.Format("D:\\all\\cloud points iteration %02d.txt", ii);
			OutputPointCloud(strInfo,mK0,mR0,mt0,fx0_1,fy0_1,img0,mDepth,mHx,mHy,mScore);
		} 
		else
		{
			for (i=imgHeight-1;i>=0;i--)
			{
				strInfo.Format("evaluate row %04d in iteration %02d", i, ii);
				theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

				for (j=imgWidth-1;j>=0;j--)
				{
					int i_real, j_real;
					MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

					vector<double> vDepths_candidates, vHx_candidates, vHy_candidates, vScores_candidates;
					vector<uchar> vVisi_candidates;

					// first evaluate current parameter set for (i,j)
					double depth0 = mDepth.at<float>(i,j);
					double hx0 = mHx.at<float>(i,j);
					double hy0 = mHy.at<float>(i,j);
					double score0 = mScore.at<float>(i,j);
					uchar visi0 = mVisi.at<uchar>(i,j);

					vScores_candidates.push_back(score0);
					vDepths_candidates.push_back(depth0);
					vHx_candidates.push_back(hx0);
					vHy_candidates.push_back(hy0);
					vVisi_candidates.push_back(visi0);

					if (j+1<imgWidth) // means that there is a right neighbor
					{
						double hx_right = mHx.at<float>(i,j+1);
						double hy_right = mHy.at<float>(i,j+1);
						double depth_right = mDepth.at<float>(i,j+1);

						vector<double> vScores, vAngs;
						CheckOnePixel_givenOneParamSet_allSptImgs(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs,vRs,vts,vImgs,vfx_1,vfy_1,
							j_real,i_real,depth_right,hx_right,hy_right,vScores,vAngs,size);

						double score_right = GetScore(vScores,thresh_ncc,1);
						uchar visi_right = GetVisibilityVector_uchar(vScores,thresh_ncc);

						vScores_candidates.push_back(score_right);
						vDepths_candidates.push_back(depth_right);
						vHx_candidates.push_back(hx_right);
						vHy_candidates.push_back(hy_right);
						vVisi_candidates.push_back(visi_right);
					}

					if (i+1<imgHeight) // means that there is a lower neighbor
					{
						double hx_lower = mHx.at<float>(i+1,j);
						double hy_lower = mHy.at<float>(i+1,j);
						double depth_lower = mDepth.at<float>(i+1,j);

						vector<double> vScores, vAngs;
						CheckOnePixel_givenOneParamSet_allSptImgs(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs,vRs,vts,vImgs,vfx_1,vfy_1,
							j_real,i_real,depth_lower,hx_lower,hy_lower,vScores,vAngs,size);

						double score_lower = GetScore(vScores,thresh_ncc,1);
						uchar visi_lower = GetVisibilityVector_uchar(vScores,thresh_ncc);

						vScores_candidates.push_back(score_lower);
						vDepths_candidates.push_back(depth_lower);
						vHx_candidates.push_back(hx_lower);
						vHy_candidates.push_back(hy_lower);
						vVisi_candidates.push_back(visi_lower);
					}

					vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
					double max_score = *iterDouble;
					int idx_max_score = iterDouble - vScores_candidates.begin();

					double depth_possible = vDepths_candidates[idx_max_score];
					double hx_possible = vHx_candidates[idx_max_score];
					double hy_possible = vHy_candidates[idx_max_score];
					double score_possible = max_score;
					uchar visi_possible = vVisi_candidates[idx_max_score];

					vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear(); vVisi_candidates.clear();

					vScores_candidates.push_back(score_possible);
					vDepths_candidates.push_back(depth_possible);
					vHx_candidates.push_back(hx_possible);
					vHy_candidates.push_back(hy_possible);
					vVisi_candidates.push_back(visi_possible);

					for (rk=0;rk<nRandSamp;rk++)
					{
						double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
						if (rk==0)
						{
							d_max_k = depth_max;
							d_min_k = depth_min;
							hx_max_k = h_max;
							hx_min_k = h_min;
							hy_max_k = h_max;
							hy_min_k = h_min;
						}
						else
						{
							double factor_k = pow(factor, rk);
							double d_r = factor_k*d_range*0.5;
							double h_r = factor_k*h_range*0.5;
							DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
							DetermineInterval(h_max, h_min, hx_possible, h_r, hx_max_k, hx_min_k);
							DetermineInterval(h_max, h_min, hy_possible, h_r, hy_max_k, hy_min_k);
						}

						// generate current parameter set
						double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
						double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
						double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

						vector<double> vScores, vAngs;
						CheckOnePixel_givenOneParamSet_allSptImgs(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs,vRs,vts,vImgs,vfx_1,vfy_1,
							j_real,i_real,depth_k,hx_k,hy_k,vScores,vAngs,size);

						double score_k = GetScore(vScores,thresh_ncc,1);
						uchar visi_k = GetVisibilityVector_uchar(vScores,thresh_ncc);

						vScores_candidates.push_back(score_k);
						vDepths_candidates.push_back(depth_k);
						vHx_candidates.push_back(hx_k);
						vHy_candidates.push_back(hy_k);
						vVisi_candidates.push_back(visi_k);
					}

					iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
					max_score = *iterDouble;
					idx_max_score = iterDouble - vScores_candidates.begin();

					mDepth.at<float>(i,j) = vDepths_candidates[idx_max_score];
					mHx.at<float>(i,j) = vHx_candidates[idx_max_score];
					mHy.at<float>(i,j) = vHy_candidates[idx_max_score];
					mScore.at<float>(i,j) = max_score;
					mVisi.at<uchar>(i,j) = vVisi_candidates[idx_max_score];
				}
			}

			Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3);

			double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

			minMaxIdx(mDepth, &min_depth, &max_depth);
			minMaxIdx(mHx, &min_incre_x, &max_incre_x);
			minMaxIdx(mHy, &min_incre_y, &max_incre_y);

			mDepth.convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
			mHx.convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
			mHy.convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

			for (i=0;i<imgHeight;i++)
			{
				for (j=0;j<imgWidth;j++)
				{
					if (mScore.at<float>(i,j)<0)
					{
						mScore_map.at<Vec3b>(i,j).val[0] = 0;
						mScore_map.at<Vec3b>(i,j).val[1] = 0;
						mScore_map.at<Vec3b>(i,j).val[2] = 255;
					}
					else
					{
						mScore_map.at<Vec3b>(i,j).val[0] = 0;
						mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
						mScore_map.at<Vec3b>(i,j).val[2] = 0;
					}
				}
			}

			strInfo.Format("D:\\all\\depth map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mDepth_map);
			strInfo.Format("D:\\all\\hx map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mHx_map);
			strInfo.Format("D:\\all\\hy map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mHy_map);
			strInfo.Format("D:\\all\\score map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mScore_map);

			Mat mNormColor;
			GetNormColorField(mK0, mR0, mt0, fx0_1, fy0_1, mDepth, mHx, mHy, mNormColor);
			strInfo.Format("D:\\all\\normcolor map iteration %02d.bmp", ii);
			imwrite(strInfo.GetBuffer(), mNormColor);

			strInfo.Format("D:\\all\\cloud points iteration %02d.txt", ii);
			OutputPointCloud(strInfo,mK0,mR0,mt0,fx0_1,fy0_1,img0,mDepth,mHx,mHy,mScore);
		}
	}
}

void DeepVoid::PatchMatch_withViewPropagation_fixedVisi(const vector<cam_data> & vCams,	// input:	all camera data
													    const vector<Mat> & vImgs,		// input:	all images
													    vector<Mat> & vDepths,			// output:	all the depth maps
													    vector<Mat> & vHxs,				// output:	all the hx maps
													    vector<Mat> & vHys,				// output:	all the hy maps
													    vector<Mat> & vScores,			// output:	all the score maps
													    const vector<Mat> & vVisis,		// input:	all the visibility maps
													    const vector<Mat> & vVisiNs,	// input:	all the visible image number maps
													    int size/* = 5*/,				// input:	the window size of the image patch, should be odd number
													    double thresh_ncc /*= 0.8*/,	// input:	the threshold within which to be considered as a successful ncc
													    double angLimit /*= 80*/,		// input:	the angular range limit of the normal of every object point, in angle, not radian
														double thresh_visiAng /*= 75*/,		
													    int maxIter /*= 4*/,			// input:	maximum iteration
													    int mincams /*= 1*/,
													    double factor /*= 0.5*/,
													    int nRandSamp /*= 6*/
													    )
{
	int i,j,k,ii,jj,kk,rk;

	double thresh_angle = 90;

	int nImg = vCams.size();
	int imgWidth = vImgs[0].cols;
	int imgHeight = vImgs[0].rows;
	int wndSizeHalf = (size-1)/2;
	double tana = tan(angLimit*D2R);

	vector<Matx33d> vRs,vKs; vector<Matx31d> vts;
	vector<double> vfx_1, vfy_1;

	for (k=0;k<nImg;k++)
	{
		Matx33d mR,mK; Matx31d mt;

		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR(i,j) = vCams[k].R[i*3+j];
			}
		}
		mK(0,0) = vCams[k].fx;	mK(0,1) = vCams[k].s;  mK(0,2) = vCams[k].cx;
		mK(1,1) = vCams[k].fy;	mK(1,2) = vCams[k].cy; mK(2,2) = 1;
		mt(0) = vCams[k].t[0];	mt(1) = vCams[k].t[1]; mt(2) = vCams[k].t[2];

		vRs.push_back(mR);
		vKs.push_back(mK);
		vts.push_back(mt);
		vfx_1.push_back(1/vCams[k].fx);
		vfy_1.push_back(1/vCams[k].fy);
	}

	CString strInfo;

	// initialize all depth, hx, hy maps randomly
	for (k=0;k<nImg;k++)
	{
		// at the same time evaluate all parameters under fixed visibility
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("evaluate row %04d of image %02d", i, k);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				if (vScores[k].at<float>(i,j)<0) // if this pixel is invalid then no need to update its score
				{
					continue;
				}

				uchar visi = vVisis[k].at<uchar>(i,j);

				int i_real, j_real, nVisi;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				double depth = vDepths[k].at<float>(i,j);
				double hx = vHxs[k].at<float>(i,j);
				double hy = vHys[k].at<float>(i,j);

				vector<double> vnccs;
				CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth,hx,hy,vnccs,size,thresh_angle);
				vScores[k].at<float>(i,j) = GetScore_fixedVisi(vnccs, visi);
			}
		}
	}

	// start propagation
	for (ii=0;ii<maxIter;ii++)
	{
		if (ii%2 == 0)
		{
			for (k=0;k<nImg;k++)
			{
				// determine the sampling ranges of all parameters //////////////////////////////////////////////////////////////////////////
				double fx = vKs[k](0,0);
				double fy = vKs[k](1,1);
				double cx = vKs[k](0,2);
				double cy = vKs[k](1,2);
				double fx_1 = vfx_1[k];
				double fy_1 = vfy_1[k];
				double f=(fx+fy)*0.5;
				//////////////////////////////////////////////////////////////////////////

				for (i=0;i<imgHeight;i++)
				{
					strInfo.Format("evaluate row %04d of image %02d in iteration %02d", i, k, ii);
					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

					double nimgy = (i-cy)*fy_1;

					for (j=0;j<imgWidth;j++)
					{
						int i_real, j_real, nVisi;
						MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

						// normalized image point, i.e. the direction
						double nimgx = (j-cx)*fx_1;

						vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
						vector<double> vScores_candidates;

						// first evaluate current parameter set for (i,j)
						double depth0 = vDepths[k].at<float>(i,j);
						double hx0 = vHxs[k].at<float>(i,j);
						double hy0 = vHys[k].at<float>(i,j);
						double score0 = vScores[k].at<float>(i,j);
						uchar visi0 = vVisis[k].at<uchar>(i,j);

						if (score0<0)
						{
							continue;
						}

						vScores_candidates.push_back(score0);
						vDepths_candidates.push_back(depth0);
						vHx_candidates.push_back(hx0);
						vHy_candidates.push_back(hy0);

						if (j-1>=0) // means that there is a left neighbor
						{
							double depth_left = vDepths[k].at<float>(i,j-1);
							double hx_left = vHxs[k].at<float>(i,j-1);
							double hy_left = vHys[k].at<float>(i,j-1);

							vector<double> vScores_left;
							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_left,hx_left,hy_left,vScores_left,size,thresh_angle);
							vScores_candidates.push_back(GetScore_fixedVisi(vScores_left, visi0));
							vDepths_candidates.push_back(depth_left);
							vHx_candidates.push_back(hx_left);
							vHy_candidates.push_back(hy_left);
						}

						if (i-1>=0) // means that there is a upper neighbor
						{
							double depth_upper = vDepths[k].at<float>(i-1,j);
							double hx_upper = vHxs[k].at<float>(i-1,j);
							double hy_upper = vHys[k].at<float>(i-1,j);

							vector<double> vScores_upper;
							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_upper,hx_upper,hy_upper,vScores_upper,size,thresh_angle);
							vScores_candidates.push_back(GetScore_fixedVisi(vScores_upper, visi0));
							vDepths_candidates.push_back(depth_upper);
							vHx_candidates.push_back(hx_upper);
							vHy_candidates.push_back(hy_upper);
						}

						vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						double max_score = *iterDouble;
						int idx_max_score = iterDouble - vScores_candidates.begin();

						double depth_possible = vDepths_candidates[idx_max_score];
						double hx_possible = vHx_candidates[idx_max_score];
						double hy_possible = vHy_candidates[idx_max_score];
						double score_possible = max_score;

						vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

						vScores_candidates.push_back(score_possible);
						vDepths_candidates.push_back(depth_possible);
						vHx_candidates.push_back(hx_possible);
						vHy_candidates.push_back(hy_possible);

						for (rk=0;rk<nRandSamp;rk++)
						{
							double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
							
							double factor_k = pow(factor, rk)*0.1; double factor_min = 1-factor_k; double factor_max = 1+factor_k;
							d_min_k = depth_possible*factor_min; d_max_k = depth_possible*factor_max;
							hx_min_k = hx_possible*factor_min; hx_max_k = hx_possible*factor_max;
							hy_min_k = hy_possible*factor_min; hy_max_k = hy_possible*factor_max;
							
							// generate current parameter set
							double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
							double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
							double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

							vector<double> vScores_k;
							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size,thresh_angle);
							vScores_candidates.push_back(GetScore_fixedVisi(vScores_k, visi0));
							vDepths_candidates.push_back(depth_k);
							vHx_candidates.push_back(hx_k);
							vHy_candidates.push_back(hy_k);
						}

						iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						max_score = *iterDouble;
						idx_max_score = iterDouble - vScores_candidates.begin();

						double d   = vDepths[k].at<float>(i,j) = vDepths_candidates[idx_max_score];
						double hx  = vHxs[k].at<float>(i,j) = vHx_candidates[idx_max_score];
						double hy  = vHys[k].at<float>(i,j) = vHy_candidates[idx_max_score];
						vScores[k].at<float>(i,j) = max_score;

						// propagate current parameters to all matched pixels in other images, if they are better than their current guess then adopt it.
						// get the 3D coordinates of the point associated with current pixel
						Matx31d pt3d = GetXYZ_givenDepth(vRs[k], vts[k], nimgx, nimgy, d);
						// get the normal of current obtained parameters
						Matx31d mn0; mn0(2)=1;
						get_normal_givendrhxhy(fx, fy, nimgx, nimgy, d, hx, hy, mn0(0), mn0(1));
						Matx31d mnw = vRs[k].t()*mn0; // convert the normal into world coordinate system
						vector<bool> vbools;
						InterpVisiVector_uchar(visi0, vbools);
						for (kk=0;kk<nImg;kk++)
						{
							if (!vbools[kk]){continue;}

							double fx_kk = vKs[kk](0,0); double fy_kk = vKs[kk](1,1); 
							double cx_kk = vKs[kk](0,2); double cy_kk = vKs[kk](1,2); 
							double fx_kk_1 = vfx_1[kk];  double fy_kk_1 = vfy_1[kk];

							// get the patch normal in kk image
							Matx31d mnkk = vRs[kk]*mnw;

							Matx31d pt3d_proj = vRs[kk]*pt3d+vts[kk];

							Matx31d imgpt = vKs[kk]*pt3d_proj;
							double zk_1 = 1/imgpt(2);
							double xk = imgpt(0)*zk_1;
							double yk = imgpt(1)*zk_1;

							if (xk<0||xk>(imgWidth-1)||yk<0||yk>(imgHeight-1)){continue;}

							int xk_int = int(xk+0.5);
							int yk_int = int(yk+0.5);

							uchar visikk = vVisis[kk].at<uchar>(yk_int,xk_int);
							double score_old = vScores[kk].at<float>(yk_int,xk_int);

							if (score_old<0){continue;}

							int xk_real, yk_real;
							MakeSureNotOutBorder(xk_int,yk_int,xk_real,yk_real,wndSizeHalf,imgWidth,imgHeight);

							double u_kk = 0; double v_kk = 0; double d_kk = pt3d_proj(2);
							optim_gn_uvrou_initialdk(vKs[k], vRs[k], vts[k], vKs[kk], vRs[kk], vts[kk], d, hx, hy, j, i, xk_int, yk_int, u_kk, v_kk, d_kk);

							double nimgx_kk = (xk_int-cx_kk)*fx_kk_1;
							double nimgy_kk = (yk_int-cy_kk)*fy_kk_1;

							double hx_kk, hy_kk;
							get_hxhy_givendrnormal(fx_kk, fy_kk, nimgx_kk, nimgy_kk, d_kk, mnkk, hx_kk, hy_kk);

							vector<double> vScores_kk;
							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs,kk,xk_real,yk_real,d_kk,hx_kk,hy_kk,vScores_kk,size,thresh_angle);
							double score_new = GetScore_fixedVisi(vScores_kk, visikk);
							
							if (score_new>score_old)
							{
								vDepths[kk].at<float>(yk_int,xk_int) = d_kk;
								vHxs[kk].at<float>(yk_int,xk_int) = hx_kk;
								vHys[kk].at<float>(yk_int,xk_int) = hy_kk;
								vScores[kk].at<float>(yk_int,xk_int) = score_new;
							}
						}
					}
				}

				double maxncc_minncc_1 = 1/(1-thresh_ncc);
				// output runtime info
				for (kk=0;kk<nImg;kk++)
				{
					Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3), mVisiN_map(imgHeight, imgWidth, CV_8UC3);

					double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

					minMaxIdx(vDepths[kk], &min_depth, &max_depth);
					minMaxIdx(vHxs[kk], &min_incre_x, &max_incre_x);
					minMaxIdx(vHys[kk], &min_incre_y, &max_incre_y);

					vDepths[kk].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
					vHxs[kk].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
					vHys[kk].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

					for (i=0;i<imgHeight;i++)
					{
						for (j=0;j<imgWidth;j++)
						{
							if (vScores[kk].at<float>(i,j)<0)
							{
								mScore_map.at<Vec3b>(i,j).val[0] = 0;
								mScore_map.at<Vec3b>(i,j).val[1] = 0;
								mScore_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else
							{
								mScore_map.at<Vec3b>(i,j).val[0] = 0;
								mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*(vScores[kk].at<float>(i,j)-thresh_ncc)*maxncc_minncc_1);
								mScore_map.at<Vec3b>(i,j).val[2] = 0;
							}

							uchar nnn = vVisiNs[kk].at<uchar>(i,j);

							if (nnn==0)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==1)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==2)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==3)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
							}
							else
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
							}
						}
					}

					strInfo.Format("D:\\all\\depth map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mDepth_map);
					strInfo.Format("D:\\all\\hx map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mHx_map);
					strInfo.Format("D:\\all\\hy map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mHy_map);
					strInfo.Format("D:\\all\\score map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mScore_map);
					strInfo.Format("D:\\all\\visi map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), vVisis[kk]);
					strInfo.Format("D:\\all\\visiN map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mVisiN_map);
					strInfo.Format("D:\\all\\cloud points iteration %02d ref %02d img %02d.txt", ii, k, kk);
					/*WriteDepthMap(strInfo,vCams[kk],vImgs[kk],vDepths[kk],vScores[kk]);*/
					OutputPointCloud(strInfo,vCams[kk],vImgs[kk],vDepths[kk],vHxs[kk],vHys[kk],vScores[kk]);
				}

				// 				if (ii==0&&k==1)
				// 				{
				// 					break;
				// 				}
			}
		} 
		else
		{
			for (k=(nImg-1);k>=0;k--)
			{
				// determine the sampling ranges of all parameters //////////////////////////////////////////////////////////////////////////
				double fx = vKs[k](0,0);
				double fy = vKs[k](1,1);
				double cx = vKs[k](0,2);
				double cy = vKs[k](1,2);
				double fx_1 = vfx_1[k];
				double fy_1 = vfy_1[k];
				double f=(fx+fy)*0.5;
				//////////////////////////////////////////////////////////////////////////

				for (i=imgHeight-1;i>=0;i--)
				{
					strInfo.Format("evaluate row %04d of image %02d in iteration %02d", i, k, ii);
					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

					double nimgy = (i-cy)*fy_1;

					for (j=imgWidth-1;j>=0;j--)
					{
						int i_real, j_real, nVisi;
						MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

						// normalized image point, i.e. the direction
						double nimgx = (j-cx)*fx_1;

						vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
						vector<double> vScores_candidates;

						// first evaluate current parameter set for (i,j)
						double depth0 = vDepths[k].at<float>(i,j);
						double hx0 = vHxs[k].at<float>(i,j);
						double hy0 = vHys[k].at<float>(i,j);
						double score0 = vScores[k].at<float>(i,j);
						uchar visi0 = vVisis[k].at<uchar>(i,j);

						if (score0<0)
						{
							continue;
						}
						
						vScores_candidates.push_back(score0);
						vDepths_candidates.push_back(depth0);
						vHx_candidates.push_back(hx0);
						vHy_candidates.push_back(hy0);

						if (j+1<imgWidth) // means that there is a right neighbor
						{
							double depth_right = vDepths[k].at<float>(i,j+1);
							double hx_right = vHxs[k].at<float>(i,j+1);
							double hy_right = vHys[k].at<float>(i,j+1);

							vector<double> vScores_right;
							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_right,hx_right,hy_right,vScores_right,size,thresh_angle);
							vScores_candidates.push_back(GetScore_fixedVisi(vScores_right, visi0));
							vDepths_candidates.push_back(depth_right);
							vHx_candidates.push_back(hx_right);
							vHy_candidates.push_back(hy_right);
						}

						if (i+1<imgHeight) // means that there is a lower neighbor
						{
							double depth_lower = vDepths[k].at<float>(i+1,j);
							double hx_lower = vHxs[k].at<float>(i+1,j);
							double hy_lower = vHys[k].at<float>(i+1,j);

							vector<double> vScores_lower;
							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_lower,hx_lower,hy_lower,vScores_lower,size,thresh_angle);
							vScores_candidates.push_back(GetScore_fixedVisi(vScores_lower, visi0));
							vDepths_candidates.push_back(depth_lower);
							vHx_candidates.push_back(hx_lower);
							vHy_candidates.push_back(hy_lower);
						}

						vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						double max_score = *iterDouble;
						int idx_max_score = iterDouble - vScores_candidates.begin();

						double depth_possible = vDepths_candidates[idx_max_score];
						double hx_possible = vHx_candidates[idx_max_score];
						double hy_possible = vHy_candidates[idx_max_score];
						double score_possible = max_score;

						vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

						vScores_candidates.push_back(score_possible);
						vDepths_candidates.push_back(depth_possible);
						vHx_candidates.push_back(hx_possible);
						vHy_candidates.push_back(hy_possible);

						for (rk=0;rk<nRandSamp;rk++)
						{
							double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
							
							double factor_k = pow(factor, rk)*0.1; double factor_min = 1-factor_k; double factor_max = 1+factor_k;
							d_min_k = depth_possible*factor_min; d_max_k = depth_possible*factor_max;
							hx_min_k = hx_possible*factor_min; hx_max_k = hx_possible*factor_max;
							hy_min_k = hy_possible*factor_min; hy_max_k = hy_possible*factor_max;

							// generate current parameter set
							double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
							double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
							double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

							vector<double> vScores_k;
							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs, k, j_real,i_real,depth_k,hx_k,hy_k,vScores_k,size,thresh_angle);
							vScores_candidates.push_back(GetScore_fixedVisi(vScores_k, visi0));
							vDepths_candidates.push_back(depth_k);
							vHx_candidates.push_back(hx_k);
							vHy_candidates.push_back(hy_k);
						}

						iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						max_score = *iterDouble;
						idx_max_score = iterDouble - vScores_candidates.begin();

						double d   = vDepths[k].at<float>(i,j) = vDepths_candidates[idx_max_score];
						double hx  = vHxs[k].at<float>(i,j) = vHx_candidates[idx_max_score];
						double hy  = vHys[k].at<float>(i,j) = vHy_candidates[idx_max_score];
						vScores[k].at<float>(i,j) = max_score;

						// propagate current parameters to all matched pixels in other images, if they are better than their current guess then adopt it.
						// get the 3D coordinates of the point associated with current pixel
						Matx31d pt3d = GetXYZ_givenDepth(vRs[k], vts[k], nimgx, nimgy, d);
						// get the normal of current obtained parameters
						Matx31d mn0; mn0(2)=1;
						get_normal_givendrhxhy(fx, fy, nimgx, nimgy, d, hx, hy, mn0(0), mn0(1));
						Matx31d mnw = vRs[k].t()*mn0; // convert the normal into world coordinate system
						vector<bool> vbools;
						InterpVisiVector_uchar(visi0, vbools);
						for (kk=0;kk<nImg;kk++)
						{
							if (!vbools[kk]){continue;}

							double fx_kk = vKs[kk](0,0); double fy_kk = vKs[kk](1,1); 
							double cx_kk = vKs[kk](0,2); double cy_kk = vKs[kk](1,2); 
							double fx_kk_1 = vfx_1[kk];  double fy_kk_1 = vfy_1[kk];

							// get the patch normal in kk image
							Matx31d mnkk = vRs[kk]*mnw;

							Matx31d pt3d_proj = vRs[kk]*pt3d+vts[kk];

							Matx31d imgpt = vKs[kk]*pt3d_proj;
							double zk_1 = 1/imgpt(2);
							double xk = imgpt(0)*zk_1;
							double yk = imgpt(1)*zk_1;

							if (xk<0||xk>(imgWidth-1)||yk<0||yk>(imgHeight-1)){continue;}

							int xk_int = int(xk+0.5);
							int yk_int = int(yk+0.5);

							uchar visikk = vVisis[kk].at<uchar>(yk_int,xk_int);
							double score_old = vScores[kk].at<float>(yk_int,xk_int);

							if (score_old<0){continue;}

							int xk_real, yk_real;
							MakeSureNotOutBorder(xk_int,yk_int,xk_real,yk_real,wndSizeHalf,imgWidth,imgHeight);

							double u_kk = 0; double v_kk = 0; double d_kk = pt3d_proj(2);
							optim_gn_uvrou_initialdk(vKs[k], vRs[k], vts[k], vKs[kk], vRs[kk], vts[kk], d, hx, hy, j, i, xk_int, yk_int, u_kk, v_kk, d_kk);

							double nimgx_kk = (xk_int-cx_kk)*fx_kk_1;
							double nimgy_kk = (yk_int-cy_kk)*fy_kk_1;

							double hx_kk, hy_kk;
							get_hxhy_givendrnormal(fx_kk, fy_kk, nimgx_kk, nimgy_kk, d_kk, mnkk, hx_kk, hy_kk);

							vector<double> vScores_kk;
							CheckOnePixel_givenOneParamSet_normalangle(vKs, vRs, vts, vfx_1, vfy_1, vImgs,kk,xk_real,yk_real,d_kk,hx_kk,hy_kk,vScores_kk,size,thresh_angle);
							double score_new = GetScore_fixedVisi(vScores_kk, visikk);
							
							if (score_new>score_old)
							{
								vDepths[kk].at<float>(yk_int,xk_int) = d_kk;
								vHxs[kk].at<float>(yk_int,xk_int) = hx_kk;
								vHys[kk].at<float>(yk_int,xk_int) = hy_kk;
								vScores[kk].at<float>(yk_int,xk_int) = score_new;
							}
						}
					}
				}

				double maxncc_minncc_1 = 1/(1-thresh_ncc);
				// output runtime info
				for (kk=0;kk<nImg;kk++)
				{
					Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3), mVisiN_map(imgHeight, imgWidth, CV_8UC3);

					double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

					minMaxIdx(vDepths[kk], &min_depth, &max_depth);
					minMaxIdx(vHxs[kk], &min_incre_x, &max_incre_x);
					minMaxIdx(vHys[kk], &min_incre_y, &max_incre_y);

					vDepths[kk].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
					vHxs[kk].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
					vHys[kk].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

					for (i=0;i<imgHeight;i++)
					{
						for (j=0;j<imgWidth;j++)
						{
							if (vScores[kk].at<float>(i,j)<0)
							{
								mScore_map.at<Vec3b>(i,j).val[0] = 0;
								mScore_map.at<Vec3b>(i,j).val[1] = 0;
								mScore_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else
							{
								mScore_map.at<Vec3b>(i,j).val[0] = 0;
								mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*(vScores[kk].at<float>(i,j)-thresh_ncc)*maxncc_minncc_1);
								mScore_map.at<Vec3b>(i,j).val[2] = 0;
							}

							uchar nnn = vVisiNs[kk].at<uchar>(i,j);

							if (nnn==0)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==1)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==2)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
							}
							else if (nnn==3)
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
							}
							else
							{
								mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
								mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
								mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
							}
						}
					}

					strInfo.Format("D:\\all\\depth map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mDepth_map);
					strInfo.Format("D:\\all\\hx map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mHx_map);
					strInfo.Format("D:\\all\\hy map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mHy_map);
					strInfo.Format("D:\\all\\score map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mScore_map);
					strInfo.Format("D:\\all\\visi map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), vVisis[kk]);
					strInfo.Format("D:\\all\\visiN map iteration %02d ref %02d img %02d.bmp", ii, k, kk);
					imwrite(strInfo.GetBuffer(), mVisiN_map);
					strInfo.Format("D:\\all\\cloud points iteration %02d ref %02d img %02d.txt", ii, k, kk);
					/*WriteDepthMap(strInfo,vCams[kk],vImgs[kk],vDepths[kk],vScores[kk]);*/
					OutputPointCloud(strInfo,vCams[kk],vImgs[kk],vDepths[kk],vHxs[kk],vHys[kk],vScores[kk]);
				}
			}
		}

		// 		if (ii==0&&k==1)
		// 		{
		// 			break;
		// 		}
	}

	for (k=0;k<nImg;k++)
	{
		strInfo.Format("D:\\all\\final PatchMatch depth map ref %02d.txt", k);
		FILE * file_depth = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch hx map ref %02d.txt", k);
		FILE * file_hx = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch hy map ref %02d.txt", k);
		FILE * file_hy = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch score map ref %02d.txt", k);
		FILE * file_score = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch visi map ref %02d.txt", k);
		FILE * file_visi = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch visiN map ref %02d.txt", k);
		FILE * file_visiN = fopen(strInfo, "w");	

		// at the same time evaluate all parameters
		for (i=0;i<imgHeight;i++)
		{
			for (j=0;j<imgWidth;j++)
			{
				fprintf(file_depth, "%.12f	", vDepths[k].at<float>(i,j));
				fprintf(file_hx, "%.12f	", vHxs[k].at<float>(i,j));
				fprintf(file_hy, "%.12f	", vHys[k].at<float>(i,j));
				fprintf(file_score, "%.12f	", vScores[k].at<float>(i,j));
				fprintf(file_visi, "%d	", vVisis[k].at<uchar>(i,j));
				fprintf(file_visiN, "%d	", vVisiNs[k].at<uchar>(i,j));
			}
			fprintf(file_depth, "\n");
			fprintf(file_hx, "\n");
			fprintf(file_hy, "\n");
			fprintf(file_score, "\n");
			fprintf(file_visi, "\n");
			fprintf(file_visiN, "\n");
		}
		fclose(file_depth);
		fclose(file_hx);
		fclose(file_hy);
		fclose(file_score);
		fclose(file_visi);
		fclose(file_visiN);
	}
}

// void DeepVoid::VisibilityUpdate(const vector<cam_data> & vCams,	// input:	all camera data
// 								const vector<Mat> & vDepths,	// input
// 								const vector<Mat> & vHxs,		// input
// 								const vector<Mat> & vHys,		// input
// 								vector<Mat> & vScores,			// input&output
// 								const vector<Mat> & vVisis,		// input
// 								vector<Mat> & vVisis_updated,	// output:	updated visibility
// 								vector<Mat> & vVisisN_updated,	// output:	updated
// 								double thresh_ratio/* = 0.01*/			
// 								)
// {
// 	int k,i,j,kk;
// 
// 	vVisis_updated.clear(); vVisisN_updated.clear();
// 
// 	int nImg = vDepths.size();
// 	int imgWidth = vDepths[0].cols;
// 	int imgHeight = vDepths[0].rows;
// 
// 	vector<Matx33d> vRs,vKs; vector<Matx31d> vts;
// 	vector<double> vfx_1, vfy_1;
// 
// 	for (k=0;k<nImg;k++)
// 	{
// 		Matx33d mR,mK; Matx31d mt;
// 
// 		for (i=0;i<3;i++)
// 		{
// 			for (j=0;j<3;j++)
// 			{
// 				mR(i,j) = vCams[k].R[i*3+j];
// 			}
// 		}
// 		mK(0,0) = vCams[k].fx;	mK(0,1) = vCams[k].s;  mK(0,2) = vCams[k].cx;
// 		mK(1,1) = vCams[k].fy;	mK(1,2) = vCams[k].cy; mK(2,2) = 1;
// 		mt(0) = vCams[k].t[0];	mt(1) = vCams[k].t[1]; mt(2) = vCams[k].t[2];
// 
// 		vRs.push_back(mR);
// 		vKs.push_back(mK);
// 		vts.push_back(mt);
// 		vfx_1.push_back(1/vCams[k].fx);
// 		vfy_1.push_back(1/vCams[k].fy);
// 	}
// 
// 	for (k=0;k<nImg;k++)
// 	{
// 		Mat mVisi(imgHeight,imgWidth,CV_8UC1), mVisiN(imgHeight,imgWidth,CV_8UC1);
// 
// 		for (i=0;i<imgHeight;i++)
// 		{
// 			for (j=0;j<imgWidth;j++)
// 			{
// 				double score0 = vScores[k].at<float>(i,j);
// 
// 				if (score0<0)
// 				{
// 					mVisi.at<uchar>(i,j) = 0;
// 					mVisiN.at<uchar>(i,j) = 0;
// 					continue;
// 				}
// 
// 				double nimgx = (j-vCams[k].cx)*vfx_1[k];
// 				double nimgy = (i-vCams[k].cy)*vfy_1[k];
// 
// 				double d0 = vDepths[k].at<float>(i,j);
// 				double hx0 = vHxs[k].at<float>(i,j);
// 				double hy0 = vHys[k].at<float>(i,j);
// 
// 				Matx31d pt3d = GetXYZ_givenDepth(vRs[k], vts[k], nimgx, nimgy, d0);
// 
// 				vector<bool> vbools; uchar nVisi = 0;
// 				for (kk=0;kk<nImg;kk++)
// 				{
// 					if (kk==k)
// 					{
// 						vbools.push_back(false);
// 						continue;
// 					}
// 
// 					Matx31d pt3d_kk = vRs[kk]*pt3d+vts[kk];
// 
// 					Matx31d imgpt = vKs[kk]*pt3d_kk;
// 					double zk_1 = 1/imgpt(2);
// 					double xk = imgpt(0)*zk_1;
// 					double yk = imgpt(1)*zk_1;
// 
// 					if (xk < 0 || xk > imgWidth-1 || yk < 0 || yk > imgHeight-1)
// 					{
// 						vbools.push_back(false);
// 						continue;
// 					}
// 
// 					int xk_int = int(xk+0.5);
// 					int yk_int = int(yk+0.5);
// 
// 					double score_kk = vScores[kk].at<float>(yk_int, xk_int);
// 					double d_kk = vDepths[kk].at<float>(yk_int, xk_int);
// 					double hx_kk = vHxs[kk].at<float>(yk_int, xk_int);
// 					double hy_kk = vHys[kk].at<float>(yk_int, xk_int);
// 
// 					if (score_kk<0)
// 					{
// 						vbools.push_back(false);
// 						continue;
// 					}
// 
// 					double u = xk-xk_int;
// 					double v = yk-yk_int;
// 
// 					double ddd = d_kk + u*hx_kk + v*hy_kk;
// 					double ratio = fabs((pt3d_kk(2)-ddd)/pt3d_kk(2));
// 
// 					if (ratio<thresh_ratio)
// 					{
// 						vbools.push_back(true);
// 						++nVisi;
// 					} 
// 					else
// 					{
// 						vbools.push_back(false);
// 					}
// 				}
// 				uchar visi_old = vVisis[k].at<uchar>(i,j);
// 				uchar visi_new = GetVisibilityVector_uchar(vbools);
// 				mVisi.at<uchar>(i,j) = visi_new;
// 				mVisiN.at<uchar>(i,j) = nVisi;
// 
// 				if (nVisi==0)
// 				{
// 					vScores[k].at<float>(i,j) = -1;
// 				}
// 			}
// 		}
// 
// 		vVisis_updated.push_back(mVisi);
// 		vVisisN_updated.push_back(mVisiN);
// 	}
// 
// 	double thresh_ncc = 0.6;
// 	double maxncc_minncc_1 = 1/(1-thresh_ncc);
// 
// 	for (kk=0;kk<nImg;kk++)
// 	{
// 		Mat mVisiN_map(imgHeight, imgWidth, CV_8UC3), mScore_map(imgHeight, imgWidth, CV_8UC3);
// 
// 		for (i=0;i<imgHeight;i++)
// 		{
// 			for (j=0;j<imgWidth;j++)
// 			{
// 				if (vScores[kk].at<float>(i,j)<0)
// 				{
// 					mScore_map.at<Vec3b>(i,j).val[0] = 0;
// 					mScore_map.at<Vec3b>(i,j).val[1] = 0;
// 					mScore_map.at<Vec3b>(i,j).val[2] = 255;
// 				}
// 				else
// 				{
// 					mScore_map.at<Vec3b>(i,j).val[0] = 0;
// 					mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*(vScores[kk].at<float>(i,j)-thresh_ncc)*maxncc_minncc_1);
// 					mScore_map.at<Vec3b>(i,j).val[2] = 0;
// 				}
// 
// 				uchar nnn = vVisisN_updated[kk].at<uchar>(i,j);
// 
// 				if (nnn==0)
// 				{
// 					mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
// 					mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
// 					mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
// 				}
// 				else if (nnn==1)
// 				{
// 					mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
// 					mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
// 					mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
// 				}
// 				else if (nnn==2)
// 				{
// 					mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
// 					mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
// 					mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
// 				}
// 				else if (nnn==3)
// 				{
// 					mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
// 					mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
// 					mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
// 				}
// 				else
// 				{
// 					mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
// 					mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
// 					mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
// 				}
// 			}
// 		}
// 
// 		CString strInfo;
// 		strInfo.Format("D:\\all\\score map updated img %02d.bmp", kk);
// 		imwrite(strInfo.GetBuffer(), mScore_map);
// 		strInfo.Format("D:\\all\\visi map updated img %02d.bmp", kk);
// 		imwrite(strInfo.GetBuffer(), vVisis_updated[kk]);
// 		strInfo.Format("D:\\all\\visiN map updated img %02d.bmp", kk);
// 		imwrite(strInfo.GetBuffer(), mVisiN_map);
// 	}
// }

void DeepVoid::VisibilityUpdate(const vector<cam_data> & vCams,	// input:	all camera data
							    const vector<Mat> & vDepths,		// input
							    const vector<Mat> & vHxs,			// input
							    const vector<Mat> & vHys,			// input
							    vector<Mat> & vScores,			// input&output
							    vector<Mat> & vVisis,				// input&output
							    vector<Mat> & vVisisN,			// input&output
							    double thresh_ratio /*= 0.01*/			
							    )
{
	int k,i,j,kk;

	int nImg = vDepths.size();
	int imgWidth = vDepths[0].cols;
	int imgHeight = vDepths[0].rows;

	vector<Matx33d> vRs,vKs; vector<Matx31d> vts;
	vector<double> vfx_1, vfy_1;

	for (k=0;k<nImg;k++)
	{
		Matx33d mR,mK; Matx31d mt;

		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR(i,j) = vCams[k].R[i*3+j];
			}
		}
		mK(0,0) = vCams[k].fx;	mK(0,1) = vCams[k].s;  mK(0,2) = vCams[k].cx;
		mK(1,1) = vCams[k].fy;	mK(1,2) = vCams[k].cy; mK(2,2) = 1;
		mt(0) = vCams[k].t[0];	mt(1) = vCams[k].t[1]; mt(2) = vCams[k].t[2];

		vRs.push_back(mR);
		vKs.push_back(mK);
		vts.push_back(mt);
		vfx_1.push_back(1/vCams[k].fx);
		vfy_1.push_back(1/vCams[k].fy);
	}

	CString strInfo;

	for (k=0;k<nImg;k++)
	{
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("update visibility of row %04d of image %02d", i, k);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				double score0 = vScores[k].at<float>(i,j);

				if (score0<0)
				{
					continue;
				}

				double nimgx = (j-vCams[k].cx)*vfx_1[k];
				double nimgy = (i-vCams[k].cy)*vfy_1[k];

				double d0 = vDepths[k].at<float>(i,j);
				double hx0 = vHxs[k].at<float>(i,j);
				double hy0 = vHys[k].at<float>(i,j);

				Matx31d pt3d = GetXYZ_givenDepth(vRs[k], vts[k], nimgx, nimgy, d0);

				vector<bool> vbools; uchar nVisi = 0;
				for (kk=0;kk<nImg;kk++)
				{
					if (kk==k)
					{
						vbools.push_back(false);
						continue;
					}

					Matx31d pt3d_kk = vRs[kk]*pt3d+vts[kk];

					Matx31d imgpt = vKs[kk]*pt3d_kk;
					double zk_1 = 1/imgpt(2);
					double xk = imgpt(0)*zk_1;
					double yk = imgpt(1)*zk_1;

					if (xk < 0 || xk > imgWidth-1 || yk < 0 || yk > imgHeight-1)
					{
						vbools.push_back(false);
						continue;
					}

					int xk_int = int(xk+0.5);
					int yk_int = int(yk+0.5);

					double score_kk = vScores[kk].at<float>(yk_int, xk_int);
					double d_kk = vDepths[kk].at<float>(yk_int, xk_int);
					double hx_kk = vHxs[kk].at<float>(yk_int, xk_int);
					double hy_kk = vHys[kk].at<float>(yk_int, xk_int);

					if (score_kk<0)
					{
						vbools.push_back(false);
						continue;
					}

					double u = xk-xk_int;
					double v = yk-yk_int;

					double ddd = d_kk + u*hx_kk + v*hy_kk;
					double ratio = fabs((pt3d_kk(2)-ddd)/pt3d_kk(2));

					if (ratio<thresh_ratio)
					{
						vbools.push_back(true);
						++nVisi;
					} 
					else
					{
						vbools.push_back(false);
					}
				}
				uchar visi_old = vVisis[k].at<uchar>(i,j);
				uchar visi_new = GetVisibilityVector_uchar(vbools);
				vVisis[k].at<uchar>(i,j) = visi_new;
				vVisisN[k].at<uchar>(i,j) = nVisi;

				if (nVisi==0)
				{
					vScores[k].at<float>(i,j) = -1;
				}
			}
		}
	}

	double thresh_ncc = 0.6;
	double maxncc_minncc_1 = 1/(1-thresh_ncc);

	for (kk=0;kk<nImg;kk++)
	{
		Mat mVisiN_map(imgHeight, imgWidth, CV_8UC3), mScore_map(imgHeight, imgWidth, CV_8UC3);

		for (i=0;i<imgHeight;i++)
		{
			for (j=0;j<imgWidth;j++)
			{
				if (vScores[kk].at<float>(i,j)<0)
				{
					mScore_map.at<Vec3b>(i,j).val[0] = 0;
					mScore_map.at<Vec3b>(i,j).val[1] = 0;
					mScore_map.at<Vec3b>(i,j).val[2] = 255;
				}
				else
				{
					mScore_map.at<Vec3b>(i,j).val[0] = 0;
					mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*(vScores[kk].at<float>(i,j)-thresh_ncc)*maxncc_minncc_1);
					mScore_map.at<Vec3b>(i,j).val[2] = 0;
				}

				uchar nnn = vVisisN[kk].at<uchar>(i,j);

				if (nnn==0)
				{
					mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
				}
				else if (nnn==1)
				{
					mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
					mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
				}
				else if (nnn==2)
				{
					mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
					mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
				}
				else if (nnn==3)
				{
					mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
					mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
				}
				else
				{
					mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
					mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
				}
			}
		}

		CString strInfo;
		strInfo.Format("D:\\all\\score map updated img %02d.bmp", kk);
		imwrite(strInfo.GetBuffer(), mScore_map);
		strInfo.Format("D:\\all\\visi map updated img %02d.bmp", kk);
		imwrite(strInfo.GetBuffer(), vVisis[kk]);
		strInfo.Format("D:\\all\\visiN map updated img %02d.bmp", kk);
		imwrite(strInfo.GetBuffer(), mVisiN_map);
	}
}

void DeepVoid::VisibilityUpdate(const vector<cam_data> & vCams,	// input:	all camera data
							    const vector<Mat> & vImgs,		// input:	all images
							    const vector<Mat> & vDepths,	// input
							    const vector<Mat> & vHxs,		// input
							    const vector<Mat> & vHys,		// input
							    vector<Mat> & vScores,			// input&output
							    vector<Mat> & vVisis,			// input&output
							    vector<Mat> & vVisisN,			// input&output
								int size/* = 5*/,				// input:	the window size of the image patch, should be odd number
							    double thresh_ncc /*= 0.6*/,
							    double thresh_ratio /*= 0.01*/			
							    )
{
	int k,i,j,kk;

	int nImg = vDepths.size();
	int imgWidth = vDepths[0].cols;
	int imgHeight = vDepths[0].rows;
	int wndSizeHalf = (size-1)/2;

	vector<Matx33d> vRs,vKs; vector<Matx31d> vts;
	vector<double> vfx_1, vfy_1;

	for (k=0;k<nImg;k++)
	{
		Matx33d mR,mK; Matx31d mt;

		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR(i,j) = vCams[k].R[i*3+j];
			}
		}
		mK(0,0) = vCams[k].fx;	mK(0,1) = vCams[k].s;  mK(0,2) = vCams[k].cx;
		mK(1,1) = vCams[k].fy;	mK(1,2) = vCams[k].cy; mK(2,2) = 1;
		mt(0) = vCams[k].t[0];	mt(1) = vCams[k].t[1]; mt(2) = vCams[k].t[2];

		vRs.push_back(mR);
		vKs.push_back(mK);
		vts.push_back(mt);
		vfx_1.push_back(1/vCams[k].fx);
		vfy_1.push_back(1/vCams[k].fy);
	}

	CString strInfo;

	for (k=0;k<nImg;k++)
	{
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("update visibility of row %04d of image %02d", i, k);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				double score0 = vScores[k].at<float>(i,j);

				if (score0<0)
				{
					continue;
				}

				double nimgx = (j-vCams[k].cx)*vfx_1[k];
				double nimgy = (i-vCams[k].cy)*vfy_1[k];

				double d0 = vDepths[k].at<float>(i,j);
				double hx0 = vHxs[k].at<float>(i,j);
				double hy0 = vHys[k].at<float>(i,j);

				int i_real, j_real;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				// get the ncc values with all other images
				vector<double> vnccs;
				CheckOnePixel_givenOneParamSet(vKs, vRs, vts, vImgs, k, j_real, i_real, d0, hx0, hy0, vnccs, size);

				Matx31d pt3d = GetXYZ_givenDepth(vRs[k], vts[k], nimgx, nimgy, d0);

				vector<bool> vbools; uchar nVisi = 0;
				for (kk=0;kk<nImg;kk++)
				{
					if (kk==k)
					{
						vbools.push_back(false);
						continue;
					}

					Matx31d pt3d_kk = vRs[kk]*pt3d+vts[kk];

					Matx31d imgpt = vKs[kk]*pt3d_kk;
					double zk_1 = 1/imgpt(2);
					double xk = imgpt(0)*zk_1;
					double yk = imgpt(1)*zk_1;

					if (xk < 0 || xk > imgWidth-1 || yk < 0 || yk > imgHeight-1)
					{
						vbools.push_back(false);
						continue;
					}

					int xk_int = int(xk+0.5);
					int yk_int = int(yk+0.5);

					double score_kk = vScores[kk].at<float>(yk_int, xk_int);
					double d_kk = vDepths[kk].at<float>(yk_int, xk_int);
					double hx_kk = vHxs[kk].at<float>(yk_int, xk_int);
					double hy_kk = vHys[kk].at<float>(yk_int, xk_int);

					if (score_kk<0)
					{
						vbools.push_back(false);
						continue;
					}

					double u = xk-xk_int;
					double v = yk-yk_int;

					double ddd = d_kk + u*hx_kk + v*hy_kk;
					double ratio = fabs((pt3d_kk(2)-ddd)/pt3d_kk(2));

					if (ratio>=thresh_ratio)
					{
						vbools.push_back(false);
						continue;
					}

					if (vnccs[kk]>thresh_ncc)
					{
						vbools.push_back(true);
						++nVisi;
					}
					else
					{
						vbools.push_back(false);
					}
				}
				uchar visi_old = vVisis[k].at<uchar>(i,j);
				uchar visi_new = GetVisibilityVector_uchar(vbools);
				vVisis[k].at<uchar>(i,j) = visi_new;
				vVisisN[k].at<uchar>(i,j) = nVisi;

				if (nVisi==0)
				{
					vScores[k].at<float>(i,j) = -1;
				}
			}
		}
	}

	double maxncc_minncc_1 = 1/(1-thresh_ncc);

	for (kk=0;kk<nImg;kk++)
	{
		Mat mVisiN_map(imgHeight, imgWidth, CV_8UC3), mScore_map(imgHeight, imgWidth, CV_8UC3);

		for (i=0;i<imgHeight;i++)
		{
			for (j=0;j<imgWidth;j++)
			{
				if (vScores[kk].at<float>(i,j)<0)
				{
					mScore_map.at<Vec3b>(i,j).val[0] = 0;
					mScore_map.at<Vec3b>(i,j).val[1] = 0;
					mScore_map.at<Vec3b>(i,j).val[2] = 255;
				}
				else
				{
					mScore_map.at<Vec3b>(i,j).val[0] = 0;
					mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*(vScores[kk].at<float>(i,j)-thresh_ncc)*maxncc_minncc_1);
					mScore_map.at<Vec3b>(i,j).val[2] = 0;
				}

				uchar nnn = vVisisN[kk].at<uchar>(i,j);

				if (nnn==0)
				{
					mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
				}
				else if (nnn==1)
				{
					mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
					mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
				}
				else if (nnn==2)
				{
					mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
					mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
				}
				else if (nnn==3)
				{
					mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
					mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
				}
				else
				{
					mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
					mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
				}
			}
		}

		CString strInfo;
		strInfo.Format("D:\\all\\score map updated img %02d.bmp", kk);
		imwrite(strInfo.GetBuffer(), mScore_map);
		strInfo.Format("D:\\all\\visi map updated img %02d.bmp", kk);
		imwrite(strInfo.GetBuffer(), vVisis[kk]);
		strInfo.Format("D:\\all\\visiN map updated img %02d.bmp", kk);
		imwrite(strInfo.GetBuffer(), mVisiN_map);
	}
}

void DeepVoid::MPGC(const vector<cam_data> & vCams,		// input:	all camera data
					const vector<Mat> & vImgs,			// input:	all images
					vector<Mat> & vDepths,				// input&output:	all the depth maps
					vector<Mat> & vHxs,					// input&output:	all the hx maps
					vector<Mat> & vHys,					// input&output:	all the hy maps
					vector<Mat> & vScores,				// input&output:	all the score maps
					vector<Mat> & vVisis,				// input&output:	all the visibility maps
					vector<Mat> & vVisiNs,				// input&output:	all the visible image number maps
					int size /*= 5*/,					// input:	the window size of the image patch, should be odd number
					bool bFixCk /*= false*/,			// input:	fix all ck or not
					int maxIter /*= 20*/,				// input: max iteration
					double xEps /*= 1.0E-8*/,			// input: threshold
					double fEps /*= 1.0E-6*/			// input: threshold
					)
{
	int k,i,j,kk;

	int nImg = vDepths.size();
	int imgWidth = vDepths[0].cols;
	int imgHeight = vDepths[0].rows;
	int halfwnd = (size-1)*0.5;

	vector<Matx33d> vRs,vKs; vector<Matx31d> vts;
	vector<double> vfx_1, vfy_1;

	for (k=0;k<nImg;k++)
	{
		Matx33d mR,mK; Matx31d mt;

		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR(i,j) = vCams[k].R[i*3+j];
			}
		}
		mK(0,0) = vCams[k].fx;	mK(0,1) = vCams[k].s;  mK(0,2) = vCams[k].cx;
		mK(1,1) = vCams[k].fy;	mK(1,2) = vCams[k].cy; mK(2,2) = 1;
		mt(0) = vCams[k].t[0];	mt(1) = vCams[k].t[1]; mt(2) = vCams[k].t[2];

		vRs.push_back(mR);
		vKs.push_back(mK);
		vts.push_back(mt);
		vfx_1.push_back(1/vCams[k].fx);
		vfy_1.push_back(1/vCams[k].fy);
	}

	CString strInfo;

	for (k=0;k<nImg;k++)
	{
		double min_depth,max_depth,min_incre_x,max_incre_x,min_incre_y,max_incre_y;

		minMaxIdx(vDepths[k], &min_depth, &max_depth);
		minMaxIdx(vHxs[k], &min_incre_x, &max_incre_x);
		minMaxIdx(vHys[k], &min_incre_y, &max_incre_y);

		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("optimize row %04d of image %02d", i, k);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				double depth_init = vDepths[k].at<float>(i,j);
				double hx_init = vHxs[k].at<float>(i,j);
				double hy_init = vHys[k].at<float>(i,j);
				double score = vScores[k].at<float>(i,j);

				if (score<0)
				{
					continue; // do nothing
				}

				int i_real, j_real;
				MakeSureNotOutBorder(j,i,j_real,i_real,halfwnd,imgWidth,imgHeight);

				vector<bool> vbools;
				InterpVisiVector_uchar(vVisis[k].at<uchar>(i,j), vbools);

				vector<int> vIdxValidCam;
				for (kk=0;kk<nImg;kk++)
				{
					if (!vbools[kk])
					{
						continue;
					}
					vIdxValidCam.push_back(kk);
				}

				double depth_optim, hx_optim, hy_optim;
// 				if (optim_gn_drhxhyck(vKs, vRs, vts, vImgs, vIdxValidCam, k, j_real, i_real, size, size,
// 					depth_init, hx_init, hy_init, depth_optim, hx_optim, hy_optim, bFixCk, maxIter, xEps, fEps) &&
// 					depth_optim>min_depth && depth_optim<max_depth
// 					//&& isvalid_hxhy(fx_ref,fy_ref,nimgx,nimgy,depth_optim,hx_optim,hy_optim,thresh_normdir)// hx_optim>min_incre_x && hx_optim<max_incre_x && hy_optim>min_incre_y && hy_optim<max_incre_y
// 					)
				if (optim_gn_drhxhyck_NCCcontrolled(vKs, vRs, vts, vImgs, vIdxValidCam, k, j_real, i_real, size, size,
					depth_init, hx_init, hy_init, depth_optim, hx_optim, hy_optim, maxIter, xEps, fEps) &&
					depth_optim>min_depth && depth_optim<max_depth
					//&& isvalid_hxhy(fx_ref,fy_ref,nimgx,nimgy,depth_optim,hx_optim,hy_optim,thresh_normdir)// hx_optim>min_incre_x && hx_optim<max_incre_x && hy_optim>min_incre_y && hy_optim<max_incre_y
					)
				{
					vDepths[k].at<float>(i,j) = depth_optim;
					vHxs[k].at<float>(i,j) = hx_optim;
					vHys[k].at<float>(i,j) = hy_optim;
				}
				else
				{
					vVisis[k].at<uchar>(i,j) = vVisiNs[k].at<uchar>(i,j) = 0;
					vScores[k].at<float>(i,j) = -1;
				}
			}
		}
	}

	// output runtime info
	double thresh_ncc = 0.6;
	double maxncc_minncc_1 = 1/(1-thresh_ncc);
	// output runtime info
	for (kk=0;kk<nImg;kk++)
	{
		Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3), mVisiN_map(imgHeight, imgWidth, CV_8UC3);

		double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

		minMaxIdx(vDepths[kk], &min_depth, &max_depth);
		minMaxIdx(vHxs[kk], &min_incre_x, &max_incre_x);
		minMaxIdx(vHys[kk], &min_incre_y, &max_incre_y);

		vDepths[kk].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
		vHxs[kk].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
		vHys[kk].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

		for (i=0;i<imgHeight;i++)
		{
			for (j=0;j<imgWidth;j++)
			{
				if (vScores[kk].at<float>(i,j)<0)
				{
					mScore_map.at<Vec3b>(i,j).val[0] = 0;
					mScore_map.at<Vec3b>(i,j).val[1] = 0;
					mScore_map.at<Vec3b>(i,j).val[2] = 255;
				}
				else
				{
					mScore_map.at<Vec3b>(i,j).val[0] = 0;
					mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*(vScores[kk].at<float>(i,j)-thresh_ncc)*maxncc_minncc_1);
					mScore_map.at<Vec3b>(i,j).val[2] = 0;
				}

				uchar nnn = vVisiNs[kk].at<uchar>(i,j);

				if (nnn==0)
				{
					mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
				}
				else if (nnn==1)
				{
					mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
					mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
				}
				else if (nnn==2)
				{
					mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
					mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
				}
				else if (nnn==3)
				{
					mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
					mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
				}
				else
				{
					mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
					mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
					mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
				}
			}
		}

		strInfo.Format("D:\\all\\depth map MPGC ref %02d.bmp", kk);
		imwrite(strInfo.GetBuffer(), mDepth_map);
		strInfo.Format("D:\\all\\hx map MPGC ref %02d.bmp", kk);
		imwrite(strInfo.GetBuffer(), mHx_map);
		strInfo.Format("D:\\all\\hy map MPGC ref %02d.bmp", kk);
		imwrite(strInfo.GetBuffer(), mHy_map);
		strInfo.Format("D:\\all\\score map MPGC ref %02d.bmp", kk);
		imwrite(strInfo.GetBuffer(), mScore_map);
		strInfo.Format("D:\\all\\visi map MPGC ref %02d.bmp", kk);
		imwrite(strInfo.GetBuffer(), vVisis[kk]);
		strInfo.Format("D:\\all\\visiN map MPGC ref %02d.bmp", kk);
		imwrite(strInfo.GetBuffer(), mVisiN_map);
		strInfo.Format("D:\\all\\cloud points MPGC ref %02d.txt", kk);
		WriteDepthMap(strInfo,vCams[kk],vImgs[kk],vDepths[kk],vScores[kk]);
	}
}

void DeepVoid::CheckOnePixel_givenOneParamSet(const vector<cam_data> & vCams,	// input:	all camera data
											  int idx_refimg,				// input:	the index of the reference image
											  int x, int y,					// input:	the indices of the pixel to be checked
											  double depth,					// input:	the depth assigned to this pixel
											  double hx, double hy,			// input:	the depth incremental factor along x and y axis assigned to this pixel
											  vector<double> & scores,		// output:	all the scores obained by compare the patch in reference image and other patches mapped in other images
											  int size /*= 5*/				// input:	the window size of the image patch
											  )
{
	int i, j, ii,jj;

	scores.clear();

	int nCam = vCams.size();

	cam_data cam_ref = vCams[idx_refimg];

	Matx33d mR_ref,mK_ref;
	Matx31d mt_ref;

	for (ii=0;ii<3;ii++)
	{
		for (jj=0;jj<3;jj++)
		{
			mR_ref(ii,jj) = cam_ref.R[ii*3+jj];
		}
	}
	mK_ref(0,0) = cam_ref.fx; mK_ref(0,1) = cam_ref.s;	mK_ref(0,2) = cam_ref.cx;
	mK_ref(1,1) = cam_ref.fy; mK_ref(1,2) = cam_ref.cy; mK_ref(2,2) = 1;
	mt_ref(0) = cam_ref.t[0]; mt_ref(1) = cam_ref.t[1]; mt_ref(2) = cam_ref.t[2];

	Mat imgsmall0(size, size, CV_8UC3), imgsmalli(size, size, CV_8UC3);

	vector<Point3d> vWrdPts;

	char * pDir = (char *)theApp.m_pMainFrame->m_wndImgThumbnailPane.m_wndImgListCtrl.GetItemData(idx_refimg);

	CString strDir;
	strDir.Format(_T("%s"), pDir);
	strDir.Trim();

	//theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("read image starts");
	Mat img = imread(strDir.GetBuffer(), CV_LOAD_IMAGE_UNCHANGED);
	//theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("read image ends");

	for (i=-(size-1)/2;i<=(size-1)/2;i++)
	{
		for (j=-(size-1)/2;j<=(size-1)/2;j++)
		{
			Matx31d XYZ = GetXYZ_givenDepth(mK_ref, mR_ref, mt_ref, x+j, y+i, depth+hx*j+hy*i);
			Point3d pt3d;
			pt3d.x = XYZ(0);
			pt3d.y = XYZ(1);
			pt3d.z = XYZ(2);
			vWrdPts.push_back(pt3d);

			imgsmall0.at<Vec3b>(i+(size-1)/2, j+(size-1)/2).val[0] = img.at<Vec3b>(y+i,x+j).val[0];
			imgsmall0.at<Vec3b>(i+(size-1)/2, j+(size-1)/2).val[1] = img.at<Vec3b>(y+i,x+j).val[1];
			imgsmall0.at<Vec3b>(i+(size-1)/2, j+(size-1)/2).val[2] = img.at<Vec3b>(y+i,x+j).val[2];
		}
	}

// 	CString pathPatch;
// 	pathPatch.Format("D:\\patches\\imgPatch00_%03d.bmp", idx_choosen);
// 	imwrite(pathPatch.GetBuffer(), imgsmall0);

	for (i=0;i<nCam;i++)
	{
		if (i==idx_refimg)
		{
			scores.push_back(-1);
			continue;
		}

		// read corresponding image data into memory first
		pDir = (char *)theApp.m_pMainFrame->m_wndImgThumbnailPane.m_wndImgListCtrl.GetItemData(i);

		strDir.Format(_T("%s"), pDir);
		strDir.Trim();

		//theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("read image starts");
		img = imread(strDir.GetBuffer(), CV_LOAD_IMAGE_UNCHANGED);
		//theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("read image ends");

		cam_data cami = vCams[i];

		for (ii=0;ii<3;ii++)
		{
			for (jj=0;jj<3;jj++)
			{
				mR_ref(ii,jj) = cami.R[ii*3+jj];
			}
		}
		mK_ref(0,0) = cami.fx;	mK_ref(0,1) = cami.s;  mK_ref(0,2) = cami.cx;
		mK_ref(1,1) = cami.fy; mK_ref(1,2) = cami.cy; mK_ref(2,2) = 1;
		mt_ref(0) = cami.t[0]; mt_ref(1) = cami.t[1]; mt_ref(2) = cami.t[2];

		bool bOutBorder = false;

		//theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("BilinearInterp starts");
		for (ii=0;ii<size;ii++)
		{
			for (jj=0;jj<size;jj++)
			{
				uchar r,g,b;
				if (BilinearInterp(mK_ref,mR_ref,mt_ref,img,vWrdPts[ii*size+jj].x, vWrdPts[ii*size+jj].y, vWrdPts[ii*size+jj].z, r,g,b))
				{
					imgsmalli.at<Vec3b>(ii, jj).val[0] = b;
					imgsmalli.at<Vec3b>(ii, jj).val[1] = g;
					imgsmalli.at<Vec3b>(ii, jj).val[2] = r;
				} 
				else
				{
					bOutBorder = true;
					break;
				}
			}
			if (bOutBorder)
			{
				break;
			}
		}
		//theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("BilinearInterp ends");

		if (bOutBorder)
		{
			scores.push_back(-1);
			continue;
		}

		/// Create the result matrix
		int result_cols =  imgsmalli.cols - imgsmall0.cols + 1;
		int result_rows = imgsmalli.rows - imgsmall0.rows + 1;

		Mat result(result_rows, result_cols, CV_32FC1);

		/// Do the Matching and Normalize
		//theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("ncc starts");
		matchTemplate(imgsmall0, imgsmalli, result, /*CV_TM_SQDIFF_NORMED*/CV_TM_CCORR_NORMED);
		//theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("ncc ends");

		scores.push_back(result.at<float>(0));
		/*scores.push_back(1-result.at<float>(0));*/

// 		pathPatch.Format("D:\\patches\\imgPatch%02d_%03d_%lf.bmp", i, idx_choosen, result.at<float>(0));
// 		imwrite(pathPatch.GetBuffer(), imgsmalli);
	}
}

void DeepVoid::CheckOnePixel_givenOneParamSet(const vector<cam_data> & vCams,	// input:	all camera data
											  const vector<Mat> & vImgs,		// input:	all images
											  int idx_refimg,					// input:	the index of the reference image
											  int x, int y,					// input:	the indices of the pixel to be checked
											  double depth,					// input:	the depth assigned to this pixel
											  double hx, double hy,			// input:	the depth incremental factor along x and y axis assigned to this pixel
											  vector<double> & scores,		// output:	all the scores obained by compare the patch in reference image and other patches mapped in other images
											  int size /*= 5*/					// input:	the window size of the image patch
											  )
{
	int i, j, ii,jj;

	int half_s = (size-1)*0.5;

	scores.clear();

	int nCam = vCams.size();

	cam_data cam_ref = vCams[idx_refimg];

	Matx33d mR_ref,mK_ref;
	Matx31d mt_ref;

	for (ii=0;ii<3;ii++)
	{
		for (jj=0;jj<3;jj++)
		{
			mR_ref(ii,jj) = cam_ref.R[ii*3+jj];
		}
	}
	mK_ref(0,0) = cam_ref.fx; mK_ref(0,1) = cam_ref.s;	mK_ref(0,2) = cam_ref.cx;
	mK_ref(1,1) = cam_ref.fy; mK_ref(1,2) = cam_ref.cy; mK_ref(2,2) = 1;
	mt_ref(0) = cam_ref.t[0]; mt_ref(1) = cam_ref.t[1]; mt_ref(2) = cam_ref.t[2];

	vector<Point3d> vWrdPts;

	Mat img = vImgs[idx_refimg];

	int nChannel = img.channels();

	Mat imgsmall0, imgsmalli;

	if (nChannel==1) // gray level image
	{
		imgsmall0 = Mat(size, size, CV_32FC1); imgsmalli = Mat(size, size, CV_32FC1);

		for (i=-half_s;i<=half_s;i++)
		{
			for (j=-half_s;j<=half_s;j++)
			{
				Matx31d XYZ = GetXYZ_givenDepth(mK_ref, mR_ref, mt_ref, x+j, y+i, depth+hx*j+hy*i);
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);

				imgsmall0.at<float>(i+half_s, j+half_s) = img.at<uchar>(y+i,x+j);
				imgsmall0.at<float>(i+half_s, j+half_s) = img.at<uchar>(y+i,x+j);
				imgsmall0.at<float>(i+half_s, j+half_s) = img.at<uchar>(y+i,x+j);
			}
		}
	} 
	else // color image
	{
		imgsmall0 = Mat(size, size, CV_32FC3); imgsmalli = Mat(size, size, CV_32FC3);

		for (i=-half_s;i<=half_s;i++)
		{
			for (j=-half_s;j<=half_s;j++)
			{
				Matx31d XYZ = GetXYZ_givenDepth(mK_ref, mR_ref, mt_ref, x+j, y+i, depth+hx*j+hy*i);
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);

				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[0] = img.at<Vec3b>(y+i,x+j).val[0];
				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[1] = img.at<Vec3b>(y+i,x+j).val[1];
				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[2] = img.at<Vec3b>(y+i,x+j).val[2];
			}
		}
	}

	//UINT census0 = GetCensusTransform_BitString_55(imgsmall0, 2, 2);
	
	for (i=0;i<nCam;i++)
	{
		if (i==idx_refimg)
		{
			scores.push_back(-1);
			continue;
		}

		img = vImgs[i];

		cam_data cami = vCams[i];

		for (ii=0;ii<3;ii++)
		{
			for (jj=0;jj<3;jj++)
			{
				mR_ref(ii,jj) = cami.R[ii*3+jj];
			}
		}
		mK_ref(0,0) = cami.fx;	mK_ref(0,1) = cami.s;  mK_ref(0,2) = cami.cx;
		mK_ref(1,1) = cami.fy; mK_ref(1,2) = cami.cy; mK_ref(2,2) = 1;
		mt_ref(0) = cami.t[0]; mt_ref(1) = cami.t[1]; mt_ref(2) = cami.t[2];

		vector<Point2d> vImgPts;

		bool bOutBorder = false;

		for (ii=0;ii<size;ii++)
		{
			for (jj=0;jj<size;jj++)
			{
				double r,g,b, imgpt_x, imgpt_y;
				if (BilinearInterp(mK_ref,mR_ref,mt_ref,img,vWrdPts[ii*size+jj].x, vWrdPts[ii*size+jj].y, vWrdPts[ii*size+jj].z, r,g,b, &imgpt_x, &imgpt_y))
				{
					if (nChannel==1)
					{
						imgsmalli.at<float>(ii, jj) = b;
					} 
					else
					{
						imgsmalli.at<Vec3f>(ii, jj).val[0] = b;
						imgsmalli.at<Vec3f>(ii, jj).val[1] = g;
						imgsmalli.at<Vec3f>(ii, jj).val[2] = r;
					}
				} 
				else
				{
					bOutBorder = true;
					break;
				}

				if (ii==0&&jj==0) // topleft
				{
					Point2d pt2d;
					pt2d.x = imgpt_x;
					pt2d.y = imgpt_y;
					vImgPts.push_back(pt2d);
				}
				if (ii==0&&jj==(size-1)) // topright
				{
					Point2d pt2d;
					pt2d.x = imgpt_x;
					pt2d.y = imgpt_y;
					vImgPts.push_back(pt2d);
				}
				if (ii==(size-1)&&jj==0) // bottomleft
				{
					Point2d pt2d;
					pt2d.x = imgpt_x;
					pt2d.y = imgpt_y;
					vImgPts.push_back(pt2d);
				}
				if (ii==(size-1)&&jj==(size-1)) // bottomright
				{
					Point2d pt2d;
					pt2d.x = imgpt_x;
					pt2d.y = imgpt_y;
					vImgPts.push_back(pt2d);
				}
			}
			if (bOutBorder)
			{
				break;
			}
		}

		if (bOutBorder)
		{
			scores.push_back(-1);
			continue;
		}

		double dx1 = vImgPts[1].x-vImgPts[0].x;
		double dx2 = vImgPts[3].x-vImgPts[2].x;
		double dy1 = vImgPts[2].y-vImgPts[0].y;
		double dy2 = vImgPts[3].y-vImgPts[1].y;

		int minLength = 0/*half_s*/;

		if (dx1<minLength||dx2<minLength||dy1<minLength||dy2<minLength)
		{
			scores.push_back(-1);
			continue;
		}

		// Create the result matrix
		int result_cols = imgsmalli.cols - imgsmall0.cols + 1;
		int result_rows = imgsmalli.rows - imgsmall0.rows + 1;
		Mat result(result_rows, result_cols, CV_32FC1);
		matchTemplate(imgsmall0, imgsmalli, result, /*CV_TM_SQDIFF_NORMED*/CV_TM_CCORR_NORMED);
		scores.push_back(result.at<float>(0));
		
		// census transform
// 		UINT censusi = GetCensusTransform_BitString_55(imgsmalli, 2, 2);
// 		UINT dist = hamdist(census0, censusi);
// 		scores.push_back((24-dist)/24.0);
	}
}

void DeepVoid::CheckOnePixel_givenOneParamSet(const vector<Matx33d> & vKs,
											  const vector<Matx33d> & vRs,
											  const vector<Matx31d> & vts,
											  const vector<Mat> & vImgs,	// input:	all images
											  int idx_refimg,				// input:	the index of the reference image
											  int x, int y,					// input:	the indices of the pixel to be checked
											  double depth,					// input:	the depth assigned to this pixel
											  double hx, double hy,			// input:	the depth incremental factor along x and y axis assigned to this pixel
											  vector<double> & scores,		// output:	all the scores obained by compare the patch in reference image and other patches mapped in other images
											  int size /*= 5*/					// input:	the window size of the image patch
											  )
{
	int i, j, ii,jj;

	int half_s = (size-1)*0.5;

	scores.clear();

	int nCam = vKs.size();

	vector<Point3d> vWrdPts;

	Mat img = vImgs[idx_refimg];

	int nChannel = img.channels();

	Mat imgsmall0, imgsmalli;

	if (nChannel==1) // gray level image
	{
		imgsmall0 = Mat(size, size, CV_32FC1); imgsmalli = Mat(size, size, CV_32FC1);

		for (i=-half_s;i<=half_s;i++)
		{
			for (j=-half_s;j<=half_s;j++)
			{
				Matx31d XYZ = GetXYZ_givenDepth(vKs[idx_refimg], vRs[idx_refimg], vts[idx_refimg], x+j, y+i, depth+hx*j+hy*i);
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);

				imgsmall0.at<float>(i+half_s, j+half_s) = img.at<uchar>(y+i,x+j);
				imgsmall0.at<float>(i+half_s, j+half_s) = img.at<uchar>(y+i,x+j);
				imgsmall0.at<float>(i+half_s, j+half_s) = img.at<uchar>(y+i,x+j);
			}
		}
	} 
	else // color image
	{
		imgsmall0 = Mat(size, size, CV_32FC3); imgsmalli = Mat(size, size, CV_32FC3);

		for (i=-half_s;i<=half_s;i++)
		{
			for (j=-half_s;j<=half_s;j++)
			{
				Matx31d XYZ = GetXYZ_givenDepth(vKs[idx_refimg], vRs[idx_refimg], vts[idx_refimg], x+j, y+i, depth+hx*j+hy*i);
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);

				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[0] = img.at<Vec3b>(y+i,x+j).val[0];
				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[1] = img.at<Vec3b>(y+i,x+j).val[1];
				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[2] = img.at<Vec3b>(y+i,x+j).val[2];
			}
		}
	}

	//UINT census0 = GetCensusTransform_BitString_55(imgsmall0, 2, 2);

	for (i=0;i<nCam;i++)
	{
		if (i==idx_refimg)
		{
			scores.push_back(-1);
			continue;
		}

		vector<Point2d> vImgPts;

		bool bOutBorder = false;

		for (ii=0;ii<size;ii++)
		{
			for (jj=0;jj<size;jj++)
			{
				double r,g,b, imgpt_x, imgpt_y;
				if (BilinearInterp(vKs[i],vRs[i],vts[i],vImgs[i],vWrdPts[ii*size+jj].x, vWrdPts[ii*size+jj].y, vWrdPts[ii*size+jj].z, r,g,b, &imgpt_x, &imgpt_y))
				{
					if (nChannel==1)
					{
						imgsmalli.at<float>(ii, jj) = b;
					} 
					else
					{
						imgsmalli.at<Vec3f>(ii, jj).val[0] = b;
						imgsmalli.at<Vec3f>(ii, jj).val[1] = g;
						imgsmalli.at<Vec3f>(ii, jj).val[2] = r;
					}
				} 
				else
				{
					bOutBorder = true;
					break;
				}

				if (ii==0&&jj==0) // topleft
				{
					Point2d pt2d;
					pt2d.x = imgpt_x;
					pt2d.y = imgpt_y;
					vImgPts.push_back(pt2d);
				}
				if (ii==0&&jj==(size-1)) // topright
				{
					Point2d pt2d;
					pt2d.x = imgpt_x;
					pt2d.y = imgpt_y;
					vImgPts.push_back(pt2d);
				}
				if (ii==(size-1)&&jj==0) // bottomleft
				{
					Point2d pt2d;
					pt2d.x = imgpt_x;
					pt2d.y = imgpt_y;
					vImgPts.push_back(pt2d);
				}
				if (ii==(size-1)&&jj==(size-1)) // bottomright
				{
					Point2d pt2d;
					pt2d.x = imgpt_x;
					pt2d.y = imgpt_y;
					vImgPts.push_back(pt2d);
				}
			}
			if (bOutBorder)
			{
				break;
			}
		}

		if (bOutBorder)
		{
			scores.push_back(-1);
			continue;
		}

		double dx1 = vImgPts[1].x-vImgPts[0].x;
		double dx2 = vImgPts[3].x-vImgPts[2].x;
		double dy1 = vImgPts[2].y-vImgPts[0].y;
		double dy2 = vImgPts[3].y-vImgPts[1].y;
		int minLength = half_s;
		if (dx1<minLength||dx2<minLength||dy1<minLength||dy2<minLength)
		{
			scores.push_back(-1);
			continue;
		}

		// Create the result matrix
		int result_cols = imgsmalli.cols - imgsmall0.cols + 1;
		int result_rows = imgsmalli.rows - imgsmall0.rows + 1;
		Mat result(result_rows, result_cols, CV_32FC1);
		matchTemplate(imgsmall0, imgsmalli, result, /*CV_TM_SQDIFF_NORMED*/CV_TM_CCORR_NORMED);
		scores.push_back(result.at<float>(0));
	}
}

void DeepVoid::CheckOnePixel_givenOneParamSet_normalangle(const vector<Matx33d> & vKs,
														  const vector<Matx33d> & vRs,
														  const vector<Matx31d> & vts,
														  const vector<double> & vfx_1,
														  const vector<double> & vfy_1,
														  const vector<Mat> & vImgs,	// input:	all images
														  int idx_refimg,				// input:	the index of the reference image
														  int x, int y,					// input:	the indices of the pixel to be checked
														  double depth,					// input:	the depth assigned to this pixel
														  double hx, double hy,			// input:	the depth incremental factor along x and y axis assigned to this pixel
														  vector<double> & scores,		// output:	all the scores obained by compare the patch in reference image and other patches mapped in other images
														  int size /*= 5*/,				// input:	the window size of the image patch
														  double thresh_angle /*= 60*/
														  )
{
	int i, j, ii,jj;

	int half_s = (size-1)*0.5;

	scores.clear();

	int nCam = vKs.size();

	vector<Point3d> vWrdPts;

	Mat img = vImgs[idx_refimg];

	int nChannel = img.channels();

	Mat imgsmall0, imgsmalli;

	if (nChannel==1) // gray level image
	{
		imgsmall0 = Mat(size, size, CV_32FC1); imgsmalli = Mat(size, size, CV_32FC1);

		for (i=-half_s;i<=half_s;i++)
		{
			for (j=-half_s;j<=half_s;j++)
			{
				Matx31d XYZ = GetXYZ_givenDepth(vKs[idx_refimg], vRs[idx_refimg], vts[idx_refimg], x+j, y+i, depth+hx*j+hy*i);
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);

				imgsmall0.at<float>(i+half_s, j+half_s) = img.at<uchar>(y+i,x+j);
				imgsmall0.at<float>(i+half_s, j+half_s) = img.at<uchar>(y+i,x+j);
				imgsmall0.at<float>(i+half_s, j+half_s) = img.at<uchar>(y+i,x+j);
			}
		}
	} 
	else // color image
	{
		imgsmall0 = Mat(size, size, CV_32FC3); imgsmalli = Mat(size, size, CV_32FC3);

		for (i=-half_s;i<=half_s;i++)
		{
			for (j=-half_s;j<=half_s;j++)
			{
				Matx31d XYZ = GetXYZ_givenDepth(vKs[idx_refimg], vRs[idx_refimg], vts[idx_refimg], x+j, y+i, depth+hx*j+hy*i);
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);

				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[0] = img.at<Vec3b>(y+i,x+j).val[0];
				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[1] = img.at<Vec3b>(y+i,x+j).val[1];
				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[2] = img.at<Vec3b>(y+i,x+j).val[2];
			}
		}
	}

	//UINT census0 = GetCensusTransform_BitString_55(imgsmall0, 2, 2);

	// first, compute the normal corresponds to current parameter set
	double fx0 = vKs[idx_refimg](0,0); double fy0 = vKs[idx_refimg](1,1);
	double cx0 = vKs[idx_refimg](0,2); double cy0 = vKs[idx_refimg](1,2);
	double nimgx = (x-cx0)*vfx_1[idx_refimg];
	double nimgy = (y-cy0)*vfy_1[idx_refimg];
	Matx31d mn0; mn0(2)=1;
	get_normal_givendrhxhy(fx0, fy0, nimgx, nimgy, depth, hx, hy, mn0(0), mn0(1));
	Matx31d mnw = -vRs[idx_refimg].t()*mn0; // convert the normal into world coordinate system
	double nmnw = norm(mnw);

	for (i=0;i<nCam;i++)
	{
		if (i==idx_refimg)
		{
			scores.push_back(-1);
			continue;
		}

		double x_k, y_k;

		bool bOutBorder = false;

		for (ii=0;ii<size;ii++)
		{
			for (jj=0;jj<size;jj++)
			{
				double r,g,b, imgpt_x, imgpt_y;
				if (BilinearInterp(vKs[i],vRs[i],vts[i],vImgs[i],vWrdPts[ii*size+jj].x, vWrdPts[ii*size+jj].y, vWrdPts[ii*size+jj].z, r,g,b, &imgpt_x, &imgpt_y))
				{
					if (nChannel==1)
					{
						imgsmalli.at<float>(ii, jj) = b;
					} 
					else
					{
						imgsmalli.at<Vec3f>(ii, jj).val[0] = b;
						imgsmalli.at<Vec3f>(ii, jj).val[1] = g;
						imgsmalli.at<Vec3f>(ii, jj).val[2] = r;
					}
				} 
				else
				{
					bOutBorder = true;
					break;
				}

				if (ii==half_s&&jj==half_s)
				{
					x_k = imgpt_x;
					y_k = imgpt_y;
				}
			}
			if (bOutBorder)
			{
				break;
			}
		}

		if (bOutBorder)
		{
			scores.push_back(-1);
			continue;
		}

		// current line of sight
		Matx31d msightvec; // from image point to optical center
		msightvec(0) = -(x_k-vKs[i](0,2))*vfx_1[i];
		msightvec(1) = -(y_k-vKs[i](1,2))*vfy_1[i];
		msightvec(2) = -1;
		Matx31d mnk = vRs[i]*mnw;
		Matx<double, 1, 1> mcosa = mnk.t()*msightvec;
		double cosa = mcosa(0)/(nmnw*norm(msightvec));
		double ang = acos(cosa)*R2D;
		if (ang>thresh_angle)
		{
			scores.push_back(-1);
			continue;
		}

		// Create the result matrix
		int result_cols = imgsmalli.cols - imgsmall0.cols + 1;
		int result_rows = imgsmalli.rows - imgsmall0.rows + 1;
		Mat result(result_rows, result_cols, CV_32FC1);
		matchTemplate(imgsmall0, imgsmalli, result, /*CV_TM_SQDIFF_NORMED*/CV_TM_CCORR_NORMED);
		scores.push_back(result.at<float>(0));
	}
}

// 20140729, output the angles between current patch normal estimate and all the sight lines
void DeepVoid::CheckOnePixel_givenOneParamSet_outputAngles(const vector<Matx33d> & vKs,
														   const vector<Matx33d> & vRs,
														   const vector<Matx31d> & vts,
														   const vector<double> & vfx_1,
														   const vector<double> & vfy_1,
														   const vector<Mat> & vImgs,	// input:	all images
														   int idx_refimg,				// input:	the index of the reference image
														   int x, int y,				// input:	the indices of the pixel to be checked
														   double depth,				// input:	the depth assigned to this pixel
														   double hx, double hy,		// input:	the depth incremental factor along x and y axis assigned to this pixel
														   vector<double> & scores,		// output:	all the scores obained by compare the patch in reference image and other patches mapped in other images
														   vector<double> & angles,		// output:	the angles between current patch normal estimate and all the sight lines
														   int size /*= 5*/				// input:	the window size of the image patch
														   )
{
	int i, j, ii,jj;

	int half_s = (size-1)*0.5;

	scores.clear();
	angles.clear();

	int nCam = vKs.size();

	vector<Point3d> vWrdPts;

	Mat img = vImgs[idx_refimg];

	int nChannel = img.channels();

	Mat imgsmall0, imgsmalli;

	if (nChannel==1) // gray level image
	{
		imgsmall0 = Mat(size, size, CV_32FC1); imgsmalli = Mat(size, size, CV_32FC1);

		for (i=-half_s;i<=half_s;i++)
		{
			for (j=-half_s;j<=half_s;j++)
			{
				Matx31d XYZ = GetXYZ_givenDepth(vKs[idx_refimg], vRs[idx_refimg], vts[idx_refimg], x+j, y+i, depth+hx*j+hy*i);
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);

				imgsmall0.at<float>(i+half_s, j+half_s) = img.at<uchar>(y+i,x+j);
				imgsmall0.at<float>(i+half_s, j+half_s) = img.at<uchar>(y+i,x+j);
				imgsmall0.at<float>(i+half_s, j+half_s) = img.at<uchar>(y+i,x+j);
			}
		}
	} 
	else // color image
	{
		imgsmall0 = Mat(size, size, CV_32FC3); imgsmalli = Mat(size, size, CV_32FC3);

		for (i=-half_s;i<=half_s;i++)
		{
			for (j=-half_s;j<=half_s;j++)
			{
				Matx31d XYZ = GetXYZ_givenDepth(vKs[idx_refimg], vRs[idx_refimg], vts[idx_refimg], x+j, y+i, depth+hx*j+hy*i);
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);

				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[0] = img.at<Vec3b>(y+i,x+j).val[0];
				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[1] = img.at<Vec3b>(y+i,x+j).val[1];
				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[2] = img.at<Vec3b>(y+i,x+j).val[2];
			}
		}
	}

	//UINT census0 = GetCensusTransform_BitString_55(imgsmall0, 2, 2);

	// first, compute the normal corresponds to current parameter set
	double fx0 = vKs[idx_refimg](0,0); double fy0 = vKs[idx_refimg](1,1);
	double cx0 = vKs[idx_refimg](0,2); double cy0 = vKs[idx_refimg](1,2);
	double nimgx = (x-cx0)*vfx_1[idx_refimg];
	double nimgy = (y-cy0)*vfy_1[idx_refimg];
	Matx31d mn0; mn0(2)=1;
	get_normal_givendrhxhy(fx0, fy0, nimgx, nimgy, depth, hx, hy, mn0(0), mn0(1));
	Matx31d mnw = -vRs[idx_refimg].t()*mn0; // convert the normal into world coordinate system
	double nmnw = norm(mnw);

	for (i=0;i<nCam;i++)
	{
		if (i==idx_refimg)
		{
			scores.push_back(-1);
			angles.push_back(-1);
			continue;
		}

		double x_k, y_k;

		bool bOutBorder = false;

		for (ii=0;ii<size;ii++)
		{
			for (jj=0;jj<size;jj++)
			{
				double r,g,b, imgpt_x, imgpt_y;
				if (BilinearInterp(vKs[i],vRs[i],vts[i],vImgs[i],vWrdPts[ii*size+jj].x, vWrdPts[ii*size+jj].y, vWrdPts[ii*size+jj].z, r,g,b, &imgpt_x, &imgpt_y))
				{
					if (nChannel==1)
					{
						imgsmalli.at<float>(ii, jj) = b;
					} 
					else
					{
						imgsmalli.at<Vec3f>(ii, jj).val[0] = b;
						imgsmalli.at<Vec3f>(ii, jj).val[1] = g;
						imgsmalli.at<Vec3f>(ii, jj).val[2] = r;
					}
				} 
				else
				{
					bOutBorder = true;
					break;
				}

				if (ii==half_s&&jj==half_s)
				{
					x_k = imgpt_x;
					y_k = imgpt_y;
				}
			}
			if (bOutBorder)
			{
				break;
			}
		}

		if (bOutBorder)
		{
			scores.push_back(-1);
			angles.push_back(-1);
			continue;
		}

		// current line of sight
		Matx31d msightvec; // from image point to optical center
		msightvec(0) = -(x_k-vKs[i](0,2))*vfx_1[i];
		msightvec(1) = -(y_k-vKs[i](1,2))*vfy_1[i];
		msightvec(2) = -1;
		Matx31d mnk = vRs[i]*mnw;
		Matx<double, 1, 1> mcosa = mnk.t()*msightvec;
		double cosa = mcosa(0)/(nmnw*norm(msightvec));
		double ang = acos(cosa)*R2D;
		angles.push_back(ang);
		

		// Create the result matrix
		int result_cols = imgsmalli.cols - imgsmall0.cols + 1;
		int result_rows = imgsmalli.rows - imgsmall0.rows + 1;
		Mat result(result_rows, result_cols, CV_32FC1);
		matchTemplate(imgsmall0, imgsmalli, result, /*CV_TM_SQDIFF_NORMED*/CV_TM_CCORR_NORMED);
		scores.push_back(result.at<float>(0));
	}
}

// 20140802, check one parameter set wrt one particular image not all support images
void DeepVoid::CheckOnePixel_givenOneParamSet_oneImg(const Matx33d & mK0, const Matx33d & mK,	// input: mK0 reference image, mK one specific support image
												     const Matx33d & mR0, const Matx33d & mR,	// input: mR0 reference image, mR one specific support image
												     const Matx31d & mt0, const Matx31d & mt,	// input: mt0 reference image, mt one specific support image
												     double fx0_1, double fx_1,					// input: fx0_1 = 1/fx0, fx_1 = 1/fx
												     double fy0_1, double fy_1,					// input: fy0_1 = 1/fy0, fy_1 = 1/fy
												     const Mat & img0, const Mat & img,			// input: reference image and the support image
												     int x, int y,								// input:	the indices of the pixel to be checked
												     double depth,								// input:	the depth assigned to this pixel
												     double hx, double hy,						// input:	the depth incremental factor along x and y axis assigned to this pixel
												     double & score,							// output:	evaluation score of current parameter set
													 double & angle,							// output:	the angle between current patch normal estimate and the sight line wrt support image
												     int size /*= 5*/							// input:	the window size of the image patch
												     )
{
	int i, j, ii,jj;

	int half_s = (size-1)*0.5;

	vector<Point3d> vWrdPts;

	int nChannel = img0.channels();

	Mat imgsmall0, imgsmalli;

	if (nChannel==1) // gray level image
	{
		imgsmall0 = Mat(size, size, CV_32FC1); imgsmalli = Mat(size, size, CV_32FC1);

		for (i=-half_s;i<=half_s;i++)
		{
			for (j=-half_s;j<=half_s;j++)
			{
				Matx31d XYZ = GetXYZ_givenDepth(mK0, mR0, mt0, x+j, y+i, depth+hx*j+hy*i);
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);

				imgsmall0.at<float>(i+half_s, j+half_s) = img0.at<uchar>(y+i,x+j);
				imgsmall0.at<float>(i+half_s, j+half_s) = img0.at<uchar>(y+i,x+j);
				imgsmall0.at<float>(i+half_s, j+half_s) = img0.at<uchar>(y+i,x+j);
			}
		}
	} 
	else // color image
	{
		imgsmall0 = Mat(size, size, CV_32FC3); imgsmalli = Mat(size, size, CV_32FC3);

		for (i=-half_s;i<=half_s;i++)
		{
			for (j=-half_s;j<=half_s;j++)
			{
				Matx31d XYZ = GetXYZ_givenDepth(mK0, mR0, mt0, x+j, y+i, depth+hx*j+hy*i);
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);

				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[0] = img0.at<Vec3b>(y+i,x+j).val[0];
				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[1] = img0.at<Vec3b>(y+i,x+j).val[1];
				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[2] = img0.at<Vec3b>(y+i,x+j).val[2];
			}
		}
	}

	// first, compute the normal corresponds to current parameter set
	double fx0 = mK0(0,0); double fy0 = mK0(1,1);
	double cx0 = mK0(0,2); double cy0 = mK0(1,2);
	double nimgx = (x-cx0)*fx0_1;
	double nimgy = (y-cy0)*fy0_1;
	Matx31d mn0; mn0(2)=1;
	get_normal_givendrhxhy(fx0, fy0, nimgx, nimgy, depth, hx, hy, mn0(0), mn0(1));
	Matx31d mnw = -mR0.t()*mn0; // convert the normal into world coordinate system
	double nmnw = norm(mnw);

	//////////////////////////////////////////////////////////////////////////
	double x_k, y_k;

	bool bOutBorder = false;

	for (ii=0;ii<size;ii++)
	{
		for (jj=0;jj<size;jj++)
		{
			double r,g,b, imgpt_x, imgpt_y;
			if (BilinearInterp(mK,mR,mt,img,vWrdPts[ii*size+jj].x, vWrdPts[ii*size+jj].y, vWrdPts[ii*size+jj].z, r,g,b, &imgpt_x, &imgpt_y))
			{
				if (nChannel==1)
				{
					imgsmalli.at<float>(ii, jj) = b;
				} 
				else
				{
					imgsmalli.at<Vec3f>(ii, jj).val[0] = b;
					imgsmalli.at<Vec3f>(ii, jj).val[1] = g;
					imgsmalli.at<Vec3f>(ii, jj).val[2] = r;
				}
			} 
			else
			{
				bOutBorder = true;
				break;
			}

			if (ii==half_s&&jj==half_s)
			{
				x_k = imgpt_x;
				y_k = imgpt_y;
			}
		}
		if (bOutBorder)
		{
			break;
		}
	}

	if (bOutBorder)
	{
		score = -1;
		angle = -1;
		return;
	}

	// current line of sight
	Matx31d msightvec; // from image point to optical center
	msightvec(0) = -(x_k-mK(0,2))*fx_1;
	msightvec(1) = -(y_k-mK(1,2))*fy_1;
	msightvec(2) = -1;
	Matx31d mnk = mR*mnw;
	Matx<double, 1, 1> mcosa = mnk.t()*msightvec;
	double cosa = mcosa(0)/(nmnw*norm(msightvec));
	double ang = acos(cosa)*R2D;
	angle = ang;
//	if (ang>=90){score=-1;return;} // ang is supposed to be smaller than 90 if it is visible


	// Create the result matrix
	int result_cols = imgsmalli.cols - imgsmall0.cols + 1;
	int result_rows = imgsmalli.rows - imgsmall0.rows + 1;
	Mat result(result_rows, result_cols, CV_32FC1);
	matchTemplate(imgsmall0, imgsmalli, result, /*CV_TM_SQDIFF_NORMED*/CV_TM_CCORR_NORMED);
	score = result.at<float>(0);
}

// 20140914, self-contained version, check one parameter set wrt one particular image not all support images
void DeepVoid::CheckOnePixel_givenOneParamSet_oneImg(const Matx33d & mK0, 	// input: mK0 reference image
												     const Matx33d & mR0, 	// input: mR0 reference image
												     const Matx31d & mt0, 	// input: mt0 reference image
												     const Mat & img0,		// input: the reference image
												     double fx0_1,			// input: fx0_1 = 1/fx0
												     double fy0_1, 			// input: fy0_1 = 1/fy0
												     const Matx33d & mK,	// input: mK one specific support image
												     const Matx33d & mR,	// input: mR one specific support image
												     const Matx31d & mt,	// input: mt one specific support image
												     const Mat & img,		// input: the support image
												     double fx_1,			// input: fx_1 = 1/fx
												     double fy_1,			// input: fy_1 = 1/fy
												     int x, int y,			// input:	the indices of the pixel to be checked
												     double depth,			// input:	the depth assigned to this pixel
												     double hx, double hy,	// input:	the depth incremental factor along x and y axis assigned to this pixel
												     double & score,		// output:	evaluation score of current parameter set
												     double & angle,		// output:	the angle between current patch normal estimate and the sight line wrt support image
												     int size /*= 5*/		// input:	the window size of the image patch
												     )
{
	int i, j, ii,jj;

	int half_s = (size-1)*0.5;

	vector<Point3d> vWrdPts;

	int nChannel = img0.channels();

	Mat imgsmall0, imgsmalli;

	if (nChannel==1) // gray level image
	{
		imgsmall0 = Mat(size, size, CV_32FC1); imgsmalli = Mat(size, size, CV_32FC1);

		for (i=-half_s;i<=half_s;i++)
		{
			for (j=-half_s;j<=half_s;j++)
			{
				Matx31d XYZ = GetXYZ_givenDepth(mK0, mR0, mt0, x+j, y+i, depth+hx*j+hy*i);
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);

				imgsmall0.at<float>(i+half_s, j+half_s) = img0.at<uchar>(y+i,x+j);
				imgsmall0.at<float>(i+half_s, j+half_s) = img0.at<uchar>(y+i,x+j);
				imgsmall0.at<float>(i+half_s, j+half_s) = img0.at<uchar>(y+i,x+j);
			}
		}
	} 
	else // color image
	{
		imgsmall0 = Mat(size, size, CV_32FC3); imgsmalli = Mat(size, size, CV_32FC3);

		for (i=-half_s;i<=half_s;i++)
		{
			for (j=-half_s;j<=half_s;j++)
			{
				Matx31d XYZ = GetXYZ_givenDepth(mK0, mR0, mt0, x+j, y+i, depth+hx*j+hy*i);
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);

				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[0] = img0.at<Vec3b>(y+i,x+j).val[0];
				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[1] = img0.at<Vec3b>(y+i,x+j).val[1];
				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[2] = img0.at<Vec3b>(y+i,x+j).val[2];
			}
		}
	}

	// first, compute the normal corresponds to current parameter set
	double fx0 = mK0(0,0); double fy0 = mK0(1,1);
	double cx0 = mK0(0,2); double cy0 = mK0(1,2);
	double nimgx = (x-cx0)*fx0_1;
	double nimgy = (y-cy0)*fy0_1;
	Matx31d mn0; mn0(2)=1;
	get_normal_givendrhxhy(fx0, fy0, nimgx, nimgy, depth, hx, hy, mn0(0), mn0(1));
	Matx31d mnw = -mR0.t()*mn0; // convert the normal into world coordinate system
	double nmnw = norm(mnw);

	//////////////////////////////////////////////////////////////////////////
	double x_k, y_k;

	bool bOutBorder = false;

	for (ii=0;ii<size;ii++)
	{
		for (jj=0;jj<size;jj++)
		{
			double r,g,b, imgpt_x, imgpt_y;
			if (BilinearInterp(mK,mR,mt,img,vWrdPts[ii*size+jj].x, vWrdPts[ii*size+jj].y, vWrdPts[ii*size+jj].z, r,g,b, &imgpt_x, &imgpt_y))
			{
				if (nChannel==1)
				{
					imgsmalli.at<float>(ii, jj) = b;
				} 
				else
				{
					imgsmalli.at<Vec3f>(ii, jj).val[0] = b;
					imgsmalli.at<Vec3f>(ii, jj).val[1] = g;
					imgsmalli.at<Vec3f>(ii, jj).val[2] = r;
				}
			} 
			else
			{
				bOutBorder = true;
				break;
			}

			if (ii==half_s&&jj==half_s)
			{
				x_k = imgpt_x;
				y_k = imgpt_y;
			}
		}
		if (bOutBorder)
		{
			break;
		}
	}

	if (bOutBorder)
	{
		score = -1;
		angle = -1;
		return;
	}

	// current line of sight
	Matx31d msightvec; // from image point to optical center
	msightvec(0) = -(x_k-mK(0,2))*fx_1;
	msightvec(1) = -(y_k-mK(1,2))*fy_1;
	msightvec(2) = -1;
	Matx31d mnk = mR*mnw;
	Matx<double, 1, 1> mcosa = mnk.t()*msightvec;
	double cosa = mcosa(0)/(nmnw*norm(msightvec));
	double ang = acos(cosa)*R2D;
	angle = ang;
	//	if (ang>=90){score=-1;return;} // ang is supposed to be smaller than 90 if it is visible


	// Create the result matrix
	int result_cols = imgsmalli.cols - imgsmall0.cols + 1;
	int result_rows = imgsmalli.rows - imgsmall0.rows + 1;
	Mat result(result_rows, result_cols, CV_32FC1);
	matchTemplate(imgsmall0, imgsmalli, result, /*CV_TM_SQDIFF_NORMED*/CV_TM_CCORR_NORMED);
	score = result.at<float>(0);
}

// 20140805, check one parameter set wrt multiple designated visible images not all support images
void DeepVoid::CheckOnePixel_givenOneParamSet_mulImg(const Matx33d & mK0, const vector<Matx33d> & vKs,	// input: mK0 reference image, vKs multiple designated visible images
												     const Matx33d & mR0, const vector<Matx33d> & vRs,	// input: mR0 reference image, vRs multiple designated visible images
												     const Matx31d & mt0, const vector<Matx31d> & vts,	// input: mt0 reference image, vts multiple designated visible images
												     double fx0_1, const vector<double> & vfx_1,		// input: fx0_1 = 1/fx0, fx_1 = 1/fx
												     double fy0_1, const vector<double> & vfy_1,		// input: fy0_1 = 1/fy0, fy_1 = 1/fy
												     const Mat & img0, const vector<Mat> & vImgs,		// input: reference image and all the support images
												     int x, int y,										// input:	the indices of the pixel to be checked
												     double depth,										// input:	the depth assigned to this pixel
												     double hx, double hy,								// input:	the depth incremental factor along x and y axis assigned to this pixel
												     uchar visi,										// input:	the designated visibility wrt the support images
												     double & score,									// output:	evaluation score of current parameter set
												     int size /*= 5*/									// input:	the window size of the image patch
												     )
{
	int i, j, k, ii,jj;

	int nCam = vKs.size(); // the number of support images

	int half_s = (size-1)*0.5;

	vector<Point3d> vWrdPts;

	int nChannel = img0.channels();

	Mat imgsmall0, imgsmalli;

	if (nChannel==1) // gray level image
	{
		imgsmall0 = Mat(size, size, CV_32FC1); imgsmalli = Mat(size, size, CV_32FC1);

		for (i=-half_s;i<=half_s;i++)
		{
			for (j=-half_s;j<=half_s;j++)
			{
				Matx31d XYZ = GetXYZ_givenDepth(mK0, mR0, mt0, x+j, y+i, depth+hx*j+hy*i);
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);

				imgsmall0.at<float>(i+half_s, j+half_s) = img0.at<uchar>(y+i,x+j);
				imgsmall0.at<float>(i+half_s, j+half_s) = img0.at<uchar>(y+i,x+j);
				imgsmall0.at<float>(i+half_s, j+half_s) = img0.at<uchar>(y+i,x+j);
			}
		}
	} 
	else // color image
	{
		imgsmall0 = Mat(size, size, CV_32FC3); imgsmalli = Mat(size, size, CV_32FC3);

		for (i=-half_s;i<=half_s;i++)
		{
			for (j=-half_s;j<=half_s;j++)
			{
				Matx31d XYZ = GetXYZ_givenDepth(mK0, mR0, mt0, x+j, y+i, depth+hx*j+hy*i);
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);

				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[0] = img0.at<Vec3b>(y+i,x+j).val[0];
				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[1] = img0.at<Vec3b>(y+i,x+j).val[1];
				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[2] = img0.at<Vec3b>(y+i,x+j).val[2];
			}
		}
	}

	// first, compute the normal corresponds to current parameter set
	double fx0 = mK0(0,0); double fy0 = mK0(1,1);
	double cx0 = mK0(0,2); double cy0 = mK0(1,2);
	double nimgx = (x-cx0)*fx0_1;
	double nimgy = (y-cy0)*fy0_1;
	Matx31d mn0; mn0(2)=1;
	get_normal_givendrhxhy(fx0, fy0, nimgx, nimgy, depth, hx, hy, mn0(0), mn0(1));
	Matx31d mnw = -mR0.t()*mn0; // convert the normal into world coordinate system
	double nmnw = norm(mnw);

	//////////////////////////////////////////////////////////////////////////
	vector<bool> vbools; int nvisi;
	InterpVisiVector_uchar(visi, vbools, &nvisi);

	double sum_score = 0;

	for (k=0;k<nCam;k++)
	{
		if (!vbools[k]){continue;}

		double x_k, y_k;

		bool bOutBorder = false;

		for (ii=0;ii<size;ii++)
		{
			for (jj=0;jj<size;jj++)
			{
				double r,g,b, imgpt_x, imgpt_y;
				if (BilinearInterp(vKs[k],vRs[k],vts[k],vImgs[k],vWrdPts[ii*size+jj].x, vWrdPts[ii*size+jj].y, vWrdPts[ii*size+jj].z, r,g,b, &imgpt_x, &imgpt_y))
				{
					if (nChannel==1)
					{
						imgsmalli.at<float>(ii, jj) = b;
					} 
					else
					{
						imgsmalli.at<Vec3f>(ii, jj).val[0] = b;
						imgsmalli.at<Vec3f>(ii, jj).val[1] = g;
						imgsmalli.at<Vec3f>(ii, jj).val[2] = r;
					}
				} 
				else
				{
					bOutBorder = true;
					break;
				}

				if (ii==half_s&&jj==half_s)
				{
					x_k = imgpt_x;
					y_k = imgpt_y;
				}
			}
			if (bOutBorder)
			{
				break;
			}
		}

		if (bOutBorder){continue;}

		// current line of sight
		Matx31d msightvec; // from image point to optical center
		msightvec(0) = -(x_k-vKs[k](0,2))*vfx_1[k];
		msightvec(1) = -(y_k-vKs[k](1,2))*vfy_1[k];
		msightvec(2) = -1;
		Matx31d mnk = vRs[k]*mnw;
		Matx<double, 1, 1> mcosa = mnk.t()*msightvec;
		double cosa = mcosa(0)/(nmnw*norm(msightvec));
		double ang = acos(cosa)*R2D; // 0-180
//		if (ang>=90){continue;} // ang is supposed to be smaller than 90 if it is visible


		// Create the result matrix
		int result_cols = imgsmalli.cols - imgsmall0.cols + 1;
		int result_rows = imgsmalli.rows - imgsmall0.rows + 1;
		Mat result(result_rows, result_cols, CV_32FC1);
		matchTemplate(imgsmall0, imgsmalli, result, /*CV_TM_SQDIFF_NORMED*/CV_TM_CCORR_NORMED);
		double oneScore = result.at<float>(0);

		sum_score += oneScore;
	}

	score = sum_score/nvisi;
}

// 20141210, check one parameter set wrt all support images
void DeepVoid::CheckOnePixel_givenOneParamSet_allSptImgs(const Matx33d & mK0, 			// input: mK0 reference image 
													     const Matx33d & mR0, 			// input: mR0 reference image vRs multiple designated visible images
													     const Matx31d & mt0,			// input: mt0 reference image
													     const Mat & img0,				// input: img0 reference image
													     double fx0_1,					// input: fx0_1 = 1/fx0
													     double fy0_1,					// input: fy0_1 = 1/fy0 
													     const vector<Matx33d> & vKs,	// input: vKs all support images
													     const vector<Matx33d> & vRs,	// input: vRs all support images
													     const vector<Matx31d> & vts,	// input: vts all support images
													     const vector<Mat> & vImgs,		// input: all the support images
													     const vector<double> & vfx_1,	// input: all the support images
													     const vector<double> & vfy_1,	// input: all the support images
													     int x, int y,					// input: the indices of the pixel to be checked
													     double depth,					// input: the depth assigned to this pixel
													     double hx, double hy,			// input: the depth incremental factor along x and y axis assigned to this pixel
													     vector<double> & scores,		// output:all the scores obained by compare the patch in reference image and other patches mapped in other images
													     vector<double> & angles,		// output:the angles between current patch normal estimate and all the sight lines
													     int size /*= 5*/				// input: the window size of the image patch
													     )
{
	scores.clear();
	angles.clear();
	
	int i, j, k, ii,jj;

	int nCam = vKs.size(); // the number of support images

	int half_s = (size-1)*0.5;

	vector<Point3d> vWrdPts;

	int nChannel = img0.channels();

	Mat imgsmall0, imgsmalli;

	if (nChannel==1) // gray level image
	{
		imgsmall0 = Mat(size, size, CV_32FC1); imgsmalli = Mat(size, size, CV_32FC1);

		for (i=-half_s;i<=half_s;i++)
		{
			for (j=-half_s;j<=half_s;j++)
			{
				Matx31d XYZ = GetXYZ_givenDepth(mK0, mR0, mt0, x+j, y+i, depth+hx*j+hy*i);
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);

				imgsmall0.at<float>(i+half_s, j+half_s) = img0.at<uchar>(y+i,x+j);
				imgsmall0.at<float>(i+half_s, j+half_s) = img0.at<uchar>(y+i,x+j);
				imgsmall0.at<float>(i+half_s, j+half_s) = img0.at<uchar>(y+i,x+j);
			}
		}
	} 
	else // color image
	{
		imgsmall0 = Mat(size, size, CV_32FC3); imgsmalli = Mat(size, size, CV_32FC3);

		for (i=-half_s;i<=half_s;i++)
		{
			for (j=-half_s;j<=half_s;j++)
			{
				Matx31d XYZ = GetXYZ_givenDepth(mK0, mR0, mt0, x+j, y+i, depth+hx*j+hy*i);
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);

				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[0] = img0.at<Vec3b>(y+i,x+j).val[0];
				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[1] = img0.at<Vec3b>(y+i,x+j).val[1];
				imgsmall0.at<Vec3f>(i+half_s, j+half_s).val[2] = img0.at<Vec3b>(y+i,x+j).val[2];
			}
		}
	}

	// first, compute the normal corresponds to current parameter set
	double fx0 = mK0(0,0); double fy0 = mK0(1,1);
	double cx0 = mK0(0,2); double cy0 = mK0(1,2);
	double nimgx = (x-cx0)*fx0_1;
	double nimgy = (y-cy0)*fy0_1;
	Matx31d mn0; mn0(2)=1;
	get_normal_givendrhxhy(fx0, fy0, nimgx, nimgy, depth, hx, hy, mn0(0), mn0(1));
	Matx31d mnw = -mR0.t()*mn0; // convert the normal into world coordinate system
	double nmnw = norm(mnw);

	for (k=0;k<nCam;k++)
	{
		double x_k, y_k;

		bool bOutBorder = false;

		for (ii=0;ii<size;ii++)
		{
			for (jj=0;jj<size;jj++)
			{
				double r,g,b, imgpt_x, imgpt_y;
				if (BilinearInterp(vKs[k],vRs[k],vts[k],vImgs[k],vWrdPts[ii*size+jj].x, vWrdPts[ii*size+jj].y, vWrdPts[ii*size+jj].z, r,g,b, &imgpt_x, &imgpt_y))
				{
					if (nChannel==1)
					{
						imgsmalli.at<float>(ii, jj) = b;
					} 
					else
					{
						imgsmalli.at<Vec3f>(ii, jj).val[0] = b;
						imgsmalli.at<Vec3f>(ii, jj).val[1] = g;
						imgsmalli.at<Vec3f>(ii, jj).val[2] = r;
					}
				} 
				else
				{
					bOutBorder = true;
					break;
				}

				if (ii==half_s&&jj==half_s)
				{
					x_k = imgpt_x;
					y_k = imgpt_y;
				}
			}
			if (bOutBorder)
			{
				break;
			}
		}

		if (bOutBorder)
		{
			scores.push_back(-1);
			angles.push_back(-1);
			continue;
		}

		// current line of sight
		Matx31d msightvec; // from image point to optical center
		msightvec(0) = -(x_k-vKs[k](0,2))*vfx_1[k];
		msightvec(1) = -(y_k-vKs[k](1,2))*vfy_1[k];
		msightvec(2) = -1;
		Matx31d mnk = vRs[k]*mnw;
		Matx<double, 1, 1> mcosa = mnk.t()*msightvec;
		double cosa = mcosa(0)/(nmnw*norm(msightvec));
		double ang = acos(cosa)*R2D; // 0-180

		// Create the result matrix
		int result_cols = imgsmalli.cols - imgsmall0.cols + 1;
		int result_rows = imgsmalli.rows - imgsmall0.rows + 1;
		Mat result(result_rows, result_cols, CV_32FC1);
		matchTemplate(imgsmall0, imgsmalli, result, /*CV_TM_SQDIFF_NORMED*/CV_TM_CCORR_NORMED);
		double oneScore = result.at<float>(0);

		scores.push_back(oneScore);
		angles.push_back(ang);
	}
}

double DeepVoid::GetScore(const vector<double> & vScores,
						  double thresh /*= 0.8*/,
						  int minCam /*= 3*/,
						  int * nVisi /*= NULL*/
						  )
{
	int i;

	int n = vScores.size();

	double sum = 0;

	int nValid = 0;
	for (i=0;i<n;i++)
	{
		if (vScores[i]>thresh)
		{
			sum += vScores[i];
			nValid++;
		}
	}

	if (nVisi)
	{
		*nVisi = nValid;
	}

	if (nValid<minCam)
	{
		return -1;
	}
	else
	{
		/*return sum/nValid;*/

		// weighted by the number of images that observed this patch, if two parameter sets have the same average NCC i.e. sum/nValid
		// then the score favers the one with more observed images
		// the min value is thresh*minCam/(n-1), the max value is still 1
		/*return sum/(n-1);*/

		return sum/nValid; // average NCC value, not weighted by number of visible images
	}
}

double DeepVoid::GetScore_angleWeighted(const vector<double> & vScores,
									    const vector<double> & vWeights,
									    double thresh /*= 0.8*/,
									    int minCam /*= 3*/,
									    int * nVisi /*= NULL*/
									    )
{
	int i;

	int n = vScores.size();

	double sum = 0;

	double sum_w = 0;
	int nValid = 0;
	for (i=0;i<n;i++)
	{
		if (vScores[i]>thresh)
		{
			sum += vScores[i]*vWeights[i];
			sum_w += vWeights[i];
			nValid++;
		}
//		sum_w += vWeights[i];
	}

	if (nVisi)
	{
		*nVisi = nValid;
	}

	if (nValid<minCam)
	{
		return -1;
	}
	else
	{
		/*return sum/nValid;*/

		// weighted by the number of images that observed this patch, if two parameter sets have the same average NCC i.e. sum/nValid
		// then the score favers the one with more observed images
		// the min value is thresh*minCam/(n-1), the max value is still 1
		/*return sum/(n-1);*/

		//return sum/nValid; // average NCC value, not weighted by number of visible images
		return sum/sum_w;
	}
}

double DeepVoid::GetScore_allWeighted(const vector<double> & vScores,
									  const vector<double> & vAngs,
									  const vector<double> & vWeights_camangs,
									  double thresh_ncc /*= 0.6*/,
									  double thresh_ang /*= 90*/,
									  int * nVisi /*= NULL*/
									  )
{
	int i;

	int n = vScores.size();

	double sigma_ncc = (1-thresh_ncc)/3.0;
	double sigma_ang = thresh_ang/3.0;

	double sum = 0;

	double sum_w = 0;
	int nValid = 0;
	for (i=0;i<n;i++)
	{
		if (vScores[i]>0)
		{
			double w_ncc = exp_miu_sigma(vScores[i], 1, sigma_ncc);
			double w_ang = exp_miu_sigma(vAngs[i], 0, sigma_ang);
			double w_all = vWeights_camangs[i]*w_ncc*w_ang;
			sum += vScores[i]*w_all;
			sum_w += w_all;
			nValid++;
		}
		//		sum_w += vWeights[i];
	}

	if (nVisi)
	{
		*nVisi = nValid;
	}

	if (nValid<1)
	{
		return -1;
	}
	else
	{
		double meanval = sum/sum_w;

		return meanval;
	}
}

// 20140801 output the weights in percentages
double DeepVoid::GetScore_allWeighted(const vector<double> & vScores,
									  const vector<double> & vAngs,
									  const vector<double> & vWeights_camangs,
									  vector<double> & vWeights_percent,
									  double thresh_ncc /*= 0.6*/,
									  double thresh_ang /*= 90*/,
									  int * nVisi /*= NULL*/
									  )
{
	int i;

	int n = vScores.size();

	vWeights_percent.clear();

	double sigma_ncc = (1-thresh_ncc)/3.0;
	double sigma_ang = thresh_ang/3.0;

	vector<double> vtmp;

	double sum = 0;

	double sum_w = 0;
	int nValid = 0;
	for (i=0;i<n;i++)
	{
		if (vScores[i]>0)
		{
			double w_ncc = exp_miu_sigma(vScores[i], 1, sigma_ncc);
			double w_ang = exp_miu_sigma(vAngs[i], 0, sigma_ang);
			double w_all = vWeights_camangs[i]*w_ncc*w_ang;
			sum += vScores[i]*w_all;
			sum_w += w_all;
			nValid++;

			vtmp.push_back(w_all);
		}
		else
		{
			vtmp.push_back(-1);
		}
		//		sum_w += vWeights[i];
	}

	if (nVisi)
	{
		*nVisi = nValid;
	}

	if (nValid<1)
	{
		for (i=0;i<n;i++)
		{
			vWeights_percent.push_back(-1);
		}

		return -1;
	}
	else
	{
		double sum_w_1 = 1/sum_w;
		double meanval = sum*sum_w_1;

		for (i=0;i<n;i++)
		{
			if (vtmp[i]<0)
			{
				vWeights_percent.push_back(-1);
			} 
			else
			{
				vWeights_percent.push_back(vtmp[i]*sum_w_1);
			}
		}

		return meanval;
	}
}

double DeepVoid::GetScore_fixedVisi(const vector<double> & vScores, uchar visi)
{
	int i, nVisi;

	vector<bool> vbools;
	InterpVisiVector_uchar(visi, vbools, &nVisi);

	if (nVisi==0)
	{
		return -1;
	}

	double sum = 0;
	for (i=0;i<vScores.size();i++)
	{
		if (!vbools[i])
		{
			continue;
		}
		sum+=vScores[i];
	}

	return sum/nVisi;
}

// get the 8-bit visibility vector, if vScores=[-1 0.9 0.4 0.5 0.7], thresh = 0.6, then visi=0001 0010
// |vScores|<=8
uchar DeepVoid::GetVisibilityVector_uchar(const vector<double> & vScores, double thresh /*= 0.6*/)
{
	int i;

	int n = vScores.size();

	uchar visi = 0;

	for (i=n-1;i>=0;i--)
	{
		visi<<=1;

		if (vScores[i]>thresh)
		{
			++visi;
		}
	}

	return visi;
}

uchar DeepVoid::GetVisibilityVector_uchar(const vector<bool> & vbools)
{
	int i;

	int n = vbools.size();

	uchar visi = 0;

	for (i=n-1;i>=0;i--)
	{
		visi<<=1;

		if (vbools[i])
		{
			++visi;
		}
	}

	return visi;
}

// if visi=0001 0010, then vec=[f t f f t f f f]
void DeepVoid::InterpVisiVector_uchar(uchar visi, vector<bool> & vec, int * nValid /*= NULL*/)
{
	vec.clear();

	int nnn = 0;

	int i;
	for (i=0;i<8;i++)
	{
		uchar bit = pow(2.0,i);

		if (bit&visi)
		{
			vec.push_back(true);
			++nnn;
		} 
		else
		{
			vec.push_back(false);
		}
	}

	if (nValid)
	{
		*nValid = nnn;
	}
}

// get the confidence value proposed by M. Goesele in <Multi-view revisited>
double DeepVoid::GetConfidence(const vector<double> & vScores,
							   double thresh /*= 0.6*/,
							   int minCam /*= 1*/
							   )
{
	int i;

	int n = vScores.size();

	double sum = 0;

	int nValid = 0;
	for (i=0;i<n;i++)
	{
		if (vScores[i]>thresh)
		{
			sum += vScores[i]-thresh;
			nValid++;
		}
	}

	if (nValid<minCam)
	{
		return -1;
	}
	else
	{
		return sum/(n-n*thresh+thresh-1);
	}
}

void DeepVoid::EvaluateOneParamSet(const vector<cam_data> & vCams,	// input:	all camera data
								   int idx_refimg,					// input:	the index of the reference image
								   const Mat & mDepth,			// input:	given depth map, the 32FC1 matrix
								   const Mat & mIncre_x,		// input:	given hx map, the 32FC1 matrix
								   const Mat & mIncre_y,		// input:	given hy map, the 32FC1 matrix
								   Mat & mScore,				// output:	the output score matrix corresponding to given parameter set
								   int size /*= 5*/,			// input:	the window size of the image patch, should be odd number
								   double thresh_ncc /*= 0.8*/	// input:	the threshold within which to be considered as a successful ncc
								   )
{
	int i,j;

	int wndSizeHalf = (size-1)/2;
	int imgWidth = mDepth.cols;
	int imgHeight = mDepth.rows;

	mScore = Mat(imgHeight, imgWidth, CV_32FC1);

	CString strInfo;

	for (i=0;i<imgHeight;i++)
	{
		strInfo.Format("evaluate row %04d", i);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		for (j=0;j<imgWidth;j++)
		{
			int i_real, j_real;
			MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

			double depth = mDepth.at<float>(i,j);
			double hx = mIncre_x.at<float>(i,j);
			double hy = mIncre_y.at<float>(i,j);

			vector<double> vScores;
			//theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("check one pixel starts");
			CheckOnePixel_givenOneParamSet(vCams,idx_refimg,j_real,i_real,depth,hx,hy,vScores,size);
			//theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("check one pixel ends");
			mScore.at<float>(i,j)=GetScore(vScores, thresh_ncc, 3);
		}
	}
}

void DeepVoid::EvaluateOneParamSet(const vector<cam_data> & vCams,	// input:	all camera data
								   const vector<Mat> & vImgs,		// input:	all images
								   int idx_refimg,					// input:	the index of the reference image
								   const Mat & mDepth,				// input:	given depth map, the 32FC1 matrix
								   const Mat & mIncre_x,			// input:	given hx map, the 32FC1 matrix
								   const Mat & mIncre_y,			// input:	given hy map, the 32FC1 matrix
								   Mat & mScore,					// output:	the output score matrix corresponding to given parameter set
								   int mincam /*= 3*/,
								   int size /*= 5*/,				// input:	the window size of the image patch, should be odd number
								   double thresh_ncc /*= 0.8*/		// input:	the threshold within which to be considered as a successful ncc
								   )
{
	int i,j;

	int wndSizeHalf = (size-1)/2;
	int imgWidth = mDepth.cols;
	int imgHeight = mDepth.rows;

	mScore = Mat(imgHeight, imgWidth, CV_32FC1);

	CString strInfo;

	for (i=0;i<imgHeight;i++)
	{
		strInfo.Format("evaluate row %04d", i);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		for (j=0;j<imgWidth;j++)
		{
			int i_real, j_real;
			MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

			double depth = mDepth.at<float>(i,j);
			double hx = mIncre_x.at<float>(i,j);
			double hy = mIncre_y.at<float>(i,j);

			vector<double> vScores;
			//theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("check one pixel starts");
			CheckOnePixel_givenOneParamSet(vCams,vImgs,idx_refimg,j_real,i_real,depth,hx,hy,vScores,size);
			//theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("check one pixel ends");
			mScore.at<float>(i,j)=GetScore(vScores, thresh_ncc, mincam);
		}
	}
}

void DeepVoid::WriteDepthMap(CString strFile,		// input:	the file to write
							 const cam_data & cam,// input:	the camera parameters
							 const Mat & img,		// input:	the image
							 const Mat & mDepth,	// input:	given depth map relative to the given image
							 const Mat & mScores	// input:	the confidence map of the given depth map, if -1 means the corresponding depth is invalid
							 )
{
	int i,j,ii,jj;

	int imgWidth = img.cols;
	int imgHeight = img.rows;

	Matx33d mR,mK;
	Matx31d mt;

	for (ii=0;ii<3;ii++)
	{
		for (jj=0;jj<3;jj++)
		{
			mR(ii,jj) = cam.R[ii*3+jj];
		}
	}
	mK(0,0) = cam.fx; mK(0,1) = cam.s;	mK(0,2) = cam.cx;
	mK(1,1) = cam.fy; mK(1,2) = cam.cy; mK(2,2) = 1;
	mt(0) = cam.t[0]; mt(1) = cam.t[1]; mt(2) = cam.t[2];

	FILE * file = fopen(strFile, "w");
	for (i=0;i<imgHeight;i++)
	{
		for (j=0;j<imgWidth;j++)
		{
			if (mScores.at<float>(i,j)<0)
			{
				continue;
			}

			double depth = mDepth.at<float>(i,j);

			Matx31d XYZ = GetXYZ_givenDepth(mK, mR, mt, j, i, depth);

			int rgbRed,rgbGreen,rgbBlue;

			if (1 == img.channels())
			{
				Scalar pix = img.at<uchar>(i,j);
				rgbRed = rgbGreen = rgbBlue = pix.val[0];
			} 
			else
			{
				Vec3b pix = img.at<Vec3b>(i,j);
				rgbBlue = pix.val[0]; rgbGreen = pix.val[1]; rgbRed = pix.val[2];
			}

			fprintf(file, "%.12f;%.12f;%.12f;%d;%d;%d\n", XYZ(0), XYZ(1), XYZ(2), rgbRed, rgbGreen, rgbBlue);
		}
	}
	fclose(file);
}

void DeepVoid::OutputPointCloud(CString strFile,		// input:	the file to write
							    const cam_data & cam,// input:	the camera parameters
							    const Mat & img,		// input:	the image
							    const Mat & mDepth,	// input:	given depth map relative to the given image
							    const Mat & mHx,
							    const Mat & mHy,
							    const Mat & mScores	// input:	the confidence map of the given depth map, if -1 means the corresponding depth is invalid
							    )
{
	int i,j,ii,jj;

	int imgWidth = img.cols;
	int imgHeight = img.rows;

	Matx33d mR,mK;
	Matx31d mt;

	for (ii=0;ii<3;ii++)
	{
		for (jj=0;jj<3;jj++)
		{
			mR(ii,jj) = cam.R[ii*3+jj];
		}
	}
	mK(0,0) = cam.fx; mK(0,1) = cam.s;	mK(0,2) = cam.cx;
	mK(1,1) = cam.fy; mK(1,2) = cam.cy; mK(2,2) = 1;
	mt(0) = cam.t[0]; mt(1) = cam.t[1]; mt(2) = cam.t[2];

	double fx_1 = 1/cam.fx;
	double fy_1 = 1/cam.fy;

	FILE * file = fopen(strFile, "w");
	for (i=0;i<imgHeight;i++)
	{
		double nimgy = (i-cam.cy)*fy_1;

		for (j=0;j<imgWidth;j++)
		{
			if (mScores.at<float>(i,j)<0)
			{
				continue;
			}

			double nimgx = (j-cam.cx)*fx_1;

			double depth = mDepth.at<float>(i,j);
			double hx = mHx.at<float>(i,j);
			double hy = mHy.at<float>(i,j);

			Matx31d XYZ = GetXYZ_givenDepth(mK, mR, mt, j, i, depth);

			// get the normal of current obtained parameters
			Matx31d mn0; mn0(2)=1;
			get_normal_givendrhxhy(cam.fx, cam.fy, nimgx, nimgy, depth, hx, hy, mn0(0), mn0(1));
			Matx31d mnw = -mR.t()*mn0; // convert the normal into world coordinate system
			double normN = norm(mnw);
			mnw(0)/=normN;mnw(1)/=normN;mnw(2)/=normN;

			int rgbRed,rgbGreen,rgbBlue;

			if (1 == img.channels())
			{
				Scalar pix = img.at<uchar>(i,j);
				rgbRed = rgbGreen = rgbBlue = pix.val[0];
			} 
			else
			{
				Vec3b pix = img.at<Vec3b>(i,j);
				rgbBlue = pix.val[0]; rgbGreen = pix.val[1]; rgbRed = pix.val[2];
			}

			fprintf(file, "%.12f;%.12f;%.12f;%d;%d;%d;%.12f;%.12f;%.12f\n", XYZ(0), XYZ(1), XYZ(2), rgbRed, rgbGreen, rgbBlue, mnw(0), mnw(1), mnw(2));
		}
	}
	fclose(file);
}

void DeepVoid::OutputPointCloud(CString strFile,	// input:	the file to write
							    const Matx33d & mK,	// input:	the camera parameters
							    const Matx33d & mR,
							    const Matx31d & mt,
							    double fx_1,
							    double fy_1,
							    const Mat & img,	// input:	the image
							    const Mat & mDepth,	// input:	given depth map relative to the given image
							    const Mat & mHx,
							    const Mat & mHy,
							    const Mat & mScores	// input:	the confidence map of the given depth map, if -1 means the corresponding depth is invalid
							    )
{
	int i,j,ii,jj;

	int imgWidth = img.cols;
	int imgHeight = img.rows;

	double fx = mK(0,0);
	double fy = mK(1,1);
	double cx = mK(0,2);
	double cy = mK(1,2);

	FILE * file = fopen(strFile, "w");
	for (i=0;i<imgHeight;i++)
	{
		double nimgy = (i-cy)*fy_1;

		for (j=0;j<imgWidth;j++)
		{
			if (mScores.at<float>(i,j)<0)
			{
				continue;
			}

			double nimgx = (j-cx)*fx_1;

			double depth = mDepth.at<float>(i,j);
			double hx = mHx.at<float>(i,j);
			double hy = mHy.at<float>(i,j);

			Matx31d XYZ = GetXYZ_givenDepth(mR, mt, nimgx, nimgy, depth);

			// get the normal of current obtained parameters
			Matx31d mn0; mn0(2)=1;
			get_normal_givendrhxhy(fx, fy, nimgx, nimgy, depth, hx, hy, mn0(0), mn0(1));
			Matx31d mnw = -mR.t()*mn0; // convert the normal into world coordinate system
			double normN = norm(mnw);
			mnw(0)/=normN;mnw(1)/=normN;mnw(2)/=normN;

			int rgbRed,rgbGreen,rgbBlue;

			if (1 == img.channels())
			{
				Scalar pix = img.at<uchar>(i,j);
				rgbRed = rgbGreen = rgbBlue = pix.val[0];
			} 
			else
			{
				Vec3b pix = img.at<Vec3b>(i,j);
				rgbBlue = pix.val[0]; rgbGreen = pix.val[1]; rgbRed = pix.val[2];
			}

			fprintf(file, "%.12f;%.12f;%.12f;%d;%d;%d;%.12f;%.12f;%.12f\n", XYZ(0), XYZ(1), XYZ(2), rgbRed, rgbGreen, rgbBlue, mnw(0), mnw(1), mnw(2));
		}
	}
	fclose(file);
}

void DeepVoid::GetNormColorField(const cam_data & cam,	// input:	the camera parameters
							     const Mat & mDepth,	// input:	given depth map relative to the given image
							     const Mat & mHx,
							     const Mat & mHy,
							     Mat & mNormColor		// output:	3 channel matrix
							     )
{
	int i,j,ii,jj;

	int imgWidth = mDepth.cols;
	int imgHeight = mDepth.rows;

	double max_norm = 1.0;
	double min_norm = -1.0;
	double max_min_1 = 1/(max_norm - min_norm);

	mNormColor = Mat(imgHeight, imgWidth, CV_8UC3);

	Matx33d mR,mK;
	Matx31d mt;

	for (ii=0;ii<3;ii++)
	{
		for (jj=0;jj<3;jj++)
		{
			mR(ii,jj) = cam.R[ii*3+jj];
		}
	}
	mK(0,0) = cam.fx; mK(0,1) = cam.s;	mK(0,2) = cam.cx;
	mK(1,1) = cam.fy; mK(1,2) = cam.cy; mK(2,2) = 1;
	mt(0) = cam.t[0]; mt(1) = cam.t[1]; mt(2) = cam.t[2];

	double fx_1 = 1/cam.fx;
	double fy_1 = 1/cam.fy;

	for (i=0;i<imgHeight;i++)
	{
		double nimgy = (i-cam.cy)*fy_1;

		for (j=0;j<imgWidth;j++)
		{
			double nimgx = (j-cam.cx)*fx_1;

			double depth = mDepth.at<float>(i,j);
			double hx = mHx.at<float>(i,j);
			double hy = mHy.at<float>(i,j);

			Matx31d XYZ = GetXYZ_givenDepth(mK, mR, mt, j, i, depth);

			// get the normal of current obtained parameters
			Matx31d mn0; mn0(2)=1;
			get_normal_givendrhxhy(cam.fx, cam.fy, nimgx, nimgy, depth, hx, hy, mn0(0), mn0(1));
			Matx31d mnw = -mR.t()*mn0; // convert the normal into world coordinate system
			double normN = norm(mnw);
			mnw(0)/=normN;mnw(1)/=normN;mnw(2)/=normN;

			uchar r = 255 * (mnw(0)-min_norm) * max_min_1;
			uchar g = 255 * (mnw(1)-min_norm) * max_min_1;
			uchar b = 255 * (mnw(2)-min_norm) * max_min_1;

			mNormColor.at<Vec3b>(i,j)[0] = b;
			mNormColor.at<Vec3b>(i,j)[1] = g;
			mNormColor.at<Vec3b>(i,j)[2] = r;
		}
	}
}

void DeepVoid::GetNormColorField(const Matx33d & mK,	// input:	the camera parameters
							     const Matx33d & mR,
							     const Matx31d & mt,
							     double fx_1,
							     double fy_1,
							     const Mat & mDepth,	// input:	given depth map relative to the given image
							     const Mat & mHx,
							     const Mat & mHy,
							     Mat & mNormColor		// output:	3 channel matrix
							     )
{
	int i,j,ii,jj;

	int imgWidth = mDepth.cols;
	int imgHeight = mDepth.rows;

	double max_norm = 1.0;
	double min_norm = -1.0;
	double max_min_1 = 1/(max_norm - min_norm);

	double fx = mK(0,0);
	double fy = mK(1,1);
	double cx = mK(0,2);
	double cy = mK(1,2);

	mNormColor = Mat(imgHeight, imgWidth, CV_8UC3);

	for (i=0;i<imgHeight;i++)
	{
		double nimgy = (i-cy)*fy_1;

		for (j=0;j<imgWidth;j++)
		{
			double nimgx = (j-cx)*fx_1;

			double depth = mDepth.at<float>(i,j);
			double hx = mHx.at<float>(i,j);
			double hy = mHy.at<float>(i,j);

			Matx31d XYZ = GetXYZ_givenDepth(mK, mR, mt, j, i, depth);

			// get the normal of current obtained parameters
			Matx31d mn0; mn0(2)=1;
			get_normal_givendrhxhy(fx, fy, nimgx, nimgy, depth, hx, hy, mn0(0), mn0(1));
			Matx31d mnw = -mR.t()*mn0; // convert the normal into world coordinate system
			double normN = norm(mnw);
			mnw(0)/=normN;mnw(1)/=normN;mnw(2)/=normN;

			uchar r = 255 * (mnw(0)-min_norm) * max_min_1;
			uchar g = 255 * (mnw(1)-min_norm) * max_min_1;
			uchar b = 255 * (mnw(2)-min_norm) * max_min_1;

			mNormColor.at<Vec3b>(i,j)[0] = b;
			mNormColor.at<Vec3b>(i,j)[1] = g;
			mNormColor.at<Vec3b>(i,j)[2] = r;
		}
	}
}

void DeepVoid::WriteDepthMap(CString strFile,		// input:	the file to write
							 const cam_data & cam,// input:	the camera parameters
							 const Mat & img,		// input:	the image
							 const Mat & mDepth	// input:	given depth map relative to the given image
							 )
{
	int i,j,ii,jj;

	int imgWidth = img.cols;
	int imgHeight = img.rows;

	Matx33d mR,mK;
	Matx31d mt;

	for (ii=0;ii<3;ii++)
	{
		for (jj=0;jj<3;jj++)
		{
			mR(ii,jj) = cam.R[ii*3+jj];
		}
	}
	mK(0,0) = cam.fx; mK(0,1) = cam.s;	mK(0,2) = cam.cx;
	mK(1,1) = cam.fy; mK(1,2) = cam.cy; mK(2,2) = 1;
	mt(0) = cam.t[0]; mt(1) = cam.t[1]; mt(2) = cam.t[2];

	FILE * file = fopen(strFile, "w");
	for (i=0;i<imgHeight;i++)
	{
		for (j=0;j<imgWidth;j++)
		{
			double depth = mDepth.at<float>(i,j);

			if (depth<0)
			{
				continue;
			}

			Matx31d XYZ = GetXYZ_givenDepth(mK, mR, mt, j, i, depth);

			int rgbRed,rgbGreen,rgbBlue;

			if (1 == img.channels())
			{
				Scalar pix = img.at<uchar>(i,j);
				rgbRed = rgbGreen = rgbBlue = pix.val[0];
			} 
			else
			{
				Vec3b pix = img.at<Vec3b>(i,j);
				rgbBlue = pix.val[0]; rgbGreen = pix.val[1]; rgbRed = pix.val[2];
			}

			fprintf(file, "%.12f;%.12f;%.12f;%d;%d;%d\n", XYZ(0), XYZ(1), XYZ(2), rgbRed, rgbGreen, rgbBlue);
		}
	}
	fclose(file);
}

bool DeepVoid::MPGC_get_patch_gx_gy_roberts(const Mat & img,					// input:	the image data to be resampled
											const vector<Point2d> & vImgPts,	// input:	the image coordinates of all the samples
											int patchWidth, int patchHeight,	// input:	the size of the image patch
											Mat & mPatch,						// output:	the resampled image patch
											Mat & mGx,							// output:	the dI/dx matrix of every pixel in image patch
											Mat & mGy							// output:	the dI/dy matrix of every pixel in image patch
											)
{
	int i,j,k;
	int imgWidth = img.cols;
	int imgHeight = img.rows;
	int nChannel = img.channels();

	if (nChannel == 1)
	{
		mPatch = Mat(patchHeight, patchWidth, CV_32FC1);
		mGx = Mat(patchHeight, patchWidth, CV_32FC1);
		mGy = Mat(patchHeight, patchWidth, CV_32FC1);

		for (i=0;i<patchHeight;i++)
		{
			for (j=0;j<patchWidth;j++)
			{
				double img_x = vImgPts[i*patchWidth+j].x;
				double img_y = vImgPts[i*patchWidth+j].y;

				double r,g,b;
				double rl,gl,bl; // rgb of the I(x-1,y)
				double rr,gr,br; // rgb of the I(x+1,y)
				double ru,gu,bu; // rgb of the I(x,y-1)
				double rb,gb,bb; // rgb of the I(x,y+1)
				if (BilinearInterp(img, img_x, img_y, r, g, b) &&
					BilinearInterp(img, img_x-1, img_y, rl, gl, bl) && BilinearInterp(img, img_x+1, img_y, rr, gr, br) && 
					BilinearInterp(img, img_x, img_y-1, ru, gu, bu) && BilinearInterp(img, img_x, img_y+1, rb, gb, bb))
				{
					mPatch.at<float>(i,j) = r;
					mGx.at<float>(i,j) = (rr-rl)*0.5; // dI/dx = (I(x+1,y)-I(x-1,y))/2
					mGy.at<float>(i,j) = (rb-ru)*0.5; // dI/dy = (I(x,y+1)-I(x,y-1))/2
				} 
				else
				{
					return false;
				}
			}
		}

// 		for (i=0;i<patchHeight;i++)
// 		{
// 			for (j=0;j<patchWidth;j++)
// 			{
// 				if (j==0)
// 				{
// 					mGx.at<float>(i,j)=mPatch.at<float>(i,j+1)-mPatch.at<float>(i,j);
// 				}
// 				else if (j==(patchWidth-1))
// 				{
// 					mGx.at<float>(i,j)=mPatch.at<float>(i,j)-mPatch.at<float>(i,j-1);
// 				}
// 				else
// 				{
// 					mGx.at<float>(i,j)=(mPatch.at<float>(i,j+1)-mPatch.at<float>(i,j-1))*0.5;
// 				}
// 
// 				if (i==0)
// 				{
// 					mGy.at<float>(i,j)=mPatch.at<float>(i+1,j)-mPatch.at<float>(i,j);
// 				} 
// 				else if (i==(patchHeight-1))
// 				{
// 					mGy.at<float>(i,j)=mPatch.at<float>(i,j)-mPatch.at<float>(i-1,j);
// 				}
// 				else
// 				{
// 					mGy.at<float>(i,j)=(mPatch.at<float>(i+1,j)-mPatch.at<float>(i-1,j))*0.5;
// 				}
// 			}
// 		}
	}
	else
	{
		mPatch = Mat(patchHeight, patchWidth, CV_32FC3);
		mGx = Mat(patchHeight, patchWidth, CV_32FC3);
		mGy = Mat(patchHeight, patchWidth, CV_32FC3);

		for (i=0;i<patchHeight;i++)
		{
			for (j=0;j<patchWidth;j++)
			{
				double img_x = vImgPts[i*patchWidth+j].x;
				double img_y = vImgPts[i*patchWidth+j].y;

				double r,g,b;
				double rl,gl,bl; // rgb of the I(x-1,y)
				double rr,gr,br; // rgb of the I(x+1,y)
				double ru,gu,bu; // rgb of the I(x,y-1)
				double rb,gb,bb; // rgb of the I(x,y+1)
				if (BilinearInterp(img, img_x, img_y, r, g, b) &&
					BilinearInterp(img, img_x-1, img_y, rl, gl, bl) && BilinearInterp(img, img_x+1, img_y, rr, gr, br) && 
					BilinearInterp(img, img_x, img_y-1, ru, gu, bu) && BilinearInterp(img, img_x, img_y+1, rb, gb, bb))
				{
					mPatch.at<Vec3f>(i,j).val[0] = b;
					mPatch.at<Vec3f>(i,j).val[1] = g;
					mPatch.at<Vec3f>(i,j).val[2] = r;

					mGx.at<Vec3f>(i,j).val[0] = (br-bl)*0.5; // dI/dx = (I(x+1,y)-I(x-1,y))/2
					mGx.at<Vec3f>(i,j).val[1] = (gr-gl)*0.5; // dI/dx = (I(x+1,y)-I(x-1,y))/2
					mGx.at<Vec3f>(i,j).val[2] = (rr-rl)*0.5; // dI/dx = (I(x+1,y)-I(x-1,y))/2

					mGy.at<Vec3f>(i,j).val[0] = (bb-bu)*0.5; // dI/dy = (I(x,y+1)-I(x,y-1))/2
					mGy.at<Vec3f>(i,j).val[1] = (gb-gu)*0.5; // dI/dy = (I(x,y+1)-I(x,y-1))/2
					mGy.at<Vec3f>(i,j).val[2] = (rb-ru)*0.5; // dI/dy = (I(x,y+1)-I(x,y-1))/2
				} 
				else
				{
					return false;
				}
			}
		}

// 		for (i=0;i<patchHeight;i++)
// 		{
// 			for (j=0;j<patchWidth;j++)
// 			{
// 				if (j==0)
// 				{
// 					for (k=0;k<3;k++)
// 					{
// 						mGx.at<Vec3f>(i,j).val[k]=mPatch.at<Vec3f>(i,j+1).val[k]-mPatch.at<Vec3f>(i,j).val[k];
// 					}
// 				}
// 				else if (j==(patchWidth-1))
// 				{
// 					for (k=0;k<3;k++)
// 					{
// 						mGx.at<Vec3f>(i,j).val[k]=mPatch.at<Vec3f>(i,j).val[k]-mPatch.at<Vec3f>(i,j-1).val[k];
// 					}
// 				}
// 				else
// 				{
// 					for (k=0;k<3;k++)
// 					{
// 						mGx.at<Vec3f>(i,j).val[k]=(mPatch.at<Vec3f>(i,j+1).val[k]-mPatch.at<Vec3f>(i,j-1).val[k])*0.5;
// 					}
// 				}
// 
// 				if (i==0)
// 				{
// 					for (k=0;k<3;k++)
// 					{
// 						mGy.at<Vec3f>(i,j).val[k]=mPatch.at<Vec3f>(i+1,j).val[k]-mPatch.at<Vec3f>(i,j).val[k];
// 					}
// 				} 
// 				else if (i==(patchHeight-1))
// 				{
// 					for (k=0;k<3;k++)
// 					{
// 						mGy.at<Vec3f>(i,j).val[k]=mPatch.at<Vec3f>(i,j).val[k]-mPatch.at<Vec3f>(i-1,j).val[k];
// 					}
// 				}
// 				else
// 				{
// 					for (k=0;k<3;k++)
// 					{
// 						mGy.at<Vec3f>(i,j).val[k]=(mPatch.at<Vec3f>(i+1,j).val[k]-mPatch.at<Vec3f>(i-1,j).val[k])*0.5;
// 					}
// 				}
// 			}
// 		}
	}

	return true;
}

bool DeepVoid::MPGC_get_patch_gx_gy_scharr(const Mat & img,					// input:	the image data to be resampled
										   const vector<Point2d> & vImgPts,	// input:	the image coordinates of all the samples
										   int patchWidth, int patchHeight,	// input:	the size of the image patch
										   Mat & mPatch,						// output:	the resampled image patch
										   Mat & mGx,							// output:	the dI/dx matrix of every pixel in image patch
										   Mat & mGy							// output:	the dI/dy matrix of every pixel in image patch
										   )
{
	int i,j,ii,jj,k;
	int imgWidth = img.cols;
	int imgHeight = img.rows;
	int nChannel = img.channels();

	// generate the 3*3 scharr derivative kernel first
	Matx31f mKx,mKy;
	Matx33f mDx,mDy;
	getDerivKernels(mKx, mKy, 1, 0, CV_SCHARR, true, CV_32F);
	mDx = mKy*mKx.t(); // 1/32 [-3 0 3; -10 0 10; -3 0 3]
	mDy = mDx.t();     // 1/32 [-3 -10 -3; 0 0 0; 3 10 3]
	
	if (nChannel == 1)
	{
		mPatch = Mat(patchHeight, patchWidth, CV_32FC1);
		mGx = Mat(patchHeight, patchWidth, CV_32FC1);
		mGy = Mat(patchHeight, patchWidth, CV_32FC1);

		for (i=0;i<patchHeight;i++)
		{
			for (j=0;j<patchWidth;j++)
			{
				double img_x = vImgPts[i*patchWidth+j].x;
				double img_y = vImgPts[i*patchWidth+j].y;

				double sum_x = 0;
				double sum_y = 0;
				for (ii=-1;ii<=1;ii++)
				{
					for (jj=-1;jj<=1;jj++)
					{
						double r,g,b;
						if (BilinearInterp(img, img_x+jj, img_y+ii, r, g, b))
						{
							if (ii==0&&jj==0)
							{
								mPatch.at<float>(i,j) = r;
							}
							
							sum_x += r*mDx(ii+1,jj+1);
							sum_y += r*mDy(ii+1,jj+1);
						} 
						else
						{
							return false;
						}
					}
				}

				mGx.at<float>(i,j) = sum_x;
				mGy.at<float>(i,j) = sum_y;
			}
		}
	}
	else
	{
		mPatch = Mat(patchHeight, patchWidth, CV_32FC3);
		mGx = Mat(patchHeight, patchWidth, CV_32FC3);
		mGy = Mat(patchHeight, patchWidth, CV_32FC3);

		for (i=0;i<patchHeight;i++)
		{
			for (j=0;j<patchWidth;j++)
			{
				double img_x = vImgPts[i*patchWidth+j].x;
				double img_y = vImgPts[i*patchWidth+j].y;

				double sum_x_r = 0;double sum_y_r = 0;
				double sum_x_g = 0;double sum_y_g = 0;
				double sum_x_b = 0;double sum_y_b = 0;
				for (ii=-1;ii<=1;ii++)
				{
					for (jj=-1;jj<=1;jj++)
					{
						double r,g,b;
						if (BilinearInterp(img, img_x+jj, img_y+ii, r, g, b))
						{
							if (ii==0&&jj==0)
							{
								mPatch.at<Vec3f>(i,j).val[0] = b;
								mPatch.at<Vec3f>(i,j).val[1] = g;
								mPatch.at<Vec3f>(i,j).val[2] = r;
							}
							
							sum_x_r += r*mDx(ii+1,jj+1);	sum_y_r += r*mDy(ii+1,jj+1);
							sum_x_g += g*mDx(ii+1,jj+1);	sum_y_g += g*mDy(ii+1,jj+1);
							sum_x_b += b*mDx(ii+1,jj+1);	sum_y_b += b*mDy(ii+1,jj+1);
						} 
						else
						{
							return false;
						}
					}
				}

				mGx.at<Vec3f>(i,j).val[0] = sum_x_b;
				mGx.at<Vec3f>(i,j).val[1] = sum_x_g;
				mGx.at<Vec3f>(i,j).val[2] = sum_x_r;

				mGy.at<Vec3f>(i,j).val[0] = sum_y_b;
				mGy.at<Vec3f>(i,j).val[1] = sum_y_g;
				mGy.at<Vec3f>(i,j).val[2] = sum_y_r;
			}
		}
	}

	return true;
}

// return the jacobian matrix of kth image
bool DeepVoid::f_jacob_fk_drhxhyck_patchref_uchar(const Mat & patch_ref,				// input:	the patch image in reference image
								   const Mat & img,						// input:	the kth image, supposed to be distortion free
								   const Matx33d & mK,					// input:	the kth image's intrinsic parameters
								   const Matx33d & mR,					// input:	the kth image's rotation matrix
								   const Matx31d & mt,					// input:	the kth image's translation vector
								   const vector<Point3d> & vPts3D,		// input:	the spatial coordinates of every points in the patch
								   const vector<Point3d> & vNImgPts_ref,// input:	the normalized image coordinates of every points in the patch in reference image
								   double ck,							// input:	current estimate of the photometric factor
								   Mat & mJacob,						// output:	the jacobian matrix
								   Mat & mF,							// output:	the objective vector
								   Mat & patch_rsamp					// output:	the resampled patch in kth image
								   )
{
	int i,j,k;

	int nChannel = img.channels();

	int n_pts = vPts3D.size();

	int patchWidth = patch_ref.cols;
	int patchHeight = patch_ref.rows;

	int halfpatchwidth = (patchWidth-1)/2;
	int halfpatchheight = (patchHeight-1)/2;

	Matx33d mKR = mK*mR;
	Matx31d mKt = mK*mt;

	vector<double> vz_1;
	vector<Point2d> vImgPts;
	for (i=0;i<n_pts;i++)
	{
		Matx31d XYZ;
		XYZ(0) = vPts3D[i].x;
		XYZ(1) = vPts3D[i].y;
		XYZ(2) = vPts3D[i].z;

		XYZ = mKR*XYZ+mKt;

		double z_1 = 1/XYZ(2);
		Point2d pt2d;
		pt2d.x = XYZ(0)*z_1;
		pt2d.y = XYZ(1)*z_1;
		vz_1.push_back(z_1);
		vImgPts.push_back(pt2d);
	}

	Mat mGx, mGy;

	if (!MPGC_get_patch_gx_gy_roberts(img, vImgPts, patchWidth, patchHeight, patch_rsamp, mGx, mGy))
	{
		return false;
	}

	mJacob = Mat(nChannel*n_pts, 4, CV_32FC1, Scalar(0));
	mF = Mat(nChannel*n_pts, 1, CV_32FC1, Scalar(0));

	for (i=0;i<patchHeight;i++)
	{
		int v = i-halfpatchheight;
		for (j=0;j<patchWidth;j++)
		{
			int u = j-halfpatchwidth;
			double z_1 = vz_1[i*patchWidth+j];
			Matx31d XYZ;
			XYZ(0) = vNImgPts_ref[i*patchWidth+j].x;
			XYZ(1) = vNImgPts_ref[i*patchWidth+j].y;
			XYZ(2) = vNImgPts_ref[i*patchWidth+j].z;
			/*XYZ(2) = 1;*/
			Matx31d mKRx = ck * z_1 * mKR * XYZ;

			if (nChannel == 1)
			{
				Matx13d dI_dxdy;
				dI_dxdy(0) = mGx.at<float>(i,j);
				dI_dxdy(1) = mGy.at<float>(i,j);
				dI_dxdy(2) = 0;

				Matx<double, 1, 1> df_ddr = dI_dxdy * mKRx;

				int idxrow = i*patchWidth+j;
				mJacob.at<float>(idxrow, 0) = df_ddr(0);
				mJacob.at<float>(idxrow, 1) = df_ddr(0)*u;
				mJacob.at<float>(idxrow, 2) = df_ddr(0)*v;
				mJacob.at<float>(idxrow, 3) = patch_rsamp.at<float>(i,j);
				patch_rsamp.at<float>(i,j) *= ck; // make sure df = ckIk - Ir
				mF.at<float>(idxrow) = patch_rsamp.at<float>(i,j) - patch_ref.at<uchar>(i,j);
//				mF.at<float>(idxrow) = patch_rsamp.at<float>(i,j) - patch_ref.at<float>(i,j);
			}
			else
			{
				Matx33d dI_dxdy;
				for (k=0;k<3;k++)
				{
					dI_dxdy(k,0) = mGx.at<Vec3f>(i,j).val[k];
					dI_dxdy(k,1) = mGy.at<Vec3f>(i,j).val[k];
					dI_dxdy(k,2) = 0;
				}
				
				Matx31d df_ddr = dI_dxdy * mKRx;

				for (k=0;k<3;k++)
				{
					int idxrow = (i*patchWidth+j)*3+k;
					mJacob.at<float>(idxrow, 0) = df_ddr(k);
					mJacob.at<float>(idxrow, 1) = df_ddr(k)*u;
					mJacob.at<float>(idxrow, 2) = df_ddr(k)*v;
					mJacob.at<float>(idxrow, 3) = patch_rsamp.at<Vec3f>(i,j).val[k];
					patch_rsamp.at<Vec3f>(i,j).val[k] *= ck; // make sure df = ckIk - Ir
					mF.at<float>(idxrow) = patch_rsamp.at<Vec3f>(i,j).val[k] - patch_ref.at<Vec3b>(i,j).val[k];
//					mF.at<float>(idxrow) = patch_rsamp.at<Vec3f>(i,j).val[k] - patch_ref.at<Vec3f>(i,j).val[k];
				}
			}
		}
	}

	return true;
}

// return the jacobian matrix of kth image
bool DeepVoid::f_jacob_fk_drhxhyck_patchref_float(const Mat & patch_ref,				// input:	the patch image in reference image
												  const Mat & img,						// input:	the kth image, supposed to be distortion free
												  const Matx33d & mK,					// input:	the kth image's intrinsic parameters
												  const Matx33d & mR,					// input:	the kth image's rotation matrix
												  const Matx31d & mt,					// input:	the kth image's translation vector
												  const vector<Point3d> & vPts3D,		// input:	the spatial coordinates of every points in the patch
												  const vector<Point3d> & vNImgPts_ref,	// input:	the normalized image coordinates of every points in the patch in reference image
												  double ck,							// input:	current estimate of the photometric factor
												  Mat & mJacob,							// output:	the jacobian matrix
												  Mat & mF,								// output:	the objective vector 
												  Mat & patch_rsamp						// output:	the resampled patch in kth image
												  )
{
	int i,j,k;

	int nChannel = img.channels();

	int n_pts = vPts3D.size();

	int patchWidth = patch_ref.cols;
	int patchHeight = patch_ref.rows;

	int halfpatchwidth = (patchWidth-1)/2;
	int halfpatchheight = (patchHeight-1)/2;

	Matx33d mKR = mK*mR;
	Matx31d mKt = mK*mt;

	vector<double> vz_1;
	vector<Point2d> vImgPts;
	for (i=0;i<n_pts;i++)
	{
		Matx31d XYZ;
		XYZ(0) = vPts3D[i].x;
		XYZ(1) = vPts3D[i].y;
		XYZ(2) = vPts3D[i].z;

		XYZ = mKR*XYZ+mKt;

		double z_1 = 1/XYZ(2);
		Point2d pt2d;
		pt2d.x = XYZ(0)*z_1;
		pt2d.y = XYZ(1)*z_1;
		vz_1.push_back(z_1);
		vImgPts.push_back(pt2d);
	}

	Mat mGx, mGy;

	if (!MPGC_get_patch_gx_gy_roberts(img, vImgPts, patchWidth, patchHeight, patch_rsamp, mGx, mGy))
	{
		return false;
	}

	mJacob = Mat(nChannel*n_pts, 4, CV_32FC1, Scalar(0));
	mF = Mat(nChannel*n_pts, 1, CV_32FC1, Scalar(0));

	for (i=0;i<patchHeight;i++)
	{
		int v = i-halfpatchheight;
		for (j=0;j<patchWidth;j++)
		{
			int u = j-halfpatchwidth;
			double z_1 = vz_1[i*patchWidth+j];
			Matx31d XYZ;
			XYZ(0) = vNImgPts_ref[i*patchWidth+j].x;
			XYZ(1) = vNImgPts_ref[i*patchWidth+j].y;
			XYZ(2) = vNImgPts_ref[i*patchWidth+j].z;
			/*XYZ(2) = 1;*/
			Matx31d mKRx = ck * z_1 * mKR * XYZ;

			if (nChannel == 1)
			{
				Matx13d dI_dxdy;
				dI_dxdy(0) = mGx.at<float>(i,j);
				dI_dxdy(1) = mGy.at<float>(i,j);
				dI_dxdy(2) = 0;

				Matx<double, 1, 1> df_ddr = dI_dxdy * mKRx;

				int idxrow = i*patchWidth+j;
				mJacob.at<float>(idxrow, 0) = df_ddr(0);
				mJacob.at<float>(idxrow, 1) = df_ddr(0)*u;
				mJacob.at<float>(idxrow, 2) = df_ddr(0)*v;
				mJacob.at<float>(idxrow, 3) = patch_rsamp.at<float>(i,j);
				patch_rsamp.at<float>(i,j) *= ck; // make sure df = ckIk - Ir
				mF.at<float>(idxrow) = patch_rsamp.at<float>(i,j) - patch_ref.at<float>(i,j);
			}
			else
			{
				Matx33d dI_dxdy;
				for (k=0;k<3;k++)
				{
					dI_dxdy(k,0) = mGx.at<Vec3f>(i,j).val[k];
					dI_dxdy(k,1) = mGy.at<Vec3f>(i,j).val[k];
					dI_dxdy(k,2) = 0;
				}

				Matx31d df_ddr = dI_dxdy * mKRx;

				for (k=0;k<3;k++)
				{
					int idxrow = (i*patchWidth+j)*3+k;
					mJacob.at<float>(idxrow, 0) = df_ddr(k);
					mJacob.at<float>(idxrow, 1) = df_ddr(k)*u;
					mJacob.at<float>(idxrow, 2) = df_ddr(k)*v;
					mJacob.at<float>(idxrow, 3) = patch_rsamp.at<Vec3f>(i,j).val[k];
					patch_rsamp.at<Vec3f>(i,j).val[k] *= ck; // make sure df = ckIk - Ir
					mF.at<float>(idxrow) = patch_rsamp.at<Vec3f>(i,j).val[k] - patch_ref.at<Vec3f>(i,j).val[k];
				}
			}
		}
	}

	return true;
}

// 20140904 return the objective vector and jacobian matrix of kth image
bool DeepVoid::f_jacob_fk_drhxhyck_patchref_float_20140904(const Mat & patch_ref,				// input:	the patch image in reference image
														   const Mat & img,						// input:	the kth image, supposed to be distortion free
														   const Matx33d & mKR,					// input:	the kth image's intrinsic parameters
														   const Matx31d & mKt,					// input:	the kth image's rotation matrix
														   const vector<Matx31d> & vXYZs,		// input:	the spatial coordinates of every points in the patch
														   const vector<Matx31d> & vRtxs_ref,	// input:	the normalized image coordinates of every points in the patch in reference image
														   double ck,							// input:	current estimate of the photometric factor
														   Mat & mJacob,						// output:	the jacobian matrix
														   Mat & mF,							// output:	the objective vector 
														   Mat & patch_rsamp					// output:	the resampled patch in kth image
														   )
{
	int i,j,k;

	int nChannel = img.channels();

	int n_pts = vXYZs.size();

	int w = patch_ref.cols;
	int h = patch_ref.rows;

	int hw = (w-1)/2;
	int hh = (h-1)/2;

	vector<Point2d> vImgPts;
	for (i=0;i<n_pts;i++)
	{
		Matx31d mImg = mKR*vXYZs[i]+mKt;

		double z_1 = 1/mImg(2);
		Point2d pt2d;
		pt2d.x = mImg(0)*z_1;
		pt2d.y = mImg(1)*z_1;
		vImgPts.push_back(pt2d);
	}

	Mat mGx, mGy;

	if (!MPGC_get_patch_gx_gy_roberts(img, vImgPts, w, h, patch_rsamp, mGx, mGy))
	{
		return false;
	}

	mJacob = Mat(nChannel*n_pts, 4, CV_32FC1, Scalar(0));
	mF = Mat(nChannel*n_pts, 1, CV_32FC1, Scalar(0));

	for (i=0;i<h;i++)
	{
		int v = i-hh;
		for (j=0;j<w;j++)
		{
			int u = j-hw;

			// dXYZ/ddrhxhy
			Matx33d dXYZ_ddrhxhy = Jacobian_XYZ_drhxhy(vRtxs_ref[i*w+j],u,v);

			// dxy/dXYZ
			double imgx,imgy;
			Matx23d dxy_dXYZ = Jacobian_xy_XYZ(mKR,mKt,vXYZs[i*w+j](0),vXYZs[i*w+j](1),vXYZs[i*w+j](2),imgx,imgy);

			// dxy/ddrhxhy
			Matx23d dxy_ddrhxhy = dxy_dXYZ*dXYZ_ddrhxhy;

			if (nChannel == 1)
			{
				Matx12d dI_dxy;
				dI_dxy(0) = mGx.at<float>(i,j);
				dI_dxy(1) = mGy.at<float>(i,j);

				Matx13d df_ddrhxhy = ck * dI_dxy * dxy_ddrhxhy;

				int idxrow = i*w+j;
				mJacob.at<float>(idxrow, 0) = df_ddrhxhy(0);
				mJacob.at<float>(idxrow, 1) = df_ddrhxhy(1);
				mJacob.at<float>(idxrow, 2) = df_ddrhxhy(2);
				mJacob.at<float>(idxrow, 3) = patch_rsamp.at<float>(i,j);
				patch_rsamp.at<float>(i,j) *= ck; // make sure df = ckIk - Ir
				mF.at<float>(idxrow) = patch_rsamp.at<float>(i,j) - patch_ref.at<float>(i,j);
			}
			else
			{
				Matx32d dI_dxy;
				for (k=0;k<3;k++)
				{
					dI_dxy(k,0) = mGx.at<Vec3f>(i,j).val[k];
					dI_dxy(k,1) = mGy.at<Vec3f>(i,j).val[k];
				}

				Matx33d df_ddrhxhy = ck * dI_dxy * dxy_ddrhxhy;

				for (k=0;k<3;k++)
				{
					int idxrow = (i*w+j)*3+k;
					mJacob.at<float>(idxrow, 0) = df_ddrhxhy(k,0);
					mJacob.at<float>(idxrow, 1) = df_ddrhxhy(k,1);
					mJacob.at<float>(idxrow, 2) = df_ddrhxhy(k,2);
					mJacob.at<float>(idxrow, 3) = patch_rsamp.at<Vec3f>(i,j).val[k];
					patch_rsamp.at<Vec3f>(i,j).val[k] *= ck; // make sure df = ckIk - Ir
					mF.at<float>(idxrow) = patch_rsamp.at<Vec3f>(i,j).val[k] - patch_ref.at<Vec3f>(i,j).val[k];
				}
			}
		}
	}

	return true;
}

// 20140911 return the objective vector and jacobian matrix of kth image
bool DeepVoid::f_jacob_fk_drhxhyck_patchref_float_20140911(const Mat & patch_ref,				// input:	the patch image in reference image
														   const Mat & img,						// input:	the kth image, supposed to be distortion free
														   const Mat & mask,					// input:	mask
														   int nValid,							// input:	number of valid pixels in mask
														   const Matx33d & mK,
														   const Matx33d & mR,
														   const Matx33d & mKR,					// input:	the kth image's intrinsic parameters
														   const Matx31d & mKt,					// input:	the kth image's rotation matrix
														   double fx_1, double fy_1,
														   const Matx31d & mnw,					// input:	the normal vector of reference patch in world coordinate
														   const vector<Matx31d> & vXYZs,		// input:	the spatial coordinates of every points in the patch
														   const vector<Matx31d> & vRtxs_ref,	// input:	the normalized image coordinates of every points in the patch in reference image
														   double ck,							// input:	current estimate of the photometric factor
														   Mat & mJacob,						// output:	the jacobian matrix
														   Mat & mF,							// output:	the objective vector 
														   double & ncc,						// output:	the ncc
														   bool & bOppo							// output:	whether if normal is opposite or not
														   )
{
	int i,j,k;

	if (nValid<3) // at least 3 valid pixels
	{
		return false;
	}

	int nChannel = img.channels();

	int n_pts = vXYZs.size();

	int w = patch_ref.cols;
	int h = patch_ref.rows;

	int hw = (w-1)/2;
	int hh = (h-1)/2;

	double cx = mK(0,2);
	double cy = mK(1,2);

	double imgx_mid, imgy_mid;

	vector<Point2d> vImgPts;
	for (i=0;i<n_pts;i++)
	{
		Matx31d mImg = mKR*vXYZs[i]+mKt;

		double z_1 = 1/mImg(2);
		Point2d pt2d;
		pt2d.x = mImg(0)*z_1;
		pt2d.y = mImg(1)*z_1;
		vImgPts.push_back(pt2d);

		if (i==(hh*w+hw))
		{
			imgx_mid = pt2d.x;
			imgy_mid = pt2d.y;
		}
	}

	Mat mGx, mGy, mPatch_rsmp;

	if (!MPGC_get_patch_gx_gy_roberts(img, vImgPts, w, h, mPatch_rsmp, mGx, mGy))
	{
		return false;
	}

	mJacob = Mat(nChannel*nValid, 4, CV_32FC1, Scalar(0));
	mF = Mat(nChannel*nValid, 1, CV_32FC1, Scalar(0));

	Mat mCkIk, mIr;
	if (nChannel==1) // gray image
	{
		mCkIk = Mat(nValid, 1, CV_32FC1, Scalar(0));
		mIr   = Mat(nValid, 1, CV_32FC1, Scalar(0));
	} 
	else // color image
	{
		mCkIk = Mat(nValid, 1, CV_32FC3, Scalar(0));
		mIr   = Mat(nValid, 1, CV_32FC3, Scalar(0));
	}


	int idx_cur = 0; // number of currently been considered valid pixels

	for (i=0;i<h;i++)
	{
		int v = i-hh;
		for (j=0;j<w;j++)
		{
			int u = j-hw;

			uchar val_mask = mask.at<uchar>(i,j);
			if (val_mask==0) // this means that this pixel is not valid, it should not be considered in MPGC
			{
				continue;
			}

			// dXYZ/ddrhxhy
			Matx33d dXYZ_ddrhxhy = Jacobian_XYZ_drhxhy(vRtxs_ref[i*w+j],u,v);

			// dxy/dXYZ
			double imgx,imgy;
			Matx23d dxy_dXYZ = Jacobian_xy_XYZ(mKR,mKt,vXYZs[i*w+j](0),vXYZs[i*w+j](1),vXYZs[i*w+j](2),imgx,imgy);

			// dxy/ddrhxhy
			Matx23d dxy_ddrhxhy = dxy_dXYZ*dXYZ_ddrhxhy;

			if (nChannel == 1)
			{
				Matx12d dI_dxy;
				dI_dxy(0) = mGx.at<float>(i,j);
				dI_dxy(1) = mGy.at<float>(i,j);

				Matx13d df_ddrhxhy = ck * dI_dxy * dxy_ddrhxhy;

				int idxrow = idx_cur;
				mJacob.at<float>(idxrow, 0) = df_ddrhxhy(0);
				mJacob.at<float>(idxrow, 1) = df_ddrhxhy(1);
				mJacob.at<float>(idxrow, 2) = df_ddrhxhy(2);
				mJacob.at<float>(idxrow, 3) = mPatch_rsmp.at<float>(i,j);
				double ckIk = mPatch_rsmp.at<float>(i,j) * ck;
				double Ir = patch_ref.at<float>(i,j);
				mF.at<float>(idxrow) = ckIk - Ir; // df = ckIk - Ir

				mCkIk.at<float>(idx_cur) = ckIk;
				mIr.at<float>(idx_cur) = Ir;
			}
			else
			{
				Matx32d dI_dxy;
				for (k=0;k<3;k++)
				{
					dI_dxy(k,0) = mGx.at<Vec3f>(i,j).val[k];
					dI_dxy(k,1) = mGy.at<Vec3f>(i,j).val[k];
				}

				Matx33d df_ddrhxhy = ck * dI_dxy * dxy_ddrhxhy;

				for (k=0;k<3;k++)
				{
					int idxrow = (idx_cur)*3+k;
					mJacob.at<float>(idxrow, 0) = df_ddrhxhy(k,0);
					mJacob.at<float>(idxrow, 1) = df_ddrhxhy(k,1);
					mJacob.at<float>(idxrow, 2) = df_ddrhxhy(k,2);
					mJacob.at<float>(idxrow, 3) = mPatch_rsmp.at<Vec3f>(i,j).val[k];
					double ckIk = mPatch_rsmp.at<Vec3f>(i,j).val[k] * ck;
					double Ir = patch_ref.at<Vec3f>(i,j).val[k];
					mF.at<float>(idxrow) = ckIk - Ir; // df = ckIk - Ir

					mCkIk.at<Vec3f>(idx_cur).val[k] = ckIk;
					mIr.at<Vec3f>(idx_cur).val[k] = Ir;
				}
			}

			++idx_cur;
		}
	}

	Mat mNCC(1, 1, CV_32FC1);
	matchTemplate(mIr, mCkIk, mNCC, CV_TM_CCORR_NORMED); // compute NCC
	ncc = mNCC.at<float>(0);

	// compute the angle between normal and the line of sight
	// current line of sight
	Matx31d msightvec; // from image point to optical center
	msightvec(0) = -(imgx_mid-cx)*fx_1;
	msightvec(1) = -(imgy_mid-cy)*fy_1;
	msightvec(2) = -1;
	Matx31d mnk = mR*mnw;
	double cosa = ComputeCosa(mnk, msightvec);
	if (cosa<=0) // ang is supposed to be smaller than 90 if it is visible
	{
		bOppo = true;
	}
	else
	{
		bOppo = false;
	}

// 	matchTemplate(patch_ref, mPatch_rsmp, mNCC, CV_TM_CCORR_NORMED);
// 	double ncc_old = mNCC.at<float>(0);

	return true;
}

bool DeepVoid::optim_gn_drhxhyck(const vector<cam_data> & vCams,	// input:	all camera data
								 const vector<Mat> & vImgs,			// input:	all images
								 const vector<int> & vIdxVisiCams,	// input:	indices of all visible cameras
								 int idx_refimg,					// input:	the index of the reference image
								 int x, int y,						// input:	the indices of the pixel to be checked
								 int patchWidth, int patchHeight,	// input:	the patch size
								 double depth_init,					// input:	initial depth of this pixel
								 double hx_init,					// input:	initial normal of this pixel
								 double hy_init,					// input:	initial normal of this pixel
								 double & depth_optim,				// output:	optimized depth of this pixel
								 double & hx_optim,					// output:	optimized normal of this pixel
								 double & hy_optim,					// output:	optimized normal of this pixel
								 bool bFixCk /*= false*/,			// input:	fix all ck or not
								 int maxIter /*= 128*/,				// input: max iteration
								 double xEps /*= 1.0E-12*/,			// input: threshold
								 double fEps /*= 1.0E-12*/,			// input: threshold
								 int * iterNum/* = NULL*/			// output:iteration number when quiting
								 )
{
	int i,j,k,ii;

	int npts_patch = patchWidth*patchHeight;
	int ncams_visi = vIdxVisiCams.size();

	int nChannel = vImgs[idx_refimg].channels();

	int halfpatch_w = (patchWidth-1)*0.5;
	int halfpatch_h = (patchHeight-1)*0.5;

	cam_data cam_ref = vCams[idx_refimg];

	Matx33d mK_ref, mR_ref;
	Matx31d mt_ref;

	vector<Matx33d> vKs(ncams_visi),vRs(ncams_visi);
	vector<Matx31d> vts(ncams_visi);

	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mR_ref(i,j) = cam_ref.R[i*3+j];

			for (k=0;k<ncams_visi;k++)
			{
				vRs[k](i,j) = vCams[vIdxVisiCams[k]].R[i*3+j];
			}
		}
	}
	mK_ref(0,0) = cam_ref.fx;	mK_ref(0,1) = cam_ref.s;  mK_ref(0,2) = cam_ref.cx;
	mK_ref(1,1) = cam_ref.fy;	mK_ref(1,2) = cam_ref.cy; mK_ref(2,2) = 1;
	mt_ref(0) = cam_ref.t[0];	mt_ref(1) = cam_ref.t[1]; mt_ref(2) = cam_ref.t[2];

	Matx31d mC_ref = -mR_ref.t() * mt_ref;

	for (k=0;k<ncams_visi;k++)
	{
		vKs[k](0,0) = vCams[vIdxVisiCams[k]].fx;	vKs[k](0,1) = vCams[vIdxVisiCams[k]].s;		vKs[k](0,2) = vCams[vIdxVisiCams[k]].cx;
		vKs[k](1,1) = vCams[vIdxVisiCams[k]].fy;	vKs[k](1,2) = vCams[vIdxVisiCams[k]].cy;	vKs[k](2,2) = 1;
		vts[k](0) = vCams[vIdxVisiCams[k]].t[0];	vts[k](1) = vCams[vIdxVisiCams[k]].t[1];	vts[k](2) = vCams[vIdxVisiCams[k]].t[2];	
	}

	//vector<Point2d> vNImgPts_ref; // the normalized image points or directions of every patch points
	vector<Point3d> vNImgPts_ref; // the normalized image points or directions of every patch points
	for (i=-halfpatch_h;i<=halfpatch_h;i++)
	{
		for (j=-halfpatch_w;j<=halfpatch_w;j++)
		{
			Matx31d xyz;
			xyz(0) = x+j;
			xyz(1) = y+i;
			xyz(2) = 1;

// 			Matx31d nxy = mK_ref.inv()*xyz;
// 
// 			Point2d pt2d;
// 			pt2d.x = nxy(0);
// 			pt2d.y = nxy(1);

			Matx31d nxy = mR_ref.t()*mK_ref.inv()*xyz;

			Point3d pt3d;
			pt3d.x = nxy(0);
			pt3d.y = nxy(1);
			pt3d.z = nxy(2);

			vNImgPts_ref.push_back(pt3d);
		}
	}

//	Mat patch_ref(vImgs[idx_refimg], cv::Rect(x-halfpatch_w, y-halfpatch_h, patchWidth, patchHeight));
	Mat patch_ref;
	if (nChannel==1) // gray level image
	{
		patch_ref = Mat(patchHeight, patchWidth, CV_32FC1);

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				patch_ref.at<float>(i+halfpatch_h, j+halfpatch_w) = vImgs[idx_refimg].at<uchar>(y+i,x+j);
				patch_ref.at<float>(i+halfpatch_h, j+halfpatch_w) = vImgs[idx_refimg].at<uchar>(y+i,x+j);
				patch_ref.at<float>(i+halfpatch_h, j+halfpatch_w) = vImgs[idx_refimg].at<uchar>(y+i,x+j);
			}
		}
	} 
	else // color image
	{
		patch_ref = Mat(patchHeight, patchWidth, CV_32FC3);

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[0] = vImgs[idx_refimg].at<Vec3b>(y+i,x+j).val[0];
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[1] = vImgs[idx_refimg].at<Vec3b>(y+i,x+j).val[1];
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[2] = vImgs[idx_refimg].at<Vec3b>(y+i,x+j).val[2];
			}
		}
	}

// 	CString strtmp;
// 	strtmp.Format("C:\\Users\\DeepVoid\\Desktop\\results\\MPGC\\patch_ref.bmp");
// 	imwrite(strtmp.GetBuffer(), patch_ref);

	double depth = depth_init;
	double hx = hx_init;
	double hy = hy_init;
	vector<double> vck(ncams_visi, 1);

	double depth_old, hx_old, hy_old;

	bool bDivergent = false;

	double fVal_old = 0; double ncc_mean_old = 0;
	double fVal_new; double ncc_mean_new;
	double hVal;

	for (k=0;k<maxIter;k++)
	{
		CString strinfo;
		strinfo.Format("C:\\Users\\DeepVoid\\Desktop\\support window of iteration %02d.txt", k);
		OutputSupportWindow(strinfo, mK_ref, mR_ref, mt_ref, x, y, depth, hx, hy, patchWidth, patchHeight, 255, 255, 0, 5);

		// first get the 3d patch points corresponding to current parameter set
		vector<Point3d> vWrdPts;

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				Matx31d mDir;
				mDir(0) = vNImgPts_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w].x;
				mDir(1) = vNImgPts_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w].y;
				mDir(2) = vNImgPts_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w].z;
				/*mDir(2) = 1;*/
			
				Matx31d XYZ = mC_ref + (depth+hx*j+hy*i) * mDir;
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);
			}
		}

		vector<Mat> vJacobs, vFs;
		vector<int> vIdxValid;

		int nAllRows = 0;

		Mat mJacob_k, mF_k, imgPatchResamp; vector<double> vnccs; double sum_ncc = 0;
		for (ii=0;ii<ncams_visi;ii++)
		{
			if (!f_jacob_fk_drhxhyck_patchref_uchar(patch_ref, vImgs[vIdxVisiCams[ii]], vKs[ii], vRs[ii], vts[ii], vWrdPts, vNImgPts_ref, vck[ii], mJacob_k, mF_k, imgPatchResamp))
			{
				continue;
			}

			int result_cols = imgPatchResamp.cols - patch_ref.cols + 1;
			int result_rows = imgPatchResamp.rows - patch_ref.rows + 1;
			Mat mNCC(result_rows, result_cols, CV_32FC1);
			matchTemplate(patch_ref, imgPatchResamp, mNCC, /*CV_TM_SQDIFF_NORMED*/CV_TM_CCORR_NORMED);
			vnccs.push_back(mNCC.at<float>(0));
			sum_ncc += mNCC.at<float>(0);

// 			strtmp.Format("C:\\Users\\DeepVoid\\Desktop\\results\\MPGC\\patch%02d_iter%03d.bmp", vIdxVisiCams[ii], k);
// 			imwrite(strtmp.GetBuffer(), imgPatchResamp);

// 			FILE * file = fopen(strtmp, "w");
// 			for (i=0;i<mJacob_k.rows;i++)
// 			{
// 				for (j=0;j<mJacob_k.cols;j++)
// 				{
// 					fprintf(file, "%lf	", mJacob_k.at<float>(i,j));
// 				}
// 				fprintf(file, "\n");
// 			}
// 			fclose(file);
// 
// 			strtmp.Format("C:\\Users\\DeepVoid\\Desktop\\mF%02d.txt", ii);
// 			file = fopen(strtmp, "w");
// 			for (i=0;i<mF_k.rows;i++)
// 			{
// 				for (j=0;j<mF_k.cols;j++)
// 				{
// 					fprintf(file, "%lf	", mF_k.at<float>(i,j));
// 				}
// 				fprintf(file, "\n");
// 			}
// 			fclose(file);

			nAllRows += mJacob_k.rows;

			vJacobs.push_back(mJacob_k);
			vFs.push_back(mF_k);
			vIdxValid.push_back(ii);
		}

		int nValid = vJacobs.size();
		int nAllCols = 3+nValid;

		if (nValid == 0)
		{
			return false;
		}

		Mat mJ, mF;

		if (bFixCk)
		{
			mJ = Mat(nAllRows, 3, CV_32FC1, Scalar(0));
			mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));

			int ntmp = 0;
			for (i=0;i<nValid;i++)
			{
				for (j=0;j<vJacobs[i].rows;j++)
				{
					mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,0);
					mJ.at<float>(ntmp+j,1) = vJacobs[i].at<float>(j,1);
					mJ.at<float>(ntmp+j,2) = vJacobs[i].at<float>(j,2);
					mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
				}

				ntmp += vJacobs[i].rows;
			}
		} 
		else
		{
			mJ = Mat(nAllRows, nAllCols, CV_32FC1, Scalar(0)); 
			mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));

			int ntmp = 0;
			for (i=0;i<nValid;i++)
			{
				for (j=0;j<vJacobs[i].rows;j++)
				{
					mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,0);
					mJ.at<float>(ntmp+j,1) = vJacobs[i].at<float>(j,1);
					mJ.at<float>(ntmp+j,2) = vJacobs[i].at<float>(j,2);
					mJ.at<float>(ntmp+j,3+i) = vJacobs[i].at<float>(j,3);
					mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
				}

				ntmp += vJacobs[i].rows;
			}
		}

// 		FILE * file = fopen("C:\\Users\\DeepVoid\\Desktop\\mJ.txt", "w");
// 		for (i=0;i<mJ.rows;i++)
// 		{
// 			for (j=0;j<mJ.cols;j++)
// 			{
// 				fprintf(file, "%lf	", mJ.at<float>(i,j));
// 			}
// 			fprintf(file, "\n");
// 		}
// 		fclose(file);
// 
// 		file = fopen("C:\\Users\\DeepVoid\\Desktop\\mF.txt", "w");
// 		for (i=0;i<mF.rows;i++)
// 		{
// 			for (j=0;j<mF.cols;j++)
// 			{
// 				fprintf(file, "%lf	", mF.at<float>(i,j));
// 			}
// 			fprintf(file, "\n");
// 		}
// 		fclose(file);

		// 解方程组 (J'J) h = -J'f 得到的 h 即为待优化参数的改正量，下次迭代的 x(k + 1) = x(k) + h
		Mat mA = mJ.t() * mJ;
		Mat mb = -mJ.t() * mF;
		Mat mA_1 = mA.inv(DECOMP_CHOLESKY);

		Mat mh = mA_1*mb;

		fVal_new = norm(mF)*norm(mF);
		hVal     = norm(mh);
		ncc_mean_new = sum_ncc/vnccs.size();

		double s0 = sqrt(fVal_new/(mJ.rows-mJ.cols));

		vector<double> vStds;
		for (i=0;i<mA_1.rows;i++)
		{
			double stdev = s0 * sqrt(mA_1.at<float>(i,i));
			vStds.push_back(stdev);
		}

		double df2 = fVal_new - fVal_old;

		if (k!=0&&df2/fVal_old>0.001)
		{
			bDivergent = true;
			break;
		}

		// 当目标函数值的平方和变化量小于一定阈值或者改正量的范数值小于一定阈值时认为迭代收敛，退出迭代
		if ((fabs(df2) < fEps) || (hVal < xEps))
		{
			break;
		}

		fVal_old = fVal_new;
		ncc_mean_old = ncc_mean_new;

// 		CString strInfo;
// 		strInfo.Format("iter %03d fval %lf depth %lf %lf hx %lf %lf hy %lf %lf ck1 %lf", k, fVal_new, depth, vStds[0], hx, vStds[1], hy, vStds[2], vck[0]);
// 		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		depth_old = depth;
		hx_old = hx;
		hy_old = hy;

		depth += mh.at<float>(0);
		hx    += mh.at<float>(1);
		hy    += mh.at<float>(2);

		if (!bFixCk)
		{
			for (i=0;i<nValid;i++)
			{
				vck[vIdxValid[i]] += mh.at<float>(3+i);
			}
		}
	}

	if (iterNum)
	{
		*iterNum = k;
	}

	if (bDivergent)
	{
		depth_optim = depth_old;
		hx_optim = hx_old;
		hy_optim = hy_old;
	} 
	else
	{
		depth_optim = depth;
		hx_optim = hx;
		hy_optim = hy;
	}

	CString strinfo;
	strinfo.Format("C:\\Users\\DeepVoid\\Desktop\\final support window.txt");
	OutputSupportWindow(strinfo, mK_ref, mR_ref, mt_ref, x, y, depth_optim, hx_optim, hy_optim, patchWidth, patchHeight, 255, 255, 0, 5);

	return true;
}

bool DeepVoid::optim_gn_drhxhyck_new(const vector<cam_data> & vCams,	// input:	all camera data
									 const vector<Mat> & vImgs,			// input:	all images
									 const vector<int> & vIdxVisiCams,	// input:	indices of all visible cameras
									 int idx_refimg,					// input:	the index of the reference image
									 int x, int y,						// input:	the indices of the pixel to be checked
									 int patchWidth, int patchHeight,	// input:	the patch size
									 double depth_init,					// input:	initial depth of this pixel
									 double hx_init,					// input:	initial normal of this pixel
									 double hy_init,					// input:	initial normal of this pixel
									 double & depth_optim,				// output:	optimized depth of this pixel
									 double & hx_optim,					// output:	optimized normal of this pixel
									 double & hy_optim,					// output:	optimized normal of this pixel
									 bool bFixCk /*= false*/,			// input:	fix all ck or not
									 int maxIter /*= 128*/,				// input: max iteration
									 double xEps /*= 1.0E-12*/,			// input: threshold
									 double fEps /*= 1.0E-12*/,			// input: threshold
									 int * iterNum/* = NULL*/			// output:iteration number when quiting
									 )
{
	int i,j,k,ii;

	int npts_patch = patchWidth*patchHeight;
	int ncams_visi = vIdxVisiCams.size();

	int nChannel = vImgs[idx_refimg].channels();

	int halfpatch_w = (patchWidth-1)*0.5;
	int halfpatch_h = (patchHeight-1)*0.5;

	cam_data cam_ref = vCams[idx_refimg];

	Matx33d mK_ref, mR_ref;
	Matx31d mt_ref;

	vector<Matx33d> vKs(ncams_visi),vRs(ncams_visi);
	vector<Matx31d> vts(ncams_visi);

	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mR_ref(i,j) = cam_ref.R[i*3+j];

			for (k=0;k<ncams_visi;k++)
			{
				vRs[k](i,j) = vCams[vIdxVisiCams[k]].R[i*3+j];
			}
		}
	}
	mK_ref(0,0) = cam_ref.fx;	mK_ref(0,1) = cam_ref.s;  mK_ref(0,2) = cam_ref.cx;
	mK_ref(1,1) = cam_ref.fy;	mK_ref(1,2) = cam_ref.cy; mK_ref(2,2) = 1;
	mt_ref(0) = cam_ref.t[0];	mt_ref(1) = cam_ref.t[1]; mt_ref(2) = cam_ref.t[2];

	Matx31d mC_ref = -mR_ref.t() * mt_ref;

	for (k=0;k<ncams_visi;k++)
	{
		vKs[k](0,0) = vCams[vIdxVisiCams[k]].fx;	vKs[k](0,1) = vCams[vIdxVisiCams[k]].s;		vKs[k](0,2) = vCams[vIdxVisiCams[k]].cx;
		vKs[k](1,1) = vCams[vIdxVisiCams[k]].fy;	vKs[k](1,2) = vCams[vIdxVisiCams[k]].cy;	vKs[k](2,2) = 1;
		vts[k](0) = vCams[vIdxVisiCams[k]].t[0];	vts[k](1) = vCams[vIdxVisiCams[k]].t[1];	vts[k](2) = vCams[vIdxVisiCams[k]].t[2];	
	}

	//vector<Point2d> vNImgPts_ref; // the normalized image points or directions of every patch points
	vector<Point3d> vNImgPts_ref; // the normalized image points or directions of every patch points
	for (i=-halfpatch_h;i<=halfpatch_h;i++)
	{
		for (j=-halfpatch_w;j<=halfpatch_w;j++)
		{
			Matx31d xyz;
			xyz(0) = x+j;
			xyz(1) = y+i;
			xyz(2) = 1;

			Matx31d nxy = mR_ref.t()*mK_ref.inv()*xyz;

			Point3d pt3d;
			pt3d.x = nxy(0);
			pt3d.y = nxy(1);
			pt3d.z = nxy(2);

			vNImgPts_ref.push_back(pt3d);
		}
	}

	Mat patch_ref(vImgs[idx_refimg], cv::Rect(x-halfpatch_w, y-halfpatch_h, patchWidth, patchHeight));

	double depth = depth_init;
	double hx = hx_init;
	double hy = hy_init;
	vector<double> vck(ncams_visi, 1);

	double depth_old, hx_old, hy_old;

	bool bDivergent = false;

	double fVal_old = 0;
	double fVal_new;
	double hVal;

	for (k=0;k<maxIter;k++)
	{
		CString strinfo;
		strinfo.Format("C:\\Users\\DeepVoid\\Desktop\\support window of iteration %02d.txt", k);
		OutputSupportWindow(strinfo, mK_ref, mR_ref, mt_ref, x, y, depth, hx, hy, patchWidth, patchHeight, 255, 255, 0, 5);

		// first get the 3d patch points corresponding to current parameter set
		vector<Point3d> vWrdPts;

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				Matx31d mDir;
				mDir(0) = vNImgPts_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w].x;
				mDir(1) = vNImgPts_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w].y;
				mDir(2) = vNImgPts_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w].z;
				/*mDir(2) = 1;*/
			
				Matx31d XYZ = mC_ref + (depth+hx*j+hy*i) * mDir;
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);
			}
		}

		vector<Mat> vJacobs, vFs;
		vector<int> vIdxValid;

		int nAllRows = 0;

		Mat mJacob_k, mF_k, imgPatchResamp;
		for (ii=0;ii<ncams_visi;ii++)
		{
			if (!f_jacob_fk_drhxhyck_patchref_uchar(patch_ref, vImgs[vIdxVisiCams[ii]], vKs[ii], vRs[ii], vts[ii], vWrdPts, vNImgPts_ref, vck[ii], mJacob_k, mF_k, imgPatchResamp))
			{
				continue;
			}

			nAllRows += mJacob_k.rows;

			vJacobs.push_back(mJacob_k);
			vFs.push_back(mF_k);
			vIdxValid.push_back(ii);
		}

		int nValid = vJacobs.size();
		int nAllCols = 3+nValid;

		if (nValid == 0)
		{
			return false;
		}

		Mat mJ, mF;

		if (bFixCk)
		{
// 			mJ = Mat(nAllRows, 3, CV_32FC1, Scalar(0));
// 			mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));
// 
// 			int ntmp = 0;
// 			for (i=0;i<nValid;i++)
// 			{
// 				for (j=0;j<vJacobs[i].rows;j++)
// 				{
// 					mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,0);
// 					mJ.at<float>(ntmp+j,1) = vJacobs[i].at<float>(j,1);
// 					mJ.at<float>(ntmp+j,2) = vJacobs[i].at<float>(j,2);
// 					mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
// 				}
// 
// 				ntmp += vJacobs[i].rows;
// 			}

// 			mJ = Mat(nAllRows, 1, CV_32FC1, Scalar(0));
// 			mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));
// 
// 			int ntmp = 0;
// 			for (i=0;i<nValid;i++)
// 			{
// 				for (j=0;j<vJacobs[i].rows;j++)
// 				{
// 					mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,0);
// 					mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
// 				}
// 
// 				ntmp += vJacobs[i].rows;
// 			}

			mJ = Mat(nAllRows, 2, CV_32FC1, Scalar(0));
			mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));

			int ntmp = 0;
			for (i=0;i<nValid;i++)
			{
				for (j=0;j<vJacobs[i].rows;j++)
				{
					mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,1);
 					mJ.at<float>(ntmp+j,1) = vJacobs[i].at<float>(j,2);
					mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
				}

				ntmp += vJacobs[i].rows;
			}
		} 
		else
		{
// 			mJ = Mat(nAllRows, nAllCols, CV_32FC1, Scalar(0)); 
// 			mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));
// 
// 			int ntmp = 0;
// 			for (i=0;i<nValid;i++)
// 			{
// 				for (j=0;j<vJacobs[i].rows;j++)
// 				{
// 					mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,0);
// 					mJ.at<float>(ntmp+j,1) = vJacobs[i].at<float>(j,1);
// 					mJ.at<float>(ntmp+j,2) = vJacobs[i].at<float>(j,2);
// 					mJ.at<float>(ntmp+j,3+i) = vJacobs[i].at<float>(j,3);
// 					mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
// 				}
// 
// 				ntmp += vJacobs[i].rows;
// 			}

// 			mJ = Mat(nAllRows, nAllCols-2, CV_32FC1, Scalar(0)); 
// 			mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));
// 
// 			int ntmp = 0;
// 			for (i=0;i<nValid;i++)
// 			{
// 				for (j=0;j<vJacobs[i].rows;j++)
// 				{
// 					mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,0);
// 					mJ.at<float>(ntmp+j,1+i) = vJacobs[i].at<float>(j,3);
// 					mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
// 				}
// 
// 				ntmp += vJacobs[i].rows;
// 			}

			mJ = Mat(nAllRows, nAllCols-1, CV_32FC1, Scalar(0));
			mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));

			int ntmp = 0;
			for (i=0;i<nValid;i++)
			{
				for (j=0;j<vJacobs[i].rows;j++)
				{
					mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,1);
 					mJ.at<float>(ntmp+j,1) = vJacobs[i].at<float>(j,2);
					mJ.at<float>(ntmp+j,2+i) = vJacobs[i].at<float>(j,3);
					mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
				}

				ntmp += vJacobs[i].rows;
			}
		}

		// 解方程组 (J'J) h = -J'f 得到的 h 即为待优化参数的改正量，下次迭代的 x(k + 1) = x(k) + h
		Mat mA = mJ.t() * mJ;
		Mat mb = -mJ.t() * mF;
		Mat mA_1 = mA.inv(DECOMP_CHOLESKY);

		Mat mh = mA_1*mb;

		fVal_new = norm(mF)*norm(mF);
		hVal     = norm(mh);

		double s0 = sqrt(fVal_new/(mJ.rows-mJ.cols));

		vector<double> vStds;
		for (i=0;i<mA_1.rows;i++)
		{
			double stdev = s0 * sqrt(mA_1.at<float>(i,i));
			vStds.push_back(stdev);
		}

		double df2 = fVal_new - fVal_old;

		if (k!=0&&df2/fVal_old>0.001)
//		if (k!=0&&df2/fVal_old>1)
		{
			bDivergent = true;
			break;
		}

		// 当目标函数值的平方和变化量小于一定阈值或者改正量的范数值小于一定阈值时认为迭代收敛，退出迭代
		if ((fabs(df2) < fEps) || (hVal < xEps))
		{
			break;
		}

		fVal_old = fVal_new;

//		depth_old = depth;
		hx_old = hx;
		hy_old = hy;

//		depth += mh.at<float>(0);
// 		hx    += mh.at<float>(1);
// 		hy    += mh.at<float>(2);
		hx    += mh.at<float>(0);
		hy    += mh.at<float>(1);

		if (!bFixCk)
		{
			for (i=0;i<nValid;i++)
			{
				vck[vIdxValid[i]] += mh.at<float>(2+i);
//				vck[vIdxValid[i]] += mh.at<float>(3+i);
			}
		}
	}

	if (iterNum)
	{
		*iterNum = k;
	}

	if (bDivergent)
	{
//		depth_optim = depth_old;
		depth_optim = depth;
		hx_optim = hx_old;
		hy_optim = hy_old;
// 		hx_optim = hx;
// 		hy_optim = hy;
	} 
	else
	{
		depth_optim = depth;
		hx_optim = hx;
		hy_optim = hy;
	}

	CString strinfo;
	strinfo.Format("C:\\Users\\DeepVoid\\Desktop\\final support window.txt");
	OutputSupportWindow(strinfo, mK_ref, mR_ref, mt_ref, x, y, depth_optim, hx_optim, hy_optim, patchWidth, patchHeight, 255, 255, 0, 5);

	return true;
}

bool DeepVoid::optim_gn_drhxhyck(const vector<Matx33d> & vKs,
							     const vector<Matx33d> & vRs,
							     const vector<Matx31d> & vts,
							     const vector<Mat> & vImgs,			// input:	all images
							     const vector<int> & vIdxVisiCams,	// input:	indices of all visible cameras
							     int idx_refimg,					// input:	the index of the reference image
							     int x, int y,						// input:	the indices of the pixel to be checked
							     int patchWidth, int patchHeight,	// input:	the patch size
							     double depth_init,					// input:	initial depth of this pixel
							     double hx_init,					// input:	initial normal of this pixel
							     double hy_init,					// input:	initial normal of this pixel
							     double & depth_optim,				// output:	optimized depth of this pixel
							     double & hx_optim,					// output:	optimized normal of this pixel
							     double & hy_optim,					// output:	optimized normal of this pixel
							     bool bFixCk /*= false*/,			// input:	fix all ck or not
							     int maxIter /*= 128*/,				// input: max iteration
							     double xEps /*= 1.0E-8*/,			// input: threshold
							     double fEps /*= 1.0E-6*/,			// input: threshold
							     int * iterNum /*= NULL*/			// output:iteration number when quiting
							     )
{
	int i,j,k,ii;

	int npts_patch = patchWidth*patchHeight;
	int ncams_visi = vIdxVisiCams.size();

	int nChannel = vImgs[idx_refimg].channels();

	int halfpatch_w = (patchWidth-1)*0.5;
	int halfpatch_h = (patchHeight-1)*0.5;

	Matx33d mK_ref = vKs[idx_refimg]; Matx33d mR_ref = vRs[idx_refimg];
	Matx31d mt_ref = vts[idx_refimg];

	vector<Matx33d> vKs_visi(ncams_visi),vRs_visi(ncams_visi);
	vector<Matx31d> vts_visi(ncams_visi);

	for (k=0;k<ncams_visi;k++)
	{
		vKs_visi[k] = vKs[vIdxVisiCams[k]];
		vRs_visi[k] = vRs[vIdxVisiCams[k]];
		vts_visi[k] = vts[vIdxVisiCams[k]];
	}

	Matx31d mC_ref = -mR_ref.t() * mt_ref;

	//vector<Point2d> vNImgPts_ref; // the normalized image points or directions of every patch points
	vector<Point3d> vNImgPts_ref; // the normalized image points or directions of every patch points
	for (i=-halfpatch_h;i<=halfpatch_h;i++)
	{
		for (j=-halfpatch_w;j<=halfpatch_w;j++)
		{
			Matx31d xyz;
			xyz(0) = x+j;
			xyz(1) = y+i;
			xyz(2) = 1;

			Matx31d nxy = mR_ref.t()*mK_ref.inv()*xyz;

			Point3d pt3d;
			pt3d.x = nxy(0);
			pt3d.y = nxy(1);
			pt3d.z = nxy(2);

			vNImgPts_ref.push_back(pt3d);
		}
	}

	Mat patch_ref(vImgs[idx_refimg], cv::Rect(x-halfpatch_w, y-halfpatch_h, patchWidth, patchHeight));

	double depth = depth_init;
	double hx = hx_init;
	double hy = hy_init;
	vector<double> vck(ncams_visi, 1);

	double depth_old, hx_old, hy_old;

	bool bDivergent = false;

	double fVal_old = 0;
	double fVal_new;
	double hVal;

	for (k=0;k<maxIter;k++)
	{
		// first get the 3d patch points corresponding to current parameter set
		vector<Point3d> vWrdPts;

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				Matx31d mDir;
				mDir(0) = vNImgPts_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w].x;
				mDir(1) = vNImgPts_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w].y;
				mDir(2) = vNImgPts_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w].z;
				/*mDir(2) = 1;*/

				Matx31d XYZ = mC_ref + (depth+hx*j+hy*i) * mDir;
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);
			}
		}

		vector<Mat> vJacobs, vFs;
		vector<int> vIdxValid;

		int nAllRows = 0;

		Mat mJacob_k, mF_k, imgPatchResamp;
		for (ii=0;ii<ncams_visi;ii++)
		{
			if (!f_jacob_fk_drhxhyck_patchref_uchar(patch_ref, vImgs[vIdxVisiCams[ii]], vKs_visi[ii], vRs_visi[ii], vts_visi[ii], vWrdPts, vNImgPts_ref, vck[ii], mJacob_k, mF_k, imgPatchResamp))
			{
				continue;
			}

			nAllRows += mJacob_k.rows;

			vJacobs.push_back(mJacob_k);
			vFs.push_back(mF_k);
			vIdxValid.push_back(ii);
		}

		int nValid = vJacobs.size();
		int nAllCols = 3+nValid;

		if (nValid == 0)
		{
			return false;
		}

		Mat mJ, mF;

		if (bFixCk)
		{
			mJ = Mat(nAllRows, 3, CV_32FC1, Scalar(0));
			mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));

			int ntmp = 0;
			for (i=0;i<nValid;i++)
			{
				for (j=0;j<vJacobs[i].rows;j++)
				{
					mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,0);
					mJ.at<float>(ntmp+j,1) = vJacobs[i].at<float>(j,1);
					mJ.at<float>(ntmp+j,2) = vJacobs[i].at<float>(j,2);
					mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
				}

				ntmp += vJacobs[i].rows;
			}
		} 
		else
		{
			mJ = Mat(nAllRows, nAllCols, CV_32FC1, Scalar(0)); 
			mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));

			int ntmp = 0;
			for (i=0;i<nValid;i++)
			{
				for (j=0;j<vJacobs[i].rows;j++)
				{
					mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,0);
					mJ.at<float>(ntmp+j,1) = vJacobs[i].at<float>(j,1);
					mJ.at<float>(ntmp+j,2) = vJacobs[i].at<float>(j,2);
					mJ.at<float>(ntmp+j,3+i) = vJacobs[i].at<float>(j,3);
					mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
				}

				ntmp += vJacobs[i].rows;
			}
		}

		// 解方程组 (J'J) h = -J'f 得到的 h 即为待优化参数的改正量，下次迭代的 x(k + 1) = x(k) + h
		Mat mA = mJ.t() * mJ;
		Mat mb = -mJ.t() * mF;
		Mat mA_1 = mA.inv(DECOMP_CHOLESKY);

		Mat mh = mA_1*mb;

		fVal_new = norm(mF)*norm(mF);
		hVal     = norm(mh);

		double s0 = sqrt(fVal_new/(mJ.rows-mJ.cols));

		vector<double> vStds;
		for (i=0;i<mA_1.rows;i++)
		{
			double stdev = s0 * sqrt(mA_1.at<float>(i,i));
			vStds.push_back(stdev);
		}

		double df2 = fVal_new - fVal_old;

		if (k!=0&&df2/fVal_old>0.001)
		{
			bDivergent = true;
			break;
		}

		// 当目标函数值的平方和变化量小于一定阈值或者改正量的范数值小于一定阈值时认为迭代收敛，退出迭代
		if ((fabs(df2) < fEps) || (hVal < xEps))
		{
			break;
		}

		fVal_old = fVal_new;
		depth_old = depth;
		hx_old = hx;
		hy_old = hy;

		depth += mh.at<float>(0);
		hx    += mh.at<float>(1);
		hy    += mh.at<float>(2);

		if (!bFixCk)
		{
			for (i=0;i<nValid;i++)
			{
				vck[vIdxValid[i]] += mh.at<float>(3+i);
			}
		}
	}

	if (iterNum)
	{
		*iterNum = k;
	}

	if (bDivergent)
	{
		depth_optim = depth_old;
		hx_optim = hx_old;
		hy_optim = hy_old;
	} 
	else
	{
		depth_optim = depth;
		hx_optim = hx;
		hy_optim = hy;
	}

	return true;
}

// 20140604
bool DeepVoid::optim_gn_drhxhyck_NCCcontrolled(const vector<Matx33d> & vKs,
											   const vector<Matx33d> & vRs,
											   const vector<Matx31d> & vts,
											   const vector<Mat> & vImgs,		// input:	all images
											   const vector<int> & vIdxVisiCams,// input:	indices of all visible cameras
											   int idx_refimg,					// input:	the index of the reference image
											   int x, int y,					// input:	the indices of the pixel to be checked
											   int patchWidth, int patchHeight,	// input:	the patch size
											   double depth_init,				// input:	initial depth of this pixel
											   double hx_init,					// input:	initial normal of this pixel
											   double hy_init,					// input:	initial normal of this pixel
											   double & depth_optim,			// output:	optimized depth of this pixel
											   double & hx_optim,				// output:	optimized normal of this pixel
											   double & hy_optim,				// output:	optimized normal of this pixel
											   int maxIter /*= 128*/,			// input: max iteration
											   double xEps /*= 1.0E-8*/,		// input: threshold
											   double fEps /*= 1.0E-6*/,		// input: threshold
											   int * iterNum /*= NULL*/			// output:iteration number when quiting
											   )
{
	int i,j,k,ii;

	int npts_patch = patchWidth*patchHeight;
	int ncams_visi = vIdxVisiCams.size();

	int nChannel = vImgs[idx_refimg].channels();

	int halfpatch_w = (patchWidth-1)*0.5;
	int halfpatch_h = (patchHeight-1)*0.5;

	Matx33d mK_ref = vKs[idx_refimg]; Matx33d mR_ref = vRs[idx_refimg];
	Matx31d mt_ref = vts[idx_refimg];

	vector<Matx33d> vKs_visi(ncams_visi),vRs_visi(ncams_visi);
	vector<Matx31d> vts_visi(ncams_visi);

	for (k=0;k<ncams_visi;k++)
	{
		vKs_visi[k] = vKs[vIdxVisiCams[k]];
		vRs_visi[k] = vRs[vIdxVisiCams[k]];
		vts_visi[k] = vts[vIdxVisiCams[k]];
	}

	Matx31d mC_ref = -mR_ref.t() * mt_ref;

	//vector<Point2d> vNImgPts_ref; // the normalized image points or directions of every patch points
	vector<Point3d> vNImgPts_ref; // the normalized image points or directions of every patch points
	for (i=-halfpatch_h;i<=halfpatch_h;i++)
	{
		for (j=-halfpatch_w;j<=halfpatch_w;j++)
		{
			Matx31d xyz;
			xyz(0) = x+j;
			xyz(1) = y+i;
			xyz(2) = 1;

			Matx31d nxy = mR_ref.t()*mK_ref.inv()*xyz;

			Point3d pt3d;
			pt3d.x = nxy(0);
			pt3d.y = nxy(1);
			pt3d.z = nxy(2);

			vNImgPts_ref.push_back(pt3d);
		}
	}

//	Mat patch_ref(vImgs[idx_refimg], cv::Rect(x-halfpatch_w, y-halfpatch_h, patchWidth, patchHeight));
	Mat patch_ref;
	if (nChannel==1) // gray level image
	{
		patch_ref = Mat(patchHeight, patchWidth, CV_32FC1);

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				patch_ref.at<float>(i+halfpatch_h, j+halfpatch_w) = vImgs[idx_refimg].at<uchar>(y+i,x+j);
				patch_ref.at<float>(i+halfpatch_h, j+halfpatch_w) = vImgs[idx_refimg].at<uchar>(y+i,x+j);
				patch_ref.at<float>(i+halfpatch_h, j+halfpatch_w) = vImgs[idx_refimg].at<uchar>(y+i,x+j);
			}
		}
	} 
	else // color image
	{
		patch_ref = Mat(patchHeight, patchWidth, CV_32FC3);

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[0] = vImgs[idx_refimg].at<Vec3b>(y+i,x+j).val[0];
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[1] = vImgs[idx_refimg].at<Vec3b>(y+i,x+j).val[1];
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[2] = vImgs[idx_refimg].at<Vec3b>(y+i,x+j).val[2];
			}
		}
	}

	double depth = depth_init;
	double hx = hx_init;
	double hy = hy_init;
	vector<double> vck(ncams_visi, 1);

	double depth_old, hx_old, hy_old;

	bool bDivergent = false;

	double fVal_old = 0; double ncc_mean_old = 0;
	double fVal_new; double ncc_mean_new;
	double hVal;

	bool bUpdatehxhyck;
	for (k=0;k<maxIter;k++)
	{
		if ((k+1)%5==0)
		{
			bUpdatehxhyck = true;
		} 
		else
		{
			bUpdatehxhyck = false;
		}

		// first get the 3d patch points corresponding to current parameter set
		vector<Point3d> vWrdPts;

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				Matx31d mDir;
				mDir(0) = vNImgPts_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w].x;
				mDir(1) = vNImgPts_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w].y;
				mDir(2) = vNImgPts_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w].z;
				/*mDir(2) = 1;*/

				Matx31d XYZ = mC_ref + (depth+hx*j+hy*i) * mDir;
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);
			}
		}

		vector<Mat> vJacobs, vFs;
		vector<int> vIdxValid;

		int nAllRows = 0;

		Mat mJacob_k, mF_k, imgPatchResamp; vector<double> vnccs; double sum_ncc = 0;
		for (ii=0;ii<ncams_visi;ii++)
		{
			if (!f_jacob_fk_drhxhyck_patchref_float(patch_ref, vImgs[vIdxVisiCams[ii]], vKs_visi[ii], vRs_visi[ii], vts_visi[ii], vWrdPts, vNImgPts_ref, vck[ii], mJacob_k, mF_k, imgPatchResamp))
			{
				continue;
			}

			int result_cols = imgPatchResamp.cols - patch_ref.cols + 1;
			int result_rows = imgPatchResamp.rows - patch_ref.rows + 1;
			Mat mNCC(result_rows, result_cols, CV_32FC1);
			matchTemplate(patch_ref, imgPatchResamp, mNCC, /*CV_TM_SQDIFF_NORMED*/CV_TM_CCORR_NORMED);
			vnccs.push_back(mNCC.at<float>(0));
			sum_ncc += mNCC.at<float>(0);

			nAllRows += mJacob_k.rows;

			vJacobs.push_back(mJacob_k);
			vFs.push_back(mF_k);
			vIdxValid.push_back(ii);
		}

		int nValid = vJacobs.size();
		int nAllCols = 3+nValid;

		if (nValid == 0)
		{
			return false;
		}

		Mat mJ, mF;

		if (!bUpdatehxhyck) // update depth only
		{
			mJ = Mat(nAllRows, 1, CV_32FC1, Scalar(0));
			mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));

			int ntmp = 0;
			for (i=0;i<nValid;i++)
			{
				for (j=0;j<vJacobs[i].rows;j++)
				{
					mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,0);
					mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
				}

				ntmp += vJacobs[i].rows;
			}
		} 
		else // update depth, hx, hy and ck
		{
			mJ = Mat(nAllRows, nAllCols, CV_32FC1, Scalar(0)); 
			mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));

			int ntmp = 0;
			for (i=0;i<nValid;i++)
			{
				for (j=0;j<vJacobs[i].rows;j++)
				{
					mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,0);
					mJ.at<float>(ntmp+j,1) = vJacobs[i].at<float>(j,1);
					mJ.at<float>(ntmp+j,2) = vJacobs[i].at<float>(j,2);
					mJ.at<float>(ntmp+j,3+i) = vJacobs[i].at<float>(j,3);
					mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
				}

				ntmp += vJacobs[i].rows;
			}
		}

		// 解方程组 (J'J) h = -J'f 得到的 h 即为待优化参数的改正量，下次迭代的 x(k + 1) = x(k) + h
		Mat mA = mJ.t() * mJ;
		Mat mb = -mJ.t() * mF;
		Mat mA_1 = mA.inv(DECOMP_CHOLESKY);

		Mat mh = mA_1*mb;

		fVal_new = norm(mF)*norm(mF);
		hVal     = norm(mh);
		ncc_mean_new = sum_ncc/vnccs.size();

		double s0 = sqrt(fVal_new/(mJ.rows-mJ.cols));

		vector<double> vStds;
		for (i=0;i<mA_1.rows;i++)
		{
			double stdev = s0 * sqrt(mA_1.at<float>(i,i));
			vStds.push_back(stdev);
		}

		double df2 = fVal_new - fVal_old;
		double dncc = ncc_mean_new - ncc_mean_old;

// 		if (k!=0&&df2/fVal_old>0.001)
// 		{
// 			bDivergent = true;
// 			break;
// 		}

		if (k!=0&&dncc<0)
		{
			bDivergent = true;
			break;
		}

		// 当目标函数值的平方和变化量小于一定阈值或者改正量的范数值小于一定阈值时认为迭代收敛，退出迭代
		if ((fabs(df2) < fEps) || (hVal < xEps) || (dncc<0.0001))
		{
			break;
		}

		fVal_old = fVal_new;
		ncc_mean_old = ncc_mean_new;

		depth_old = depth;
		hx_old = hx;
		hy_old = hy;

		if (!bUpdatehxhyck)
		{
			depth += mh.at<float>(0);
		} 
		else
		{
			depth += mh.at<float>(0);
			hx    += mh.at<float>(1);
			hy    += mh.at<float>(2);

			for (i=0;i<nValid;i++)
			{
				vck[vIdxValid[i]] += mh.at<float>(3+i);
			}
		}
	}

	if (iterNum)
	{
		*iterNum = k;
	}

	if (bDivergent)
	{
		depth_optim = depth_old;
		hx_optim = hx_old;
		hy_optim = hy_old;
	} 
	else
	{
		depth_optim = depth;
		hx_optim = hx;
		hy_optim = hy;
	}

	return true;
}

// 20140904
bool DeepVoid::optim_gn_drhxhyck_NCCcontrolled(const vector<Matx33d> & vKs,
											   const vector<Matx33d> & vRs,
											   const vector<Matx31d> & vts,
											   const vector<double> & vfx_1,			// input:	
											   const vector<double> & vfy_1,			// input:
											   const vector<Mat> & vImgs,				// input:	all images
											   const vector<vector<int>> & vIdxSupports,// input:	all images' support images' index
											   int idx_refimg,							// input:	the index of the reference image
											   int x, int y,							// input:	the indices of the pixel to be checked
											   uchar visi,								// input:	visibility within support images
											   int patchWidth, int patchHeight,			// input:	the patch size
											   double depth_init,						// input:	initial depth of this pixel
											   double hx_init,							// input:	initial normal of this pixel
											   double hy_init,							// input:	initial normal of this pixel
											   double score_init,						// input:	initial mean ncc value
											   double & depth_optim,					// output:	optimized depth of this pixel
											   double & hx_optim,						// output:	optimized normal of this pixel
											   double & hy_optim,						// output:	optimized normal of this pixel
											   double & score_optim,					// output:	optimized mean ncc value
											   int maxIter /*= 128*/,					// input: max iteration
											   double xEps /*= 1.0E-8*/,				// input: threshold
											   double fEps /*= 1.0E-6*/,				// input: threshold
											   int * iterNum /*= NULL*/					// output:iteration number when quiting
											   )
{
	int i,j,k,ii;

	vector<bool> vbools; int ncams_visi;
	InterpVisiVector_uchar(visi, vbools, &ncams_visi);

	vector<int> vIdx_spts = vIdxSupports[idx_refimg];

	int npts_patch = patchWidth*patchHeight;

	int nChannel = vImgs[idx_refimg].channels();

	int halfpatch_w = (patchWidth-1)*0.5;
	int halfpatch_h = (patchHeight-1)*0.5;

	Matx33d mK_ref = vKs[idx_refimg]; Matx33d mR_ref = vRs[idx_refimg];
	Matx31d mt_ref = vts[idx_refimg];

	vector<Matx33d> vKRs_visi;
	vector<Matx31d> vKts_visi;
	vector<int> vIdxVisiCams;

	for (k=0;k<vIdx_spts.size();k++)
	{
		if (vbools[k])
		{
			vKRs_visi.push_back(vKs[vIdx_spts[k]]*vRs[vIdx_spts[k]]);
			vKts_visi.push_back(vKs[vIdx_spts[k]]*vts[vIdx_spts[k]]);
			vIdxVisiCams.push_back(vIdx_spts[k]);
		}
	}

	Matx31d mC_ref = -mR_ref.t() * mt_ref;

	Matx33d mR_ref_t = mR_ref.t();

	double cx0 = vKs[idx_refimg](0,2);
	double cy0 = vKs[idx_refimg](1,2);

	vector<Matx31d> vRtxs_ref; // the normalized image points or directions of every patch points
	for (i=-halfpatch_h;i<=halfpatch_h;i++)
	{
		double nimgy = (y+i-cy0)*vfy_1[idx_refimg];

		for (j=-halfpatch_w;j<=halfpatch_w;j++)
		{
			double nimgx = (x+j-cx0)*vfx_1[idx_refimg];

			Matx31d xyz;
			xyz(0) = nimgx;
			xyz(1) = nimgy;
			xyz(2) = 1;

			Matx31d nxy = mR_ref_t*xyz; // R'x(u,v) transpose of R * normalized image points of (u,v)

			vRtxs_ref.push_back(nxy);
		}
	}

	//	Mat patch_ref(vImgs[idx_refimg], cv::Rect(x-halfpatch_w, y-halfpatch_h, patchWidth, patchHeight));
	Mat patch_ref;
	if (nChannel==1) // gray level image
	{
		patch_ref = Mat(patchHeight, patchWidth, CV_32FC1);

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				patch_ref.at<float>(i+halfpatch_h, j+halfpatch_w) = vImgs[idx_refimg].at<uchar>(y+i,x+j);
			}
		}
	} 
	else // color image
	{
		patch_ref = Mat(patchHeight, patchWidth, CV_32FC3);

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[0] = vImgs[idx_refimg].at<Vec3b>(y+i,x+j).val[0];
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[1] = vImgs[idx_refimg].at<Vec3b>(y+i,x+j).val[1];
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[2] = vImgs[idx_refimg].at<Vec3b>(y+i,x+j).val[2];
			}
		}
	}

	double depth = depth_init;
	double hx = hx_init;
	double hy = hy_init;
	vector<double> vck(ncams_visi, 1);

	// record runtime info of each iteration
	vector<double> vDepths, vHxs, vHys, vScores, vF2;

	double fVal_old = 0; double ncc_mean_old = 0;
	double fVal_new; double ncc_mean_new;
	double hVal;

	for (k=0;k<maxIter;k++)
	{
		// first get the 3d patch points corresponding to current parameter set
		vector<Matx31d> vWrdPts;

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				Matx31d mDir;
				mDir(0) = vRtxs_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w](0);
				mDir(1) = vRtxs_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w](1);
				mDir(2) = vRtxs_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w](2);

				Matx31d XYZ = mC_ref + (depth+hx*j+hy*i) * mDir;
				
				vWrdPts.push_back(XYZ);
			}
		}

		vector<Mat> vJacobs, vFs;
		vector<int> vIdxValid;

		int nAllRows = 0;

		Mat mJacob_k, mF_k, imgPatchResamp; vector<double> vnccs; double sum_ncc = 0;
		for (ii=0;ii<ncams_visi;ii++)
		{
			if (!f_jacob_fk_drhxhyck_patchref_float_20140904(patch_ref,vImgs[vIdxVisiCams[ii]],vKRs_visi[ii],vKts_visi[ii],vWrdPts,vRtxs_ref,vck[ii],mJacob_k,mF_k,imgPatchResamp))
			{
				continue;
			}

			int result_cols = imgPatchResamp.cols - patch_ref.cols + 1;
			int result_rows = imgPatchResamp.rows - patch_ref.rows + 1;
			Mat mNCC(result_rows, result_cols, CV_32FC1);
			matchTemplate(patch_ref, imgPatchResamp, mNCC, CV_TM_CCORR_NORMED); // compute NCC
			vnccs.push_back(mNCC.at<float>(0));
			sum_ncc += mNCC.at<float>(0);

			nAllRows += mJacob_k.rows;

			vJacobs.push_back(mJacob_k);
			vFs.push_back(mF_k);
			vIdxValid.push_back(ii);
		}

		int nValid = vJacobs.size();
		int nAllCols = 3+nValid;

		if (nValid == 0)
		{
			// if no valid observations exist, then all parameters stay unchanged
			depth_optim = depth_init;
			hx_optim = hx_init;
			hy_optim = hy_init;
			score_optim = score_init;
			return false;
		}

		Mat mJ, mF;

		mJ = Mat(nAllRows, nAllCols, CV_32FC1, Scalar(0)); 
		mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));

		int ntmp = 0;
		for (i=0;i<nValid;i++)
		{
			for (j=0;j<vJacobs[i].rows;j++)
			{
				mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,0);
				mJ.at<float>(ntmp+j,1) = vJacobs[i].at<float>(j,1);
				mJ.at<float>(ntmp+j,2) = vJacobs[i].at<float>(j,2);
				mJ.at<float>(ntmp+j,3+i) = vJacobs[i].at<float>(j,3);
				mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
			}

			ntmp += vJacobs[i].rows;
		}
		
		// 解方程组 (J'J) h = -J'f 得到的 h 即为待优化参数的改正量，下次迭代的 x(k + 1) = x(k) + h
		Mat mA = mJ.t() * mJ;
		Mat mb = -mJ.t() * mF;
		Mat mA_1 = mA.inv(DECOMP_CHOLESKY);

		Mat mh = mA_1*mb;

		fVal_new = norm(mF)*norm(mF);
		hVal     = norm(mh);
		ncc_mean_new = sum_ncc/vnccs.size();

		// record this iteration
		vDepths.push_back(depth);
		vHxs.push_back(hx);
		vHys.push_back(hy);
		vScores.push_back(ncc_mean_new);
		vF2.push_back(fVal_new);

		double s0 = sqrt(fVal_new/(mJ.rows-mJ.cols));

		vector<double> vStds;
		for (i=0;i<mA_1.rows;i++)
		{
			double stdev = s0 * sqrt(mA_1.at<float>(i,i));
			vStds.push_back(stdev);
		}

		double df2 = fVal_new - fVal_old;
		double dncc = ncc_mean_new - ncc_mean_old;

		// 当目标函数值的平方和变化量小于一定阈值或者改正量的范数值小于一定阈值时认为迭代收敛，退出迭代
		if ((fabs(df2) < fEps) || (hVal < xEps))
		{
			break;
		}

		fVal_old = fVal_new;
		ncc_mean_old = ncc_mean_new;

		depth += mh.at<float>(0);
		hx    += mh.at<float>(1);
		hy    += mh.at<float>(2);

		for (i=0;i<nValid;i++)
		{
			vck[vIdxValid[i]] += mh.at<float>(3+i);
		}
	}

	if (iterNum)
	{
		*iterNum = k;
	}

	vector <double>::const_iterator iterDouble = max_element(vScores.begin(), vScores.end());
	double max_score = *iterDouble;
	int idx_max_score = iterDouble - vScores.begin();

	iterDouble = min_element(vF2.begin(), vF2.end());
	double min_F2 = *iterDouble;
	int idx_min_F2 = iterDouble - vF2.begin();

	int idx_final = idx_max_score;
//	int idx_final = idx_min_F2;

	depth_optim = vDepths[idx_final];
	hx_optim = vHxs[idx_final];
	hy_optim = vHys[idx_final];
	score_optim = vScores[idx_final];

	return true;
}

// 20140911 with masks to ensure unimodal MPGC
bool DeepVoid::optim_gn_drhxhyck_NCCcontrolled_masks(const vector<Matx33d> & vKs,
												     const vector<Matx33d> & vRs,
												     const vector<Matx31d> & vts,
												     const vector<double> & vfx_1,				// input:	
												     const vector<double> & vfy_1,				// input:
												     const vector<Mat> & vImgs,					// input:	all images
												     const vector<vector<int>> & vIdxSupports,	// input:	all images' support images' index
												     const vector<Mat> & vMasks,				// input:	pre-determined masks, one for each visible image
													 const vector<int> & vNum,					// input:	number of valid pixels in each mask
												     int idx_refimg,							// input:	the index of the reference image
												     int x, int y,								// input:	the indices of the pixel to be checked
												     uchar visi,								// input:	visibility within support images
												     int patchWidth, int patchHeight,			// input:	the patch size
												     double depth_init,							// input:	initial depth of this pixel
												     double hx_init,							// input:	initial normal of this pixel
												     double hy_init,							// input:	initial normal of this pixel
												     double score_init,							// input:	initial mean ncc value
												     double & depth_optim,						// output:	optimized depth of this pixel
												     double & hx_optim,							// output:	optimized normal of this pixel
												     double & hy_optim,							// output:	optimized normal of this pixel
												     double & score_optim,						// output:	optimized mean ncc value
												     int maxIter /*= 128*/,						// input: max iteration
												     double xEps /*= 1.0E-8*/,					// input: threshold
												     double fEps /*= 1.0E-6*/,					// input: threshold
												     int * iterNum /*= NULL*/					// output:iteration number when quiting
												     )
{
	int i,j,k,ii;

	vector<bool> vbools; int ncams_visi;
	InterpVisiVector_uchar(visi, vbools, &ncams_visi);

	vector<int> vIdx_spts = vIdxSupports[idx_refimg];

	int npts_patch = patchWidth*patchHeight;

	int nChannel = vImgs[idx_refimg].channels();

	int halfpatch_w = (patchWidth-1)*0.5;
	int halfpatch_h = (patchHeight-1)*0.5;

	Matx33d mK_ref = vKs[idx_refimg]; Matx33d mR_ref = vRs[idx_refimg];
	Matx31d mt_ref = vts[idx_refimg];

	vector<Matx33d> vKRs_visi;
	vector<Matx31d> vKts_visi;
	vector<int> vIdxVisiCams;

	for (k=0;k<vIdx_spts.size();k++)
	{
		if (vbools[k])
		{
			vKRs_visi.push_back(vKs[vIdx_spts[k]]*vRs[vIdx_spts[k]]);
			vKts_visi.push_back(vKs[vIdx_spts[k]]*vts[vIdx_spts[k]]);
			vIdxVisiCams.push_back(vIdx_spts[k]);
		}
	}

	Matx31d mC_ref = -mR_ref.t() * mt_ref;

	Matx33d mR_ref_t = mR_ref.t();

	double fx0 = vKs[idx_refimg](0,0);
	double fy0 = vKs[idx_refimg](1,1);
	double cx0 = vKs[idx_refimg](0,2);
	double cy0 = vKs[idx_refimg](1,2);

	// normalized image point
	double nimgx0 = (x-cx0)*vfx_1[idx_refimg];
	double nimgy0 = (y-cy0)*vfy_1[idx_refimg];

	vector<Matx31d> vRtxs_ref; // the normalized image points or directions of every patch points
	for (i=-halfpatch_h;i<=halfpatch_h;i++)
	{
		double nimgy = (y+i-cy0)*vfy_1[idx_refimg];

		for (j=-halfpatch_w;j<=halfpatch_w;j++)
		{
			double nimgx = (x+j-cx0)*vfx_1[idx_refimg];

			Matx31d xyz;
			xyz(0) = nimgx;
			xyz(1) = nimgy;
			xyz(2) = 1;

			Matx31d nxy = mR_ref_t*xyz; // R'x(u,v) transpose of R * normalized image points of (u,v)

			vRtxs_ref.push_back(nxy);
		}
	}

	//	Mat patch_ref(vImgs[idx_refimg], cv::Rect(x-halfpatch_w, y-halfpatch_h, patchWidth, patchHeight));
	Mat patch_ref;
	if (nChannel==1) // gray level image
	{
		patch_ref = Mat(patchHeight, patchWidth, CV_32FC1);

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				patch_ref.at<float>(i+halfpatch_h, j+halfpatch_w) = vImgs[idx_refimg].at<uchar>(y+i,x+j);
			}
		}
	} 
	else // color image
	{
		patch_ref = Mat(patchHeight, patchWidth, CV_32FC3);

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[0] = vImgs[idx_refimg].at<Vec3b>(y+i,x+j).val[0];
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[1] = vImgs[idx_refimg].at<Vec3b>(y+i,x+j).val[1];
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[2] = vImgs[idx_refimg].at<Vec3b>(y+i,x+j).val[2];
			}
		}
	}

	double depth = depth_init;
	double hx = hx_init;
	double hy = hy_init;
	vector<double> vck(ncams_visi, 1);

	// record runtime info of each iteration
	vector<double> vDepths, vHxs, vHys, vScores, vF2;

	double fVal_old = 0; double ncc_mean_old = 0;
	double fVal_new; double ncc_mean_new;
	double hVal;

	for (k=0;k<maxIter;k++)
	{
		// first get the 3d patch points corresponding to current parameter set
		vector<Matx31d> vWrdPts;

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				Matx31d mDir;
				mDir(0) = vRtxs_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w](0);
				mDir(1) = vRtxs_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w](1);
				mDir(2) = vRtxs_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w](2);

				Matx31d XYZ = mC_ref + (depth+hx*j+hy*i) * mDir;

				vWrdPts.push_back(XYZ);
			}
		}

		// current window normal
		Matx31d mn0; mn0(2)=1;
		get_normal_givendrhxhy(fx0,fy0,nimgx0,nimgy0,depth,hx,hy,mn0(0),mn0(1));
		// convert the normal into world coordinate system
		// the reason why is not R'n here is because the normal output by get_normal_givendrhxhy() is actually -n
		Matx31d mnw = -vRs[idx_refimg].t()*mn0; 

		vector<Mat> vJacobs, vFs;
		vector<int> vIdxValid;

		int nAllRows = 0;

		Mat mJacob_k, mF_k, imgPatchResamp; vector<double> vnccs; double sum_ncc = 0; int sum_num = 0; bool bInvalid = false;
		for (ii=0;ii<ncams_visi;ii++)
		{
			double ncc; bool bOppo;

			if (!f_jacob_fk_drhxhyck_patchref_float_20140911(patch_ref,vImgs[vIdxVisiCams[ii]],vMasks[ii],vNum[ii],vKs[vIdxVisiCams[ii]],vRs[vIdxVisiCams[ii]],
				vKRs_visi[ii],vKts_visi[ii],vfx_1[vIdxVisiCams[ii]],vfy_1[vIdxVisiCams[ii]],mnw,vWrdPts,vRtxs_ref,vck[ii],mJacob_k,mF_k,ncc,bOppo))
			{
				continue;
			}

			if (!bInvalid && bOppo)
			{
				bInvalid = true;
			}

			vnccs.push_back(ncc);
			sum_ncc += ncc*vNum[ii];
			sum_num += vNum[ii];

			nAllRows += mJacob_k.rows;

			vJacobs.push_back(mJacob_k);
			vFs.push_back(mF_k);
			vIdxValid.push_back(ii);
		}

		int nValid = vJacobs.size();
		int nAllCols = 3+nValid;

		if (nValid == 0)
		{
			// if no valid observations exist, then all parameters stay unchanged
			depth_optim = depth_init;
			hx_optim = hx_init;
			hy_optim = hy_init;
			score_optim = score_init;
			return false;
		}

		Mat mJ, mF;

		mJ = Mat(nAllRows, nAllCols, CV_32FC1, Scalar(0)); 
		mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));

		int ntmp = 0;
		for (i=0;i<nValid;i++)
		{
			for (j=0;j<vJacobs[i].rows;j++)
			{
				mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,0);
				mJ.at<float>(ntmp+j,1) = vJacobs[i].at<float>(j,1);
				mJ.at<float>(ntmp+j,2) = vJacobs[i].at<float>(j,2);
				mJ.at<float>(ntmp+j,3+i) = vJacobs[i].at<float>(j,3);
				mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
			}

			ntmp += vJacobs[i].rows;
		}

		// 解方程组 (J'J) h = -J'f 得到的 h 即为待优化参数的改正量，下次迭代的 x(k + 1) = x(k) + h
		Mat mA = mJ.t() * mJ;
		Mat mb = -mJ.t() * mF;
		Mat mA_1 = mA.inv(DECOMP_CHOLESKY);

		Mat mh = mA_1*mb;

		fVal_new = norm(mF)*norm(mF);
		hVal     = norm(mh);
		ncc_mean_new = sum_ncc/sum_num;

		// record this iteration
		vDepths.push_back(depth);
		vHxs.push_back(hx);
		vHys.push_back(hy);
		if (bInvalid) // this means current parameter voilated the normal requirement
		{
			vScores.push_back(-1);
		} 
		else
		{
			vScores.push_back(ncc_mean_new);
		}
		vF2.push_back(fVal_new);

		double s0 = sqrt(fVal_new/(mJ.rows-mJ.cols));

		vector<double> vStds;
		for (i=0;i<mA_1.rows;i++)
		{
			double stdev = s0 * sqrt(mA_1.at<float>(i,i));
			vStds.push_back(stdev);
		}

		double df2 = fVal_new - fVal_old;
		double dncc = ncc_mean_new - ncc_mean_old;

		// 当目标函数值的平方和变化量小于一定阈值或者改正量的范数值小于一定阈值时认为迭代收敛，退出迭代
		if ((fabs(df2) < fEps) || (hVal < xEps))
		{
			break;
		}

		fVal_old = fVal_new;
		ncc_mean_old = ncc_mean_new;

		depth += mh.at<float>(0);
		hx    += mh.at<float>(1);
		hy    += mh.at<float>(2);

		for (i=0;i<nValid;i++)
		{
			vck[vIdxValid[i]] += mh.at<float>(3+i);
		}
	}

	if (iterNum)
	{
		*iterNum = k;
	}

	vector <double>::const_iterator iterDouble = max_element(vScores.begin(), vScores.end());
	double max_score = *iterDouble;

	if (max_score < 0) // this means all parameter candidates have inreasonable normals
	{
		// if no valid observations exist, then all parameters stay unchanged
		depth_optim = depth_init;
		hx_optim = hx_init;
		hy_optim = hy_init;
		score_optim = score_init;
		return false;
	}

	int idx_max_score = iterDouble - vScores.begin();

	iterDouble = min_element(vF2.begin(), vF2.end());
	double min_F2 = *iterDouble;
	int idx_min_F2 = iterDouble - vF2.begin();

	int idx_final = idx_max_score;
//	int idx_final = idx_min_F2;

	depth_optim = vDepths[idx_final];
	hx_optim = vHxs[idx_final];
	hy_optim = vHys[idx_final];
	score_optim = vScores[idx_final];

	return true;
}

// 20140913, self-contained, with masks to ensure unimodal MPGC
bool DeepVoid::optim_gn_drhxhyck_NCCcontrolled_masks(const Matx33d & mK0,				// input:	interior matrix of reference image
												     const Matx33d & mR0,				// input:	rotation matrix of reference image
												     const Matx31d & mt0,				// input:	translation vector of reference image
													 const Mat & img0,					// input:	reference image
												     const vector<Matx33d> & vKs,		// input:	interior matrix of all visible support images
												     const vector<Matx33d> & vRs,		// input:	rotation matrix of all visible support images
												     const vector<Matx31d> & vts,		// input:	translation vectors of all visible support images
												     const vector<Mat> & vImgs,			// input:	images of all visible support images
												     const vector<Mat> & vMasks,		// input:	pre-determined masks, one for each visible image
												     const vector<int> & vNum,			// input:	number of valid pixels in each mask, one for each visible image
												     int x, int y,						// input:	the indices of the pixel to be checked
												     int patchWidth, int patchHeight,	// input:	the patch size
												     double depth_init,					// input:	initial depth of this pixel
												     double hx_init,					// input:	initial normal of this pixel
												     double hy_init,					// input:	initial normal of this pixel
												     double score_init,					// input:	initial mean ncc value
												     double & depth_optim,				// output:	optimized depth of this pixel
												     double & hx_optim,					// output:	optimized normal of this pixel
												     double & hy_optim,					// output:	optimized normal of this pixel
												     double & score_optim,				// output:	optimized mean ncc value
												     int maxIter /*= 128*/,				// input: max iteration
												     double xEps /*= 1.0E-8*/,			// input: threshold
												     double fEps /*= 1.0E-6*/,			// input: threshold
												     int * iterNum /*= NULL*/			// output:iteration number when quiting
												     )
{
	int i,j,k,ii;

	int npts_patch = patchWidth*patchHeight;

	int n_visi = vKs.size(); // number of visible support images

	int nChannel = img0.channels();

	int halfpatch_w = (patchWidth-1)*0.5;
	int halfpatch_h = (patchHeight-1)*0.5;

	vector<Matx33d> vKRs;
	vector<Matx31d> vKts;
	vector<double> vfx_1,vfy_1;

	for (k=0;k<n_visi;k++)
	{
		vKRs.push_back(vKs[k]*vRs[k]);
		vKts.push_back(vKs[k]*vts[k]);

		double fx_1 = 1/vKs[k](0,0);
		double fy_1 = 1/vKs[k](1,1);

		vfx_1.push_back(fx_1);
		vfy_1.push_back(fy_1);
	}

	Matx31d mC0 = -mR0.t() * mt0;

	Matx33d mR0_t = mR0.t();

	double fx0 = mK0(0,0);
	double fy0 = mK0(1,1);
	double fx0_1 = 1/fx0;
	double fy0_1 = 1/fy0;
	double cx0 = mK0(0,2);
	double cy0 = mK0(1,2);

	// normalized image point
	double nimgx0 = (x-cx0)*fx0_1;
	double nimgy0 = (y-cy0)*fy0_1;

	vector<Matx31d> vRtxs_ref; // the normalized image points or directions of every patch points
	for (i=-halfpatch_h;i<=halfpatch_h;i++)
	{
		double nimgy = (y+i-cy0)*fy0_1;

		for (j=-halfpatch_w;j<=halfpatch_w;j++)
		{
			double nimgx = (x+j-cx0)*fx0_1;

			Matx31d xyz;
			xyz(0) = nimgx;
			xyz(1) = nimgy;
			xyz(2) = 1;

			Matx31d nxy = mR0_t*xyz; // R'x(u,v) transpose of R * normalized image points of (u,v)

			vRtxs_ref.push_back(nxy);
		}
	}

	Mat patch_ref;
	if (nChannel==1) // gray level image
	{
		patch_ref = Mat(patchHeight, patchWidth, CV_32FC1);

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				patch_ref.at<float>(i+halfpatch_h, j+halfpatch_w) = img0.at<uchar>(y+i,x+j);
			}
		}
	} 
	else // color image
	{
		patch_ref = Mat(patchHeight, patchWidth, CV_32FC3);

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[0] = img0.at<Vec3b>(y+i,x+j).val[0];
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[1] = img0.at<Vec3b>(y+i,x+j).val[1];
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[2] = img0.at<Vec3b>(y+i,x+j).val[2];
			}
		}
	}

	double depth = depth_init;
	double hx = hx_init;
	double hy = hy_init;
	vector<double> vck(n_visi, 1);

	// record runtime info of each iteration
	vector<double> vDepths, vHxs, vHys, vScores, vF2;

	double fVal_old = 0; double ncc_mean_old = 0;
	double fVal_new; double ncc_mean_new;
	double hVal;

	for (k=0;k<maxIter;k++)
	{
		// first get the 3d patch points corresponding to current parameter set
		vector<Matx31d> vWrdPts;

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				Matx31d mDir;
				mDir(0) = vRtxs_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w](0);
				mDir(1) = vRtxs_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w](1);
				mDir(2) = vRtxs_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w](2);

				Matx31d XYZ = mC0 + (depth+hx*j+hy*i) * mDir;

				vWrdPts.push_back(XYZ);
			}
		}

		// current window normal
		Matx31d mn0; mn0(2)=1;
		get_normal_givendrhxhy(fx0,fy0,nimgx0,nimgy0,depth,hx,hy,mn0(0),mn0(1));
		// convert the normal into world coordinate system
		// the reason why is not R'n here is because the normal output by get_normal_givendrhxhy() is actually -n
		Matx31d mnw = -mR0_t*mn0; 

		vector<Mat> vJacobs, vFs;
		vector<int> vIdxValid;

		int nAllRows = 0;

		Mat mJacob_k, mF_k, imgPatchResamp; vector<double> vnccs; double sum_ncc = 0; int sum_num = 0; bool bInvalid = false;
		for (ii=0;ii<n_visi;ii++)
		{
			double ncc; bool bOppo;

			if (!f_jacob_fk_drhxhyck_patchref_float_20140911(patch_ref,vImgs[ii],vMasks[ii],vNum[ii],vKs[ii],vRs[ii],
				vKRs[ii],vKts[ii],vfx_1[ii],vfy_1[ii],mnw,vWrdPts,vRtxs_ref,vck[ii],mJacob_k,mF_k,ncc,bOppo))
			{
				continue;
			}

			if (!bInvalid && bOppo)
			{
				bInvalid = true;
			}

			vnccs.push_back(ncc);
			sum_ncc += ncc*vNum[ii];
			sum_num += vNum[ii];

			nAllRows += mJacob_k.rows;

			vJacobs.push_back(mJacob_k);
			vFs.push_back(mF_k);
			vIdxValid.push_back(ii);
		}

		int nValid = vJacobs.size();
		int nAllCols = 3+nValid;

		if (nValid == 0)
		{
			// if no valid observations exist, then all parameters stay unchanged
			depth_optim = depth_init;
			hx_optim = hx_init;
			hy_optim = hy_init;
			score_optim = score_init;
			return false;
		}

		Mat mJ, mF;

		mJ = Mat(nAllRows, nAllCols, CV_32FC1, Scalar(0)); 
		mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));

		int ntmp = 0;
		for (i=0;i<nValid;i++)
		{
			for (j=0;j<vJacobs[i].rows;j++)
			{
				mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,0);
				mJ.at<float>(ntmp+j,1) = vJacobs[i].at<float>(j,1);
				mJ.at<float>(ntmp+j,2) = vJacobs[i].at<float>(j,2);
				mJ.at<float>(ntmp+j,3+i) = vJacobs[i].at<float>(j,3);
				mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
			}

			ntmp += vJacobs[i].rows;
		}

		// 解方程组 (J'J) h = -J'f 得到的 h 即为待优化参数的改正量，下次迭代的 x(k + 1) = x(k) + h
		Mat mA = mJ.t() * mJ;
		Mat mb = -mJ.t() * mF;
		Mat mA_1 = mA.inv(DECOMP_CHOLESKY);

		Mat mh = mA_1*mb;

		fVal_new = norm(mF)*norm(mF);
		hVal     = norm(mh);
		ncc_mean_new = sum_ncc/sum_num;

		// record this iteration
		vDepths.push_back(depth);
		vHxs.push_back(hx);
		vHys.push_back(hy);
		if (bInvalid) // this means current parameter voilated the normal requirement
		{
			vScores.push_back(-1);
		} 
		else
		{
			vScores.push_back(ncc_mean_new);
		}
		vF2.push_back(fVal_new);

		double s0 = sqrt(fVal_new/(mJ.rows-mJ.cols));

		vector<double> vStds;
		for (i=0;i<mA_1.rows;i++)
		{
			double stdev = s0 * sqrt(mA_1.at<float>(i,i));
			vStds.push_back(stdev);
		}

		double df2 = fVal_new - fVal_old;
		double dncc = ncc_mean_new - ncc_mean_old;

		// 当目标函数值的平方和变化量小于一定阈值或者改正量的范数值小于一定阈值时认为迭代收敛，退出迭代
		if ((fabs(df2) < fEps) || (hVal < xEps))
		{
			break;
		}

		fVal_old = fVal_new;
		ncc_mean_old = ncc_mean_new;

		depth += mh.at<float>(0);
		hx    += mh.at<float>(1);
		hy    += mh.at<float>(2);

		for (i=0;i<nValid;i++)
		{
			vck[vIdxValid[i]] += mh.at<float>(3+i);
		}
	}

	if (iterNum)
	{
		*iterNum = k;
	}

	vector <double>::const_iterator iterDouble = max_element(vScores.begin(), vScores.end());
	double max_score = *iterDouble;

	if (max_score < 0) // this means all parameter candidates have inreasonable normals
	{
		// if no valid observations exist, then all parameters stay unchanged
		depth_optim = depth_init;
		hx_optim = hx_init;
		hy_optim = hy_init;
		score_optim = score_init;
		return false;
	}

	int idx_max_score = iterDouble - vScores.begin();

//	iterDouble = min_element(vF2.begin(), vF2.end());
	double min_F2/* = *iterDouble*/;
	int idx_min_F2/* = iterDouble - vF2.begin()*/;

// 	bool bFirst = true;
// 	for (i=0;i<vF2.size();i++)
// 	{
// 		if (vScores[i]<0)
// 		{
// 			continue;
// 		}
// 
// 		if (bFirst)
// 		{
// 			min_F2 = vF2[i];
// 			idx_min_F2 = i;
// 			bFirst = false;
// 			continue;
// 		}
// 
// 		if (vF2[i]<min_F2)
// 		{
// 			min_F2 = vF2[i];
// 			idx_min_F2 = i;
// 		}
// 	}

	int idx_final = idx_max_score;
//	int idx_final = idx_min_F2;

	depth_optim = vDepths[idx_final];
	hx_optim = vHxs[idx_final];
	hy_optim = vHys[idx_final];
	score_optim = vScores[idx_final];

	return true;
}

// 20140903
void DeepVoid::optim_gn_depth_minimizingProjError(const Matx33d & mR0,
												  const Matx31d & mt0,
												  const vector<Matx33d> & vKs,
												  const vector<Matx33d> & vRs,
												  const vector<Matx31d> & vts,
												  const vector<double> & vDs,
												  double nimgx, double nimgy,
												  double & depth_optim,
												  int maxIter /*= 128*/,
												  double xEps /*= 1.0E-8*/,				// input: threshold
												  double fEps /*= 1.0E-6*/				// input: threshold
												  )
{
	int i,j;

	int nObs = vKs.size();

	vector<Matx33d> vKRs;
	vector<Matx31d> vKts;
	vector<double> vimgxs; // observations
	vector<double> vimgys; // observations

	double sum_d = 0;
	for (i=0;i<nObs;i++)
	{
		double depth = vDs[i];
		sum_d += depth;

		Matx31d XYZ = GetXYZ_givenDepth(mR0, mt0, nimgx, nimgy, depth);

		Matx33d mKR = vKs[i]*vRs[i];
		Matx31d mKt = vKs[i]*vts[i];
		vKRs.push_back(mKR);
		vKts.push_back(mKt);

		Matx31d proj = mKR*XYZ+mKt;
		double z_1 = 1/proj(2);
		double imgx = proj(0)*z_1;
		double imgy = proj(1)*z_1;

		vimgxs.push_back(imgx);
		vimgys.push_back(imgy);
	}

	double d = sum_d/nObs; // initial depth

	double fVal_old = 0;
	double fVal_new;
	double hVal;

	Mat mJ(nObs*2, 1, CV_32FC1, Scalar(0));
	Mat mF(nObs*2, 1, CV_32FC1, Scalar(0));

	for (i=0;i<maxIter;i++)
	{
		// compute XYZ corresponds to current depth
		Matx31d XYZ = GetXYZ_givenDepth(mR0, mt0, nimgx, nimgy, d);

		Matx31d dXYZ_dd;
		Jacobian_XYZ_depth(mR0,nimgx,nimgy,dXYZ_dd(0),dXYZ_dd(1),dXYZ_dd(2));

		for (j=0;j<nObs;j++)
		{
			double imgx_proj, imgy_proj;
			Matx23d dxy_dXYZ = Jacobian_xy_XYZ(vKRs[j], vKts[j], XYZ(0), XYZ(1), XYZ(2), imgx_proj, imgy_proj);

			Matx21d dxy_dd = dxy_dXYZ*dXYZ_dd;

			mJ.at<float>(2*j) = dxy_dd(0);
			mJ.at<float>(2*j+1) = dxy_dd(1);

			mF.at<float>(2*j) = imgx_proj - vimgxs[j];
			mF.at<float>(2*j+1) = imgy_proj - vimgys[j];
		}

		// 解方程组 (J'J) h = -J'f 得到的 h 即为待优化参数的改正量，下次迭代的 x(k + 1) = x(k) + h
		Mat mA = mJ.t() * mJ;
		Mat mb = -mJ.t() * mF;

		double A = mA.at<float>(0);
		double b = mb.at<float>(0);

		double h = b/A;
		
		fVal_new = norm(mF)*norm(mF);
		hVal     = fabs(h);

		double df2 = fVal_new - fVal_old;

		if ((fabs(df2) < fEps) || (hVal < xEps))
		{
			break;
		}

		fVal_old = fVal_new;

		d+=h;
	}

	depth_optim = d;
}

// 20140604
bool DeepVoid::optim_gn_drhxhyck_NCCcontrolled(const vector<cam_data> & vCams,	// input:	all camera data
											 const vector<Mat> & vImgs,			// input:	all images
											 const vector<int> & vIdxVisiCams,	// input:	indices of all visible cameras
											 int idx_refimg,					// input:	the index of the reference image
											 int x, int y,						// input:	the indices of the pixel to be checked
											 int patchWidth, int patchHeight,	// input:	the patch size
											 double depth_init,					// input:	initial depth of this pixel
											 double hx_init,					// input:	initial normal of this pixel
											 double hy_init,					// input:	initial normal of this pixel
											 double & depth_optim,				// output:	optimized depth of this pixel
											 double & hx_optim,					// output:	optimized normal of this pixel
											 double & hy_optim,					// output:	optimized normal of this pixel
											 int maxIter /*= 128*/,					// input: max iteration
											 double xEps /*= 1.0E-8*/,				// input: threshold
											 double fEps /*= 1.0E-6*/,				// input: threshold
											 int * iterNum /*= NULL*/				// output:iteration number when quiting
											 )
{
	int i,j,k,ii;

	int npts_patch = patchWidth*patchHeight;
	int ncams_visi = vIdxVisiCams.size();

	int nChannel = vImgs[idx_refimg].channels();

	int halfpatch_w = (patchWidth-1)*0.5;
	int halfpatch_h = (patchHeight-1)*0.5;

	cam_data cam_ref = vCams[idx_refimg];

	Matx33d mK_ref, mR_ref;
	Matx31d mt_ref;

	vector<Matx33d> vKs(ncams_visi),vRs(ncams_visi);
	vector<Matx31d> vts(ncams_visi);

	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mR_ref(i,j) = cam_ref.R[i*3+j];

			for (k=0;k<ncams_visi;k++)
			{
				vRs[k](i,j) = vCams[vIdxVisiCams[k]].R[i*3+j];
			}
		}
	}
	mK_ref(0,0) = cam_ref.fx;	mK_ref(0,1) = cam_ref.s;  mK_ref(0,2) = cam_ref.cx;
	mK_ref(1,1) = cam_ref.fy;	mK_ref(1,2) = cam_ref.cy; mK_ref(2,2) = 1;
	mt_ref(0) = cam_ref.t[0];	mt_ref(1) = cam_ref.t[1]; mt_ref(2) = cam_ref.t[2];

	Matx31d mC_ref = -mR_ref.t() * mt_ref;

	for (k=0;k<ncams_visi;k++)
	{
		vKs[k](0,0) = vCams[vIdxVisiCams[k]].fx;	vKs[k](0,1) = vCams[vIdxVisiCams[k]].s;		vKs[k](0,2) = vCams[vIdxVisiCams[k]].cx;
		vKs[k](1,1) = vCams[vIdxVisiCams[k]].fy;	vKs[k](1,2) = vCams[vIdxVisiCams[k]].cy;	vKs[k](2,2) = 1;
		vts[k](0) = vCams[vIdxVisiCams[k]].t[0];	vts[k](1) = vCams[vIdxVisiCams[k]].t[1];	vts[k](2) = vCams[vIdxVisiCams[k]].t[2];	
	}

	//vector<Point2d> vNImgPts_ref; // the normalized image points or directions of every patch points
	vector<Point3d> vNImgPts_ref; // the normalized image points or directions of every patch points
	for (i=-halfpatch_h;i<=halfpatch_h;i++)
	{
		for (j=-halfpatch_w;j<=halfpatch_w;j++)
		{
			Matx31d xyz;
			xyz(0) = x+j;
			xyz(1) = y+i;
			xyz(2) = 1;

			Matx31d nxy = mR_ref.t()*mK_ref.inv()*xyz;

			Point3d pt3d;
			pt3d.x = nxy(0);
			pt3d.y = nxy(1);
			pt3d.z = nxy(2);

			vNImgPts_ref.push_back(pt3d);
		}
	}

	//	Mat patch_ref(vImgs[idx_refimg], cv::Rect(x-halfpatch_w, y-halfpatch_h, patchWidth, patchHeight));
	Mat patch_ref;
	if (nChannel==1) // gray level image
	{
		patch_ref = Mat(patchHeight, patchWidth, CV_32FC1);

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				patch_ref.at<float>(i+halfpatch_h, j+halfpatch_w) = vImgs[idx_refimg].at<uchar>(y+i,x+j);
				patch_ref.at<float>(i+halfpatch_h, j+halfpatch_w) = vImgs[idx_refimg].at<uchar>(y+i,x+j);
				patch_ref.at<float>(i+halfpatch_h, j+halfpatch_w) = vImgs[idx_refimg].at<uchar>(y+i,x+j);
			}
		}
	} 
	else // color image
	{
		patch_ref = Mat(patchHeight, patchWidth, CV_32FC3);

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[0] = vImgs[idx_refimg].at<Vec3b>(y+i,x+j).val[0];
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[1] = vImgs[idx_refimg].at<Vec3b>(y+i,x+j).val[1];
				patch_ref.at<Vec3f>(i+halfpatch_h, j+halfpatch_w).val[2] = vImgs[idx_refimg].at<Vec3b>(y+i,x+j).val[2];
			}
		}
	}

	double depth = depth_init;
	double hx = hx_init;
	double hy = hy_init;
	vector<double> vck(ncams_visi, 1);

	double depth_old, hx_old, hy_old;

	bool bDivergent = false;

	double fVal_old = 0; double ncc_mean_old = 0;
	double fVal_new; double ncc_mean_new;
	double hVal;

	bool bUpdatehxhyck;
	for (k=0;k<maxIter;k++)
	{
		if ((k+1)%5==0)
		{
			bUpdatehxhyck = true;
		} 
		else
		{
			bUpdatehxhyck = false;
		}

// 		CString strinfo;
// 		strinfo.Format("C:\\Users\\DeepVoid\\Desktop\\support window of iteration %02d.txt", k);
// 		OutputSupportWindow(strinfo, mK_ref, mR_ref, mt_ref, x, y, depth, hx, hy, patchWidth, patchHeight, 255, 255, 0, 5);

		// first get the 3d patch points corresponding to current parameter set
		vector<Point3d> vWrdPts;

		for (i=-halfpatch_h;i<=halfpatch_h;i++)
		{
			for (j=-halfpatch_w;j<=halfpatch_w;j++)
			{
				Matx31d mDir;
				mDir(0) = vNImgPts_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w].x;
				mDir(1) = vNImgPts_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w].y;
				mDir(2) = vNImgPts_ref[(i+halfpatch_h)*patchWidth+j+halfpatch_w].z;
				/*mDir(2) = 1;*/

				Matx31d XYZ = mC_ref + (depth+hx*j+hy*i) * mDir;
				Point3d pt3d;
				pt3d.x = XYZ(0);
				pt3d.y = XYZ(1);
				pt3d.z = XYZ(2);
				vWrdPts.push_back(pt3d);
			}
		}

		vector<Mat> vJacobs, vFs;
		vector<int> vIdxValid;

		int nAllRows = 0;

		Mat mJacob_k, mF_k, imgPatchResamp; vector<double> vnccs; double sum_ncc = 0;
		for (ii=0;ii<ncams_visi;ii++)
		{
			if (!f_jacob_fk_drhxhyck_patchref_float(patch_ref, vImgs[vIdxVisiCams[ii]], vKs[ii], vRs[ii], vts[ii], vWrdPts, vNImgPts_ref, vck[ii], mJacob_k, mF_k, imgPatchResamp))
			{
				continue;
			}

			int result_cols = imgPatchResamp.cols - patch_ref.cols + 1;
			int result_rows = imgPatchResamp.rows - patch_ref.rows + 1;
			Mat mNCC(result_rows, result_cols, CV_32FC1);
			matchTemplate(patch_ref, imgPatchResamp, mNCC, /*CV_TM_SQDIFF_NORMED*/CV_TM_CCORR_NORMED);
			vnccs.push_back(mNCC.at<float>(0));
			sum_ncc += mNCC.at<float>(0);

			nAllRows += mJacob_k.rows;

			vJacobs.push_back(mJacob_k);
			vFs.push_back(mF_k);
			vIdxValid.push_back(ii);
		}

		int nValid = vJacobs.size();
		int nAllCols = 3+nValid;

		if (nValid == 0)
		{
			return false;
		}

		Mat mJ, mF;

		if (!bUpdatehxhyck)
		{
			mJ = Mat(nAllRows, 1, CV_32FC1, Scalar(0));
			mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));

			int ntmp = 0;
			for (i=0;i<nValid;i++)
			{
				for (j=0;j<vJacobs[i].rows;j++)
				{
					mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,0);
					mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
				}

				ntmp += vJacobs[i].rows;
			}
		} 
		else
		{
			mJ = Mat(nAllRows, nAllCols, CV_32FC1, Scalar(0)); 
			mF = Mat(nAllRows, 1, CV_32FC1, Scalar(0));

			int ntmp = 0;
			for (i=0;i<nValid;i++)
			{
				for (j=0;j<vJacobs[i].rows;j++)
				{
					mJ.at<float>(ntmp+j,0) = vJacobs[i].at<float>(j,0);
					mJ.at<float>(ntmp+j,1) = vJacobs[i].at<float>(j,1);
					mJ.at<float>(ntmp+j,2) = vJacobs[i].at<float>(j,2);
					mJ.at<float>(ntmp+j,3+i) = vJacobs[i].at<float>(j,3);
					mF.at<float>(ntmp+j) = vFs[i].at<float>(j);
				}

				ntmp += vJacobs[i].rows;
			}
		}

		// 解方程组 (J'J) h = -J'f 得到的 h 即为待优化参数的改正量，下次迭代的 x(k + 1) = x(k) + h
		Mat mA = mJ.t() * mJ;
		Mat mb = -mJ.t() * mF;
		Mat mA_1 = mA.inv(DECOMP_CHOLESKY);

		Mat mh = mA_1*mb;

		fVal_new = norm(mF)*norm(mF);
		hVal     = norm(mh);
		ncc_mean_new = sum_ncc/vnccs.size();

		double s0 = sqrt(fVal_new/(mJ.rows-mJ.cols));

		vector<double> vStds;
		for (i=0;i<mA_1.rows;i++)
		{
			double stdev = s0 * sqrt(mA_1.at<float>(i,i));
			vStds.push_back(stdev);
		}

		double df2 = fVal_new - fVal_old;
		double dncc = ncc_mean_new - ncc_mean_old;

// 		if (k!=0&&df2/fVal_old>0.001)
// 		{
// 			bDivergent = true;
// 			break;
// 		}

		if (k!=0&&dncc<0)
		{
			bDivergent = true;
			break;
		}

		// 当目标函数值的平方和变化量小于一定阈值或者改正量的范数值小于一定阈值时认为迭代收敛，退出迭代
		if ((fabs(df2) < fEps) || (hVal < xEps) || (dncc<0.001))
		{
			break;
		}

		fVal_old = fVal_new;
		ncc_mean_old = ncc_mean_new;

		depth_old = depth;
		hx_old = hx;
		hy_old = hy;

		if (!bUpdatehxhyck)
		{
			depth += mh.at<float>(0);
		} 
		else
		{
			depth += mh.at<float>(0);
			hx    += mh.at<float>(1);
			hy    += mh.at<float>(2);

			for (i=0;i<nValid;i++)
			{
				vck[vIdxValid[i]] += mh.at<float>(3+i);
			}
		}
	}

	if (iterNum)
	{
		*iterNum = k;
	}

	if (bDivergent)
	{
		depth_optim = depth_old;
		hx_optim = hx_old;
		hy_optim = hy_old;
	} 
	else
	{
		depth_optim = depth;
		hx_optim = hx;
		hy_optim = hy;
	}

// 	CString strinfo;
// 	strinfo.Format("C:\\Users\\DeepVoid\\Desktop\\final support window.txt");
// 	OutputSupportWindow(strinfo, mK_ref, mR_ref, mt_ref, x, y, depth_optim, hx_optim, hy_optim, patchWidth, patchHeight, 255, 255, 0, 5);

	return true;
}

// the normal n(a,b,1) is the opposite normal, the actual normal is -n(-a,-b,-1)
void DeepVoid::get_normal_givendrhxhy(double fx, double fy,			// input:	equivalent focal length
									  double nimgx, double nimgy,	// input:	the normalized image point
									  double dr,					// input:	the depth of given pixel
									  double hx, double hy,			// input:	the depth gradient
									  double & a, double & b		// output:	the normal is n(a,b,1)
									  )
{
	double fxhx = fx*hx;
	double fyhy = fy*hy;
	double dd = fxhx*nimgx+fyhy*nimgy+dr;

// 	a = -fxhx/dd;
// 	b = -fyhy/dd;

	double dd_1 = 1.0/dd;

	a = -fxhx*dd_1;
	b = -fyhy*dd_1;
}

void DeepVoid::get_hxhy_givendrnormal(double fx, double fy,		// input:	equivalent focal length
									  double nimgx, double nimgy,	// input:	the normalized image point
									  double dr,					// input:	the depth of given pixel
									  const Matx31d & mn,			// input:	the normal
									  double & hx, double & hy	// output:	the normal is n(a,b,1)
									  )
{
	double a = mn(0); double b = mn(1);
	Matx31d mx; mx(0) = nimgx; mx(1) = nimgy; mx(2) = 1;
	Matx<double, 1, 1> ntx = mn.t()*mx;

	hx = -(a*dr)/(fx*ntx(0));
	hy = -(b*dr)/(fy*ntx(0));
}

bool DeepVoid::isvalid_hxhy(double fx, double fy,		// input:	equivalent focal length
							double nimgx, double nimgy,	// input:	the normalized image point
							double dr,					// input:	the depth of given pixel
							double hx, double hy,		// input:	the depth gradient
							double thresh /*= 0.1*/		// input:	threshold 
							)
{
	// get the normal vector
	double a,b;

	get_normal_givendrhxhy(fx, fy, nimgx, nimgy, dr, hx, hy, a, b);

	double dn = sqrt(a*a+b*b+1);
	double dx = sqrt(nimgx*nimgx+nimgy*nimgy+1);

	double val = fabs((a*nimgx+b*nimgy+1)/(dn*dx));

	if (val <= thresh)
	{
		return false;
	}

	return true;
}

void DeepVoid::f_jacob_uvrou(const Matx33d & mKr, const Matx33d & mRr, const Matx31d & mtr,
							 const Matx33d & mK,  const Matx33d & mR,  const Matx31d & mt,
							 double d, double hx, double hy,
							 double x0, double y0,
							 double xk, double yk,
							 double u, double v, double rou,
							 Matx33d & mJ,
							 Matx31d & mF
							 )
{
	Matx31d mOr = -mRr.t() * mtr;

	Matx31d mA = mK*mR*mOr+mK*mt;

	Matx33d mtmp;
	mtmp(0,0) = mtmp(1,1) = mtmp(2,2) = 1;
	mtmp(0,2) = x0; mtmp(1,2) = y0;

	Matx33d mB = mK*mR*mRr.t()*mKr.inv()*mtmp;

	double a1 = mA(0); double a2 = mA(1); double a3 = mA(2);

	double b1 = mB(0,0); double b2 = mB(0,1); double b3 = mB(0,2);
	double b4 = mB(1,0); double b5 = mB(1,1); double b6 = mB(1,2);
	double b7 = mB(2,0); double b8 = mB(2,1); double b9 = mB(2,2);

	double b1hx=b1*hx;	double b2hx=b2*hx;	double b3hx=b3*hx;
	double b1hy=b1*hy;	double b2hy=b2*hy;	double b3hy=b3*hy;
	double b1d=b1*d;	double b2d=b2*d;	double b3d=b3*d;

	double b4hx=b4*hx;	double b5hx=b5*hx;	double b6hx=b6*hx;
	double b4hy=b4*hy;	double b5hy=b5*hy;	double b6hy=b6*hy;
	double b4d=b4*d;	double b5d=b5*d;	double b6d=b6*d;

	double b7hx=b7*hx;	double b8hx=b8*hx;	double b9hx=b9*hx;
	double b7hy=b7*hy;	double b8hy=b8*hy;	double b9hy=b9*hy;
	double b7d=b7*d;	double b8d=b8*d;	double b9d=b9*d;

	mJ(0,0)=-xk;	mJ(0,1)=2*b1hx*u+(b2hx+b1hy)*v+b1d+b3hx;	mJ(0,2)=2*b2hy*v+(b2hx+b1hy)*u+b2d+b3hy;
	mJ(1,0)=-yk;	mJ(1,1)=2*b4hx*u+(b5hx+b4hy)*v+b4d+b6hx;	mJ(1,2)=2*b5hy*v+(b5hx+b4hy)*u+b5d+b6hy;
	mJ(2,0)=-1;		mJ(2,1)=2*b7hx*u+(b8hx+b7hy)*v+b7d+b9hx;	mJ(2,2)=2*b8hy*v+(b8hx+b7hy)*u+b8d+b9hy;

	double u2 = u*u;
	double v2 = v*v;
	double uv = u*v;

	mF(0) = a1+b1hx*u2+b2hy*v2+(b2hx+b1hy)*uv+(b1d+b3hx)*u+(b2d+b3hy)*v+b3d-xk*rou;
	mF(1) = a2+b4hx*u2+b5hy*v2+(b5hx+b4hy)*uv+(b4d+b6hx)*u+(b5d+b6hy)*v+b6d-yk*rou;
	mF(2) = a3+b7hx*u2+b8hy*v2+(b8hx+b7hy)*uv+(b7d+b9hx)*u+(b8d+b9hy)*v+b9d-rou;
}

void DeepVoid::optim_gn_uvrou(const Matx33d & mKr, const Matx33d & mRr, const Matx31d & mtr,
							  const Matx33d & mK,  const Matx33d & mR,  const Matx31d & mt,
							  double d, double hx, double hy,
							  double x0, double y0,
							  double xk, double yk,
							  double & u_optim, double & v_optim,
							  double & dk,
							  int maxIter /*= 8*/,
							  double imgptEps /*= 0.001*/,
							  int * iterNum/* = NULL	*/			
							  )
{
	int i;

	double u = 0;
	double v = 0;

	Matx31d XYZ = GetXYZ_givenDepth(mKr, mRr, mtr, x0+u, y0+v, d+u*hx+v*hy);

	Matx33d mKR = mK*mR;
	Matx31d mKt = mK*mt;

	Matx31d mx = mKR*XYZ + mKt;

	double rou = mx(2);

	Matx33d mJ, mA, mA_1;
	Matx31d mF, mb, mh;

	for (i=0;i<maxIter;i++)
	{
		f_jacob_uvrou(mKr, mRr, mtr, mK, mR, mt, d, hx, hy, x0, y0, xk, yk, u, v, rou, mJ, mF);

		// 解方程组 (J'J) h = -J'f 得到的 h 即为待优化参数的改正量，下次迭代的 x(k + 1) = x(k) + h
		mA = mJ.t() * mJ;
		mb = -mJ.t() * mF;
		mA_1 = mA.inv(DECOMP_LU);

		mh = mA_1*mb;

		double drou = mh(0);
		double du = mh(1);
		double dv = mh(2);
	
		double imgincre = sqrt(du*du+dv*dv);

		// 当目标函数值的平方和变化量小于一定阈值或者改正量的范数值小于一定阈值时认为迭代收敛，退出迭代
		if (imgincre<imgptEps)
		{
			break;
		}

		u+=du;
		v+=dv;
		rou+=drou;
	}

	if (iterNum)
	{
		*iterNum = i;
	}

	u_optim = u;
	v_optim = v;
	dk = rou;
}

void DeepVoid::optim_gn_uvrou_initialdk(const Matx33d & mKr, const Matx33d & mRr, const Matx31d & mtr,
									    const Matx33d & mK,  const Matx33d & mR,  const Matx31d & mt,
									    double d, double hx, double hy,
									    double x0, double y0,
									    double xk, double yk,
									    double & u_optim, double & v_optim,		// input&output
									    double & dk,							// input&output
									    int maxIter /*= 8*/,
									    double imgptEps /*= 0.00001*/,
									    int * iterNum /*= NULL*/
									    )
{
	int i;

	double u = u_optim;
	double v = v_optim;

	double rou = dk;

	Matx33d mJ, mA, mA_1;
	Matx31d mF, mb, mh;

	for (i=0;i<maxIter;i++)
	{
		f_jacob_uvrou(mKr, mRr, mtr, mK, mR, mt, d, hx, hy, x0, y0, xk, yk, u, v, rou, mJ, mF);

		// 解方程组 (J'J) h = -J'f 得到的 h 即为待优化参数的改正量，下次迭代的 x(k + 1) = x(k) + h
		mA = mJ.t() * mJ;
		mb = -mJ.t() * mF;
		mA_1 = mA.inv(DECOMP_LU);

		mh = mA_1*mb;

		double drou = mh(0);
		double du = mh(1);
		double dv = mh(2);

		double imgincre = sqrt(du*du+dv*dv);

		// 当目标函数值的平方和变化量小于一定阈值或者改正量的范数值小于一定阈值时认为迭代收敛，退出迭代
		if (imgincre<imgptEps)
		{
			break;
		}

		u+=du;
		v+=dv;
		rou+=drou;
	}

	if (iterNum)
	{
		*iterNum = i;
	}

	u_optim = u;
	v_optim = v;
	dk = rou;
}

void DeepVoid::optim_gn_uvrou(const cam_data & cam0,
							  const cam_data & cam,
							  double d, double hx, double hy,
							  double x0, double y0,
							  double xk, double yk,
							  double & u_optim, double & v_optim,
							  double & dk,
							  int maxIter /*= 8*/,
							  double imgptEps /*= 0.001*/,
							  int * iterNum /*= NULL*/
							  )
{
	int i,j;

	Matx33d mKr, mRr, mK, mR;
	Matx31d mtr, mt;
	
	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mRr(i,j) = cam0.R[i*3+j];
			mR(i,j) = cam.R[i*3+j];
		}
	}

	mtr(0) = cam0.t[0];	mtr(1) = cam0.t[1];	mtr(2) = cam0.t[2];	

	mt(0) = cam.t[0];	mt(1) = cam.t[1];	mt(2) = cam.t[2];	

	mKr(0,0) = cam0.fx; mKr(0,1) = cam0.s;	mKr(0,2) = cam0.cx;
	mKr(1,0) = 0;		mKr(1,1) = cam0.fy;	mKr(1,2) = cam0.cy;
	mKr(2,0) = 0;		mKr(2,1) = 0;		mKr(2,2) = 1;

	mK(0,0) = cam.fx;	mK(0,1) = cam.s;	mK(0,2) = cam.cx;
	mK(1,0) = 0;		mK(1,1) = cam.fy;	mK(1,2) = cam.cy;
	mK(2,0) = 0;		mK(2,1) = 0;		mK(2,2) = 1;

	optim_gn_uvrou(mKr, mRr, mtr, mK, mR, mt, d, hx, hy, x0, y0, xk, yk, u_optim, v_optim, dk, maxIter, imgptEps, iterNum);
}

// 20150331, compute the Jacobian matrix and function values at current estimates
void DeepVoid::J_f_optim_P_XYZ(int nPts,						// input:	number of correspondences 
							   const vector<Point2d> & vImgPts0,// input:	the measured image points in the left image
							   const vector<Point2d> & vImgPts1,// input:	the measured image points in the right image
							   const Mat & x,					// input:	current estimates
							   Mat & J,							// output:	Jacobian matrix at current estimates, should be initialized outside the function
							   Mat & f,							// output:	function values at current estimates, should be initialized outside the function
							   vector<double> & vds0,			// output:	the reprojection error vector in the 1st image, should be initialized outside the function
							   vector<double> & vds1			// output:	the reprojection error vector in the 2nd image, should be initialized outside the function
							   )
{
	// construct current camera matrix of the right image
	Matx34d mP;
	for (int i=0;i<3;++i)
	{
		for (int j=0;j<4;++j)
		{
			mP(i,j) = x.at<double>(i*4+j);
		}
	}

	Matx34d mP0;
	mP0(0,0)=mP0(1,1)=mP0(2,2)=1;

	// consider each correspondence
	for (int i=0;i<nPts;++i)
	{
		int idx_12_3i = 12+3*i;
		int idx_4i = 4*i;

		Matx41d XYZW;
		XYZW(0) = x.at<double>(idx_12_3i);
		XYZW(1) = x.at<double>(idx_12_3i+1);
		XYZW(2) = x.at<double>(idx_12_3i+2);
		XYZW(3) = 1;

		// project to each image
		Matx31d xyw0 = mP0*XYZW; double w0_1 = 1/xyw0(2);
		Matx31d xyw1 = mP *XYZW; double w1_1 = 1/xyw1(2);

		Point2d imgpt0 = vImgPts0[i];
		Point2d imgpt1 = vImgPts1[i];

		double dx0 = xyw0(0)*w0_1-imgpt0.x;
		double dy0 = xyw0(1)*w0_1-imgpt0.y;
		double d0  = sqrt(dx0*dx0+dy0*dy0);
		vds0[i] = d0;

		double dx1 = xyw1(0)*w1_1-imgpt1.x;
		double dy1 = xyw1(1)*w1_1-imgpt1.y;
		double d1  = sqrt(dx1*dx1+dy1*dy1);
		vds1[i] = d1;

		// fill the error vector
		f.at<double>(idx_4i)   = dx0;
		f.at<double>(idx_4i+1) = dy0;
		f.at<double>(idx_4i+2) = dx1;
		f.at<double>(idx_4i+3) = dy1;

		Matx23d der_xy0_XYZ = Jacobian_xy_XYZ(mP0, XYZW(0), XYZW(1), XYZW(2));
		Matx23d der_xy1_XYZ = Jacobian_xy_XYZ(mP,  XYZW(0), XYZW(1), XYZW(2));

		Matx<double,2,12> der_xy1_P = Jacobian_xy_P(mP, XYZW(0), XYZW(1), XYZW(2));

		// fill in the big jacobian matrix
		for (int ii=0;ii<2;++ii)
		{
			for (int jj=0;jj<3;++jj)
			{
				J.at<double>(idx_4i+ii,idx_12_3i+jj) = der_xy0_XYZ(ii,jj);
				J.at<double>(idx_4i+2+ii,idx_12_3i+jj) = der_xy1_XYZ(ii,jj);
			}

			for (int kk=0;kk<12;++kk)
			{
				J.at<double>(idx_4i+2+ii,kk) = der_xy1_P(ii,kk);
			}
		}
	}
}

// zhaokunz, 20150109, given camera matrix of the left image [I|0], the right image [P]
// given the measured image points in both images and the initial projective reconstructed world coordinates
// optimize the camera matrix [P] of the right image and the projective reconstructed world coordinates
// using the Gauss-Newton method
bool DeepVoid::optim_gn_P_XYZ(const vector<Point2d> & vImgPts0,		// input:	the measured image points in the left image
						      const vector<Point2d> & vImgPts1,		// input:	the measured image points in the right image
						      const Matx34d & mP_init,				// input:	the initial camera matrix of the right image
						      const vector<Point3d> & vWrdPts_init,	// input:	the initial projective XYZ coordinates of world points
						      Matx34d & mP_optim,					// output:	the optimized camera matrix of the right image
						      vector<Point3d> & vWrdPts_optim,		// output:	the optimized projective XYZ coordinates of world points
							  double & err_rpj,						// output:	the reprojection error
						      int maxIter /*= 10*/,					// input:	the maximum number of iterations
						      double xEps /*= 1.0E-8*/,				// input: threshold
						      double fEps /*= 1.0E-6*/				// input: threshold
						      )
{
	int i,j,k,ii,jj,kk;

	int nPts = vWrdPts_init.size(); // number of correspondences
	double nPts2_1 = 0.5/nPts;
	int N = 12+3*nPts; // number of variables to be optimized
	int M = 4*nPts;	// each correspondence provide 4 objective values

	Mat mX(N, 1, CV_64FC1, Scalar(0)); // the variable vector to be optimized
	Mat mJ(M, N, CV_64FC1, Scalar(0)); // the jacobian matrix
	Mat mF(M, 1, CV_64FC1, Scalar(0)); // the error vector
	
	// initialize the variable vector
	for (i=0;i<3;i++)
	{
		for (j=0;j<4;j++)
		{
			mX.at<double>(i*4+j) = mP_init(i,j);
		}
	}

	for (i=0;i<nPts;i++)
	{
		int idx_12_3i = 12+3*i;
		mX.at<double>(idx_12_3i)   = vWrdPts_init[i].x;
		mX.at<double>(idx_12_3i+1) = vWrdPts_init[i].y;
		mX.at<double>(idx_12_3i+2) = vWrdPts_init[i].z;
	}
	//////////////////////////////////////////////////////////////////////////

	vector<double> vds0(nPts), vds1(nPts);

	// camera matrix of the left image
	Matx34d mP0;
	mP0(0,0)=mP0(1,1)=mP0(2,2)=1;

	double fVal_old = 0;
	double fVal_new;
	double hVal;
	double err_rpj_init;

	// iterations
	for (k=0;k<maxIter;k++)
	{
		// construct current camera matrix of the right image
		Matx34d mP;
		for (i=0;i<3;i++)
		{
			for (j=0;j<4;j++)
			{
				mP(i,j) = mX.at<double>(i*4+j);
			}
		}

		// consider each correspondence
		for (i=0;i<nPts;i++)
		{
			int idx_12_3i = 12+3*i;
			int idx_4i = 4*i;

			Matx41d XYZW;
			XYZW(0) = mX.at<double>(idx_12_3i);
			XYZW(1) = mX.at<double>(idx_12_3i+1);
			XYZW(2) = mX.at<double>(idx_12_3i+2);
			XYZW(3) = 1;

			// project to each image
			Matx31d xyw0 = mP0*XYZW; double w0_1 = 1/xyw0(2);
			Matx31d xyw1 = mP *XYZW; double w1_1 = 1/xyw1(2);

			Point2d imgpt0 = vImgPts0[i];
			Point2d imgpt1 = vImgPts1[i];

			double dx0 = xyw0(0)*w0_1-imgpt0.x;
			double dy0 = xyw0(1)*w0_1-imgpt0.y;
			double d0  = sqrt(dx0*dx0+dy0*dy0);
			vds0[i] = d0;

			double dx1 = xyw1(0)*w1_1-imgpt1.x;
			double dy1 = xyw1(1)*w1_1-imgpt1.y;
			double d1  = sqrt(dx1*dx1+dy1*dy1);
			vds1[i] = d1;

			// fill the error vector
			mF.at<double>(idx_4i)   = dx0;
			mF.at<double>(idx_4i+1) = dy0;
			mF.at<double>(idx_4i+2) = dx1;
			mF.at<double>(idx_4i+3) = dy1;

			Matx23d der_xy0_XYZ = Jacobian_xy_XYZ(mP0, XYZW(0), XYZW(1), XYZW(2));
			Matx23d der_xy1_XYZ = Jacobian_xy_XYZ(mP,  XYZW(0), XYZW(1), XYZW(2));

			Matx<double,2,12> der_xy1_P = Jacobian_xy_P(mP, XYZW(0), XYZW(1), XYZW(2));

			// fill in the big jacobian matrix
			for (ii=0;ii<2;ii++)
			{
				for (jj=0;jj<3;jj++)
				{
					mJ.at<double>(idx_4i+ii,idx_12_3i+jj) = der_xy0_XYZ(ii,jj);
					mJ.at<double>(idx_4i+2+ii,idx_12_3i+jj) = der_xy1_XYZ(ii,jj);
				}

				for (kk=0;kk<12;kk++)
				{
					mJ.at<double>(idx_4i+2+ii,kk) = der_xy1_P(ii,kk);
				}
			}
		}

		Mat mA = mJ.t() * mJ;
		Mat mb = -mJ.t() * mF;
		Mat mh;
//		solve(mA, mb, mh, DECOMP_CHOLESKY); // not working, maybe it's because the A matrix is not symmetrical and positive definite
		solve(mA, mb, mh, DECOMP_LU); // fast, and always get the best results here
//		solve(mA, mb, mh, DECOMP_SVD); // too slow, always get the same results as the QR method does
//		solve(mA, mb, mh, DECOMP_QR); // also too slow

		fVal_new = norm(mF)*norm(mF);
		hVal     = norm(mh);

		err_rpj = sqrt(fVal_new*nPts2_1);

		if (0==k)
		{
			err_rpj_init = err_rpj; // record the initial reprojection error
		}

		double df2 = fVal_new - fVal_old;

		if ((fabs(df2) < fEps) || (hVal < xEps))
		{
			break;
		}

		fVal_old = fVal_new;

		for (i=0;i<N;i++)
		{
			mX.at<double>(i)+=mh.at<double>(i);
		}
	}

	if (err_rpj>=err_rpj_init)
	{
		// accept the optimization results only if the final reprojection error is better than the initial one
		return false; 
	}

	// output the optimized
	for (i=0;i<3;i++)
	{
		for (j=0;j<4;j++)
		{
			mP_optim(i,j) = mX.at<double>(i*4+j);
		}
	}

	vWrdPts_optim.clear();
	for (i=0;i<nPts;i++)
	{
		int idx_3i = 3*i;
	
		Point3d pt;
		pt.x = mX.at<double>(12+idx_3i);
		pt.y = mX.at<double>(12+idx_3i+1);
		pt.z = mX.at<double>(12+idx_3i+2);

		vWrdPts_optim.push_back(pt);
	}

	return true;
}

// zhaokunz, 20150331, given camera matrix of the left image [I|0], the right image [P]
// given the measured image points in both images and the initial projective reconstructed world coordinates
// optimize the camera matrix [P] of the right image and the projective reconstructed world coordinates
// using the Levenberg-Marquardt method
void DeepVoid::optim_lm_P_XYZ(const vector<Point2d> & vImgPts0,		// input:	the measured image points in the left image
						 	  const vector<Point2d> & vImgPts1,		// input:	the measured image points in the right image
							  const Matx34d & mP_init,				// input:	the initial camera matrix of the right image
							  const vector<Point3d> & vWrdPts_init,	// input:	the initial projective XYZ coordinates of world points
							  Matx34d & mP_optim,					// output:	the optimized camera matrix of the right image
							  vector<Point3d> & vWrdPts_optim,		// output:	the optimized projective XYZ coordinates of world points
							  vector<double> & info,				// output:	runtime info, 5-vector
																	// info[0]:	the initial reprojection error
																	// info[1]:	the final reprojection error
																	// info[2]: final max gradient
																	// info[3]: the number of iterations
																	// info[4]: the termination code, 0: small gradient; 1: small correction; 2: max iteration 
							  double tau /*= 1.0E-3*/,				// input:	The algorithm is not very sensitive to the choice of tau, but as a rule of thumb, one should use a small value, eg tau=1E-6 if x0 is believed to be a good approximation to real value, otherwise, use tau=1E-3 or even tau=1
							  int maxIter /*= 15*/,					// input:	the maximum number of iterations
							  double eps1 /*= 1.0E-8*/,				// input:	threshold
							  double eps2 /*= 1.0E-12*/				// input:	threshold
							  )
{
	int k = 0;		// 迭代次数索引
	int v = 2;		// 更新 u 时需要用到的一个控制量      
	double u;		// LM 优化算法中最关键的阻尼系数 (J'J + uI)h = -J'f
	double r;		// gain ratio, 增益率，用来衡量近似展开式的好坏
	double g_norm;	// 梯度的模
	double h_norm;	// 改正量的模
	double h_thresh;// 改正量收敛判断阈值 eps2*(norm(x)+eps2)

	double ratio_1_3 = 1.0/3.0;

	bool found = false; // 标识是否已经满足迭代收敛条件
	int code = 2; // termination code

	int nPts = vWrdPts_init.size(); // number of correspondences
	double nPts2_1 = 0.5/nPts;
	int N = 12+3*nPts; // number of variables to be optimized
	int M = 4*nPts;	// each correspondence provide 4 objective values

	Mat x(N, 1, CV_64FC1, Scalar(0)); // the variable vector to be optimized
	Mat J(M, N, CV_64FC1, Scalar(0)); // the jacobian matrix
	Mat f(M, 1, CV_64FC1, Scalar(0)); // the error vector
	Mat A,g,h,x_new; // A = J(x)'J(x) 近似 F(x)" ; g = J(x)'f(x) 为 F(x)'; h 为改正量

	// initialize the variable vector
	for (int i=0;i<3;++i)
	{
		for (int j=0;j<4;++j)
		{
			x.at<double>(i*4+j) = mP_init(i,j);
		}
	}

	for (int i=0;i<nPts;++i)
	{
		int idx_12_3i = 12+3*i;
		x.at<double>(idx_12_3i)   = vWrdPts_init[i].x;
		x.at<double>(idx_12_3i+1) = vWrdPts_init[i].y;
		x.at<double>(idx_12_3i+2) = vWrdPts_init[i].z;
	}
	//////////////////////////////////////////////////////////////////////////

	vector<double> vds0(nPts), vds1(nPts);

	// 生成第一个 A = J(x)'J(x)，g = J(x)'f(x) ///////////////////////////////////////////////////////
	J_f_optim_P_XYZ(nPts, vImgPts0, vImgPts1, x, J, f, vds0, vds1);
	A = J.t()*J;	// A=J(x)'J(x)
	g = J.t()*f;	// g=J(x)'f(x)

	Mat tmp = 0.5*f.t()*f;
	double Fx_old = tmp.at<double>(0);
	double Fx_new, L0_Lh;

	double err_rpj_init = sqrt(2*Fx_old*nPts2_1);
	
	g_norm = norm(g,NORM_INF);

	// 梯度收敛，说明已在平坦区域
	if (g_norm < eps1)
	{
		found = true;
		code = 0;
	}

	vector<double> Aii;
	for (int i=0;i<A.rows;++i)
	{
		Aii.push_back(A.at<double>(i,i));
	}

	auto iter = max_element(Aii.begin(),Aii.end());
	double max_Aii = *iter;

	u = tau * max_Aii; // initial tau

	while (!found && k<maxIter)
	{
		++k;

		for (int i=0;i<A.rows;++i)
		{
			A.at<double>(i,i)+=u;
		}

		solve(A, -g, h, DECOMP_CHOLESKY); // 加入阻尼系数u之后，矩阵A肯定会是对称正定的，也就是说肯定可以使用Cholesky分解

		h_norm = norm(h);
		h_thresh = eps2*(norm(x)+eps2);

		if (h_norm < h_thresh) // 改正量收敛
		{
			found = true;
			code = 1;
		} 
		else
		{
			x_new = x+h;
			
			J_f_optim_P_XYZ(nPts, vImgPts0, vImgPts1, x_new, J, f, vds0, vds1);

			tmp = 0.5*f.t()*f;
			Fx_new = tmp.at<double>(0);

			tmp = 0.5*h.t()*(u*h-g);
			L0_Lh = tmp.at<double>(0);

			r = (Fx_old - Fx_new) / L0_Lh;

			if (r>0)
			{
				x = x_new.clone();

				A = J.t()*J;	// A=J(x)'J(x)
				g = J.t()*f;	// g=J(x)'f(x)

				Fx_old = Fx_new;

				g_norm = norm(g,NORM_INF);

				if (g_norm < eps1) // 梯度收敛，说明抵达平坦区域
				{
					found = true;
					code = 0;
				}

				double tmp_db = std::max(ratio_1_3, 1 - pow(2 * r - 1, 3));
				u *= tmp_db;
				v = 2;
			} 
			else
			{
				u *= v;
				v *= 2;
			}
		}
	}

	double err_rpj_final = sqrt(2*Fx_old*nPts2_1);

	// output the optimized
	for (int i=0;i<3;++i)
	{
		for (int j=0;j<4;++j)
		{
			mP_optim(i,j) = x.at<double>(i*4+j);
		}
	}

	vWrdPts_optim.clear();
	for (int i=0;i<nPts;++i)
	{
		int idx_3i = 3*i;

		Point3d pt;
		pt.x = x.at<double>(12+idx_3i);
		pt.y = x.at<double>(12+idx_3i+1);
		pt.z = x.at<double>(12+idx_3i+2);

		vWrdPts_optim.push_back(pt);
	}

	info.clear();
	info.push_back(err_rpj_init);
	info.push_back(err_rpj_final);
	info.push_back(g_norm);
	info.push_back(k);
	info.push_back(code);
}

// 20150110, zhaokunz, optimize the given fundamental matrix according to the golden standard algorithm
bool DeepVoid::optim_gn_F(const vector<Point2d> & vImgPts0,		// input:	the measured image points in the left image
					      const vector<Point2d> & vImgPts1,		// input:	the measured image points in the right image
					      const Matx33d & mF_init,				// input:	the initial fundamental matrix
					      Matx33d & mF_optim,					// output:	the optimized fundamental matrix
					      int maxIter /*= 10*/,					// input:	the maximum number of iterations
					      double xEps /*= 1.0E-8*/,				// input:	threshold
					      double fEps /*= 1.0E-6*/				// input:	threshold
					      )
{
	int i,j;

	int n = vImgPts0.size();

	Matx34d mP0,mP1;
	GetCameraMatfromF(mF_init, mP0, mP1);

	// 20150113, zhaokunz, correctMatches based on the Optimal Triangulation Method in Multiple View Geometry
	vector<Point2d> vImgPts0_crct, vImgPts1_crct;
	correctMatches(mF_init, vImgPts0, vImgPts1, vImgPts0_crct, vImgPts1_crct);

	Mat mWrdPts;
//	triangulatePoints(mP0, mP1, vImgPts0, vImgPts1, mWrdPts);
	// 20150113, zhaokunz, use corrected image points to triangulate 3D points
	triangulatePoints(mP0, mP1, vImgPts0_crct, vImgPts1_crct, mWrdPts);

	vector<Point3d> vWrdPts_init;

	for (i=0;i<n;i++)
	{
		Point3d pt;
		double w_1 = 1.0/mWrdPts.at<double>(3,i);

		pt.x = mWrdPts.at<double>(0,i)*w_1;
		pt.y = mWrdPts.at<double>(1,i)*w_1;
		pt.z = mWrdPts.at<double>(2,i)*w_1;

		vWrdPts_init.push_back(pt);
	}

	Matx34d mP1_optim;
	vector<Point3d> vWrdPts_optim;
	double err_rpj;

	// start optimization
	if (!optim_gn_P_XYZ(vImgPts0, vImgPts1, mP1, vWrdPts_init, mP1_optim, vWrdPts_optim, err_rpj, maxIter, xEps, fEps))
	{
		// if the optimization fails, return false
		return false;
	} 
	
	// extract the optimized F matrix
	// P = [M|t], F = [t]xM
	Matx31d t; Matx33d M;
	t(0) = mP1_optim(0,3);t(1) = mP1_optim(1,3);t(2) = mP1_optim(2,3);

	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			M(i,j)=mP1_optim(i,j);
		}
	}

	mF_optim = CrossMat(t)*M;

	return true;
}

// 20150401, zhaokunz, optimize the given fundamental matrix according to the golden standard algorithm
// Levenberg-Marquardt
void DeepVoid::optim_lm_F(const vector<Point2d> & vImgPts0,	// input:	the measured image points in the left image
						  const vector<Point2d> & vImgPts1,	// input:	the measured image points in the right image
						  const Matx33d & mF_init,			// input:	the initial fundamental matrix
						  Matx33d & mF_optim,				// output:	the optimized fundamental matrix
						  double tau /*= 1.0E-3*/,			// input:	The algorithm is not very sensitive to the choice of tau, but as a rule of thumb, one should use a small value, eg tau=1E-6 if x0 is believed to be a good approximation to real value, otherwise, use tau=1E-3 or even tau=1
						  int maxIter /*= 15*/,				// input:	the maximum number of iterations
						  double eps1 /*= 1.0E-8*/,			// input:	threshold
						  double eps2 /*= 1.0E-12*/			// input:	threshold
						  )
{
	int i,j;

	int n = vImgPts0.size();

	Matx34d mP0,mP1;
	GetCameraMatfromF(mF_init, mP0, mP1);

	// 20150113, zhaokunz, correctMatches based on the Optimal Triangulation Method in Multiple View Geometry
	vector<Point2d> vImgPts0_crct, vImgPts1_crct;
	correctMatches(mF_init, vImgPts0, vImgPts1, vImgPts0_crct, vImgPts1_crct);

	Mat mWrdPts;
	//	triangulatePoints(mP0, mP1, vImgPts0, vImgPts1, mWrdPts);
	// 20150113, zhaokunz, use corrected image points to triangulate 3D points
	triangulatePoints(mP0, mP1, vImgPts0_crct, vImgPts1_crct, mWrdPts);

	vector<Point3d> vWrdPts_init;

	for (i=0;i<n;i++)
	{
		Point3d pt;
		double w_1 = 1.0/mWrdPts.at<double>(3,i);

		pt.x = mWrdPts.at<double>(0,i)*w_1;
		pt.y = mWrdPts.at<double>(1,i)*w_1;
		pt.z = mWrdPts.at<double>(2,i)*w_1;

		vWrdPts_init.push_back(pt);
	}

	Matx34d mP1_optim;
	vector<Point3d> vWrdPts_optim;
	double err_rpj;
	vector<double> info;

	// start optimization
	optim_lm_P_XYZ(vImgPts0, vImgPts1, mP1, vWrdPts_init, mP1_optim, vWrdPts_optim, info, tau, maxIter, eps1, eps2);

	// extract the optimized F matrix
	// P = [M|t], F = [t]xM
	Matx31d t; Matx33d M;
	t(0) = mP1_optim(0,3);t(1) = mP1_optim(1,3);t(2) = mP1_optim(2,3);

	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			M(i,j)=mP1_optim(i,j);
		}
	}

	mF_optim = CrossMat(t)*M;
}

void DeepVoid::PropagateDepth2OtherImage(const cam_data & cam0, const cam_data & cam,
										 const Mat & mDepth0, const Mat & mHx0, const Mat & mHy0, const Mat & mScore0,
										 Mat & mDepth, double & mindepth, double & maxdepth
										 )
{
	int i,j;

	int imgWidth = mDepth0.cols;
	int imgHeight = mDepth0.rows;

	Matx33d mK0, mR0, mK, mR;
	Matx31d mt0, mt;

	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mR0(i,j) = cam0.R[i*3+j];
			mR(i,j) = cam.R[i*3+j];
		}
	}

	mt0(0) = cam0.t[0];	mt0(1) = cam0.t[1];	mt0(2) = cam0.t[2];	

	mt(0) = cam.t[0];	mt(1) = cam.t[1];	mt(2) = cam.t[2];	

	mK0(0,0) = cam0.fx; mK0(0,1) = cam0.s;	mK0(0,2) = cam0.cx;
	mK0(1,0) = 0;		mK0(1,1) = cam0.fy;	mK0(1,2) = cam0.cy;
	mK0(2,0) = 0;		mK0(2,1) = 0;		mK0(2,2) = 1;

	mK(0,0) = cam.fx;	mK(0,1) = cam.s;	mK(0,2) = cam.cx;
	mK(1,0) = 0;		mK(1,1) = cam.fy;	mK(1,2) = cam.cy;
	mK(2,0) = 0;		mK(2,1) = 0;		mK(2,2) = 1;

	Matx33d mKR = mK*mR;
	Matx31d mKt = mK*mt;

	mDepth = Mat(imgHeight, imgWidth, CV_32FC1, Scalar(-1));
	Mat mdist(imgHeight, imgWidth, CV_32FC1, Scalar(1));

	bool bfirst = true;
	for (i=0;i<imgHeight;i++)
	{
		for (j=0;j<imgWidth;j++)
		{
			double d = mDepth0.at<float>(i,j);
			double hx = mHx0.at<float>(i,j);
			double hy = mHy0.at<float>(i,j);
			double score = mScore0.at<float>(i,j);

			if (score<0)
			{
				continue;
			}
			
			// compute corresponding XYZ
			Matx31d pt3d = GetXYZ_givenDepth(mK0, mR0, mt0, j, i, d);

			// get the projection in other image
			Matx31d imgpt = mKR*pt3d+mKt;
			double zk_1 = 1/imgpt(2);
			double xk = imgpt(0)*zk_1;
			double yk = imgpt(1)*zk_1;

			if (xk < 0 || xk > imgWidth-1 || yk < 0 || yk > imgHeight-1)
			{
				continue;
			}

			int xk_int = int(xk+0.5);
			int yk_int = int(yk+0.5);

			double dx = xk-xk_int;
			double dy = yk-yk_int;

			double dist = sqrt(dx*dx+dy*dy);
			double dist0 = mdist.at<float>(yk_int,xk_int);

			if (dist>=dist0)
			{
				continue;
			}

			double uk,vk,dk;
			optim_gn_uvrou(mK0, mR0, mt0, mK, mR, mt, d, hx, hy, j, i, xk_int, yk_int, uk, vk, dk);

			mDepth.at<float>(yk_int,xk_int) = dk;

			mdist.at<float>(yk_int,xk_int) = dist;

			if (bfirst)
			{
				mindepth = maxdepth = dk;
				bfirst = false;
				continue;
			}

			if (dk<mindepth)
			{
				mindepth = dk;
			}
			if (dk>maxdepth)
			{
				maxdepth = dk;
			}
		}
	}
}

void DeepVoid::DepthConsistencyCheck(const vector<cam_data> & vCams,
									 const vector<Mat> & vImgs,		// input:	all images
									 const vector<Mat> & vDepths, const vector<Mat> & vHxs, const vector<Mat> & vHys,
									 vector<Mat> & vDepths_final, vector<Mat> & vHxs_final, vector<Mat> & vHys_final,
									 vector<Point2d> & vMinMax_d, vector<Point2d> & vMinMax_hx, vector<Point2d> & vMinMax_hy,
									 int wndSize /*= 5*/,
									 double thresh_ncc /*= 0.5*/,
									 double thresh_radio /*= 0.001*/
									 )
{
	int i,j,ii,jj;

	int nCam = vCams.size();
	int halfwnd = (wndSize-1)*0.5;

	vDepths_final.clear();
	vHxs_final.clear();
	vHys_final.clear();
	vMinMax_d.clear();
	vMinMax_hx.clear();
	vMinMax_hy.clear();

	vector<Matx33d> vKs,vRs,vKRs;
	vector<Matx31d> vts,vKts;

	for (i=0;i<nCam;i++)
	{
		cam_data cam = vCams[i];

		Matx33d mK, mR;
		Matx31d mt;

		for (ii=0;ii<3;ii++)
		{
			for (jj=0;jj<3;jj++)
			{
				mR(ii,jj) = cam.R[ii*3+jj];
			}
		}
		mt(0)   = cam.t[0];	mt(1)   = cam.t[1];	mt(2)   = cam.t[2];	
		mK(0,0) = cam.fx;	mK(0,1) = cam.s;	mK(0,2) = cam.cx;
		mK(1,0) = 0;		mK(1,1) = cam.fy;	mK(1,2) = cam.cy;
		mK(2,0) = 0;		mK(2,1) = 0;		mK(2,2) = 1;

		vKs.push_back(mK);
		vRs.push_back(mR);
		vts.push_back(mt);
		vKRs.push_back(mK*mR);
		vKts.push_back(mK*mt);
	}

	int imgWidth = vDepths[0].cols;
	int imgHeight = vDepths[0].rows;

	CString strInfo;

	for (i=0;i<nCam;i++)
	{
		Mat mDepth(imgHeight, imgWidth, CV_32FC1, Scalar(-1));
		Mat mHx(imgHeight, imgWidth, CV_32FC1, Scalar(-1));
		Mat mHy(imgHeight, imgWidth, CV_32FC1, Scalar(-1));

		bool bfirst = true;

		double mind,maxd,minhx,maxhx,minhy,maxhy;

		for (ii=0;ii<imgHeight;ii++)
		{
			strInfo.Format("evaluate row %04d of image %02d", ii, i);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (jj=0;jj<imgWidth;jj++)
			{
				double d0 = vDepths[i].at<float>(ii,jj);
				double hx0 = vHxs[i].at<float>(ii,jj);
				double hy0 = vHys[i].at<float>(ii,jj);

				if (d0<0)
				{
					continue;
				}

				// first determine visible images through NCC
				int i_real, j_real;
				MakeSureNotOutBorder(jj,ii,j_real,i_real,halfwnd,imgWidth,imgHeight);

				vector<double> vScores;
				CheckOnePixel_givenOneParamSet(vCams,vImgs,i,j_real,i_real,d0,hx0,hy0,vScores,wndSize);

				bool bfailed = false;
				for (j=0;j<nCam;j++)
				{
					if (vScores[j]<thresh_ncc)
					{
						continue;
					}

					// compute corresponding XYZ
					Matx31d pt3d = GetXYZ_givenDepth(vKs[i], vRs[i], vts[i], jj, ii, d0);

					pt3d = vRs[j]*pt3d+vts[j];

					Matx31d imgpt = vKs[j]*pt3d;
					double zk_1 = 1/imgpt(2);
					double xk = imgpt(0)*zk_1;
					double yk = imgpt(1)*zk_1;

					if (xk < 0 || xk > imgWidth-1 || yk < 0 || yk > imgHeight-1)
					{
						bfailed = true;
						break;
					}

					int xk_int = int(xk+0.5);
					int yk_int = int(yk+0.5);

					double u = xk-xk_int;
					double v = yk-yk_int;

					double dk = vDepths[j].at<float>(yk_int, xk_int);
					double hxk = vHxs[j].at<float>(yk_int, xk_int);
					double hyk = vHys[j].at<float>(yk_int, xk_int);

					double ddd = dk + u*hxk+v*hyk;

					//double radio = fabs((pt3d(2)-ddd)/ddd);
					double radio = fabs((pt3d(2)-ddd)/pt3d(2));

					if (radio>thresh_radio)
					{
						bfailed = true;
						break;
					}

					// get the projection in other image
// 					Matx31d imgpt = vKRs[j]*pt3d+vKts[j];
// 					double zk_1 = 1/imgpt(2);
// 					double xk = imgpt(0)*zk_1;
// 					double yk = imgpt(1)*zk_1;
// 
// 					if (xk < 0 || xk > imgWidth-1 || yk < 0 || yk > imgHeight-1)
// 					{
// 						bfailed = true;
// 						break;
// 					}
// 
// 					int xk_int = int(xk+0.5);
// 					int yk_int = int(yk+0.5);
// 
// 					double uk,vk,dk;
// 					optim_gn_uvrou(vKs[i], vRs[i], vts[i], vKs[j], vRs[j], vts[j], d0, hx0, hy0, jj, ii, xk_int, yk_int, uk, vk, dk);
// 
// 					double dk0 = vDepths[j].at<float>(yk_int, xk_int);
// 
// 					double ratio = fabs((dk-dk0)/dk0);
// 
// 					if (ratio>thresh_radio)
// 					{
// 						bfailed = true;
// 						break;
// 					}
				}

				if (!bfailed)
				{
					mDepth.at<float>(ii,jj) = d0;
					mHx.at<float>(ii,jj) = hx0;
					mHy.at<float>(ii,jj) = hy0;

					if (bfirst)
					{
						mind = maxd = d0;
						minhx = maxhx = hx0;
						minhy = maxhy = hy0;
						bfirst = false;
						continue;
					}

					if (d0<mind){mind = d0;}
					if (d0>maxd){maxd = d0;}
					if (hx0<minhx){minhx = hx0;}
					if (hx0>maxhx){maxhx = hx0;}
					if (hy0<minhy){minhy = hy0;}
					if (hy0>maxhy){maxhy = hy0;}
				}
			}
		}

		vDepths_final.push_back(mDepth);
		vHxs_final.push_back(mHx);
		vHys_final.push_back(mHy);

		Point2d pt2d;
		pt2d.x = mind; pt2d.y = maxd;
		vMinMax_d.push_back(pt2d);

		pt2d.x = minhx; pt2d.y = maxhx;
		vMinMax_hx.push_back(pt2d);

		pt2d.x = minhy; pt2d.y = maxhy;
		vMinMax_hy.push_back(pt2d);
	}
}

// 20140828
void DeepVoid::DepthConsistencyCheck(const vector<Matx33d> & vKs,				// input:	all interior matrix
								     const vector<Matx33d> & vRs,				// input:	all rotation matrix
								     const vector<Matx31d> & vts,				// input:	all translation vectors
								     const vector<double> & vfx_1,				// input:	
								     const vector<double> & vfy_1,				// input:
								     const vector<vector<int>> & vIdxSupports,	// input:	all images' support images' index
								     int idx_ref,								// input:	the reference image index
								     const vector<Mat> & vDepths,
								     const vector<Mat> & vHxs,
								     const vector<Mat> & vHys,
								     vector<Mat> & vScores,						// output:	pixels do not pass check are set to invalids
								     const vector<Mat> & vVisis,
								     double thresh_ratio /*= 0.001*/
								     )
{
	int i,j,k;

	int w = vDepths[idx_ref].cols;
	int h = vDepths[idx_ref].rows;

	vector<int> vIdx_spt = vIdxSupports[idx_ref];

	double cx = vKs[idx_ref](0,2);
	double cy = vKs[idx_ref](1,2);

	for (i=0;i<h;i++)
	{
		double nimgy = (i-cy)*vfy_1[idx_ref];
		for (j=0;j<w;j++)
		{
			double score = vScores[idx_ref].at<float>(i,j);
			if (score<0){continue;} // this pixel is invalid already

			double nimgx = (j-cx)*vfx_1[idx_ref];

			double depth = vDepths[idx_ref].at<float>(i,j);
			Matx31d XYZ = GetXYZ_givenDepth(vRs[idx_ref],vts[idx_ref],nimgx,nimgy,depth);

			uchar visi = vVisis[idx_ref].at<uchar>(i,j);

			vector<bool> vbools;
			InterpVisiVector_uchar(visi, vbools);

//			bool bfailed = false;
			bool bfailed = true;
			for (k=0;k<vIdx_spt.size();k++)
			{
				if (!vbools[k]){continue;}

				Matx31d XYZ_k = vRs[vIdx_spt[k]]*XYZ+vts[vIdx_spt[k]];

				Matx31d imgpt = vKs[vIdx_spt[k]]*XYZ_k;
				double zk_1 = 1/imgpt(2);
				double xk = imgpt(0)*zk_1;
				double yk = imgpt(1)*zk_1;

// 				if (xk<0 || xk>w-1 || yk<0 || yk>h-1)
// 				{
// 					bfailed = true; // projection out of border
// 					break;
// 				}
				if (xk<0 || xk>w-1 || yk<0 || yk>h-1)
				{
					continue;
				}

				int xk_int = int(xk+0.5);
				int yk_int = int(yk+0.5);

				double u = xk-xk_int;
				double v = yk-yk_int;

//				double scorek = vScores[vIdx_spt[k]].at<float>(yk_int, xk_int);
// 				if (scorek<0)
// 				{
// // 					bfailed = true; // projection is a invalid estimate
// // 					break;
// 					continue;
// 				}

				double dk = vDepths[vIdx_spt[k]].at<float>(yk_int, xk_int);
				double hxk = vHxs[vIdx_spt[k]].at<float>(yk_int, xk_int);
				double hyk = vHys[vIdx_spt[k]].at<float>(yk_int, xk_int);

				double ddd = dk + u*hxk+v*hyk;

//				double ratio = fabs((XYZ_k(2)-ddd)/XYZ_k(2));// takes into account depth gradient estimate in k
				double ratio = fabs((XYZ_k(2)-dk)/XYZ_k(2)); // does not take into account depth gradient estimate in k

// 				if (ratio>=thresh_ratio)
// 				{
// 					bfailed = true;
// 					break;
// 				}
				if (ratio<thresh_ratio)
				{
					bfailed = false;
					break;
				}
			}

			if (bfailed)
			{
				vScores[idx_ref].at<float>(i,j) = -1;
			}
		}
	}

	Mat mScore_map(h, w, CV_8UC3);

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			if (vScores[idx_ref].at<float>(i,j)<0)
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = 0;
				mScore_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*vScores[idx_ref].at<float>(i,j));
				mScore_map.at<Vec3b>(i,j).val[2] = 0;
			}
		}
	}

	CString strInfo;
	strInfo.Format("D:\\all\\score map %02d after depth consistency check.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mScore_map);
}

// 20140913, self-contained version
void DeepVoid::DepthConsistencyCheck(const Matx33d & mK0,				// input:	interior matrix of reference image
								     const Matx33d & mR0,				// input:	rotation matrix of reference image
								     const Matx31d & mt0,				// input:	translation vector of reference image
								     const Mat & mDepth0,				// input:	depth map of reference image
								     const Mat & mVisi0,				// input:	visibility map of reference image
								     Mat & mScore0,						// output:	pixels do not pass check are set to invalids
								     const vector<Matx33d> & vKs,		// input:	interior matrix of all support images
								     const vector<Matx33d> & vRs,		// input:	rotation matrix of all support images
								     const vector<Matx31d> & vts,		// input:	translation vectors of all support images
								     const vector<Mat> & vDepths,		// input:	depth maps of all support images
								     const vector<Mat> & vHxs,			// input:	hx maps of all support images
								     const vector<Mat> & vHys,			// input:	hy maps of all support images
								     double thresh_ratio /*= 0.001*/
								     )
{
	int i,j,k;

	int w = mDepth0.cols;
	int h = mDepth0.rows;

	int n_spt = vKs.size(); // number of support images

	double fx0_1 = 1/mK0(0,0);
	double fy0_1 = 1/mK0(1,1);
	double cx0 = mK0(0,2);
	double cy0 = mK0(1,2);

	for (i=0;i<h;i++)
	{
		double nimgy0 = (i-cy0)*fy0_1;
		for (j=0;j<w;j++)
		{
			double score0 = mScore0.at<float>(i,j);
			if (score0<0){continue;} // this pixel is invalid already

			double nimgx0 = (j-cx0)*fx0_1;

			double depth0 = mDepth0.at<float>(i,j);
			Matx31d XYZ = GetXYZ_givenDepth(mR0,mt0,nimgx0,nimgy0,depth0);

			uchar visi = mVisi0.at<uchar>(i,j);

			vector<bool> vbools;
			InterpVisiVector_uchar(visi, vbools);

			bool bfailed = true;

			for (k=0;k<n_spt;k++)
			{
				if (!vbools[k]){continue;}

				Matx31d XYZ_k = vRs[k]*XYZ+vts[k];

				Matx31d imgpt = vKs[k]*XYZ_k;
				double zk_1 = 1/imgpt(2);
				double xk = imgpt(0)*zk_1;
				double yk = imgpt(1)*zk_1;

				if (xk<0 || xk>w-1 || yk<0 || yk>h-1)
				{
					continue;
				}

				int xk_int = int(xk+0.5);
				int yk_int = int(yk+0.5);

				double u = xk-xk_int;
				double v = yk-yk_int;

				double dk = vDepths[k].at<float>(yk_int, xk_int);
				double hxk = vHxs[k].at<float>(yk_int, xk_int);
				double hyk = vHys[k].at<float>(yk_int, xk_int);

				double ddd = dk + u*hxk+v*hyk;

				double ratio = fabs((XYZ_k(2)-dk)/XYZ_k(2)); // does not take into account depth gradient estimate in k

				if (ratio<thresh_ratio)
				{
					bfailed = false;
					break;
				}
			}

			if (bfailed)
			{
				mScore0.at<float>(i,j) = -1;
			}
		}
	}
}

void DeepVoid::DepthConsistencyCheck_QualityEvaluation(const vector<cam_data> & vCams,
													   const vector<Mat> & vImgs,		// input:	all images
													   const vector<Mat> & vDepths, const vector<Mat> & vHxs, const vector<Mat> & vHys,
													   vector<Mat> & vDepths_final, vector<Mat> & vHxs_final, vector<Mat> & vHys_final, vector<Mat> & vQuality_final,
													   vector<Point2d> & vMinMax_d, vector<Point2d> & vMinMax_hx, vector<Point2d> & vMinMax_hy, vector<Point2d> & vMinMax_quality,
													   int wndSize/* = 5*/,
													   double thresh_ncc/* = 0.5*/,
													   double thresh_radio /*= 0.001*/
													   )
{
	int i,j,ii,jj;

	int nCam = vCams.size();
	int halfwnd = (wndSize-1)*0.5;

	vDepths_final.clear();
	vHxs_final.clear();
	vHys_final.clear();
	vQuality_final.clear();

	vMinMax_d.clear();
	vMinMax_hx.clear();
	vMinMax_hy.clear();
	vMinMax_quality.clear();

	vector<Matx33d> vKs,vRs,vKRs;
	vector<Matx31d> vts,vKts;

	for (i=0;i<nCam;i++)
	{
		cam_data cam = vCams[i];

		Matx33d mK, mR;
		Matx31d mt;

		for (ii=0;ii<3;ii++)
		{
			for (jj=0;jj<3;jj++)
			{
				mR(ii,jj) = cam.R[ii*3+jj];
			}
		}
		mt(0)   = cam.t[0];	mt(1)   = cam.t[1];	mt(2)   = cam.t[2];	
		mK(0,0) = cam.fx;	mK(0,1) = cam.s;	mK(0,2) = cam.cx;
		mK(1,0) = 0;		mK(1,1) = cam.fy;	mK(1,2) = cam.cy;
		mK(2,0) = 0;		mK(2,1) = 0;		mK(2,2) = 1;

		vKs.push_back(mK);
		vRs.push_back(mR);
		vts.push_back(mt);
		vKRs.push_back(mK*mR);
		vKts.push_back(mK*mt);
	}

	int imgWidth = vDepths[0].cols;
	int imgHeight = vDepths[0].rows;

	CString strInfo;

	for (i=0;i<nCam;i++)
	{
		Mat mDepth(imgHeight, imgWidth, CV_32FC1, Scalar(-1));
		Mat mHx(imgHeight, imgWidth, CV_32FC1, Scalar(-1));
		Mat mHy(imgHeight, imgWidth, CV_32FC1, Scalar(-1));
		Mat mQuality(imgHeight, imgWidth, CV_32FC1, Scalar(-1));

		bool bfirst = true; bool bfirstq = true;

		double mind,maxd,minhx,maxhx,minhy,maxhy,minq,maxq;

		for (ii=0;ii<imgHeight;ii++)
		{
			strInfo.Format("evaluate row %04d of image %02d", ii, i);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (jj=0;jj<imgWidth;jj++)
			{
				double d0 = vDepths[i].at<float>(ii,jj);
				double hx0 = vHxs[i].at<float>(ii,jj);
				double hy0 = vHys[i].at<float>(ii,jj);

				if (d0<0)
				{
					continue;
				}

				// first determine visible images through NCC
				int i_real, j_real;
				MakeSureNotOutBorder(jj,ii,j_real,i_real,halfwnd,imgWidth,imgHeight);

				vector<double> vScores;
				CheckOnePixel_givenOneParamSet(vCams,vImgs,i,j_real,i_real,d0,hx0,hy0,vScores,wndSize);

				bool bfailed = false; bool bfirstCam = true; double maxratio=-1;
				for (j=0;j<nCam;j++)
				{
					if (vScores[j]<thresh_ncc)
					{
						continue;
					}

					// compute corresponding XYZ
					Matx31d pt3d = GetXYZ_givenDepth(vKs[i], vRs[i], vts[i], jj, ii, d0);

					pt3d = vRs[j]*pt3d+vts[j];

					Matx31d imgpt = vKs[j]*pt3d;
					double zk_1 = 1/imgpt(2);
					double xk = imgpt(0)*zk_1;
					double yk = imgpt(1)*zk_1;

					if (xk < 0 || xk > imgWidth-1 || yk < 0 || yk > imgHeight-1)
					{
						bfailed = true;
						break;
					}

					int xk_int = int(xk+0.5);
					int yk_int = int(yk+0.5);

					double u = xk-xk_int;
					double v = yk-yk_int;

					double dk = vDepths[j].at<float>(yk_int, xk_int);
					double hxk = vHxs[j].at<float>(yk_int, xk_int);
					double hyk = vHys[j].at<float>(yk_int, xk_int);

					double ddd = dk + u*hxk+v*hyk;

					//double ratio = fabs((pt3d(2)-ddd)/ddd);
					double ratio = fabs((pt3d(2)-ddd)/pt3d(2));

					if (ratio>thresh_radio)
					{
						bfailed = true;
					}

					if (bfirstCam)
					{
						maxratio = ratio;
						bfirstCam = false;
						continue;
					}

					if (ratio>maxratio)
					{
						maxratio = ratio;
					}
				}

				if (maxratio>=0)
				{
					mQuality.at<float>(ii,jj) = maxratio;

					if (bfirstq)
					{
						minq = maxq = maxratio;
						bfirstq = false;
					} 
					else
					{
						if (maxratio<minq){minq = maxratio;}
						if (maxratio>maxq){maxq = maxratio;}
					}
				}

				if (!bfailed&&!bfirstCam)
				{
					mDepth.at<float>(ii,jj) = d0;
					mHx.at<float>(ii,jj) = hx0;
					mHy.at<float>(ii,jj) = hy0;

					if (bfirst)
					{
						mind = maxd = d0;
						minhx = maxhx = hx0;
						minhy = maxhy = hy0;
						bfirst = false;
						continue;
					}

					if (d0<mind){mind = d0;}
					if (d0>maxd){maxd = d0;}
					if (hx0<minhx){minhx = hx0;}
					if (hx0>maxhx){maxhx = hx0;}
					if (hy0<minhy){minhy = hy0;}
					if (hy0>maxhy){maxhy = hy0;}
				}
			}
		}

		vDepths_final.push_back(mDepth);
		vHxs_final.push_back(mHx);
		vHys_final.push_back(mHy);
		vQuality_final.push_back(mQuality);

		Point2d pt2d;
		pt2d.x = mind; pt2d.y = maxd;
		vMinMax_d.push_back(pt2d);

		pt2d.x = minhx; pt2d.y = maxhx;
		vMinMax_hx.push_back(pt2d);

		pt2d.x = minhy; pt2d.y = maxhy;
		vMinMax_hy.push_back(pt2d);

		pt2d.x = minq; pt2d.y = maxq;
		vMinMax_quality.push_back(pt2d);
	}
}

void DeepVoid::DepthConsistencyCheck_QualityEvaluation_Goesele(const vector<cam_data> & vCams,
															   const vector<Mat> & vImgs,		// input:	all images
															   const vector<Mat> & vSilhouettes,	// input: silhouettes of objects
															   const vector<Mat> & vDepths, const vector<Mat> & vHxs, const vector<Mat> & vHys, const vector<Mat> & vVisis,
															   vector<Mat> & vDepths_final, vector<Mat> & vHxs_final, vector<Mat> & vHys_final, vector<Mat> & vQuality_final, vector<Mat> & vQuality_G_final,
															   vector<Point2d> & vMinMax_d, vector<Point2d> & vMinMax_hx, vector<Point2d> & vMinMax_hy, vector<Point2d> & vMinMax_quality,
															   int wndSize /*= 5*/,
															   double thresh_ncc /*= 0.5*/,
															   double thresh_radio /*= 0.001*/
															   )
{
	int i,j,ii,jj,k;

	int nCam = vCams.size();
	int halfwnd = (wndSize-1)*0.5;

	vDepths_final.clear();
	vHxs_final.clear();
	vHys_final.clear();
	vQuality_final.clear();
	vQuality_G_final.clear();

	vMinMax_d.clear();
	vMinMax_hx.clear();
	vMinMax_hy.clear();
	vMinMax_quality.clear();

	vector<Matx33d> vKs,vRs,vKRs;
	vector<Matx31d> vts,vKts;

	for (i=0;i<nCam;i++)
	{
		cam_data cam = vCams[i];

		Matx33d mK, mR;
		Matx31d mt;

		for (ii=0;ii<3;ii++)
		{
			for (jj=0;jj<3;jj++)
			{
				mR(ii,jj) = cam.R[ii*3+jj];
			}
		}
		mt(0)   = cam.t[0];	mt(1)   = cam.t[1];	mt(2)   = cam.t[2];	
		mK(0,0) = cam.fx;	mK(0,1) = cam.s;	mK(0,2) = cam.cx;
		mK(1,0) = 0;		mK(1,1) = cam.fy;	mK(1,2) = cam.cy;
		mK(2,0) = 0;		mK(2,1) = 0;		mK(2,2) = 1;

		vKs.push_back(mK);
		vRs.push_back(mR);
		vts.push_back(mt);
		vKRs.push_back(mK*mR);
		vKts.push_back(mK*mt);
	}

	int imgWidth = vDepths[0].cols;
	int imgHeight = vDepths[0].rows;

	CString strInfo;

	for (i=0;i<nCam;i++)
	{
		Mat mDepth(imgHeight, imgWidth, CV_32FC1, Scalar(-1));
		Mat mHx(imgHeight, imgWidth, CV_32FC1, Scalar(-1));
		Mat mHy(imgHeight, imgWidth, CV_32FC1, Scalar(-1));
		Mat mQuality(imgHeight, imgWidth, CV_32FC1, Scalar(-1));
		Mat mQuality_G(imgHeight, imgWidth, CV_32FC1, Scalar(-1));

		bool bfirst = true; bool bfirstq = true;

		double mind,maxd,minhx,maxhx,minhy,maxhy,minq,maxq;

		for (ii=0;ii<imgHeight;ii++)
		{
			strInfo.Format("evaluate row %04d of image %02d", ii, i);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (jj=0;jj<imgWidth;jj++)
			{
				double d0 = vDepths[i].at<float>(ii,jj);
				double hx0 = vHxs[i].at<float>(ii,jj);
				double hy0 = vHys[i].at<float>(ii,jj);
				uchar uValid = vSilhouettes[i].at<uchar>(ii,jj);

				if (i==4&&ii==394&&jj==172)
				/*if (i==4&&ii==246&&jj==460)*/
				/*if (i==4&&ii==194&&jj==512)*/
				/*if (i==4&&ii==220&&jj==400)*/
				/*if (i==4&&ii==185&&jj==450)*/
				/*if (i==4&&ii==227&&jj==190)*/
				/*if (i==4&&ii==227&&jj==450)*/
				/*if (i==4&&ii==264&&jj==310)*/
				/*if (i==4&&ii==227&&jj==246)*/
				{
					OutputSupportWindow("C:\\Users\\DeepVoid\\Desktop\\supportwindows.txt", vKs[i], vRs[i], vts[i], jj, ii, d0, hx0, hy0, wndSize, wndSize, 255, 0, 0);
				}

				if (d0<0 || uValid<128)
				{
					continue;
				}

				// first determine visible images through NCC
				int i_real, j_real;
				MakeSureNotOutBorder(jj,ii,j_real,i_real,halfwnd,imgWidth,imgHeight);

				vector<double> vScores;
				CheckOnePixel_givenOneParamSet(vCams,vImgs,i,j_real,i_real,d0,hx0,hy0,vScores,wndSize);

				vector<bool> vbools;
				InterpVisiVector_uchar(vVisis[i].at<uchar>(ii,jj), vbools);

				for (j=0;j<nCam;j++)
				{
					if (!vbools[j])
					{
						vScores[j]=-1;
					}
				}

 				mQuality_G.at<float>(ii,jj)=GetConfidence(vScores, thresh_ncc, 1);
				double qG = mQuality_G.at<float>(ii,jj);
// 				if (qG<0)
// 				{
// 					continue;
// 				}

				vector<double> vRatio;

				bool bfailed = false; bool bfirstCam = true; double maxratio=-1;
				for (j=0;j<nCam;j++)
				{
					/*if (vScores[j]<thresh_ncc)*/
					/*if (vScores[j]<0)*/
					if (!vbools[j])
					{
						continue;
					}

					// compute corresponding XYZ
					Matx31d pt3d = GetXYZ_givenDepth(vKs[i], vRs[i], vts[i], jj, ii, d0);

					pt3d = vRs[j]*pt3d+vts[j];

					Matx31d imgpt = vKs[j]*pt3d;
					double zk_1 = 1/imgpt(2);
					double xk = imgpt(0)*zk_1;
					double yk = imgpt(1)*zk_1;

					if (xk < 0 || xk > imgWidth-1 || yk < 0 || yk > imgHeight-1)
					{
						bfailed = true;
						break;
					}

					int xk_int = int(xk+0.5);
					int yk_int = int(yk+0.5);

					double u = xk-xk_int;
					double v = yk-yk_int;

					double dk = vDepths[j].at<float>(yk_int, xk_int);
					double hxk = vHxs[j].at<float>(yk_int, xk_int);
					double hyk = vHys[j].at<float>(yk_int, xk_int);

					if (dk<0 || vSilhouettes[j].at<uchar>(yk_int, xk_int)<128)
					{
						bfailed=true;
						break;
					}

					double ddd = dk + u*hxk+v*hyk;

					//double ratio = fabs((pt3d(2)-ddd)/ddd);
					double ratio = fabs((pt3d(2)-ddd)/pt3d(2));

					vRatio.push_back(ratio);

					if (i==4&&ii==394&&jj==172)
					/*if (i==4&&ii==246&&jj==460)*/
					/*if (i==4&&ii==194&&jj==512)*/
					/*if (i==4&&ii==220&&jj==400)*/
					/*if (i==4&&ii==185&&jj==450)*/
					/*if (i==4&&ii==227&&jj==190)*/
					/*if (i==4&&ii==227&&jj==450)*/
					/*if (i==4&&ii==264&&jj==310)*/
					/*if (i==4&&ii==227&&jj==246)*/
					{
						if (j==0)
						{
							OutputSupportWindow("C:\\Users\\DeepVoid\\Desktop\\supportwindows.txt", vKs[j], vRs[j], vts[j], xk_int, yk_int, dk, hxk, hyk, wndSize, wndSize, 255, 255, 255);
						}
						else if (j==1)
						{
							OutputSupportWindow("C:\\Users\\DeepVoid\\Desktop\\supportwindows.txt", vKs[j], vRs[j], vts[j], xk_int, yk_int, dk, hxk, hyk, wndSize, wndSize, 0, 255, 0);
						}
						else if (j==2)
						{
							OutputSupportWindow("C:\\Users\\DeepVoid\\Desktop\\supportwindows.txt", vKs[j], vRs[j], vts[j], xk_int, yk_int, dk, hxk, hyk, wndSize, wndSize, 255, 255, 0);
						}
						else if (j==3)
						{
							OutputSupportWindow("C:\\Users\\DeepVoid\\Desktop\\supportwindows.txt", vKs[j], vRs[j], vts[j], xk_int, yk_int, dk, hxk, hyk, wndSize, wndSize, 255, 0, 255);
						}
					}

					if (ratio>thresh_radio)
					{
						bfailed = true;
					}

					if (bfirstCam)
					{
						maxratio = ratio;
						bfirstCam = false;
						continue;
					}

					if (ratio>maxratio)
					{
						maxratio = ratio;
					}
				}

				if (maxratio>=0)
				{
					mQuality.at<float>(ii,jj) = maxratio;

					if (bfirstq)
					{
						minq = maxq = maxratio;
						bfirstq = false;
					} 
					else
					{
						if (maxratio<minq){minq = maxratio;}
						if (maxratio>maxq){maxq = maxratio;}
					}
				}

// 				if (vRatio.size()>0)
// 				{
// 					double sum_ratio2 = 0;
// 					for (k=0;k<vRatio.size();k++)
// 					{
// 						sum_ratio2 += vRatio[k]*vRatio[k];
// 					}
// 					double sigma_ratio = sqrt(sum_ratio2/vRatio.size());
// 
// 					mQuality.at<float>(ii,jj) = sigma_ratio;
// 
// 					if (bfirstq)
// 					{
// 						minq = maxq = sigma_ratio;
// 						bfirstq = false;
// 					} 
// 					else
// 					{
// 						if (sigma_ratio<minq){minq = sigma_ratio;}
// 						if (sigma_ratio>maxq){maxq = sigma_ratio;}
// 					}
// 
// 					if (sigma_ratio<thresh_radio)
// 					{
// 						mDepth.at<float>(ii,jj) = d0;
// 						mHx.at<float>(ii,jj) = hx0;
// 						mHy.at<float>(ii,jj) = hy0;
// 
// 						if (bfirst)
// 						{
// 							mind = maxd = d0;
// 							minhx = maxhx = hx0;
// 							minhy = maxhy = hy0;
// 							bfirst = false;
// 							continue;
// 						}
// 
// 						if (d0<mind){mind = d0;}
// 						if (d0>maxd){maxd = d0;}
// 						if (hx0<minhx){minhx = hx0;}
// 						if (hx0>maxhx){maxhx = hx0;}
// 						if (hy0<minhy){minhy = hy0;}
// 						if (hy0>maxhy){maxhy = hy0;}
// 					}
// 				}

				if (!bfailed&&!bfirstCam)
				{
					mDepth.at<float>(ii,jj) = d0;
					mHx.at<float>(ii,jj) = hx0;
					mHy.at<float>(ii,jj) = hy0;

					if (bfirst)
					{
						mind = maxd = d0;
						minhx = maxhx = hx0;
						minhy = maxhy = hy0;
						bfirst = false;
						continue;
					}

					if (d0<mind){mind = d0;}
					if (d0>maxd){maxd = d0;}
					if (hx0<minhx){minhx = hx0;}
					if (hx0>maxhx){maxhx = hx0;}
					if (hy0<minhy){minhy = hy0;}
					if (hy0>maxhy){maxhy = hy0;}
				}
			}
		}

		vDepths_final.push_back(mDepth);
		vHxs_final.push_back(mHx);
		vHys_final.push_back(mHy);
		vQuality_final.push_back(mQuality);
		vQuality_G_final.push_back(mQuality_G);

		Point2d pt2d;
		pt2d.x = mind; pt2d.y = maxd;
		vMinMax_d.push_back(pt2d);

		pt2d.x = minhx; pt2d.y = maxhx;
		vMinMax_hx.push_back(pt2d);

		pt2d.x = minhy; pt2d.y = maxhy;
		vMinMax_hy.push_back(pt2d);

		pt2d.x = minq; pt2d.y = maxq;
		vMinMax_quality.push_back(pt2d);
	}
}

// 20140605, reject bad depth by setting its score to -1
void DeepVoid::DepthConsistencyCheck_QualityEvaluation_visi(const vector<cam_data> & vCams,
														    const vector<Mat> & vImgs,		// input:	all images
														    const vector<Mat> & vSilhouettes,	// input: silhouettes of objects
														    const vector<Mat> & vDepths, const vector<Mat> & vHxs, const vector<Mat> & vHys, const vector<Mat> & vVisis,
														    vector<Mat> & vScores, vector<Mat> & vQuality,
														    int wndSize /*= 5*/,
														    double thresh_radio /*= 0.001*/
														    )
{
	int i,j,ii,jj,k,kk;

	int nCam = vCams.size();
	int halfwnd = (wndSize-1)*0.5;

	vQuality.clear();

	vector<Matx33d> vKs,vRs,vKRs;
	vector<Matx31d> vts,vKts;

	for (i=0;i<nCam;i++)
	{
		cam_data cam = vCams[i];

		Matx33d mK, mR;
		Matx31d mt;

		for (ii=0;ii<3;ii++)
		{
			for (jj=0;jj<3;jj++)
			{
				mR(ii,jj) = cam.R[ii*3+jj];
			}
		}
		mt(0)   = cam.t[0];	mt(1)   = cam.t[1];	mt(2)   = cam.t[2];	
		mK(0,0) = cam.fx;	mK(0,1) = cam.s;	mK(0,2) = cam.cx;
		mK(1,0) = 0;		mK(1,1) = cam.fy;	mK(1,2) = cam.cy;
		mK(2,0) = 0;		mK(2,1) = 0;		mK(2,2) = 1;

		vKs.push_back(mK);
		vRs.push_back(mR);
		vts.push_back(mt);
		vKRs.push_back(mK*mR);
		vKts.push_back(mK*mt);
	}

	int imgWidth = vDepths[0].cols;
	int imgHeight = vDepths[0].rows;

	CString strInfo;

	for (k=0;k<nCam;k++)
	{
		Mat mQuality(imgHeight, imgWidth, CV_32FC1, Scalar(-1));

		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("evaluate row %04d of image %02d", i, k);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				uchar uSil = vSilhouettes[k].at<uchar>(i,j);
				if (uSil<128) // out of the border of the object
				{
					vScores[k].at<float>(i,j) = -1;
					continue;
				}

				double score = vScores[k].at<float>(i,j);
				double depth = vDepths[k].at<float>(i,j);
				double hx = vHxs[k].at<float>(i,j);
				double hy = vHys[k].at<float>(i,j);
				uchar visi = vVisis[k].at<uchar>(i,j);

				if (score<0) // invalid pixel
				{
					continue;
				}

				// compute corresponding XYZ
				Matx31d pt3d0 = GetXYZ_givenDepth(vKs[k], vRs[k], vts[k], j, i, depth);

				vector<bool> vbools;
				InterpVisiVector_uchar(visi, vbools);

				vector<double> vratios;

				bool bfailed = false;
				for (kk=0;kk<nCam;kk++)
				{
					if (!vbools[kk])
					{
						continue;
					}

					Matx31d pt3dk = vRs[kk]*pt3d0+vts[kk];

					Matx31d imgpt = vKs[kk]*pt3dk;
					double zk_1 = 1/imgpt(2);
					double xk = imgpt(0)*zk_1;
					double yk = imgpt(1)*zk_1;

					if (xk < 0 || xk > imgWidth-1 || yk < 0 || yk > imgHeight-1)
					{
						bfailed = true;
						continue;
					}

					int xk_int = int(xk+0.5);
					int yk_int = int(yk+0.5);

					double u = xk-xk_int;
					double v = yk-yk_int;

					double scorek = vScores[kk].at<float>(yk_int, xk_int);
					double dk = vDepths[kk].at<float>(yk_int, xk_int);
					double hxk = vHxs[kk].at<float>(yk_int, xk_int);
					double hyk = vHys[kk].at<float>(yk_int, xk_int);
					uchar uSilk = vSilhouettes[kk].at<uchar>(yk_int, xk_int);

					if (scorek<0 || uSilk<128)
					{
						bfailed = true;
						continue;
					}

					double ddd=dk+u*hxk+v*hyk;

					double ratio = fabs((pt3dk(2)-ddd)/pt3dk(2));

					vratios.push_back(ratio);
				}

				if (vratios.size()==0)
				{
					bfailed == true;
				}
				
				if (bfailed)
				{
					vScores[k].at<float>(i,j) = -1;
				}
				else
				{
					vector <double>::iterator iterDouble = max_element(vratios.begin(), vratios.end());
					double max_ratio = *iterDouble;
					if (max_ratio>thresh_radio)
					{
						vScores[k].at<float>(i,j) = -1;
					} 
				
					mQuality.at<float>(i,j) = max_ratio;
				}
			}
		}

		vQuality.push_back(mQuality);
	}

	for (i=0;i<nCam;i++)
	{
		Mat mQ_interval_color(imgHeight, imgWidth, CV_8UC3);

		for (ii=0;ii<imgHeight;ii++)
		{
			for (jj=0;jj<imgWidth;jj++)
			{
				//////////////////////////////////////////////////////////////////////////
				if (fabs(vQuality[i].at<float>(ii,jj)+1)<1.0E-8)
				{
					mQ_interval_color.at<Vec3b>(ii,jj).val[0] = 0;
					mQ_interval_color.at<Vec3b>(ii,jj).val[1] = 0;
					mQ_interval_color.at<Vec3b>(ii,jj).val[2] = 255;
				}
				else
				{
					if (vQuality[i].at<float>(ii,jj)<=0.001)
					{
						mQ_interval_color.at<Vec3b>(ii,jj).val[0] = 255;
						mQ_interval_color.at<Vec3b>(ii,jj).val[1] = 0;
						mQ_interval_color.at<Vec3b>(ii,jj).val[2] = 0;
					}
					else if (vQuality[i].at<float>(ii,jj)<=0.005)
					{
						mQ_interval_color.at<Vec3b>(ii,jj).val[0] = 0;
						mQ_interval_color.at<Vec3b>(ii,jj).val[1] = 255;
						mQ_interval_color.at<Vec3b>(ii,jj).val[2] = 0;
					}
					else if (vQuality[i].at<float>(ii,jj)<=0.01)
					{
						mQ_interval_color.at<Vec3b>(ii,jj).val[0] = 0;
						mQ_interval_color.at<Vec3b>(ii,jj).val[1] = 255;
						mQ_interval_color.at<Vec3b>(ii,jj).val[2] = 255;
					}
					else if (vQuality[i].at<float>(ii,jj)<=0.05)
					{
						mQ_interval_color.at<Vec3b>(ii,jj).val[0] = 255;
						mQ_interval_color.at<Vec3b>(ii,jj).val[1] = 0;
						mQ_interval_color.at<Vec3b>(ii,jj).val[2] = 255;
					}
					else if (vQuality[i].at<float>(ii,jj)<=0.1)
					{
						mQ_interval_color.at<Vec3b>(ii,jj).val[0] = 255;
						mQ_interval_color.at<Vec3b>(ii,jj).val[1] = 255;
						mQ_interval_color.at<Vec3b>(ii,jj).val[2] = 255;
					}
					else
					{
						mQ_interval_color.at<Vec3b>(ii,jj).val[0] = 0;
						mQ_interval_color.at<Vec3b>(ii,jj).val[1] = 0;
						mQ_interval_color.at<Vec3b>(ii,jj).val[2] = 255;
					}
				}
			}
		}

		CString str;
		str.Format("D:\\all\\quality map B %d checked.bmp", i);
		imwrite(str.GetBuffer(), mQ_interval_color);

		str.Format("D:\\all\\cloud points %d checked.txt", i);
		WriteDepthMap(str, vCams[i], vImgs[i], vDepths[i], vScores[i]);

		str.Format("D:\\all\\weighted cloud points %d checked.txt", i);
		WriteDepthMap(str, vCams[i], mQ_interval_color, vDepths[i], vScores[i]);
	}
}

// 20140731, reject bad depth by setting its score to -1
void DeepVoid::DepthConsistencyCheck_QualityEvaluation_visi_20140731(const vector<cam_data> & vCams,
																     const vector<Mat> & vImgs,		// input:	all images
																     const vector<Mat> & vSilhouettes,	// input: silhouettes of objects
																     const vector<Mat> & vDepths, const vector<Mat> & vHxs, const vector<Mat> & vHys, const vector<Mat> & vVisis,
																     vector<Mat> & vScores,
																     int wndSize /*= 5*/,
																     double thresh_radio /*= 0.001*/
																     )
{
	int i,j,ii,jj,k,kk;

	int nCam = vCams.size();
	int halfwnd = (wndSize-1)*0.5;

	vector<Matx33d> vKs,vRs,vKRs;
	vector<Matx31d> vts,vKts;

	for (i=0;i<nCam;i++)
	{
		cam_data cam = vCams[i];

		Matx33d mK, mR;
		Matx31d mt;

		for (ii=0;ii<3;ii++)
		{
			for (jj=0;jj<3;jj++)
			{
				mR(ii,jj) = cam.R[ii*3+jj];
			}
		}
		mt(0)   = cam.t[0];	mt(1)   = cam.t[1];	mt(2)   = cam.t[2];	
		mK(0,0) = cam.fx;	mK(0,1) = cam.s;	mK(0,2) = cam.cx;
		mK(1,0) = 0;		mK(1,1) = cam.fy;	mK(1,2) = cam.cy;
		mK(2,0) = 0;		mK(2,1) = 0;		mK(2,2) = 1;

		vKs.push_back(mK);
		vRs.push_back(mR);
		vts.push_back(mt);
		vKRs.push_back(mK*mR);
		vKts.push_back(mK*mt);
	}

	int imgWidth = vDepths[0].cols;
	int imgHeight = vDepths[0].rows;

	CString strInfo;

	for (k=0;k<nCam;k++)
	{
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("evaluate row %04d of image %02d", i, k);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				uchar uSil = vSilhouettes[k].at<uchar>(i,j);
				if (uSil<128) // out of the border of the object
				{
					vScores[k].at<float>(i,j) = -1;
					continue;
				}

				double score = vScores[k].at<float>(i,j);
				double depth = vDepths[k].at<float>(i,j);
				double hx = vHxs[k].at<float>(i,j);
				double hy = vHys[k].at<float>(i,j);
				uchar visi = vVisis[k].at<uchar>(i,j);

				if (score<0) // invalid pixel
				{
					continue;
				}

				// compute corresponding XYZ
				Matx31d pt3d0 = GetXYZ_givenDepth(vKs[k], vRs[k], vts[k], j, i, depth);

				vector<bool> vbools;
				InterpVisiVector_uchar(visi, vbools);

				bool bfailed = true; // failed by default
				for (kk=0;kk<nCam;kk++)
				{
					if (!vbools[kk])
					{
						continue;
					}

					Matx31d pt3dk = vRs[kk]*pt3d0+vts[kk];

					Matx31d imgpt = vKs[kk]*pt3dk;
					double zk_1 = 1/imgpt(2);
					double xk = imgpt(0)*zk_1;
					double yk = imgpt(1)*zk_1;

					if (xk < 0 || xk > imgWidth-1 || yk < 0 || yk > imgHeight-1)
					{
						continue;
					}

					int xk_int = int(xk+0.5);
					int yk_int = int(yk+0.5);

					double u = xk-xk_int;
					double v = yk-yk_int;

					double scorek = vScores[kk].at<float>(yk_int, xk_int);
					double dk = vDepths[kk].at<float>(yk_int, xk_int);
					double hxk = vHxs[kk].at<float>(yk_int, xk_int);
					double hyk = vHys[kk].at<float>(yk_int, xk_int);
					uchar uSilk = vSilhouettes[kk].at<uchar>(yk_int, xk_int);

					if (scorek<0 || uSilk<128)
					{
						continue;
					}

					double ddd=dk+u*hxk+v*hyk;

					double ratio = fabs((pt3dk(2)-ddd)/pt3dk(2));

					if (ratio<thresh_radio)
					{
						bfailed = false;
						break;
					} 
				}

				if (bfailed)
				{
					vScores[k].at<float>(i,j) = -1;
				}
			}
		}
	}

	for (i=0;i<nCam;i++)
	{
		CString str;
		str.Format("D:\\all\\cloud points %d checked.txt", i);
		WriteDepthMap(str, vCams[i], vImgs[i], vDepths[i], vScores[i]);
	}
}

void DeepVoid::DepthConsistencyCheck_QualityEvaluation_visi(const vector<cam_data> & vCams,
															const vector<Mat> & vImgs,		// input:	all images
															const vector<Mat> & vDepths, const vector<Mat> & vHxs, const vector<Mat> & vHys, const vector<Mat> & vVisis,
															vector<Mat> & vDepths_final, vector<Mat> & vHxs_final, vector<Mat> & vHys_final, vector<Mat> & vVisis_diff, vector<Mat> & vQuality_final,
															vector<Point2d> & vMinMax_d, vector<Point2d> & vMinMax_hx, vector<Point2d> & vMinMax_hy, vector<Point2d> & vMinMax_quality,
															int wndSize /*= 5*/,
															double thresh_ncc /*= 0.5*/,
															double thresh_radio /*= 0.001*/
															)
{
	int i,j,ii,jj;

	int nCam = vCams.size();
	int halfwnd = (wndSize-1)*0.5;

	vDepths_final.clear();
	vHxs_final.clear();
	vHys_final.clear();
	vVisis_diff.clear();
	vQuality_final.clear();

	vMinMax_d.clear();
	vMinMax_hx.clear();
	vMinMax_hy.clear();
	vMinMax_quality.clear();

	vector<Matx33d> vKs,vRs,vKRs;
	vector<Matx31d> vts,vKts;

	for (i=0;i<nCam;i++)
	{
		cam_data cam = vCams[i];

		Matx33d mK, mR;
		Matx31d mt;

		for (ii=0;ii<3;ii++)
		{
			for (jj=0;jj<3;jj++)
			{
				mR(ii,jj) = cam.R[ii*3+jj];
			}
		}
		mt(0)   = cam.t[0];	mt(1)   = cam.t[1];	mt(2)   = cam.t[2];	
		mK(0,0) = cam.fx;	mK(0,1) = cam.s;	mK(0,2) = cam.cx;
		mK(1,0) = 0;		mK(1,1) = cam.fy;	mK(1,2) = cam.cy;
		mK(2,0) = 0;		mK(2,1) = 0;		mK(2,2) = 1;

		vKs.push_back(mK);
		vRs.push_back(mR);
		vts.push_back(mt);
		vKRs.push_back(mK*mR);
		vKts.push_back(mK*mt);
	}

	int imgWidth = vDepths[0].cols;
	int imgHeight = vDepths[0].rows;

	CString strInfo;

	for (i=0;i<nCam;i++)
	{
		Mat mDepth(imgHeight, imgWidth, CV_32FC1, Scalar(-1));
		Mat mHx(imgHeight, imgWidth, CV_32FC1, Scalar(-1));
		Mat mHy(imgHeight, imgWidth, CV_32FC1, Scalar(-1));
		Mat mQuality(imgHeight, imgWidth, CV_32FC1, Scalar(-1));
		Mat mVisiDiff(imgHeight, imgWidth, CV_8UC1, Scalar(0));

		bool bfirst = true; bool bfirstq = true;

		double mind,maxd,minhx,maxhx,minhy,maxhy,minq,maxq;

		for (ii=0;ii<imgHeight;ii++)
		{
			strInfo.Format("evaluate row %04d of image %02d", ii, i);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (jj=0;jj<imgWidth;jj++)
			{
				double d0 = vDepths[i].at<float>(ii,jj);
				double hx0 = vHxs[i].at<float>(ii,jj);
				double hy0 = vHys[i].at<float>(ii,jj);

				if (d0<0)
				{
					continue;
				}

				// first determine visible images through NCC
				int i_real, j_real;
				MakeSureNotOutBorder(jj,ii,j_real,i_real,halfwnd,imgWidth,imgHeight);

				vector<double> vScores;
				CheckOnePixel_givenOneParamSet(vCams,vImgs,i,j_real,i_real,d0,hx0,hy0,vScores,wndSize);

				vector<bool> vbools;
				InterpVisiVector_uchar(vVisis[i].at<uchar>(ii,jj), vbools);

				uchar visiNow = GetVisibilityVector_uchar(vScores, thresh_ncc);
				uchar visiOld = vVisis[i].at<uchar>(ii,jj);
				uchar visidiff = hamdist(visiNow, visiOld);
				mVisiDiff.at<uchar>(ii,jj)=visidiff;

				bool bfailed = false; bool bfirstCam = true; double maxratio=-1;
				for (j=0;j<nCam;j++)
				{
// 					if (vScores[j]<thresh_ncc)
// 					{
// 						continue;
// 					}

					if (!vbools[j])
					{
						continue;
					}

					// compute corresponding XYZ
					Matx31d pt3d = GetXYZ_givenDepth(vKs[i], vRs[i], vts[i], jj, ii, d0);

					pt3d = vRs[j]*pt3d+vts[j];

					Matx31d imgpt = vKs[j]*pt3d;
					double zk_1 = 1/imgpt(2);
					double xk = imgpt(0)*zk_1;
					double yk = imgpt(1)*zk_1;

					if (xk < 0 || xk > imgWidth-1 || yk < 0 || yk > imgHeight-1)
					{
						bfailed = true;
						break;
					}

					int xk_int = int(xk+0.5);
					int yk_int = int(yk+0.5);

					double u = xk-xk_int;
					double v = yk-yk_int;

					double dk = vDepths[j].at<float>(yk_int, xk_int);
					double hxk = vHxs[j].at<float>(yk_int, xk_int);
					double hyk = vHys[j].at<float>(yk_int, xk_int);

					double ddd = dk + u*hxk+v*hyk;

					//double ratio = fabs((pt3d(2)-ddd)/ddd);
					double ratio = fabs((pt3d(2)-ddd)/pt3d(2));

					if (ratio>thresh_radio)
					{
						bfailed = true;
					}

					if (bfirstCam)
					{
						maxratio = ratio;
						bfirstCam = false;
						continue;
					}

					if (ratio>maxratio)
					{
						maxratio = ratio;
					}
				}

				if (maxratio>=0)
				{
					mQuality.at<float>(ii,jj) = maxratio;

					if (bfirstq)
					{
						minq = maxq = maxratio;
						bfirstq = false;
					} 
					else
					{
						if (maxratio<minq){minq = maxratio;}
						if (maxratio>maxq){maxq = maxratio;}
					}
				}

				if (!bfailed&&!bfirstCam)
				{
					mDepth.at<float>(ii,jj) = d0;
					mHx.at<float>(ii,jj) = hx0;
					mHy.at<float>(ii,jj) = hy0;

					if (bfirst)
					{
						mind = maxd = d0;
						minhx = maxhx = hx0;
						minhy = maxhy = hy0;
						bfirst = false;
						continue;
					}

					if (d0<mind){mind = d0;}
					if (d0>maxd){maxd = d0;}
					if (hx0<minhx){minhx = hx0;}
					if (hx0>maxhx){maxhx = hx0;}
					if (hy0<minhy){minhy = hy0;}
					if (hy0>maxhy){maxhy = hy0;}
				}
			}
		}

		vDepths_final.push_back(mDepth);
		vHxs_final.push_back(mHx);
		vHys_final.push_back(mHy);
		vQuality_final.push_back(mQuality);
		vVisis_diff.push_back(mVisiDiff);

		Point2d pt2d;
		pt2d.x = mind; pt2d.y = maxd;
		vMinMax_d.push_back(pt2d);

		pt2d.x = minhx; pt2d.y = maxhx;
		vMinMax_hx.push_back(pt2d);

		pt2d.x = minhy; pt2d.y = maxhy;
		vMinMax_hy.push_back(pt2d);

		pt2d.x = minq; pt2d.y = maxq;
		vMinMax_quality.push_back(pt2d);
	}
}

void DeepVoid::OutputSupportWindow(CString strPath,
								   const Matx33d & mK, const Matx33d & mR, const Matx31d & mt,
							       int x, int y,
								   double depth,
								   double hx,
								   double hy,
								   int w, int h,
								   uchar r, uchar g, uchar b,
								   int nSampleNorm /*= 4*/
								   )
{
	FILE * file = fopen(strPath, "a");

	int i,j,k;

	int half_w = (w-1)*0.5;
	int half_h = (h-1)*0.5;

	// compute the normal
	double nimgx = (x-mK(0,2))/mK(0,0);
	double nimgy = (y-mK(1,2))/mK(1,1);
	Matx31d mn0; mn0(2)=1;
	get_normal_givendrhxhy(mK(0,0), mK(1,1), nimgx, nimgy, depth, hx, hy, mn0(0), mn0(1));
	Matx31d mnw = -mR.t()*mn0; // convert the normal into world coordinate system
	double normN = norm(mnw);
	mnw(0)/=normN;mnw(1)/=normN;mnw(2)/=normN;

	vector<Matx31d> vpts3d;
	for (i=-half_h;i<=half_h;i++)
	{
		for (j=-half_w;j<=half_w;j++)
		{
			Matx31d pt3d = GetXYZ_givenDepth(mK, mR, mt, x+j, y+i, depth+hx*j+hy*i);
			fprintf(file, "%lf;%lf;%lf;%d;%d;%d\n", pt3d(0), pt3d(1), pt3d(2), r, g, b);
			vpts3d.push_back(pt3d);
		}
	}

	// get the length
	Matx31d dl = vpts3d[w*h-1]-vpts3d[0];
	double length = norm(dl);
	mnw *= length;
	Matx31d mnw_step;
	mnw_step(0)=mnw(0)/nSampleNorm;
	mnw_step(1)=mnw(1)/nSampleNorm;
	mnw_step(2)=mnw(2)/nSampleNorm;

	Matx31d pttop = mnw + vpts3d[half_h*w+half_w];

	for (k=0;k<nSampleNorm;k++)
	{
		Matx31d pt3d = pttop - k*mnw_step;
		fprintf(file, "%lf;%lf;%lf;%d;%d;%d\n", pt3d(0), pt3d(1), pt3d(2), r, g, b);
	}

	fclose(file);
}

// 20140731, first cluster depth map into regions according to depth increment between neighbors
// then remove small depth regions if their area is below some threshold
void DeepVoid::RemoveSmallDepthRegions_4(const cam_data & camInfo,
									   const Mat & img,
									   const Mat & mDepth,
									   Mat & mScore,
									   double thresh_ang /*= 85*/,
									   int thresh_area/* = 15*/
									   )
{
	int i,j,k;

	int w = mDepth.cols;
	int h = mDepth.rows;

	double thresh_cos = cosd(90-thresh_ang);

	double fx_1 = 1/camInfo.fx;
	double fy_1 = 1/camInfo.fy;
	double cx = camInfo.cx;
	double cy = camInfo.cy;

	Mat mStatus(h, w, CV_8UC1, Scalar(0)); // if value is 0 it is unchecked, if 1 it is checked

	CString strInfo;

	for (i=0;i<h;i++)
	{
		strInfo.Format("evaluate row %04d (remove small depth regions)", i);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		for (j=0;j<w;j++)
		{
			double score = mScore.at<float>(i,j);
			uchar status = mStatus.at<uchar>(i,j);

			if (status==1){continue;}

			if (score<0){mStatus.at<uchar>(i,j)=1;continue;} // this pixel is already a invalid pixel or it's been checked to be a valid one

			// Breadth-first searching and clustering
			// create a queue FIFO (first in first out)
			list<Point2i> queue;
			vector<Point2i> cluster;

			Point2i pt2d;
			pt2d.x = j; pt2d.y = i;

			queue.push_back(pt2d);
			cluster.push_back(pt2d);
			mStatus.at<uchar>(i,j)=1;

			while (queue.size() > 0)
			{
				Point2i pt2d0 = queue.front(); // can not be int & t = queue.front() here, since pop_front() will delete the first element and t will point nowhere if it is a reference to the first element
				queue.pop_front();

				int i0 = pt2d0.y; int j0 = pt2d0.x;

				double d0 = mDepth.at<float>(i0,j0);

				double nimgx0 = (j0-cx)*fx_1;
				double nimgy0 = (i0-cy)*fy_1;

				Matx31d dir0;
				dir0(0) = nimgx0*d0;
				dir0(1) = nimgy0*d0;
				dir0(2) = d0;

				double normd0 = norm(dir0);
				double thresh_cosnormd0= thresh_cos*normd0;

				int l = j0-1; int r = j0+1; int u = i0-1; int b = i0+1;

				// first, check the left pixel if there is one
				if (l>=0 && mScore.at<float>(i0,l)>0 && mStatus.at<uchar>(i0,l)==0)
				{
					double d = mDepth.at<float>(i0,l);
					double nimgx = (l-cx)*fx_1;
					double nimgy = nimgy0;

					Matx31d dir;
					dir(0) = nimgx*d;
					dir(1) = nimgy*d;
					dir(2) = d;

					Matx31d dv = dir-dir0;

					double normdv = norm(dv);

					Matx<double,1,1> cosa = dir0.t() * dv;

					if (fabs(cosa(0))<thresh_cosnormd0*normdv)
					{
						Point2i pt2d_new;
						pt2d_new.x = l; pt2d_new.y = i0;
						queue.push_back(pt2d_new);
						cluster.push_back(pt2d_new);
						mStatus.at<uchar>(i0,l)=1;
					}
				}

				// second, check the right pixel if there is one
				if (r<w && mScore.at<float>(i0,r)>0 && mStatus.at<uchar>(i0,r)==0)
				{
					double d = mDepth.at<float>(i0,r);
					double nimgx = (r-cx)*fx_1;
					double nimgy = nimgy0;

					Matx31d dir;
					dir(0) = nimgx*d;
					dir(1) = nimgy*d;
					dir(2) = d;

					Matx31d dv = dir-dir0;

					double normdv = norm(dv);

					Matx<double,1,1> cosa = dir0.t() * dv;

					if (fabs(cosa(0))<thresh_cosnormd0*normdv)
					{
						Point2i pt2d_new;
						pt2d_new.x = r; pt2d_new.y = i0;
						queue.push_back(pt2d_new);
						cluster.push_back(pt2d_new);
						mStatus.at<uchar>(i0,r)=1;
					}
				}

				// third, check the upper pixel if there is one
				if (u>=0 && mScore.at<float>(u,j0)>0 && mStatus.at<uchar>(u,j0)==0)
				{
					double d = mDepth.at<float>(u,j0);
					double nimgx = nimgx0;
					double nimgy = (u-cy)*fy_1;

					Matx31d dir;
					dir(0) = nimgx*d;
					dir(1) = nimgy*d;
					dir(2) = d;

					Matx31d dv = dir-dir0;

					double normdv = norm(dv);

					Matx<double,1,1> cosa = dir0.t() * dv;

					if (fabs(cosa(0))<thresh_cosnormd0*normdv)
					{
						Point2i pt2d_new;
						pt2d_new.x = j0; pt2d_new.y = u;
						queue.push_back(pt2d_new);
						cluster.push_back(pt2d_new);
						mStatus.at<uchar>(u,j0)=1;
					}
				}

				// last, check the bottom pixel if there is one
				if (b<h && mScore.at<float>(b,j0)>0 && mStatus.at<uchar>(b,j0)==0)
				{
					double d = mDepth.at<float>(b,j0);
					double nimgx = nimgx0;
					double nimgy = (b-cy)*fy_1;

					Matx31d dir;
					dir(0) = nimgx*d;
					dir(1) = nimgy*d;
					dir(2) = d;

					Matx31d dv = dir-dir0;

					double normdv = norm(dv);

					Matx<double,1,1> cosa = dir0.t() * dv;

					if (fabs(cosa(0))<thresh_cosnormd0*normdv)
					{
						Point2i pt2d_new;
						pt2d_new.x = j0; pt2d_new.y = b;
						queue.push_back(pt2d_new);
						cluster.push_back(pt2d_new);
						mStatus.at<uchar>(b,j0)=1;
					}
				}
			}

			if (cluster.size()<thresh_area)
			{
				for (k=0;k<cluster.size();k++)
				{
					Point2i pt2d_tmp = cluster[k];
					mScore.at<float>(pt2d_tmp.y, pt2d_tmp.x) = -1;
				}
			}
		}
	}

	double thresh_ncc = 0.6;
	double maxncc_minncc_1 = 1/(1-thresh_ncc);

	Mat mScore_map(h, w, CV_8UC3);

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			if (mScore.at<float>(i,j)<0)
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = 0;
				mScore_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*(mScore.at<float>(i,j)-thresh_ncc)*maxncc_minncc_1);
				mScore_map.at<Vec3b>(i,j).val[2] = 0;
			}
		}
	}

	strInfo.Format("D:\\all\\score map checked.bmp");
	imwrite(strInfo.GetBuffer(), mScore_map);

	strInfo.Format("D:\\all\\cloud points.txt");
	
	WriteDepthMap(strInfo, camInfo, img, mDepth, mScore);
}

// 20140828
void DeepVoid::RemoveSmallDepthRegions_4(const Matx33d & mK0,		// input:	mK0 reference image
									     const Matx33d & mR0,		// input:	mR0 reference image
									     const Matx31d & mt0,		// input:	mt0 reference image
									     double fx0_1, 				// input:	fx0_1 = 1/fx0
									     double fy0_1, 				// input:	fy0_1 = 1/fy0
									     const Mat & img,
										 int idx_ref,
									     const Mat & mDepth,
										 const Mat & mHx,
										 const Mat & mHy,
									     Mat & mScore,
									     double thresh_ang /*= 85*/,
									     int thresh_area /*= 15*/
									     )
{
	int i,j,k;

	int w = mDepth.cols;
	int h = mDepth.rows;

	double thresh_cos = cosd(90-thresh_ang);

	double cx = mK0(0,2);
	double cy = mK0(1,2);

	Mat mStatus(h, w, CV_8UC1, Scalar(0)); // if value is 0 it is unchecked, if 1 it is checked

	CString strInfo;

	for (i=0;i<h;i++)
	{
		strInfo.Format("evaluate row %04d (remove small depth regions)", i);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		for (j=0;j<w;j++)
		{
			double score = mScore.at<float>(i,j);
			uchar status = mStatus.at<uchar>(i,j);

			if (status==1){continue;}

			if (score<0){mStatus.at<uchar>(i,j)=1;continue;} // this pixel is already a invalid pixel or it's been checked to be a valid one

			// Breadth-first searching and clustering
			// create a queue FIFO (first in first out)
			list<Point2i> queue;
			vector<Point2i> cluster;

			Point2i pt2d;
			pt2d.x = j; pt2d.y = i;

			queue.push_back(pt2d);
			cluster.push_back(pt2d);
			mStatus.at<uchar>(i,j)=1;

			while (queue.size() > 0)
			{
				Point2i pt2d0 = queue.front(); // can not be int & t = queue.front() here, since pop_front() will delete the first element and t will point nowhere if it is a reference to the first element
				queue.pop_front();

				int i0 = pt2d0.y; int j0 = pt2d0.x;

				double d0 = mDepth.at<float>(i0,j0);

				double nimgx0 = (j0-cx)*fx0_1;
				double nimgy0 = (i0-cy)*fy0_1;

				Matx31d dir0;
				dir0(0) = nimgx0*d0;
				dir0(1) = nimgy0*d0;
				dir0(2) = d0;

				double normd0 = norm(dir0);
				double thresh_cosnormd0= thresh_cos*normd0;

				int l = j0-1; int r = j0+1; int u = i0-1; int b = i0+1;

				// first, check the left pixel if there is one
				if (l>=0 && mScore.at<float>(i0,l)>0 && mStatus.at<uchar>(i0,l)==0)
				{
					double d = mDepth.at<float>(i0,l);
					double nimgx = (l-cx)*fx0_1;
					double nimgy = nimgy0;

					Matx31d dir;
					dir(0) = nimgx*d;
					dir(1) = nimgy*d;
					dir(2) = d;

					Matx31d dv = dir-dir0;

					double normdv = norm(dv);

					Matx<double,1,1> cosa = dir0.t() * dv;

					if (fabs(cosa(0))<thresh_cosnormd0*normdv)
					{
						Point2i pt2d_new;
						pt2d_new.x = l; pt2d_new.y = i0;
						queue.push_back(pt2d_new);
						cluster.push_back(pt2d_new);
						mStatus.at<uchar>(i0,l)=1;
					}
				}

				// second, check the right pixel if there is one
				if (r<w && mScore.at<float>(i0,r)>0 && mStatus.at<uchar>(i0,r)==0)
				{
					double d = mDepth.at<float>(i0,r);
					double nimgx = (r-cx)*fx0_1;
					double nimgy = nimgy0;

					Matx31d dir;
					dir(0) = nimgx*d;
					dir(1) = nimgy*d;
					dir(2) = d;

					Matx31d dv = dir-dir0;

					double normdv = norm(dv);

					Matx<double,1,1> cosa = dir0.t() * dv;

					if (fabs(cosa(0))<thresh_cosnormd0*normdv)
					{
						Point2i pt2d_new;
						pt2d_new.x = r; pt2d_new.y = i0;
						queue.push_back(pt2d_new);
						cluster.push_back(pt2d_new);
						mStatus.at<uchar>(i0,r)=1;
					}
				}

				// third, check the upper pixel if there is one
				if (u>=0 && mScore.at<float>(u,j0)>0 && mStatus.at<uchar>(u,j0)==0)
				{
					double d = mDepth.at<float>(u,j0);
					double nimgx = nimgx0;
					double nimgy = (u-cy)*fy0_1;

					Matx31d dir;
					dir(0) = nimgx*d;
					dir(1) = nimgy*d;
					dir(2) = d;

					Matx31d dv = dir-dir0;

					double normdv = norm(dv);

					Matx<double,1,1> cosa = dir0.t() * dv;

					if (fabs(cosa(0))<thresh_cosnormd0*normdv)
					{
						Point2i pt2d_new;
						pt2d_new.x = j0; pt2d_new.y = u;
						queue.push_back(pt2d_new);
						cluster.push_back(pt2d_new);
						mStatus.at<uchar>(u,j0)=1;
					}
				}

				// last, check the bottom pixel if there is one
				if (b<h && mScore.at<float>(b,j0)>0 && mStatus.at<uchar>(b,j0)==0)
				{
					double d = mDepth.at<float>(b,j0);
					double nimgx = nimgx0;
					double nimgy = (b-cy)*fy0_1;

					Matx31d dir;
					dir(0) = nimgx*d;
					dir(1) = nimgy*d;
					dir(2) = d;

					Matx31d dv = dir-dir0;

					double normdv = norm(dv);

					Matx<double,1,1> cosa = dir0.t() * dv;

					if (fabs(cosa(0))<thresh_cosnormd0*normdv)
					{
						Point2i pt2d_new;
						pt2d_new.x = j0; pt2d_new.y = b;
						queue.push_back(pt2d_new);
						cluster.push_back(pt2d_new);
						mStatus.at<uchar>(b,j0)=1;
					}
				}
			}

			if (cluster.size()<thresh_area)
			{
				for (k=0;k<cluster.size();k++)
				{
					Point2i pt2d_tmp = cluster[k];
					mScore.at<float>(pt2d_tmp.y, pt2d_tmp.x) = -1;
				}
			}
		}
	}

	Mat mScore_map(h, w, CV_8UC3);

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			if (mScore.at<float>(i,j)<0)
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = 0;
				mScore_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
				mScore_map.at<Vec3b>(i,j).val[2] = 0;
			}
		}
	}

	strInfo.Format("D:\\all\\score map %02d removed small regions.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mScore_map);

	strInfo.Format("D:\\all\\cloud points %02d removed small regions.txt", idx_ref);
	OutputPointCloud(strInfo,mK0,mR0,mt0,fx0_1,fy0_1,img,mDepth,mHx,mHy,mScore);
}

// 20140913, self-contained version
void DeepVoid::RemoveSmallDepthRegions_4(const Matx33d & mK,			// input:	reference image
									     const Matx33d & mR,			// input:	reference image
									     const Matx31d & mt,			// input:	reference image
									     const Mat & mDepth,
									     Mat & mScore,
									     double thresh_ratio /*= 0.01*/,
									     int thresh_area /*= 15*/
									     )
{
	int i,j,k;

	int w = mDepth.cols;
	int h = mDepth.rows;

	Mat mStatus(h, w, CV_8UC1, Scalar(0)); // if value is 0 it is unchecked, if 1 it is checked

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			double score = mScore.at<float>(i,j);
			uchar status = mStatus.at<uchar>(i,j);

			if (status==1){continue;}

			if (score<0){mStatus.at<uchar>(i,j)=1;continue;} // this pixel is already a invalid pixel or it's been checked to be a valid one

			// Breadth-first searching and clustering
			// create a queue FIFO (first in first out)
			list<Point2i> queue;
			vector<Point2i> cluster;

			Point2i pt2d;
			pt2d.x = j; pt2d.y = i;

			queue.push_back(pt2d);
			cluster.push_back(pt2d);
			mStatus.at<uchar>(i,j)=1;

			while (queue.size() > 0)
			{
				Point2i pt2d0 = queue.front(); // can not be int & t = queue.front() here, since pop_front() will delete the first element and t will point nowhere if it is a reference to the first element
				queue.pop_front();

				int i0 = pt2d0.y; int j0 = pt2d0.x;

				double d0 = mDepth.at<float>(i0,j0);

				int l = j0-1; int r = j0+1; int u = i0-1; int b = i0+1;

				// first, check the left pixel if there is one
				if (l>=0 && mScore.at<float>(i0,l)>0 && mStatus.at<uchar>(i0,l)==0)
				{
					double d = mDepth.at<float>(i0,l);
					
					double val = 0.5*thresh_ratio*(d+d0);

					if (fabs(d-d0)<val)
					{
						Point2i pt2d_new;
						pt2d_new.x = l; pt2d_new.y = i0;
						queue.push_back(pt2d_new);
						cluster.push_back(pt2d_new);
						mStatus.at<uchar>(i0,l)=1;
					}
				}

				// second, check the right pixel if there is one
				if (r<w && mScore.at<float>(i0,r)>0 && mStatus.at<uchar>(i0,r)==0)
				{
					double d = mDepth.at<float>(i0,r);
					
					double val = 0.5*thresh_ratio*(d+d0);

					if (fabs(d-d0)<val)
					{
						Point2i pt2d_new;
						pt2d_new.x = r; pt2d_new.y = i0;
						queue.push_back(pt2d_new);
						cluster.push_back(pt2d_new);
						mStatus.at<uchar>(i0,r)=1;
					}
				}

				// third, check the upper pixel if there is one
				if (u>=0 && mScore.at<float>(u,j0)>0 && mStatus.at<uchar>(u,j0)==0)
				{
					double d = mDepth.at<float>(u,j0);
					
					double val = 0.5*thresh_ratio*(d+d0);

					if (fabs(d-d0)<val)
					{
						Point2i pt2d_new;
						pt2d_new.x = j0; pt2d_new.y = u;
						queue.push_back(pt2d_new);
						cluster.push_back(pt2d_new);
						mStatus.at<uchar>(u,j0)=1;
					}
				}

				// last, check the bottom pixel if there is one
				if (b<h && mScore.at<float>(b,j0)>0 && mStatus.at<uchar>(b,j0)==0)
				{
					double d = mDepth.at<float>(b,j0);
					
					double val = 0.5*thresh_ratio*(d+d0);

					if (fabs(d-d0)<val)
					{
						Point2i pt2d_new;
						pt2d_new.x = j0; pt2d_new.y = b;
						queue.push_back(pt2d_new);
						cluster.push_back(pt2d_new);
						mStatus.at<uchar>(b,j0)=1;
					}
				}
			}

			if (cluster.size()<thresh_area)
			{
				for (k=0;k<cluster.size();k++)
				{
					Point2i pt2d_tmp = cluster[k];
					mScore.at<float>(pt2d_tmp.y, pt2d_tmp.x) = -1;
				}
			}
		}
	}
}

// 20140910 为指定的深度在其周围进行聚类，最后看那些深度能和指定深度聚到一起，也就是看存不存在depth discontinuities
void DeepVoid::Clustering_depth_4(const Mat & mDepth,			// input:	input depth map
								  int x, int y,					// input:	designated depth
								  Mat & mOut,					// output:	uchar matrix, if 1 means similar depth with designated depth, if 0 means not
								  int & nNum,					// output:	number of elements in final cluster
								  double ratio /*= 0.01*/		// input:	the depth difference threshold
								  )
{
	int i,j,k;

	int w = mDepth.cols;
	int h = mDepth.rows;

	Mat mStatus(h, w, CV_8UC1, Scalar(0)); // if value is 0 it is unchecked, if 1 it is checked

	mOut = Mat(h, w, CV_8UC1, Scalar(0));

	// Breadth-first searching and clustering
	// create a queue FIFO (first in first out)
	list<Point2i> queue;
	vector<Point2i> cluster;

	Point2i pt2d;
	pt2d.x = x; pt2d.y = y;

	queue.push_back(pt2d);
	cluster.push_back(pt2d);
	mStatus.at<uchar>(y,x)=1;

	while (queue.size() > 0)
	{
		Point2i pt2d0 = queue.front(); // can not be int & t = queue.front() here, since pop_front() will delete the first element and t will point nowhere if it is a reference to the first element
		queue.pop_front();

		int i0 = pt2d0.y; int j0 = pt2d0.x;

		double d0 = mDepth.at<float>(i0,j0);

		int l = j0-1; int r = j0+1; int u = i0-1; int b = i0+1;

		// first, check the left pixel if there is one
		if (l>=0 && mStatus.at<uchar>(i0,l)==0)
		{
			double d = mDepth.at<float>(i0,l);
			
			double val = 0.5*ratio*(d+d0);

			if (fabs(d-d0)<val)
			{
				Point2i pt2d_new;
				pt2d_new.x = l; pt2d_new.y = i0;
				queue.push_back(pt2d_new);
				cluster.push_back(pt2d_new);
				mStatus.at<uchar>(i0,l)=1;
			}
		}

		// second, check the right pixel if there is one
		if (r<w && mStatus.at<uchar>(i0,r)==0)
		{
			double d = mDepth.at<float>(i0,r);

			double val = 0.5*ratio*(d+d0);

			if (fabs(d-d0)<val)
			{
				Point2i pt2d_new;
				pt2d_new.x = r; pt2d_new.y = i0;
				queue.push_back(pt2d_new);
				cluster.push_back(pt2d_new);
				mStatus.at<uchar>(i0,r)=1;
			}
		}

		// third, check the upper pixel if there is one
		if (u>=0 && mStatus.at<uchar>(u,j0)==0)
		{
			double d = mDepth.at<float>(u,j0);

			double val = 0.5*ratio*(d+d0);

			if (fabs(d-d0)<val)
			{
				Point2i pt2d_new;
				pt2d_new.x = j0; pt2d_new.y = u;
				queue.push_back(pt2d_new);
				cluster.push_back(pt2d_new);
				mStatus.at<uchar>(u,j0)=1;
			}
		}

		// last, check the bottom pixel if there is one
		if (b<h && mStatus.at<uchar>(b,j0)==0)
		{
			double d = mDepth.at<float>(b,j0);

			double val = 0.5*ratio*(d+d0);

			if (fabs(d-d0)<val)
			{
				Point2i pt2d_new;
				pt2d_new.x = j0; pt2d_new.y = b;
				queue.push_back(pt2d_new);
				cluster.push_back(pt2d_new);
				mStatus.at<uchar>(b,j0)=1;
			}
		}
	}

	for (k=0;k<cluster.size();k++)
	{
		Point2i pt2d_tmp = cluster[k];
		mOut.at<uchar>(pt2d_tmp.y, pt2d_tmp.x) = 1;
	}

	nNum = cluster.size();
}

// 20140910 为指定的深度在其周围进行聚类，最后看那些深度能和指定深度聚到一起，也就是看存不存在depth discontinuities
void DeepVoid::Clustering_depth_8(const Mat & mDepth,		// input:	input depth map
								  int x, int y,				// input:	designated depth
								  Mat & mOut,				// output:	uchar matrix, if 1 means similar depth with designated depth, if 0 means not
								  int & nNum,				// output:	number of elements in final cluster
								  double ratio /*= 0.01*/	// input:	the depth difference threshold
								  )
{
	int i,j,k,ii,jj;

	int w = mDepth.cols;
	int h = mDepth.rows;

	Mat mStatus(h, w, CV_8UC1, Scalar(0)); // if value is 0 it is unchecked, if 1 it is checked

	mOut = Mat(h, w, CV_8UC1, Scalar(0));

	// Breadth-first searching and clustering
	// create a queue FIFO (first in first out)
	list<Point2i> queue;
	vector<Point2i> cluster;

	Point2i pt2d;
	pt2d.x = x; pt2d.y = y;

	queue.push_back(pt2d);
	cluster.push_back(pt2d);
	mStatus.at<uchar>(y,x)=1;

	while (queue.size() > 0)
	{
		Point2i pt2d0 = queue.front(); // can not be int & t = queue.front() here, since pop_front() will delete the first element and t will point nowhere if it is a reference to the first element
		queue.pop_front();

		int i0 = pt2d0.y; int j0 = pt2d0.x;

		double d0 = mDepth.at<float>(i0,j0);

		for (ii=-1;ii<=1;ii++)
		{
			for (jj=-1;jj<=1;jj++)
			{
				if (ii==0&&jj==0){continue;}

				int i_n = i0+ii;
				int j_n = j0+jj;

				if (i_n<0 || j_n<0 || i_n>=h || j_n>=w || mStatus.at<uchar>(i_n,j_n)==1){continue;}

				double d = mDepth.at<float>(i_n,j_n);
				
				double val = 2*fabs(d-d0)/(d+d0);

				if (val<ratio)
				{
					Point2i pt2d_new;
					pt2d_new.x = j_n; pt2d_new.y = i_n;
					queue.push_back(pt2d_new);
					cluster.push_back(pt2d_new);
					mStatus.at<uchar>(i_n,j_n)=1;
				}
			}
		}
	}

	for (k=0;k<cluster.size();k++)
	{
		Point2i pt2d_tmp = cluster[k];
		mOut.at<uchar>(pt2d_tmp.y, pt2d_tmp.x) = 1;
	}

	nNum = cluster.size();
}

// 20140911 为指定的深度图进行聚类标记
void DeepVoid::Labelling_depth_4(const Mat & mDepth,		// input:	input depth map
							     Mat & mLabel,				// output:	uchar matrix, if 1 means similar depth with designated depth, if 0 means not
								 int idx_ref,
							     double ratio/* = 0.01*/	// input:	the depth difference threshold
							     )
{
	int i,j,k;

	int w = mDepth.cols;
	int h = mDepth.rows;

	Mat mStatus(h, w, CV_8UC1, Scalar(0)); // if value is 0 it is unchecked, if 1 it is checked
	mLabel = Mat(h, w, CV_32SC1, Scalar(0)); // a label matrix is all _int32 type, which ranges from C2,147,483,648 to 2,147,483,647
	Mat mLabel_map(h, w, CV_8UC3); // visualize this label map by random colors

	CString strInfo;

	int idx_label = 0;

	RNG rng(12345);

	for (i=0;i<h;i++)
	{
		strInfo.Format("labelling row %04d of depth map", i);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		for (j=0;j<w;j++)
		{
			uchar status = mStatus.at<uchar>(i,j);

			if (status==1){continue;}

			// Breadth-first searching and clustering
			// create a queue FIFO (first in first out)
			list<Point2i> queue;
			vector<Point2i> cluster;

			Point2i pt2d;
			pt2d.x = j; pt2d.y = i;

			queue.push_back(pt2d);
			cluster.push_back(pt2d);
			mStatus.at<uchar>(i,j)=1;

			while (queue.size() > 0)
			{
				Point2i pt2d0 = queue.front(); // can not be int & t = queue.front() here, since pop_front() will delete the first element and t will point nowhere if it is a reference to the first element
				queue.pop_front();

				int i0 = pt2d0.y; int j0 = pt2d0.x;

				double d0 = mDepth.at<float>(i0,j0);

				int l = j0-1; int r = j0+1; int u = i0-1; int b = i0+1;

				// first, check the left pixel if there is one
				if (l>=0 && mStatus.at<uchar>(i0,l)==0)
				{
					double d = mDepth.at<float>(i0,l);
					
					double val = 2*fabs(d-d0)/(d+d0);

					if (val<ratio)
					{
						Point2i pt2d_new;
						pt2d_new.x = l; pt2d_new.y = i0;
						queue.push_back(pt2d_new);
						cluster.push_back(pt2d_new);
						mStatus.at<uchar>(i0,l)=1;
					}
				}

				// second, check the right pixel if there is one
				if (r<w && mStatus.at<uchar>(i0,r)==0)
				{
					double d = mDepth.at<float>(i0,r);
					
					double val = 2*fabs(d-d0)/(d+d0);

					if (val<ratio)
					{
						Point2i pt2d_new;
						pt2d_new.x = r; pt2d_new.y = i0;
						queue.push_back(pt2d_new);
						cluster.push_back(pt2d_new);
						mStatus.at<uchar>(i0,r)=1;
					}
				}

				// third, check the upper pixel if there is one
				if (u>=0 && mStatus.at<uchar>(u,j0)==0)
				{
					double d = mDepth.at<float>(u,j0);

					double val = 2*fabs(d-d0)/(d+d0);

					if (val<ratio)
					{
						Point2i pt2d_new;
						pt2d_new.x = j0; pt2d_new.y = u;
						queue.push_back(pt2d_new);
						cluster.push_back(pt2d_new);
						mStatus.at<uchar>(u,j0)=1;
					}
				}

				// last, check the bottom pixel if there is one
				if (b<h && mStatus.at<uchar>(b,j0)==0)
				{
					double d = mDepth.at<float>(b,j0);

					double val = 2*fabs(d-d0)/(d+d0);

					if (val<ratio)
					{
						Point2i pt2d_new;
						pt2d_new.x = j0; pt2d_new.y = b;
						queue.push_back(pt2d_new);
						cluster.push_back(pt2d_new);
						mStatus.at<uchar>(b,j0)=1;
					}
				}
			}

			int r = rng.uniform(0,255);
			int g = rng.uniform(0,255);
			int b = rng.uniform(0,255);
			
			for (k=0;k<cluster.size();k++)
			{
				Point2i pt2d_tmp = cluster[k];
				mLabel.at<int>(pt2d_tmp.y, pt2d_tmp.x) = idx_label;

				mLabel_map.at<Vec3b>(pt2d_tmp.y, pt2d_tmp.x).val[0] = b;
				mLabel_map.at<Vec3b>(pt2d_tmp.y, pt2d_tmp.x).val[1] = g;
				mLabel_map.at<Vec3b>(pt2d_tmp.y, pt2d_tmp.x).val[2] = r;
			}

			++idx_label;
		}
	}

	strInfo.Format("D:\\all\\depth label map %02d.txt", idx_ref);

	FILE * file = fopen(strInfo, "w");
	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			fprintf(file, "%d	", mLabel.at<int>(i,j));
		}
		fprintf(file, "\n");
	}
	fclose(file);

	strInfo.Format("D:\\all\\depth label map %02d.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mLabel_map);
}

// 20140801, first cluster depth map into regions according to depth increment between 8 neighbors
// then remove small depth regions if their area is below some threshold
void DeepVoid::RemoveSmallDepthRegions_8(const cam_data & camInfo,
										 const Mat & img,
										 const Mat & mDepth,
										 Mat & mScore,
										 double thresh_ang /*= 85*/,
										 int thresh_area/* = 15*/
										 )
{
	int i,j,k,ii,jj;

	int w = mDepth.cols;
	int h = mDepth.rows;

	double thresh_cos = cosd(90-thresh_ang);

	double fx_1 = 1/camInfo.fx;
	double fy_1 = 1/camInfo.fy;
	double cx = camInfo.cx;
	double cy = camInfo.cy;

	Mat mStatus(h, w, CV_8UC1, Scalar(0)); // if value is 0 it is unchecked, if 1 it is checked

	CString strInfo;

	for (i=0;i<h;i++)
	{
		strInfo.Format("evaluate row %04d (remove small depth regions)", i);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		for (j=0;j<w;j++)
		{
			double score = mScore.at<float>(i,j);
			uchar status = mStatus.at<uchar>(i,j);

			if (status==1){continue;}

			if (score<0){mStatus.at<uchar>(i,j)=1;continue;} // this pixel is already a invalid pixel or it's been checked to be a valid one

			// Breadth-first searching and clustering
			// create a queue FIFO (first in first out)
			list<Point2i> queue;
			vector<Point2i> cluster;

			Point2i pt2d;
			pt2d.x = j; pt2d.y = i;

			queue.push_back(pt2d);
			cluster.push_back(pt2d);
			mStatus.at<uchar>(i,j)=1;

			while (queue.size() > 0)
			{
				Point2i pt2d0 = queue.front(); // can not be int & t = queue.front() here, since pop_front() will delete the first element and t will point nowhere if it is a reference to the first element
				queue.pop_front();

				int i0 = pt2d0.y; int j0 = pt2d0.x;

				double d0 = mDepth.at<float>(i0,j0);

				double nimgx0 = (j0-cx)*fx_1;
				double nimgy0 = (i0-cy)*fy_1;

				Matx31d dir0;
				dir0(0) = nimgx0*d0;
				dir0(1) = nimgy0*d0;
				dir0(2) = d0;

				double normd0 = norm(dir0);
				double thresh_cosnormd0= thresh_cos*normd0;

				for (ii=-1;ii<=1;ii++)
				{
					for (jj=-1;jj<=1;jj++)
					{
						if (ii==0&&jj==0){continue;}

						int i_n = i0+ii;
						int j_n = j0+jj;

						if (i_n<0 || j_n<0 || i_n>=h || j_n>=w || mScore.at<float>(i_n,j_n)<0 || mStatus.at<uchar>(i_n,j_n)==1){continue;}

						double d = mDepth.at<float>(i_n,j_n);
						double nimgx = (j_n-cx)*fx_1;
						double nimgy = (i_n-cy)*fy_1;

						Matx31d dir;
						dir(0) = nimgx*d;
						dir(1) = nimgy*d;
						dir(2) = d;

						Matx31d dv = dir-dir0;

						double normdv = norm(dv);

						Matx<double,1,1> cosa = dir0.t() * dv;

						if (fabs(cosa(0))<thresh_cosnormd0*normdv)
						{
							Point2i pt2d_new;
							pt2d_new.x = j_n; pt2d_new.y = i_n;
							queue.push_back(pt2d_new);
							cluster.push_back(pt2d_new);
							mStatus.at<uchar>(i_n,j_n)=1;
						}
					}
				}
			}

			if (cluster.size()<thresh_area)
			{
				for (k=0;k<cluster.size();k++)
				{
					Point2i pt2d_tmp = cluster[k];
					mScore.at<float>(pt2d_tmp.y, pt2d_tmp.x) = -1;
				}
			}
		}
	}

	double thresh_ncc = 0.6;
	double maxncc_minncc_1 = 1/(1-thresh_ncc);

	Mat mScore_map(h, w, CV_8UC3);

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			if (mScore.at<float>(i,j)<0)
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = 0;
				mScore_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*(mScore.at<float>(i,j)-thresh_ncc)*maxncc_minncc_1);
				mScore_map.at<Vec3b>(i,j).val[2] = 0;
			}
		}
	}

	strInfo.Format("D:\\all\\score map checked.bmp");
	imwrite(strInfo.GetBuffer(), mScore_map);

	strInfo.Format("D:\\all\\cloud points.txt");

	WriteDepthMap(strInfo, camInfo, img, mDepth, mScore);
}

void DeepVoid::ExtractMostLikelyDepth_NCC_WTA(const cam_data & cam0,
								 const Mat & img0,
								 const vector<Mat> & vDepths,
							     const vector<Mat> & vHxs,
							     const vector<Mat> & vHys,
							     const vector<Mat> & vScores
							     )
{
	int i,j,k;

	int nCam = vDepths.size();

	int w = vDepths[0].cols;
	int h = vDepths[0].rows;

	Mat mDepth(h, w, CV_32FC1), mHx(h, w, CV_32FC1), mHy(h, w, CV_32FC1), mScore(h, w, CV_32FC1);

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			vector<double> vss;
			for (k=0;k<nCam;k++)
			{
				double s = vScores[k].at<float>(i,j);
				vss.push_back(s);
			}

			vector <double>::iterator iterDouble = max_element(vss.begin(), vss.end());
			double max_score = *iterDouble;
			int idx_max_score = iterDouble - vss.begin();

			mDepth.at<float>(i,j) = vDepths[idx_max_score].at<float>(i,j);
			mHx.at<float>(i,j) = vHxs[idx_max_score].at<float>(i,j);
			mHy.at<float>(i,j) = vHys[idx_max_score].at<float>(i,j);
			mScore.at<float>(i,j) = max_score;
		}
	}

	Mat mDepth_map, mHx_map, mHy_map, mScore_map(h, w, CV_8UC3);

	double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

	minMaxIdx(mDepth, &min_depth, &max_depth);
	minMaxIdx(mHx, &min_incre_x, &max_incre_x);
	minMaxIdx(mHy, &min_incre_y, &max_incre_y);

	mDepth.convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
	mHx.convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
	mHy.convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			if (mScore.at<float>(i,j)<0)
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = 0;
				mScore_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
				mScore_map.at<Vec3b>(i,j).val[2] = 0;
			}
		}
	}

	CString strInfo;

	strInfo.Format("D:\\all\\depth map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mDepth_map);
	strInfo.Format("D:\\all\\hx map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mHx_map);
	strInfo.Format("D:\\all\\hy map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mHy_map);
	strInfo.Format("D:\\all\\score map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mScore_map);

	Mat mNormColor;
	GetNormColorField(cam0, mDepth, mHx, mHy, mNormColor);
	strInfo.Format("D:\\all\\normcolor map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mNormColor);

	strInfo.Format("D:\\all\\cloud points extracted.txt");
	OutputPointCloud(strInfo,cam0,img0,mDepth,mHx,mHy,mScore);
}

void DeepVoid::ExtractMostLikelyDepth_DP(const cam_data & cam0,			// input:	EO and IO of reference image
									     const Mat & img0,				// input:	reference image
									     const vector<Mat> & vDepths,	// input:	all depth map relative to reference wrt each support image
									     const vector<Mat> & vHxs,		// input:	all hx map relative to reference wrt each support image
									     const vector<Mat> & vHys,		// input:	all hy map relative to reference wrt each support image
									     const vector<Mat> & vScores,	// input:	all score map relative to reference wrt each support image
									     Mat & mSel						// output:	selected best support image index for each pixel who generates the most likely depth with reference image
									     )
{
	int i,j,k;

	int nCam = vDepths.size();

	int w = img0.cols;
	int h = img0.rows;

	vector<Mat> C_dir, S_dirs;

	for (i=0;i<nCam;i++)
	{
		Mat mtmp1(h, w, CV_32FC1, Scalar(0)), mtmp2(h, w, CV_32FC1, Scalar(0));
		C_dir.push_back(mtmp1);
		S_dirs.push_back(mtmp2); // cannot push the same Mat into two vectors, otherwise C_dir[k] will have the same memory location as S_dirs[k]
	}

	vector<double> Lr_1(nCam), Lr(nCam);


	/*------------ 01 direction --------------------------------------------------------------------------*/
	// dir = [1, 0] i.e. along positive direction of x-axis or the 0 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 01 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			C_dir[k].at<float>(i,0) = 0;
		}
	}

	for (j=1;j<w;j++)
	{
		for (i=0;i<h;i++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i,j-1);
			}
			DP_step(j-1, i, j, i, vDepths, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 02 direction --------------------------------------------------------------------------*/
	// dir = [-1, 0] i.e. along negative direction of x-axis or the 180 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 02 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			C_dir[k].at<float>(i,w-1) = 0;
		}
	}

	for (j=w-2;j>-1;j--)
	{
		for (i=0;i<h;i++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i,j+1);
			}
			DP_step(j+1, i, j, i, vDepths, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 03 direction --------------------------------------------------------------------------*/
	// dir = [0, 1] i.e. along positive direction of y-axis or the -90 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 03 starts");
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=0;j<w;j++)
		{
			C_dir[k].at<float>(0,j) = 0;
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j);
			}
			DP_step(j, i-1, j, i, vDepths, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 04 direction --------------------------------------------------------------------------*/
	// dir = [0, -1] i.e. along negative direction of y-axis or the 90 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 04 starts");
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=0;j<w;j++)
		{
			C_dir[k].at<float>(h-1,j) = 0;
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=0;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j);
			}
			DP_step(j, i+1, j, i, vDepths, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}
	
	/*------------ 05 direction --------------------------------------------------------------------------*/
	// dir = [1, 1] i.e. along the -45 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 05 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			C_dir[k].at<float>(i,0) = 0;
		}
	}
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=1;j<w;j++)
		{
			C_dir[k].at<float>(0,j) = 0;
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=1;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j-1);
			}
			DP_step(j-1, i-1, j, i, vDepths, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 06 direction --------------------------------------------------------------------------*/
	// dir = [-1, -1] i.e. along the 135 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 06 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			C_dir[k].at<float>(i,w-1) = 0;
		}
	}
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=0;j<w-1;j++)
		{
			C_dir[k].at<float>(h-1,j) = 0;
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=w-2;j>-1;j--)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j+1);
			}
			DP_step(j+1, i+1, j, i, vDepths, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 07 direction --------------------------------------------------------------------------*/
	// dir = [1, -1] i.e. along the 45 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 07 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			C_dir[k].at<float>(i,0) = 0;
		}
	}
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=1;j<w;j++)
		{
			C_dir[k].at<float>(h-1,j) = 0;
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=1;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j-1);
			}
			DP_step(j-1, i+1, j, i, vDepths, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 08 direction --------------------------------------------------------------------------*/
	// dir = [-1, 1] i.e. along the -135 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 08 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			C_dir[k].at<float>(i,w-1) = 0;
		}
	}
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=0;j<w-1;j++)
		{
			C_dir[k].at<float>(0,j) = 0;
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=w-2;j>-1;j--)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j+1);
			}
			DP_step(j+1, i-1, j, i, vDepths, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	//////////////////////////////////////////////////////////////////////////
	// get the 
	Mat mDepth(h, w, CV_32FC1), mHx(h, w, CV_32FC1), mHy(h, w, CV_32FC1), mScore(h, w, CV_32FC1), mSel_map(h, w, CV_8UC3);

	mSel = Mat(h, w, CV_8UC1);

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			vector<double> vss;
			for (k=0;k<nCam;k++)
			{
				double s = S_dirs[k].at<float>(i,j);
				vss.push_back(s);
			}

			vector <double>::iterator iterDouble = min_element(vss.begin(), vss.end());
			int idx_min_score = iterDouble - vss.begin();

			mDepth.at<float>(i,j) = vDepths[idx_min_score].at<float>(i,j);
			mHx.at<float>(i,j) = vHxs[idx_min_score].at<float>(i,j);
			mHy.at<float>(i,j) = vHys[idx_min_score].at<float>(i,j);
			mScore.at<float>(i,j) = vScores[idx_min_score].at<float>(i,j);
			mSel.at<uchar>(i,j) = (uchar)idx_min_score;

			if (idx_min_score==0)
			{
				mSel_map.at<Vec3b>(i,j).val[0] = 255;
				mSel_map.at<Vec3b>(i,j).val[1] = 0;
				mSel_map.at<Vec3b>(i,j).val[2] = 0;
			}
			else if (idx_min_score==1)
			{
				mSel_map.at<Vec3b>(i,j).val[0] = 0;
				mSel_map.at<Vec3b>(i,j).val[1] = 255;
				mSel_map.at<Vec3b>(i,j).val[2] = 0;
			}
			else if (idx_min_score==2)
			{
				mSel_map.at<Vec3b>(i,j).val[0] = 255;
				mSel_map.at<Vec3b>(i,j).val[1] = 255;
				mSel_map.at<Vec3b>(i,j).val[2] = 0;
			}
			else
			{
				mSel_map.at<Vec3b>(i,j).val[0] = 0;
				mSel_map.at<Vec3b>(i,j).val[1] = 0;
				mSel_map.at<Vec3b>(i,j).val[2] = 255;
			}
		}
	}

	Mat mDepth_map, mHx_map, mHy_map, mScore_map(h, w, CV_8UC3);

	double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

	minMaxIdx(mDepth, &min_depth, &max_depth);
	minMaxIdx(mHx, &min_incre_x, &max_incre_x);
	minMaxIdx(mHy, &min_incre_y, &max_incre_y);

	mDepth.convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
	mHx.convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
	mHy.convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			if (mScore.at<float>(i,j)<0)
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = 0;
				mScore_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
				mScore_map.at<Vec3b>(i,j).val[2] = 0;
			}
		}
	}

	CString strInfo;

	strInfo.Format("D:\\all\\depth map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mDepth_map);
	strInfo.Format("D:\\all\\hx map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mHx_map);
	strInfo.Format("D:\\all\\hy map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mHy_map);
	strInfo.Format("D:\\all\\score map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mScore_map);
	strInfo.Format("D:\\all\\best visible map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mSel_map);

	Mat mNormColor;
	GetNormColorField(cam0, mDepth, mHx, mHy, mNormColor);
	strInfo.Format("D:\\all\\normcolor map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mNormColor);

	strInfo.Format("D:\\all\\cloud points extracted.txt");
	OutputPointCloud(strInfo,cam0,img0,mDepth,mHx,mHy,mScore);
}

void DeepVoid::ExtractMostLikelyDepth_DP(const Matx33d & mK0,			// input:	mK0 reference image
									     const Matx33d & mR0,			// input:	mR0 reference image
									     const Matx31d & mt0,			// input:	mt0 reference image
									     double fx0_1, 					// input:	fx0_1 = 1/fx0
									     double fy0_1, 					// input:	fy0_1 = 1/fy0
									     const Mat & img0,				// input:	reference image
										 int idx_ref,
									     const vector<Mat> & vDepths,	// input:	all depth map relative to reference wrt each support image
									     const vector<Mat> & vHxs,		// input:	all hx map relative to reference wrt each support image
									     const vector<Mat> & vHys,		// input:	all hy map relative to reference wrt each support image
									     const vector<Mat> & vScores,	// input:	all score map relative to reference wrt each support image
									     Mat & mSel						// output:	selected best support image index for each pixel who generates the most likely depth with reference image
									     )
{
	int i,j,k;

	int nCam = vDepths.size();

	int w = img0.cols;
	int h = img0.rows;

	vector<Mat> C_dir, S_dirs;

	for (i=0;i<nCam;i++)
	{
		Mat mtmp1(h, w, CV_32FC1, Scalar(0)), mtmp2(h, w, CV_32FC1, Scalar(0));
		C_dir.push_back(mtmp1);
		S_dirs.push_back(mtmp2); // cannot push the same Mat into two vectors, otherwise C_dir[k] will have the same memory location as S_dirs[k]
	}

	vector<double> Lr_1(nCam), Lr(nCam);


	/*------------ 01 direction --------------------------------------------------------------------------*/
	// dir = [1, 0] i.e. along positive direction of x-axis or the 0 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 01 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			C_dir[k].at<float>(i,0) = 0;
		}
	}

	for (j=1;j<w;j++)
	{
		for (i=0;i<h;i++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i,j-1);
			}
			DP_step(j-1, i, j, i, vDepths, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 02 direction --------------------------------------------------------------------------*/
	// dir = [-1, 0] i.e. along negative direction of x-axis or the 180 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 02 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			C_dir[k].at<float>(i,w-1) = 0;
		}
	}

	for (j=w-2;j>-1;j--)
	{
		for (i=0;i<h;i++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i,j+1);
			}
			DP_step(j+1, i, j, i, vDepths, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 03 direction --------------------------------------------------------------------------*/
	// dir = [0, 1] i.e. along positive direction of y-axis or the -90 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 03 starts");
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=0;j<w;j++)
		{
			C_dir[k].at<float>(0,j) = 0;
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j);
			}
			DP_step(j, i-1, j, i, vDepths, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 04 direction --------------------------------------------------------------------------*/
	// dir = [0, -1] i.e. along negative direction of y-axis or the 90 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 04 starts");
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=0;j<w;j++)
		{
			C_dir[k].at<float>(h-1,j) = 0;
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=0;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j);
			}
			DP_step(j, i+1, j, i, vDepths, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 05 direction --------------------------------------------------------------------------*/
	// dir = [1, 1] i.e. along the -45 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 05 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			C_dir[k].at<float>(i,0) = 0;
		}
	}
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=1;j<w;j++)
		{
			C_dir[k].at<float>(0,j) = 0;
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=1;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j-1);
			}
			DP_step(j-1, i-1, j, i, vDepths, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 06 direction --------------------------------------------------------------------------*/
	// dir = [-1, -1] i.e. along the 135 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 06 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			C_dir[k].at<float>(i,w-1) = 0;
		}
	}
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=0;j<w-1;j++)
		{
			C_dir[k].at<float>(h-1,j) = 0;
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=w-2;j>-1;j--)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j+1);
			}
			DP_step(j+1, i+1, j, i, vDepths, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 07 direction --------------------------------------------------------------------------*/
	// dir = [1, -1] i.e. along the 45 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 07 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			C_dir[k].at<float>(i,0) = 0;
		}
	}
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=1;j<w;j++)
		{
			C_dir[k].at<float>(h-1,j) = 0;
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=1;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j-1);
			}
			DP_step(j-1, i+1, j, i, vDepths, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 08 direction --------------------------------------------------------------------------*/
	// dir = [-1, 1] i.e. along the -135 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 08 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			C_dir[k].at<float>(i,w-1) = 0;
		}
	}
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=0;j<w-1;j++)
		{
			C_dir[k].at<float>(0,j) = 0;
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=w-2;j>-1;j--)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j+1);
			}
			DP_step(j+1, i-1, j, i, vDepths, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	//////////////////////////////////////////////////////////////////////////
	// get the 
	Mat mDepth(h, w, CV_32FC1), mHx(h, w, CV_32FC1), mHy(h, w, CV_32FC1), mScore(h, w, CV_32FC1), mSel_map(h, w, CV_8UC3);

	mSel = Mat(h, w, CV_8UC1);

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			vector<double> vss;
			for (k=0;k<nCam;k++)
			{
				double s = S_dirs[k].at<float>(i,j);
				vss.push_back(s);
			}

			vector <double>::iterator iterDouble = min_element(vss.begin(), vss.end());
			int idx_min_score = iterDouble - vss.begin();

			mDepth.at<float>(i,j) = vDepths[idx_min_score].at<float>(i,j);
			mHx.at<float>(i,j) = vHxs[idx_min_score].at<float>(i,j);
			mHy.at<float>(i,j) = vHys[idx_min_score].at<float>(i,j);
			mScore.at<float>(i,j) = vScores[idx_min_score].at<float>(i,j);
			mSel.at<uchar>(i,j) = (uchar)idx_min_score;

			if (idx_min_score==0)
			{
				mSel_map.at<Vec3b>(i,j).val[0] = 255;
				mSel_map.at<Vec3b>(i,j).val[1] = 0;
				mSel_map.at<Vec3b>(i,j).val[2] = 0;
			}
			else if (idx_min_score==1)
			{
				mSel_map.at<Vec3b>(i,j).val[0] = 0;
				mSel_map.at<Vec3b>(i,j).val[1] = 255;
				mSel_map.at<Vec3b>(i,j).val[2] = 0;
			}
			else if (idx_min_score==2)
			{
				mSel_map.at<Vec3b>(i,j).val[0] = 255;
				mSel_map.at<Vec3b>(i,j).val[1] = 255;
				mSel_map.at<Vec3b>(i,j).val[2] = 0;
			}
			else
			{
				mSel_map.at<Vec3b>(i,j).val[0] = 0;
				mSel_map.at<Vec3b>(i,j).val[1] = 0;
				mSel_map.at<Vec3b>(i,j).val[2] = 255;
			}
		}
	}

	Mat mDepth_map, mHx_map, mHy_map, mScore_map(h, w, CV_8UC3);

	double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

	minMaxIdx(mDepth, &min_depth, &max_depth);
	minMaxIdx(mHx, &min_incre_x, &max_incre_x);
	minMaxIdx(mHy, &min_incre_y, &max_incre_y);

	mDepth.convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
	mHx.convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
	mHy.convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			if (mScore.at<float>(i,j)<0)
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = 0;
				mScore_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
				mScore_map.at<Vec3b>(i,j).val[2] = 0;
			}
		}
	}

	CString strInfo;

	strInfo.Format("D:\\all\\depth map %02d extracted.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mDepth_map);
	strInfo.Format("D:\\all\\hx map %02d extracted.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mHx_map);
	strInfo.Format("D:\\all\\hy map %02d extracted.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mHy_map);
	strInfo.Format("D:\\all\\score map %02d extracted.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mScore_map);
	strInfo.Format("D:\\all\\best visible map %02d extracted.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mSel_map);

	Mat mNormColor;
	GetNormColorField(mK0,mR0,mt0,fx0_1,fy0_1,mDepth,mHx,mHy,mNormColor);
	strInfo.Format("D:\\all\\normcolor map %02d extracted.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mNormColor);

	strInfo.Format("D:\\all\\cloud points %02d extracted.txt", idx_ref);
	OutputPointCloud(strInfo,mK0,mR0,mt0,fx0_1,fy0_1,img0,mDepth,mHx,mHy,mScore);
}

void DeepVoid::Extract_MRF_d_DP_withInvalids(const cam_data & cam0,			// input:	EO and IO of reference image
											 const Mat & img0,				// input:	reference image
											 const vector<Mat> & vDepths,	// input:	all depth map relative to reference wrt each support image
											 const vector<Mat> & vHxs,		// input:	all hx map relative to reference wrt each support image
											 const vector<Mat> & vHys,		// input:	all hy map relative to reference wrt each support image
											 const vector<Mat> & vScores,	// input:	all score map relative to reference wrt each support image
											 Mat & mSel						// output:	selected best support image index for each pixel who generates the most likely depth with reference image
											 )
{
	int i,j,k;

	int nCam = vDepths.size();

	int w = img0.cols;
	int h = img0.rows;

	vector<Mat> C_dir, S_dirs;

	for (i=0;i<nCam;i++)
	{
		Mat mtmp1(h, w, CV_32FC1, Scalar(0)), mtmp2(h, w, CV_32FC1, Scalar(0));
		C_dir.push_back(mtmp1);
		S_dirs.push_back(mtmp2); // cannot push the same Mat into two vectors, otherwise C_dir[k] will have the same memory location as S_dirs[k]
	}

	vector<double> Lr_1(nCam), Lr(nCam);


	/*------------ 01 direction --------------------------------------------------------------------------*/
	// dir = [1, 0] i.e. along positive direction of x-axis or the 0 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 01 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,0);
			if (score<0)
			{
				C_dir[k].at<float>(i,0) = -1;
			}
			else
			{
				C_dir[k].at<float>(i,0) = 0;
			}
		}
	}

	for (j=1;j<w;j++)
	{
		for (i=0;i<h;i++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i,j-1);
			}
			DP_step_withInvalids(j-1, i, j, i, vDepths, vScores, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 02 direction --------------------------------------------------------------------------*/
	// dir = [-1, 0] i.e. along negative direction of x-axis or the 180 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 02 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,w-1);
			if (score<0)
			{
				C_dir[k].at<float>(i,w-1) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,w-1) = 0;
			}
		}
	}

	for (j=w-2;j>-1;j--)
	{
		for (i=0;i<h;i++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i,j+1);
			}
			DP_step_withInvalids(j+1, i, j, i, vDepths, vScores, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 03 direction --------------------------------------------------------------------------*/
	// dir = [0, 1] i.e. along positive direction of y-axis or the -90 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 03 starts");
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=0;j<w;j++)
		{
			double score = vScores[k].at<float>(0,j);
			if (score<0)
			{
				C_dir[k].at<float>(0,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(0,j) = 0;
			}
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j);
			}
			DP_step_withInvalids(j, i-1, j, i, vDepths, vScores, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 04 direction --------------------------------------------------------------------------*/
	// dir = [0, -1] i.e. along negative direction of y-axis or the 90 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 04 starts");
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=0;j<w;j++)
		{
			double score = vScores[k].at<float>(h-1,j);
			if (score<0)
			{
				C_dir[k].at<float>(h-1,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(h-1,j) = 0;
			}
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=0;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j);
			}
			DP_step_withInvalids(j, i+1, j, i, vDepths, vScores, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 05 direction --------------------------------------------------------------------------*/
	// dir = [1, 1] i.e. along the -45 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 05 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,0);
			if (score<0)
			{
				C_dir[k].at<float>(i,0) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,0) = 0;
			}
		}
	}
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=1;j<w;j++)
		{
			double score = vScores[k].at<float>(0,j);
			if (score<0)
			{
				C_dir[k].at<float>(0,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(0,j) = 0;
			}
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=1;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j-1);
			}
			DP_step_withInvalids(j-1, i-1, j, i, vDepths, vScores, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 06 direction --------------------------------------------------------------------------*/
	// dir = [-1, -1] i.e. along the 135 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 06 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,w-1);
			if (score<0)
			{
				C_dir[k].at<float>(i,w-1) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,w-1) = 0;
			}
		}
	}
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=0;j<w-1;j++)
		{
			double score = vScores[k].at<float>(h-1,j);
			if (score<0)
			{
				C_dir[k].at<float>(h-1,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(h-1,j) = 0;
			}	
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=w-2;j>-1;j--)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j+1);
			}
			DP_step_withInvalids(j+1, i+1, j, i, vDepths, vScores, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 07 direction --------------------------------------------------------------------------*/
	// dir = [1, -1] i.e. along the 45 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 07 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,0);
			if (score<0)
			{
				C_dir[k].at<float>(i,0) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,0) = 0;
			}
		}
	}
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=1;j<w;j++)
		{
			double score = vScores[k].at<float>(h-1,j);
			if (score<0)
			{
				C_dir[k].at<float>(h-1,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(h-1,j) = 0;
			}
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=1;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j-1);
			}
			DP_step_withInvalids(j-1, i+1, j, i, vDepths, vScores, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 08 direction --------------------------------------------------------------------------*/
	// dir = [-1, 1] i.e. along the -135 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 08 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,w-1);
			if (score<0)
			{
				C_dir[k].at<float>(i,w-1) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,w-1) = 0;
			}
		}
	}
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=0;j<w-1;j++)
		{
			double score = vScores[k].at<float>(0,j);
			if (score<0)
			{
				C_dir[k].at<float>(0,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(0,j) = 0;
			}
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=w-2;j>-1;j--)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j+1);
			}
			DP_step_withInvalids(j+1, i-1, j, i, vDepths, vScores, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	//////////////////////////////////////////////////////////////////////////
	// get the 
	Mat mDepth(h, w, CV_32FC1), mHx(h, w, CV_32FC1), mHy(h, w, CV_32FC1), mScore(h, w, CV_32FC1), mSel_map(h, w, CV_8UC3);

	mSel = Mat(h, w, CV_8UC1);

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			vector<double> vss;
			vector<int> vss_idx;
			for (k=0;k<nCam;k++)
			{
				double s = S_dirs[k].at<float>(i,j);
				if (s>0)
				{
					vss.push_back(s);
					vss_idx.push_back(k);
				}
			}

			if (vss.size()==0)
			{
				mDepth.at<float>(i,j) = vDepths[0].at<float>(i,j);
				mHx.at<float>(i,j) = vHxs[0].at<float>(i,j);
				mHy.at<float>(i,j) = vHys[0].at<float>(i,j);
				mScore.at<float>(i,j) = vScores[0].at<float>(i,j);
				mSel.at<uchar>(i,j) = 0;

				mSel_map.at<Vec3b>(i,j).val[0] = 0;
				mSel_map.at<Vec3b>(i,j).val[1] = 0;
				mSel_map.at<Vec3b>(i,j).val[2] = 0;
			} 
			else
			{
				vector <double>::iterator iterDouble = min_element(vss.begin(), vss.end());
				int idx_min_score = iterDouble - vss.begin();

				mDepth.at<float>(i,j) = vDepths[vss_idx[idx_min_score]].at<float>(i,j);
				mHx.at<float>(i,j) = vHxs[vss_idx[idx_min_score]].at<float>(i,j);
				mHy.at<float>(i,j) = vHys[vss_idx[idx_min_score]].at<float>(i,j);
				mScore.at<float>(i,j) = vScores[vss_idx[idx_min_score]].at<float>(i,j);
				mSel.at<uchar>(i,j) = (uchar)vss_idx[idx_min_score];

				if (vss_idx[idx_min_score]==0)
				{
					mSel_map.at<Vec3b>(i,j).val[0] = 255;
					mSel_map.at<Vec3b>(i,j).val[1] = 0;
					mSel_map.at<Vec3b>(i,j).val[2] = 0;
				}
				else if (vss_idx[idx_min_score]==1)
				{
					mSel_map.at<Vec3b>(i,j).val[0] = 0;
					mSel_map.at<Vec3b>(i,j).val[1] = 255;
					mSel_map.at<Vec3b>(i,j).val[2] = 0;
				}
				else if (vss_idx[idx_min_score]==2)
				{
					mSel_map.at<Vec3b>(i,j).val[0] = 255;
					mSel_map.at<Vec3b>(i,j).val[1] = 255;
					mSel_map.at<Vec3b>(i,j).val[2] = 0;
				}
				else
				{
					mSel_map.at<Vec3b>(i,j).val[0] = 0;
					mSel_map.at<Vec3b>(i,j).val[1] = 0;
					mSel_map.at<Vec3b>(i,j).val[2] = 255;
				}
			}
		}
	}

	Mat mDepth_map, mHx_map, mHy_map, mScore_map(h, w, CV_8UC3);

	double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

	minMaxIdx(mDepth, &min_depth, &max_depth);
	minMaxIdx(mHx, &min_incre_x, &max_incre_x);
	minMaxIdx(mHy, &min_incre_y, &max_incre_y);

	mDepth.convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
	mHx.convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
	mHy.convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			if (mScore.at<float>(i,j)<0)
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = 0;
				mScore_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
				mScore_map.at<Vec3b>(i,j).val[2] = 0;
			}
		}
	}

	CString strInfo;

	strInfo.Format("D:\\all\\depth map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mDepth_map);
	strInfo.Format("D:\\all\\hx map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mHx_map);
	strInfo.Format("D:\\all\\hy map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mHy_map);
	strInfo.Format("D:\\all\\score map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mScore_map);
	strInfo.Format("D:\\all\\best visible map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mSel_map);

	Mat mNormColor;
	GetNormColorField(cam0, mDepth, mHx, mHy, mNormColor);
	strInfo.Format("D:\\all\\normcolor map extracted.bmp");
	imwrite(strInfo.GetBuffer(), mNormColor);

	strInfo.Format("D:\\all\\cloud points extracted.txt");
	OutputPointCloud(strInfo,cam0,img0,mDepth,mHx,mHy,mScore);
}

void DeepVoid::Extract_MRF_d_DP_withInvalids(const Matx33d & mK0,			// input:	mK0 reference image
											 const Matx33d & mR0,			// input:	mR0 reference image
											 const Matx31d & mt0,			// input:	mt0 reference image
											 double fx0_1, 					// input:	fx0_1 = 1/fx0
											 double fy0_1, 					// input:	fy0_1 = 1/fy0
											 const Mat & img0,				// input:	reference image
											 int idx_ref,
											 const vector<Mat> & vDepths,	// input:	all depth map relative to reference wrt each support image
											 const vector<Mat> & vHxs,		// input:	all hx map relative to reference wrt each support image
											 const vector<Mat> & vHys,		// input:	all hy map relative to reference wrt each support image
											 const vector<Mat> & vScores,	// input:	all score map relative to reference wrt each support image
											 Mat & mSel,					// output:	selected best support image index for each pixel who generates the most likely depth with reference image
											 Mat & mDepth,					// output:	selected best depth map
											 Mat & mHx,						// output:	selected best hx map
											 Mat & mHy,						// output:	selected best hy map
											 Mat & mScore					// output:	selected best score map
											 )
{
	int i,j,k;

	int nCam = vDepths.size();

	int w = img0.cols;
	int h = img0.rows;

	vector<Mat> C_dir, S_dirs;

	for (i=0;i<nCam;i++)
	{
		Mat mtmp1(h, w, CV_32FC1, Scalar(0)), mtmp2(h, w, CV_32FC1, Scalar(0));
		C_dir.push_back(mtmp1);
		S_dirs.push_back(mtmp2); // cannot push the same Mat into two vectors, otherwise C_dir[k] will have the same memory location as S_dirs[k]
	}

	vector<double> Lr_1(nCam), Lr(nCam);


	/*------------ 01 direction --------------------------------------------------------------------------*/
	// dir = [1, 0] i.e. along positive direction of x-axis or the 0 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 01 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,0);
			if (score<0)
			{
				C_dir[k].at<float>(i,0) = -1;
			}
			else
			{
				C_dir[k].at<float>(i,0) = 0;
			}
		}
	}

	for (j=1;j<w;j++)
	{
		for (i=0;i<h;i++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i,j-1);
			}
			DP_step_withInvalids(j-1, i, j, i, vDepths, vScores, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 02 direction --------------------------------------------------------------------------*/
	// dir = [-1, 0] i.e. along negative direction of x-axis or the 180 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 02 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,w-1);
			if (score<0)
			{
				C_dir[k].at<float>(i,w-1) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,w-1) = 0;
			}
		}
	}

	for (j=w-2;j>-1;j--)
	{
		for (i=0;i<h;i++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i,j+1);
			}
			DP_step_withInvalids(j+1, i, j, i, vDepths, vScores, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 03 direction --------------------------------------------------------------------------*/
	// dir = [0, 1] i.e. along positive direction of y-axis or the -90 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 03 starts");
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=0;j<w;j++)
		{
			double score = vScores[k].at<float>(0,j);
			if (score<0)
			{
				C_dir[k].at<float>(0,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(0,j) = 0;
			}
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j);
			}
			DP_step_withInvalids(j, i-1, j, i, vDepths, vScores, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 04 direction --------------------------------------------------------------------------*/
	// dir = [0, -1] i.e. along negative direction of y-axis or the 90 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 04 starts");
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=0;j<w;j++)
		{
			double score = vScores[k].at<float>(h-1,j);
			if (score<0)
			{
				C_dir[k].at<float>(h-1,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(h-1,j) = 0;
			}
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=0;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j);
			}
			DP_step_withInvalids(j, i+1, j, i, vDepths, vScores, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 05 direction --------------------------------------------------------------------------*/
	// dir = [1, 1] i.e. along the -45 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 05 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,0);
			if (score<0)
			{
				C_dir[k].at<float>(i,0) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,0) = 0;
			}
		}
	}
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=1;j<w;j++)
		{
			double score = vScores[k].at<float>(0,j);
			if (score<0)
			{
				C_dir[k].at<float>(0,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(0,j) = 0;
			}
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=1;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j-1);
			}
			DP_step_withInvalids(j-1, i-1, j, i, vDepths, vScores, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 06 direction --------------------------------------------------------------------------*/
	// dir = [-1, -1] i.e. along the 135 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 06 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,w-1);
			if (score<0)
			{
				C_dir[k].at<float>(i,w-1) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,w-1) = 0;
			}
		}
	}
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=0;j<w-1;j++)
		{
			double score = vScores[k].at<float>(h-1,j);
			if (score<0)
			{
				C_dir[k].at<float>(h-1,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(h-1,j) = 0;
			}	
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=w-2;j>-1;j--)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j+1);
			}
			DP_step_withInvalids(j+1, i+1, j, i, vDepths, vScores, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 07 direction --------------------------------------------------------------------------*/
	// dir = [1, -1] i.e. along the 45 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 07 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,0);
			if (score<0)
			{
				C_dir[k].at<float>(i,0) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,0) = 0;
			}
		}
	}
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=1;j<w;j++)
		{
			double score = vScores[k].at<float>(h-1,j);
			if (score<0)
			{
				C_dir[k].at<float>(h-1,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(h-1,j) = 0;
			}
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=1;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j-1);
			}
			DP_step_withInvalids(j-1, i+1, j, i, vDepths, vScores, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 08 direction --------------------------------------------------------------------------*/
	// dir = [-1, 1] i.e. along the -135 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 08 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,w-1);
			if (score<0)
			{
				C_dir[k].at<float>(i,w-1) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,w-1) = 0;
			}
		}
	}
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=0;j<w-1;j++)
		{
			double score = vScores[k].at<float>(0,j);
			if (score<0)
			{
				C_dir[k].at<float>(0,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(0,j) = 0;
			}
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=w-2;j>-1;j--)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j+1);
			}
			DP_step_withInvalids(j+1, i-1, j, i, vDepths, vScores, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	//////////////////////////////////////////////////////////////////////////
	// get the 
	Mat mSel_map(h, w, CV_8UC3);

	mSel = Mat(h, w, CV_8UC1);
	mDepth = Mat(h, w, CV_32FC1);
	mHx = Mat(h, w, CV_32FC1);
	mHy = Mat(h, w, CV_32FC1);
	mScore = Mat(h, w, CV_32FC1);

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			vector<double> vss;
			vector<int> vss_idx;
			for (k=0;k<nCam;k++)
			{
				double s = S_dirs[k].at<float>(i,j);
				if (s>0)
				{
					vss.push_back(s);
					vss_idx.push_back(k);
				}
			}

			if (vss.size()==0)
			{
				mDepth.at<float>(i,j) = vDepths[0].at<float>(i,j);
				mHx.at<float>(i,j) = vHxs[0].at<float>(i,j);
				mHy.at<float>(i,j) = vHys[0].at<float>(i,j);
				mScore.at<float>(i,j) = vScores[0].at<float>(i,j);
				mSel.at<uchar>(i,j) = 0;

				mSel_map.at<Vec3b>(i,j).val[0] = 0;
				mSel_map.at<Vec3b>(i,j).val[1] = 0;
				mSel_map.at<Vec3b>(i,j).val[2] = 0;
			} 
			else
			{
				vector <double>::iterator iterDouble = min_element(vss.begin(), vss.end());
				int idx_min_score = iterDouble - vss.begin();

				mDepth.at<float>(i,j) = vDepths[vss_idx[idx_min_score]].at<float>(i,j);
				mHx.at<float>(i,j) = vHxs[vss_idx[idx_min_score]].at<float>(i,j);
				mHy.at<float>(i,j) = vHys[vss_idx[idx_min_score]].at<float>(i,j);
				mScore.at<float>(i,j) = vScores[vss_idx[idx_min_score]].at<float>(i,j);
				mSel.at<uchar>(i,j) = (uchar)vss_idx[idx_min_score];

				if (vss_idx[idx_min_score]==0)
				{
					mSel_map.at<Vec3b>(i,j).val[0] = 255;
					mSel_map.at<Vec3b>(i,j).val[1] = 0;
					mSel_map.at<Vec3b>(i,j).val[2] = 0;
				}
				else if (vss_idx[idx_min_score]==1)
				{
					mSel_map.at<Vec3b>(i,j).val[0] = 0;
					mSel_map.at<Vec3b>(i,j).val[1] = 255;
					mSel_map.at<Vec3b>(i,j).val[2] = 0;
				}
				else if (vss_idx[idx_min_score]==2)
				{
					mSel_map.at<Vec3b>(i,j).val[0] = 255;
					mSel_map.at<Vec3b>(i,j).val[1] = 255;
					mSel_map.at<Vec3b>(i,j).val[2] = 0;
				}
				else
				{
					mSel_map.at<Vec3b>(i,j).val[0] = 0;
					mSel_map.at<Vec3b>(i,j).val[1] = 0;
					mSel_map.at<Vec3b>(i,j).val[2] = 255;
				}
			}
		}
	}

	Mat mDepth_map, mHx_map, mHy_map, mScore_map(h, w, CV_8UC3);

	double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

	minMaxIdx(mDepth, &min_depth, &max_depth);
	minMaxIdx(mHx, &min_incre_x, &max_incre_x);
	minMaxIdx(mHy, &min_incre_y, &max_incre_y);

	mDepth.convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
	mHx.convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
	mHy.convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			if (mScore.at<float>(i,j)<0)
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = 0;
				mScore_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
				mScore_map.at<Vec3b>(i,j).val[2] = 0;
			}
		}
	}

	CString strInfo;

	strInfo.Format("D:\\all\\depth map %02d extracted.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mDepth_map);
	strInfo.Format("D:\\all\\hx map %02d extracted.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mHx_map);
	strInfo.Format("D:\\all\\hy map %02d extracted.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mHy_map);
	strInfo.Format("D:\\all\\score map %02d extracted.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mScore_map);
	strInfo.Format("D:\\all\\best visible map %02d extracted.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mSel_map);

	Mat mNormColor;
	GetNormColorField(mK0,mR0,mt0,fx0_1,fy0_1,mDepth,mHx,mHy,mNormColor);
	strInfo.Format("D:\\all\\normcolor map %02d extracted.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mNormColor);

	strInfo.Format("D:\\all\\cloud points %02d extracted.txt", idx_ref);
	OutputPointCloud(strInfo,mK0,mR0,mt0,fx0_1,fy0_1,img0,mDepth,mHx,mHy,mScore);

	
	strInfo.Format("D:\\all\\most likely depth map %02d.txt", idx_ref);
	FILE * file_depth = fopen(strInfo, "w");
	strInfo.Format("D:\\all\\most likely hx map %02d.txt", idx_ref);
	FILE * file_hx = fopen(strInfo, "w");
	strInfo.Format("D:\\all\\most likely hy map %02d.txt", idx_ref);
	FILE * file_hy = fopen(strInfo, "w");
	strInfo.Format("D:\\all\\most likely score map %02d.txt", idx_ref);
	FILE * file_score = fopen(strInfo, "w");

	// at the same time evaluate all parameters
	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			fprintf(file_depth, "%.12f	", mDepth.at<float>(i,j));
			fprintf(file_hx, "%.12f	", mHx.at<float>(i,j));
			fprintf(file_hy, "%.12f	", mHy.at<float>(i,j));
			fprintf(file_score, "%.12f	", mScore.at<float>(i,j));
		}
		fprintf(file_depth, "\n");
		fprintf(file_hx, "\n");
		fprintf(file_hy, "\n");
		fprintf(file_score, "\n");
	}
	fclose(file_depth);
	fclose(file_hx);
	fclose(file_hy);
	fclose(file_score);
}

// complete MRF model, data term is considered, and smoothness term is used on both depth and normals
void DeepVoid::Extract_MRF_ncc_d_n_DP_withInvalids(const Matx33d & mK0,			// input:	mK0 reference image
												   const Matx33d & mR0,			// input:	mR0 reference image
												   const Matx31d & mt0,			// input:	mt0 reference image
												   double fx0_1, 				// input:	fx0_1 = 1/fx0
												   double fy0_1, 				// input:	fy0_1 = 1/fy0
												   const Mat & img0,			// input:	reference image
												   int idx_ref,
												   const vector<Mat> & vDepths,	// input:	all depth map relative to reference wrt each support image
												   const vector<Mat> & vHxs,	// input:	all hx map relative to reference wrt each support image
												   const vector<Mat> & vHys,	// input:	all hy map relative to reference wrt each support image
												   const vector<Mat> & vScores,	// input:	all score map relative to reference wrt each support image
												   Mat & mSel,					// output:	selected best support image index for each pixel who generates the most likely depth with reference image
												   Mat & mDepth,				// output:	selected best depth map
												   Mat & mHx,					// output:	selected best hx map
												   Mat & mHy,					// output:	selected best hy map
												   Mat & mScore,				// output:	selected best score map
												   double P1,					// input:
												   double P2					// input:
												   )
{
	double pi_1 = 1.0/CV_PI; // 1/pi

	int i,j,k;

	int nCam = vDepths.size();

	int w = img0.cols;
	int h = img0.rows;

	vector<Mat> C_dir, S_dirs;

	for (i=0;i<nCam;i++)
	{
		Mat mtmp1(h, w, CV_32FC1, Scalar(0)), mtmp2(h, w, CV_32FC1, Scalar(0));
		C_dir.push_back(mtmp1);
		S_dirs.push_back(mtmp2); // cannot push the same Mat into two vectors, otherwise C_dir[k] will have the same memory location as S_dirs[k]
	}

	vector<double> Lr_1(nCam), Lr(nCam);


	/*------------ 01 direction --------------------------------------------------------------------------*/
	// dir = [1, 0] i.e. along positive direction of x-axis or the 0 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 01 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,0);
			if (score<0)
			{
				C_dir[k].at<float>(i,0) = -1;
			}
			else
			{
				C_dir[k].at<float>(i,0) = 1-score;
			}
		}
	}

	for (j=1;j<w;j++)
	{
		for (i=0;i<h;i++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i,j-1);
			}
			DP_step_withInvalids(mK0, mR0, mt0, fx0_1, fy0_1, j-1, i, j, i, vDepths, vHxs, vHys, vScores, pi_1, P1, P2, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 02 direction --------------------------------------------------------------------------*/
	// dir = [-1, 0] i.e. along negative direction of x-axis or the 180 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 02 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,w-1);
			if (score<0)
			{
				C_dir[k].at<float>(i,w-1) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,w-1) = 1-score;
			}
		}
	}

	for (j=w-2;j>-1;j--)
	{
		for (i=0;i<h;i++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i,j+1);
			}
			DP_step_withInvalids(mK0, mR0, mt0, fx0_1, fy0_1, j+1, i, j, i, vDepths, vHxs, vHys, vScores, pi_1, P1, P2, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 03 direction --------------------------------------------------------------------------*/
	// dir = [0, 1] i.e. along positive direction of y-axis or the -90 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 03 starts");
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=0;j<w;j++)
		{
			double score = vScores[k].at<float>(0,j);
			if (score<0)
			{
				C_dir[k].at<float>(0,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(0,j) = 1-score;
			}
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j);
			}
			DP_step_withInvalids(mK0, mR0, mt0, fx0_1, fy0_1, j, i-1, j, i, vDepths, vHxs, vHys, vScores, pi_1, P1, P2, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 04 direction --------------------------------------------------------------------------*/
	// dir = [0, -1] i.e. along negative direction of y-axis or the 90 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 04 starts");
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=0;j<w;j++)
		{
			double score = vScores[k].at<float>(h-1,j);
			if (score<0)
			{
				C_dir[k].at<float>(h-1,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(h-1,j) = 1-score;
			}
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=0;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j);
			}
			DP_step_withInvalids(mK0, mR0, mt0, fx0_1, fy0_1, j, i+1, j, i, vDepths, vHxs, vHys, vScores, pi_1, P1, P2, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 05 direction --------------------------------------------------------------------------*/
	// dir = [1, 1] i.e. along the -45 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 05 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,0);
			if (score<0)
			{
				C_dir[k].at<float>(i,0) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,0) = 1-score;
			}
		}
	}
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=1;j<w;j++)
		{
			double score = vScores[k].at<float>(0,j);
			if (score<0)
			{
				C_dir[k].at<float>(0,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(0,j) = 1-score;
			}
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=1;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j-1);
			}
			DP_step_withInvalids(mK0, mR0, mt0, fx0_1, fy0_1, j-1, i-1, j, i, vDepths, vHxs, vHys, vScores, pi_1, P1, P2, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 06 direction --------------------------------------------------------------------------*/
	// dir = [-1, -1] i.e. along the 135 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 06 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,w-1);
			if (score<0)
			{
				C_dir[k].at<float>(i,w-1) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,w-1) = 1-score;
			}
		}
	}
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=0;j<w-1;j++)
		{
			double score = vScores[k].at<float>(h-1,j);
			if (score<0)
			{
				C_dir[k].at<float>(h-1,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(h-1,j) = 1-score;
			}	
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=w-2;j>-1;j--)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j+1);
			}
			DP_step_withInvalids(mK0, mR0, mt0, fx0_1, fy0_1, j+1, i+1, j, i, vDepths, vHxs, vHys, vScores, pi_1, P1, P2, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 07 direction --------------------------------------------------------------------------*/
	// dir = [1, -1] i.e. along the 45 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 07 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,0);
			if (score<0)
			{
				C_dir[k].at<float>(i,0) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,0) = 1-score;
			}
		}
	}
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=1;j<w;j++)
		{
			double score = vScores[k].at<float>(h-1,j);
			if (score<0)
			{
				C_dir[k].at<float>(h-1,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(h-1,j) = 1-score;
			}
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=1;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j-1);
			}
			DP_step_withInvalids(mK0, mR0, mt0, fx0_1, fy0_1, j-1, i+1, j, i, vDepths, vHxs, vHys, vScores, pi_1, P1, P2, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 08 direction --------------------------------------------------------------------------*/
	// dir = [-1, 1] i.e. along the -135 direction
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 08 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,w-1);
			if (score<0)
			{
				C_dir[k].at<float>(i,w-1) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,w-1) = 1-score;
			}
		}
	}
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=0;j<w-1;j++)
		{
			double score = vScores[k].at<float>(0,j);
			if (score<0)
			{
				C_dir[k].at<float>(0,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(0,j) = 1-score;
			}
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=w-2;j>-1;j--)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j+1);
			}
			DP_step_withInvalids(mK0, mR0, mt0, fx0_1, fy0_1, j+1, i-1, j, i, vDepths, vHxs, vHys, vScores, pi_1, P1, P2, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	//////////////////////////////////////////////////////////////////////////
	// get the 
	Mat mSel_map(h, w, CV_8UC3);

	mSel = Mat(h, w, CV_8UC1);
	mDepth = Mat(h, w, CV_32FC1);
	mHx = Mat(h, w, CV_32FC1);
	mHy = Mat(h, w, CV_32FC1);
	mScore = Mat(h, w, CV_32FC1);

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			vector<double> vss;
			vector<int> vss_idx;
			for (k=0;k<nCam;k++)
			{
				double s = S_dirs[k].at<float>(i,j);
				if (s>0)
				{
					vss.push_back(s);
					vss_idx.push_back(k);
				}
			}

			if (vss.size()==0)
			{
				mDepth.at<float>(i,j) = vDepths[0].at<float>(i,j);
				mHx.at<float>(i,j) = vHxs[0].at<float>(i,j);
				mHy.at<float>(i,j) = vHys[0].at<float>(i,j);
				mScore.at<float>(i,j) = vScores[0].at<float>(i,j);
				mSel.at<uchar>(i,j) = 0;

				mSel_map.at<Vec3b>(i,j).val[0] = 0;
				mSel_map.at<Vec3b>(i,j).val[1] = 0;
				mSel_map.at<Vec3b>(i,j).val[2] = 0;
			} 
			else
			{
				vector <double>::iterator iterDouble = min_element(vss.begin(), vss.end());
				int idx_min_score = iterDouble - vss.begin();

				mDepth.at<float>(i,j) = vDepths[vss_idx[idx_min_score]].at<float>(i,j);
				mHx.at<float>(i,j) = vHxs[vss_idx[idx_min_score]].at<float>(i,j);
				mHy.at<float>(i,j) = vHys[vss_idx[idx_min_score]].at<float>(i,j);
				mScore.at<float>(i,j) = vScores[vss_idx[idx_min_score]].at<float>(i,j);
				mSel.at<uchar>(i,j) = (uchar)vss_idx[idx_min_score];

				if (vss_idx[idx_min_score]==0)
				{
					mSel_map.at<Vec3b>(i,j).val[0] = 255;
					mSel_map.at<Vec3b>(i,j).val[1] = 0;
					mSel_map.at<Vec3b>(i,j).val[2] = 0;
				}
				else if (vss_idx[idx_min_score]==1)
				{
					mSel_map.at<Vec3b>(i,j).val[0] = 0;
					mSel_map.at<Vec3b>(i,j).val[1] = 255;
					mSel_map.at<Vec3b>(i,j).val[2] = 0;
				}
				else if (vss_idx[idx_min_score]==2)
				{
					mSel_map.at<Vec3b>(i,j).val[0] = 255;
					mSel_map.at<Vec3b>(i,j).val[1] = 255;
					mSel_map.at<Vec3b>(i,j).val[2] = 0;
				}
				else
				{
					mSel_map.at<Vec3b>(i,j).val[0] = 0;
					mSel_map.at<Vec3b>(i,j).val[1] = 0;
					mSel_map.at<Vec3b>(i,j).val[2] = 255;
				}
			}
		}
	}

	Mat mDepth_map, mHx_map, mHy_map, mScore_map(h, w, CV_8UC3);

	double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

	minMaxIdx(mDepth, &min_depth, &max_depth);
	minMaxIdx(mHx, &min_incre_x, &max_incre_x);
	minMaxIdx(mHy, &min_incre_y, &max_incre_y);

	mDepth.convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
	mHx.convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
	mHy.convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			if (mScore.at<float>(i,j)<0)
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = 0;
				mScore_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
				mScore_map.at<Vec3b>(i,j).val[2] = 0;
			}
		}
	}

	CString strInfo;

	strInfo.Format("D:\\all\\depth map %02d extracted.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mDepth_map);
	strInfo.Format("D:\\all\\hx map %02d extracted.bmp", idx_ref);
//	imwrite(strInfo.GetBuffer(), mHx_map);
	strInfo.Format("D:\\all\\hy map %02d extracted.bmp", idx_ref);
//	imwrite(strInfo.GetBuffer(), mHy_map);
	strInfo.Format("D:\\all\\score map %02d extracted.bmp", idx_ref);
//	imwrite(strInfo.GetBuffer(), mScore_map);
	strInfo.Format("D:\\all\\best visible map %02d extracted.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mSel_map);

	Mat mNormColor;
	GetNormColorField(mK0,mR0,mt0,fx0_1,fy0_1,mDepth,mHx,mHy,mNormColor);
	strInfo.Format("D:\\all\\normcolor map %02d extracted.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mNormColor);

	strInfo.Format("D:\\all\\cloud points %02d extracted.txt", idx_ref);
	OutputPointCloud(strInfo,mK0,mR0,mt0,fx0_1,fy0_1,img0,mDepth,mHx,mHy,mScore);


// 	strInfo.Format("D:\\all\\most likely depth map %02d.txt", idx_ref);
// 	FILE * file_depth = fopen(strInfo, "w");
// 	strInfo.Format("D:\\all\\most likely hx map %02d.txt", idx_ref);
// 	FILE * file_hx = fopen(strInfo, "w");
// 	strInfo.Format("D:\\all\\most likely hy map %02d.txt", idx_ref);
// 	FILE * file_hy = fopen(strInfo, "w");
// 	strInfo.Format("D:\\all\\most likely score map %02d.txt", idx_ref);
// 	FILE * file_score = fopen(strInfo, "w");
// 
// 	// at the same time evaluate all parameters
// 	for (i=0;i<h;i++)
// 	{
// 		for (j=0;j<w;j++)
// 		{
// 			fprintf(file_depth, "%.12f	", mDepth.at<float>(i,j));
// 			fprintf(file_hx, "%.12f	", mHx.at<float>(i,j));
// 			fprintf(file_hy, "%.12f	", mHy.at<float>(i,j));
// 			fprintf(file_score, "%.12f	", mScore.at<float>(i,j));
// 		}
// 		fprintf(file_depth, "\n");
// 		fprintf(file_hx, "\n");
// 		fprintf(file_hy, "\n");
// 		fprintf(file_score, "\n");
// 	}
// 	fclose(file_depth);
// 	fclose(file_hx);
// 	fclose(file_hy);
// 	fclose(file_score);
}

// 20140914, self-contained version, complete MRF model, data term is considered, and smoothness term is used on both depth and normals
void DeepVoid::Extract_MRF_ncc_d_n_DP_withInvalids(const Matx33d & mK0,			// input:	mK0 reference image
												   const Matx33d & mR0,			// input:	mR0 reference image
												   const Matx31d & mt0,			// input:	mt0 reference image
												   const vector<Mat> & vDepths,	// input:	all depth map relative to reference wrt each support image
												   const vector<Mat> & vHxs,	// input:	all hx map relative to reference wrt each support image
												   const vector<Mat> & vHys,	// input:	all hy map relative to reference wrt each support image
												   const vector<Mat> & vScores,	// input:	all score map relative to reference wrt each support image
												   Mat & mSel,					// output:	selected best support image index for each pixel who generates the most likely depth with reference image
												   Mat & mDepth,				// output:	selected best depth map
												   Mat & mHx,					// output:	selected best hx map
												   Mat & mHy,					// output:	selected best hy map
												   Mat & mScore,				// output:	selected best score map
												   double P1,					// input:
												   double P2					// input:
												   )
{
	double pi_1 = 1.0/CV_PI; // 1/pi

	int i,j,k;

	int nCam = vDepths.size();

	int w = vDepths[0].cols;
	int h = vDepths[0].rows;

	double fx0_1 = 1/mK0(0,0);
	double fy0_1 = 1/mK0(1,1);

	vector<Mat> C_dir, S_dirs;

	for (i=0;i<nCam;i++)
	{
		Mat mtmp1(h, w, CV_32FC1, Scalar(0)), mtmp2(h, w, CV_32FC1, Scalar(0));
		C_dir.push_back(mtmp1);
		S_dirs.push_back(mtmp2); // cannot push the same Mat into two vectors, otherwise C_dir[k] will have the same memory location as S_dirs[k]
	}

	vector<double> Lr_1(nCam), Lr(nCam);


	/*------------ 01 direction --------------------------------------------------------------------------*/
	// dir = [1, 0] i.e. along positive direction of x-axis or the 0 direction
//	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 01 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,0);
			if (score<0)
			{
				C_dir[k].at<float>(i,0) = -1;
			}
			else
			{
				C_dir[k].at<float>(i,0) = 1-score;
			}
		}
	}

	for (j=1;j<w;j++)
	{
		for (i=0;i<h;i++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i,j-1);
			}
			DP_step_withInvalids(mK0, mR0, mt0, fx0_1, fy0_1, j-1, i, j, i, vDepths, vHxs, vHys, vScores, pi_1, P1, P2, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 02 direction --------------------------------------------------------------------------*/
	// dir = [-1, 0] i.e. along negative direction of x-axis or the 180 direction
//	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 02 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,w-1);
			if (score<0)
			{
				C_dir[k].at<float>(i,w-1) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,w-1) = 1-score;
			}
		}
	}

	for (j=w-2;j>-1;j--)
	{
		for (i=0;i<h;i++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i,j+1);
			}
			DP_step_withInvalids(mK0, mR0, mt0, fx0_1, fy0_1, j+1, i, j, i, vDepths, vHxs, vHys, vScores, pi_1, P1, P2, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 03 direction --------------------------------------------------------------------------*/
	// dir = [0, 1] i.e. along positive direction of y-axis or the -90 direction
//	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 03 starts");
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=0;j<w;j++)
		{
			double score = vScores[k].at<float>(0,j);
			if (score<0)
			{
				C_dir[k].at<float>(0,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(0,j) = 1-score;
			}
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j);
			}
			DP_step_withInvalids(mK0, mR0, mt0, fx0_1, fy0_1, j, i-1, j, i, vDepths, vHxs, vHys, vScores, pi_1, P1, P2, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 04 direction --------------------------------------------------------------------------*/
	// dir = [0, -1] i.e. along negative direction of y-axis or the 90 direction
//	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 04 starts");
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=0;j<w;j++)
		{
			double score = vScores[k].at<float>(h-1,j);
			if (score<0)
			{
				C_dir[k].at<float>(h-1,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(h-1,j) = 1-score;
			}
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=0;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j);
			}
			DP_step_withInvalids(mK0, mR0, mt0, fx0_1, fy0_1, j, i+1, j, i, vDepths, vHxs, vHys, vScores, pi_1, P1, P2, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 05 direction --------------------------------------------------------------------------*/
	// dir = [1, 1] i.e. along the -45 direction
//	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 05 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,0);
			if (score<0)
			{
				C_dir[k].at<float>(i,0) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,0) = 1-score;
			}
		}
	}
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=1;j<w;j++)
		{
			double score = vScores[k].at<float>(0,j);
			if (score<0)
			{
				C_dir[k].at<float>(0,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(0,j) = 1-score;
			}
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=1;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j-1);
			}
			DP_step_withInvalids(mK0, mR0, mt0, fx0_1, fy0_1, j-1, i-1, j, i, vDepths, vHxs, vHys, vScores, pi_1, P1, P2, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 06 direction --------------------------------------------------------------------------*/
	// dir = [-1, -1] i.e. along the 135 direction
//	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 06 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,w-1);
			if (score<0)
			{
				C_dir[k].at<float>(i,w-1) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,w-1) = 1-score;
			}
		}
	}
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=0;j<w-1;j++)
		{
			double score = vScores[k].at<float>(h-1,j);
			if (score<0)
			{
				C_dir[k].at<float>(h-1,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(h-1,j) = 1-score;
			}	
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=w-2;j>-1;j--)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j+1);
			}
			DP_step_withInvalids(mK0, mR0, mt0, fx0_1, fy0_1, j+1, i+1, j, i, vDepths, vHxs, vHys, vScores, pi_1, P1, P2, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 07 direction --------------------------------------------------------------------------*/
	// dir = [1, -1] i.e. along the 45 direction
//	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 07 starts");
	for (i=0;i<h;i++) // left image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,0);
			if (score<0)
			{
				C_dir[k].at<float>(i,0) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,0) = 1-score;
			}
		}
	}
	for (k=0;k<nCam;k++) // bottom image border
	{
		for (j=1;j<w;j++)
		{
			double score = vScores[k].at<float>(h-1,j);
			if (score<0)
			{
				C_dir[k].at<float>(h-1,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(h-1,j) = 1-score;
			}
		}
	}

	for (i=h-2;i>-1;i--)
	{
		for (j=1;j<w;j++)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i+1,j-1);
			}
			DP_step_withInvalids(mK0, mR0, mt0, fx0_1, fy0_1, j-1, i+1, j, i, vDepths, vHxs, vHys, vScores, pi_1, P1, P2, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	/*------------ 08 direction --------------------------------------------------------------------------*/
	// dir = [-1, 1] i.e. along the -135 direction
//	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo("scan direction 08 starts");
	for (i=0;i<h;i++) // right image border
	{
		for (k=0;k<nCam;k++)
		{
			double score = vScores[k].at<float>(i,w-1);
			if (score<0)
			{
				C_dir[k].at<float>(i,w-1) = -1;
			} 
			else
			{
				C_dir[k].at<float>(i,w-1) = 1-score;
			}
		}
	}
	for (k=0;k<nCam;k++) // top image border
	{
		for (j=0;j<w-1;j++)
		{
			double score = vScores[k].at<float>(0,j);
			if (score<0)
			{
				C_dir[k].at<float>(0,j) = -1;
			} 
			else
			{
				C_dir[k].at<float>(0,j) = 1-score;
			}
		}
	}

	for (i=1;i<h;i++)
	{
		for (j=w-2;j>-1;j--)
		{
			for (k=0;k<nCam;k++)
			{
				Lr_1[k] = C_dir[k].at<float>(i-1,j+1);
			}
			DP_step_withInvalids(mK0, mR0, mt0, fx0_1, fy0_1, j+1, i-1, j, i, vDepths, vHxs, vHys, vScores, pi_1, P1, P2, Lr_1, Lr);
			for (k=0;k<nCam;k++)
			{
				C_dir[k].at<float>(i,j) = Lr[k];
			}
		}
	}
	// add the 3D aggregated cost to the sum
	for (k=0;k<nCam;k++)
	{
		S_dirs[k] += C_dir[k];
	}

	//////////////////////////////////////////////////////////////////////////
	// get the 
	mSel = Mat(h, w, CV_8UC1);
	mDepth = Mat(h, w, CV_32FC1);
	mHx = Mat(h, w, CV_32FC1);
	mHy = Mat(h, w, CV_32FC1);
	mScore = Mat(h, w, CV_32FC1);

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			vector<double> vss;
			vector<int> vss_idx;
			for (k=0;k<nCam;k++)
			{
				double s = S_dirs[k].at<float>(i,j);
				if (s>0)
				{
					vss.push_back(s);
					vss_idx.push_back(k);
				}
			}

			if (vss.size()==0)
			{
				mDepth.at<float>(i,j) = vDepths[0].at<float>(i,j);
				mHx.at<float>(i,j) = vHxs[0].at<float>(i,j);
				mHy.at<float>(i,j) = vHys[0].at<float>(i,j);
				mScore.at<float>(i,j) = vScores[0].at<float>(i,j);
				mSel.at<uchar>(i,j) = 0;
			} 
			else
			{
				vector <double>::iterator iterDouble = min_element(vss.begin(), vss.end());
				int idx_min_score = iterDouble - vss.begin();

				mDepth.at<float>(i,j) = vDepths[vss_idx[idx_min_score]].at<float>(i,j);
				mHx.at<float>(i,j) = vHxs[vss_idx[idx_min_score]].at<float>(i,j);
				mHy.at<float>(i,j) = vHys[vss_idx[idx_min_score]].at<float>(i,j);
				mScore.at<float>(i,j) = vScores[vss_idx[idx_min_score]].at<float>(i,j);
				mSel.at<uchar>(i,j) = (uchar)vss_idx[idx_min_score];
			}
		}
	}
}

void DeepVoid::DP_step(int xr_1, int yr_1,
					   int xr, int yr,
					   const vector<Mat> & vDepths,
					   const vector<double> & Lr_1,
					   vector<double> & Lr
					   )
{
	int i,j;

	int nCam = vDepths.size();

	vector <double>::const_iterator iterDouble = min_element(Lr_1.begin(), Lr_1.end());
	double min_Lr_1 = *iterDouble;

	for (i=0;i<nCam;i++)
	{
		double di = vDepths[i].at<float>(yr, xr);

		vector<double> vCost;

		for (j=0;j<nCam;j++)
		{
			double dj = vDepths[j].at<float>(yr_1,xr_1);
			double cost = Lr_1[j] + fabs(di-dj);
			vCost.push_back(cost);
		}

		iterDouble = min_element(vCost.begin(), vCost.end());
		double minCost = *iterDouble;

		Lr[i] = minCost-min_Lr_1;
	}
}

// considering invalid values, just like in my SGM function
void DeepVoid::DP_step_withInvalids(int xr_1, int yr_1,
								    int xr, int yr,
								    const vector<Mat> & vDepths,
								    const vector<Mat> & vScores,
								    const vector<double> & Lr_1,
								    vector<double> & Lr
								    )
{
	int i,j;

	int nCam = vDepths.size();

	vector<int> idxValid;
	int nValid = 0;
	double min_Lr_1;

	// find all the valid depths in Lr_1, whose aggregated cost are not negative
	for (i=0;i<nCam;i++)
	{
		if (Lr_1[i]<0)
		{
			continue;
		}

		// find the minimal nonnegative value at the same time
		if (!nValid)
		{
			min_Lr_1 = Lr_1[i];
		} 
		else
		{
			if (Lr_1[i] < min_Lr_1)
			{
				min_Lr_1 = Lr_1[i];
			}
		}

		idxValid.push_back(i);
		nValid++;
	}

	// if nValid=0, it means that previous pixels definitly have no matches at all
	// then we take the right pixel next to it to be the starting pixel for cost aggregation
	if (!nValid)
	{
		for (i=0;i<nCam;i++)
		{
			double score = vScores[i].at<float>(yr,xr);
			if (score<0)
			{
				Lr[i] = -1;
			} 
			else
			{
				Lr[i] = 0;
			}
		}

		return;
	}

	vector <double>::const_iterator iterDouble;

	for (i=0;i<nCam;i++)
	{
		// if the matching cost at depth Cp(i) is negative i.e. invalid, it means that the matching cost between p and p-d is enormous
		// then there is no need to check this depth
		double score = vScores[i].at<float>(yr,xr);
		if (score<0)
		{
			Lr[i] = -1;
			continue;
		}

		double di = vDepths[i].at<float>(yr,xr);

		vector<double> vCost;

		for (j=0;j<nValid;j++)
		{
			double dj = vDepths[idxValid[j]].at<float>(yr_1,xr_1);
			double cost = Lr_1[idxValid[j]] + fabs(di-dj);
			vCost.push_back(cost);
		}

		iterDouble = min_element(vCost.begin(), vCost.end());
		double minCost = *iterDouble;

		Lr[i] = minCost-min_Lr_1;
	}
}

// DP used in complete MRF model, including data term, smoothness terms on both depth and normals
void DeepVoid::DP_step_withInvalids(const Matx33d & mK,			// input:	mK0 reference image
								    const Matx33d & mR,			// input:	mR0 reference image
								    const Matx31d & mt,			// input:	mt0 reference image
								    double fx_1, 				// input:	fx0_1 = 1/fx0
								    double fy_1,				// input:	fy0_1 = 1/fy0
								    int xr_1, int yr_1,			// input:	previous pixel
								    int xr, int yr,				// input:	current pixel
								    const vector<Mat> & vDepths,// input:	all depth candidates
								    const vector<Mat> & vHxs,	// input:	all hx map relative to reference wrt each support image
								    const vector<Mat> & vHys,	// input:	all hy map relative to reference wrt each support image
								    const vector<Mat> & vScores,
									double pi_1,				// input:	1/π
									double P1,					// input:
									double P2,					// input:
								    const vector<double> & Lr_1,
								    vector<double> & Lr
								    )
{
//	double pi_2_1 = 2*pi_1; // 1/(0.5*pi)

	int i,j;

	int nCam = vDepths.size();

	vector<int> idxValid;
	int nValid = 0;
	double min_Lr_1;

	// find all the valid depths in Lr_1, whose aggregated cost are not negative
	for (i=0;i<nCam;i++)
	{
		if (Lr_1[i]<0)
		{
			continue;
		}

		// find the minimal nonnegative value at the same time
		if (!nValid)
		{
			min_Lr_1 = Lr_1[i];
		} 
		else
		{
			if (Lr_1[i] < min_Lr_1)
			{
				min_Lr_1 = Lr_1[i];
			}
		}

		idxValid.push_back(i);
		nValid++;
	}

	// if nValid=0, it means that previous pixels definitly have no matches at all
	// then we take the right pixel next to it to be the starting pixel for cost aggregation
	if (!nValid)
	{
		for (i=0;i<nCam;i++)
		{
			double score = vScores[i].at<float>(yr,xr);
			if (score<0)
			{
				Lr[i] = -1;
			} 
			else
			{
				Lr[i] = 1-score; // the true matching cost is 1-ncc, which means the bigger ncc is, the smaller the cost is
			}
		}

		return;
	}

	// compute corresponding normalized image point of previous pixel and current pixel, i.e. the sight direction vector
	double fx = mK(0,0); double fy = mK(1,1);
	double cx = mK(0,2); double cy = mK(1,2);
	double nimgx0 = (xr_1-cx)*fx_1; double nimgy0 = (yr_1-cy)*fy_1;
	double nimgx  = (xr  -cx)*fx_1; double nimgy  = (yr  -cy)*fy_1;
// 	Matx31d dir0; dir0(0) = nimgx0; dir0(1) = nimgy0; dir0(2) = 1; // direction of previous pixel
// 	Matx31d dir;   dir(0) = nimgx;   dir(1) = nimgy;   dir(2) = 1; // direction of current pixel

	vector <double>::const_iterator iterDouble;

	for (i=0;i<nCam;i++)
	{
		// if the matching cost at depth Cp(i) is negative i.e. invalid, it means that the matching cost between p and p-d is enormous
		// then there is no need to check this depth
		double score = vScores[i].at<float>(yr,xr);
		if (score<0)
		{
			Lr[i] = -1;
			continue;
		}

		double di = vDepths[i].at<float>(yr,xr);
		double hxi = vHxs[i].at<float>(yr,xr);
		double hyi = vHys[i].at<float>(yr,xr);
		
// 		Matx31d veci = di*dir; // the sight line vector of current pixel with depth di
// 		double nvi = norm(veci);

		// normal vec
		Matx31d faxi; faxi(2)=1;
		get_normal_givendrhxhy(fx, fy, nimgx, nimgy, di, hxi, hyi, faxi(0), faxi(1));
		double nfaxi = norm(faxi);
		Matx13d faxi_t = faxi.t();

		vector<double> vCost;

		for (j=0;j<nValid;j++)
		{
			double dj = vDepths[idxValid[j]].at<float>(yr_1,xr_1);
			double hxj = vHxs[idxValid[j]].at<float>(yr_1,xr_1);
			double hyj = vHys[idxValid[j]].at<float>(yr_1,xr_1);

			// 1. depth smoothness cost by converting depth difference into an angle
// 			Matx31d vecj = dj*dir0; // the sight line vector of previous pixel with depth dj
// 			Matx31d dv = vecj-veci;
// 			double ndv = norm(dv);
// 			Matx<double,1,1> cosa = veci.t() * dv;
// 			double sinb = fabs(cosa(0)/(nvi*ndv)); // sin(beta) = |cos(alpha)| see my notebook
// 			double beta = asin(sinb);    // 0-90
//			double cost_d = beta*pi_2_1; // normalize the cost

			// 1. depth smoothness cost by converting depth difference into relative difference
			double cost_d = 2*fabs((dj-di)/(di+dj));

			// 2. normal smoothness cost
			Matx31d faxj; faxj(2)=1;
			get_normal_givendrhxhy(fx,fy,nimgx0,nimgy0,dj,hxj,hyj,faxj(0),faxj(1));
			double nfaxj = norm(faxj);
			Matx<double,1,1> cosa = faxi_t*faxj;
			double tmp = cosa(0)/(nfaxi*nfaxj);
			if (tmp>1)
			{
				tmp=1;
			}
			if (tmp<-1)
			{
				tmp=-1;
			}
			double rad = acos(tmp); // 0-180
			double cost_n = rad*pi_1;

			// compute cost in total
			double cost = Lr_1[idxValid[j]] + P1*cost_d + P2*cost_n;
			vCost.push_back(cost);
		}

		iterDouble = min_element(vCost.begin(), vCost.end());
		double minCost = *iterDouble;

		// 3. the data term cost is finally summed
		Lr[i] = (1-score)+minCost-min_Lr_1;
	}
}

void DeepVoid::AugmentVisibility_basedonMostLikelyDepth(const cam_data & cam0,			// input:	EO and IO of reference image
													    const vector<cam_data> & vCams,	// input:	EO and IO of all support images
													    const Mat & img0,				// input:	reference image
													    const vector<Mat> & vDepths,	// input:	all depth map relative to reference wrt each support image
													    const vector<Mat> & vHxs,		// input:	all hx map relative to reference wrt each support image
													    const vector<Mat> & vHys,		// input:	all hy map relative to reference wrt each support image
													    const vector<Mat> & vScores,	// input:	all score map relative to reference wrt each support image
														const Mat & mSel,				// input:	selected best support image index for each pixel who generates the most likely depth with reference image
													    Mat & mVisi,					// output:	augmented visibility within support image set based on selected most likely depth
													    double thresh_sigma/* = 1*/		// input:	image coordinate threshold for grouping depths with the most likely depth
													    )
{
	int i,j,k;

	int nCam = vDepths.size();

	int w = img0.cols;
	int h = img0.rows;

	Matx33d mR0,mK0; Matx31d mt0;

	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mR0(i,j) = cam0.R[i*3+j];
		}
	}
	mK0(0,0) = cam0.fx;	mK0(0,1) = cam0.s;  mK0(0,2) = cam0.cx;
	mK0(1,1) = cam0.fy;	mK0(1,2) = cam0.cy; mK0(2,2) = 1;
	mt0(0) = cam0.t[0];	mt0(1) = cam0.t[1]; mt0(2) = cam0.t[2];

	double fx0_1 = 1/cam0.fx;
	double fy0_1 = 1/cam0.fy;

	vector<Matx33d> vRs,vKs; vector<Matx31d> vts; // for all support images
	vector<double> vfx_1, vfy_1; // for all support images

	for (k=0;k<nCam;k++)
	{
		Matx33d mR,mK; Matx31d mt;

		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR(i,j) = vCams[k].R[i*3+j];
			}
		}
		mK(0,0) = vCams[k].fx;	mK(0,1) = vCams[k].s;  mK(0,2) = vCams[k].cx;
		mK(1,1) = vCams[k].fy;	mK(1,2) = vCams[k].cy; mK(2,2) = 1;
		mt(0) = vCams[k].t[0];	mt(1) = vCams[k].t[1]; mt(2) = vCams[k].t[2];

		vRs.push_back(mR);
		vKs.push_back(mK);
		vts.push_back(mt);
		vfx_1.push_back(1/vCams[k].fx);
		vfy_1.push_back(1/vCams[k].fy);
	}

	Mat mVisiN(h, w, CV_8UC1);
	mVisi = Mat(h, w, CV_8UC1);

	for (i=0;i<h;i++)
	{
		double nimgy = (i-cam0.cy)*fy0_1;
		for (j=0;j<w;j++)
		{
			double nimgx = (j-cam0.cx)*fx0_1;

			vector<Point2d> imgPts; vector<Matx31d> wrdPts; vector<Matx33d> vKRs; vector<Matx31d> vKts;
			// we first compute corresponding image points of every depth values in its corresponding image
			for (k=0;k<nCam;k++)
			{
				double dk = vDepths[k].at<float>(i,j);
				Matx31d XYZ = GetXYZ_givenDepth(mR0,mt0,nimgx,nimgy,dk);
				// project
				Matx33d mKR = vKs[k]*vRs[k];
				Matx31d mKt = vKs[k]*vts[k];
				Matx31d mx = mKR*XYZ + mKt;
				double z_1 = 1/mx(2);

				Point2d pt2d;
				pt2d.x = mx(0)*z_1;
				pt2d.y = mx(1)*z_1;
				imgPts.push_back(pt2d);
				wrdPts.push_back(XYZ);
				vKRs.push_back(mKR);
				vKts.push_back(mKt);
			}

			// 
			uchar bestImg = mSel.at<uchar>(i,j);
			vector<bool> vbvisi(nCam);
			vbvisi[bestImg] = true;

			uchar visiN = 1;

			for (k=0;k<nCam;k++)
			{
				if (k==bestImg){continue;}

				// first check if kth depth point falls into best depth image radius
				Matx31d mx = vKRs[bestImg]*wrdPts[k] + vKts[bestImg];
				double z_1 = 1/mx(2);

				double dx = mx(0)*z_1-imgPts[bestImg].x;
				double dy = mx(1)*z_1-imgPts[bestImg].y;

				double d = sqrt(dx*dx+dy*dy);

				if (d<thresh_sigma)
				{
					vbvisi[k] = true;
					visiN++;
					continue;
				}

				// then check if best depth point falls into kth image radius
				mx = vKRs[k]*wrdPts[bestImg] + vKts[k];
				z_1 = 1/mx(2);

				dx = mx(0)*z_1-imgPts[k].x;
				dy = mx(1)*z_1-imgPts[k].y;

				d = sqrt(dx*dx+dy*dy);

				if (d<thresh_sigma)
				{
					vbvisi[k] = true;
					visiN++;
				} 
				else
				{
					vbvisi[k] = false;
				}
			}

			uchar visi = GetVisibilityVector_uchar(vbvisi);

			mVisi.at<uchar>(i,j) = visi;
			mVisiN.at<uchar>(i,j) = visiN;
		}
	}

	Mat mVisiN_map(h, w, CV_8UC3);

	vector<Mat> vVisi_map;
	for (k=0;k<nCam;k++)
	{
		Mat mtmp(h,w,CV_8UC3);
		vVisi_map.push_back(mtmp);
	}

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			uchar nnn = mVisiN.at<uchar>(i,j);
			uchar visi = mVisi.at<uchar>(i,j);

			if (nnn==0)
			{
				mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else if (nnn==1)
			{
				mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
				mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else if (nnn==2)
			{
				mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
				mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else if (nnn==3)
			{
				mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
				mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
			}
			else
			{
				mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
				mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
			}

			vector<bool> vbools;
			InterpVisiVector_uchar(visi, vbools);

			for (k=0;k<nCam;k++)
			{
				if (vbools[k])
				{
					vVisi_map[k].at<Vec3b>(i,j).val[0] = 0;
					vVisi_map[k].at<Vec3b>(i,j).val[1] = 0;
					vVisi_map[k].at<Vec3b>(i,j).val[2] = 255;
				} 
				else
				{
					vVisi_map[k].at<Vec3b>(i,j).val[0] = img0.at<Vec3b>(i,j).val[0];
					vVisi_map[k].at<Vec3b>(i,j).val[1] = img0.at<Vec3b>(i,j).val[1];
					vVisi_map[k].at<Vec3b>(i,j).val[2] = img0.at<Vec3b>(i,j).val[2];
				}
			}
		}
	}

	CString strInfo;

	strInfo.Format("D:\\all\\visi map augmented.bmp");
	imwrite(strInfo.GetBuffer(), mVisi);
	strInfo.Format("D:\\all\\visiN map augmented.bmp");
	imwrite(strInfo.GetBuffer(), mVisiN_map);

	for (k=0;k<nCam;k++)
	{
		strInfo.Format("D:\\all\\final visi map wrt support image %02d.bmp", k);
		imwrite(strInfo.GetBuffer(), vVisi_map[k]);
	}
}

void DeepVoid::AugmentVisibility_basedonMostLikelyDepth(const vector<Matx33d> & vKs,				// input:	all interior matrix
													    const vector<Matx33d> & vRs,				// input:	all rotation matrix
													    const vector<Matx31d> & vts,				// input:	all translation vectors
													    const vector<double> & vfx_1,				// input:	
													    const vector<double> & vfy_1,				// input:
													    const vector<Mat> & vImgs,					// input:	all images
													    const vector<vector<int>> & vIdxSupports,	// input:	all images' support images' index
													    int idx_ref,								// input:	the reference image index
													    const vector<Mat> & vDepths,				// input:	all depth map relative to reference wrt each support image
													    const vector<Mat> & vHxs,					// input:	all hx map relative to reference wrt each support image
													    const vector<Mat> & vHys,					// input:	all hy map relative to reference wrt each support image
													    const vector<Mat> & vScores,				// input:	all score map relative to reference wrt each support image
													    const Mat & mSel,							// input:	selected best support image index for each pixel who generates the most likely depth with reference image
													    Mat & mVisi,								// output:	augmented visibility within support image set based on selected most likely depth
													    double thresh_sigma /*= 1*/					// input:	image coordinate threshold for grouping depths with the most likely depth
													    )
{
	int i,j,k;

	vector<int> vIdx_spt = vIdxSupports[idx_ref];
	int nCam = vIdx_spt.size();

	int w = vImgs[idx_ref].cols;
	int h = vImgs[idx_ref].rows;

	double cx = vKs[idx_ref](0,2);
	double cy = vKs[idx_ref](1,2);

	Mat mVisiN(h, w, CV_8UC1);
	mVisi = Mat(h, w, CV_8UC1);

	for (i=0;i<h;i++)
	{
		double nimgy = (i-cy)*vfy_1[idx_ref];
		for (j=0;j<w;j++)
		{
			uchar bestImg = mSel.at<uchar>(i,j);
			double score_bst = vScores[bestImg].at<float>(i,j);
			if (score_bst<0)
			{
				// if the chosen best depth is invalid, then no need to augment visibility
				// because there are definately no other valid depths available
				mVisi.at<uchar>(i,j) = 0;
				mVisiN.at<uchar>(i,j) = 0;
				continue;
			}

			double nimgx = (j-cx)*vfx_1[idx_ref];

			vector<Point2d> imgPts; vector<Matx31d> wrdPts; vector<Matx33d> vKRs; vector<Matx31d> vKts;
			// we first compute corresponding image points of every depth values in its corresponding image
			for (k=0;k<nCam;k++)
			{
				double dk = vDepths[k].at<float>(i,j);
				Matx31d XYZ = GetXYZ_givenDepth(vRs[idx_ref],vts[idx_ref],nimgx,nimgy,dk);
				// project
				Matx33d mKR = vKs[vIdx_spt[k]]*vRs[vIdx_spt[k]];
				Matx31d mKt = vKs[vIdx_spt[k]]*vts[vIdx_spt[k]];
				Matx31d mx = mKR*XYZ + mKt;
				double z_1 = 1/mx(2);

				Point2d pt2d;
				pt2d.x = mx(0)*z_1;
				pt2d.y = mx(1)*z_1;
				imgPts.push_back(pt2d);
				wrdPts.push_back(XYZ);
				vKRs.push_back(mKR);
				vKts.push_back(mKt);
			}

			vector<bool> vbvisi(nCam);
			vbvisi[bestImg] = true;

			uchar visiN = 1;

			for (k=0;k<nCam;k++)
			{
				// if current checked image is the best image itself
				// or if it is a invalid depth, then continue, no need to cluster this depth
				if (k==bestImg){continue;}
				if (vScores[k].at<float>(i,j)<0){vbvisi[k]=false; continue;}

				// first check if kth depth point falls into best depth image radius
				Matx31d mx = vKRs[bestImg]*wrdPts[k] + vKts[bestImg];
				double z_1 = 1/mx(2);

				double dx = mx(0)*z_1-imgPts[bestImg].x;
				double dy = mx(1)*z_1-imgPts[bestImg].y;

				double d = sqrt(dx*dx+dy*dy);

				if (d<thresh_sigma)
				{
					vbvisi[k] = true;
					visiN++;
					continue;
				}

				// then check if best depth point falls into kth image radius
				mx = vKRs[k]*wrdPts[bestImg] + vKts[k];
				z_1 = 1/mx(2);

				dx = mx(0)*z_1-imgPts[k].x;
				dy = mx(1)*z_1-imgPts[k].y;

				d = sqrt(dx*dx+dy*dy);

				if (d<thresh_sigma)
				{
					vbvisi[k] = true;
					visiN++;
				} 
				else
				{
					vbvisi[k] = false;
				}
			}

			uchar visi = GetVisibilityVector_uchar(vbvisi);

			mVisi.at<uchar>(i,j) = visi;
			mVisiN.at<uchar>(i,j) = visiN;
		}
	}

	Mat mVisiN_map(h, w, CV_8UC3);

	vector<Mat> vVisi_map;
	for (k=0;k<nCam;k++)
	{
		Mat mtmp(h,w,CV_8UC3);
		vVisi_map.push_back(mtmp);
	}

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			uchar nnn = mVisiN.at<uchar>(i,j);
			uchar visi = mVisi.at<uchar>(i,j);

			if (nnn==0)
			{
				mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else if (nnn==1)
			{
				mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
				mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else if (nnn==2)
			{
				mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
				mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else if (nnn==3)
			{
				mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
				mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
			}
			else
			{
				mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
				mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
			}

			vector<bool> vbools;
			InterpVisiVector_uchar(visi, vbools);

			for (k=0;k<nCam;k++)
			{
				if (vbools[k])
				{
					vVisi_map[k].at<Vec3b>(i,j).val[0] = 0;
					vVisi_map[k].at<Vec3b>(i,j).val[1] = 0;
					vVisi_map[k].at<Vec3b>(i,j).val[2] = 255;
				} 
				else
				{
					vVisi_map[k].at<Vec3b>(i,j).val[0] = vImgs[idx_ref].at<Vec3b>(i,j).val[0];
					vVisi_map[k].at<Vec3b>(i,j).val[1] = vImgs[idx_ref].at<Vec3b>(i,j).val[1];
					vVisi_map[k].at<Vec3b>(i,j).val[2] = vImgs[idx_ref].at<Vec3b>(i,j).val[2];
				}
			}
		}
	}

	CString strInfo;

	strInfo.Format("D:\\all\\visi map %02d augmented.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mVisi);
	strInfo.Format("D:\\all\\visiN map %02d augmented.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mVisiN_map);

	for (k=0;k<nCam;k++)
	{
		strInfo.Format("D:\\all\\final visi map %02d wrt support image %02d.bmp", idx_ref, vIdx_spt[k]);
		imwrite(strInfo.GetBuffer(), vVisi_map[k]);
	}

	strInfo.Format("D:\\all\\visi map %02d.txt", idx_ref);
	FILE * file_visi = fopen(strInfo, "w");

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			fprintf(file_visi, "%d	", mVisi.at<uchar>(i,j));
		}
		fprintf(file_visi, "\n");
	}
	fclose(file_visi);
}

// 20140908, take into account not only the depth but also the normal
void DeepVoid::AugmentVisibility_basedonMostLikelyDepthandNormals(const vector<Matx33d> & vKs,				// input:	all interior matrix
																  const vector<Matx33d> & vRs,				// input:	all rotation matrix
																  const vector<Matx31d> & vts,				// input:	all translation vectors
																  const vector<double> & vfx_1,				// input:	
																  const vector<double> & vfy_1,				// input:
																  const vector<Mat> & vImgs,				// input:	all images
																  const vector<vector<int>> & vIdxSupports,	// input:	all images' support images' index
																  int idx_ref,								// input:	the reference image index
																  const vector<Mat> & vDepths,				// input:	all depth map relative to reference wrt each support image
																  const vector<Mat> & vHxs,					// input:	all hx map relative to reference wrt each support image
																  const vector<Mat> & vHys,					// input:	all hy map relative to reference wrt each support image
																  const vector<Mat> & vScores,				// input:	all score map relative to reference wrt each support image
																  const Mat & mSel,							// input:	selected best support image index for each pixel who generates the most likely depth with reference image
																  Mat & mVisi,								// output:	augmented visibility within support image set based on selected most likely depth
																  double thresh_sigma /*= 1*/,				// input:	image coordinate threshold for grouping depths with the most likely depth
																  double thresh_ang /*= 90*/				// input:
																  )
{
	int i,j,k;

	double cos_thresh_ang = cosd(thresh_ang);

	vector<int> vIdx_spt = vIdxSupports[idx_ref];
	int nCam = vIdx_spt.size();

	int w = vImgs[idx_ref].cols;
	int h = vImgs[idx_ref].rows;

	double fx = vKs[idx_ref](0,0);
	double fy = vKs[idx_ref](1,1);
	double cx = vKs[idx_ref](0,2);
	double cy = vKs[idx_ref](1,2);

	Mat mVisiN(h, w, CV_8UC1);
	mVisi = Mat(h, w, CV_8UC1);

	for (i=0;i<h;i++)
	{
		double nimgy = (i-cy)*vfy_1[idx_ref];
		for (j=0;j<w;j++)
		{
			uchar bestImg = mSel.at<uchar>(i,j);
			double score_bst = vScores[bestImg].at<float>(i,j);
			if (score_bst<0)
			{
				// if the chosen best depth is invalid, then no need to augment visibility
				// because there are definately no other valid depths available
				mVisi.at<uchar>(i,j) = 0;
				mVisiN.at<uchar>(i,j) = 0;
				continue;
			}

			double nimgx = (j-cx)*vfx_1[idx_ref];

			vector<Point2d> imgPts; vector<Matx31d> wrdPts; vector<Matx33d> vKRs; vector<Matx31d> vKts; vector<Matx31d> vNormals; vector<double> vfax_norm_1;
			// we first compute corresponding image points of every depth values in its corresponding image
			for (k=0;k<nCam;k++)
			{
				double dk = vDepths[k].at<float>(i,j);
				double hxk = vHxs[k].at<float>(i,j);
				double hyk = vHys[k].at<float>(i,j);

				Matx31d XYZ = GetXYZ_givenDepth(vRs[idx_ref],vts[idx_ref],nimgx,nimgy,dk);
				// project
				Matx33d mKR = vKs[vIdx_spt[k]]*vRs[vIdx_spt[k]];
				Matx31d mKt = vKs[vIdx_spt[k]]*vts[vIdx_spt[k]];
				Matx31d mx = mKR*XYZ + mKt;
				double z_1 = 1/mx(2);

				Point2d pt2d;
				pt2d.x = mx(0)*z_1;
				pt2d.y = mx(1)*z_1;
				imgPts.push_back(pt2d);
				wrdPts.push_back(XYZ);
				vKRs.push_back(mKR);
				vKts.push_back(mKt);

				// 20140908
				// compute the normal of the best estimate
				Matx31d faxk; faxk(2)=1;
				get_normal_givendrhxhy(fx, fy, nimgx, nimgy, dk, hxk, hyk, faxk(0), faxk(1));
				double nfaxk_1 = 1/norm(faxk);
				vNormals.push_back(faxk);
				vfax_norm_1.push_back(nfaxk_1);
			}

			Matx13d best_norm_t = vNormals[bestImg].t(); // n'

			vector<bool> vbvisi(nCam);
			vbvisi[bestImg] = true;

			uchar visiN = 1;

			for (k=0;k<nCam;k++)
			{
				// if current checked image is the best image itself
				// or if it is a invalid depth, then continue, no need to cluster this depth
				if (k==bestImg){continue;}
				if (vScores[k].at<float>(i,j)<0){vbvisi[k]=false; continue;}

				// we first check if current normal estimate is consistent with the best estimate or not
				Matx<double,1,1> cosa = best_norm_t * vNormals[k];
				double cosa_d = cosa(0)*vfax_norm_1[bestImg]*vfax_norm_1[k];
				if (cosa_d<cos_thresh_ang) // this means the angle between the best normal and current normal is bigger than certain threshold
				{
					vbvisi[k]=false; // current estimate is denied, because its normal estimate is not quite consistent with the extracted best one
					continue;
				}
				//////////////////////////////////////////////////////////////////////////

				// then we check if kth depth point falls into best depth image radius
				Matx31d mx = vKRs[bestImg]*wrdPts[k] + vKts[bestImg];
				double z_1 = 1/mx(2);

				double dx = mx(0)*z_1-imgPts[bestImg].x;
				double dy = mx(1)*z_1-imgPts[bestImg].y;

				double d = sqrt(dx*dx+dy*dy);

				if (d<thresh_sigma)
				{
					vbvisi[k] = true;
					visiN++;
					continue;
				}

				// then check if best depth point falls into kth image radius
				mx = vKRs[k]*wrdPts[bestImg] + vKts[k];
				z_1 = 1/mx(2);

				dx = mx(0)*z_1-imgPts[k].x;
				dy = mx(1)*z_1-imgPts[k].y;

				d = sqrt(dx*dx+dy*dy);

				if (d<thresh_sigma)
				{
					vbvisi[k] = true;
					visiN++;
				} 
				else
				{
					vbvisi[k] = false;
				}
			}

			uchar visi = GetVisibilityVector_uchar(vbvisi);

			mVisi.at<uchar>(i,j) = visi;
			mVisiN.at<uchar>(i,j) = visiN;
		}
	}

	Mat mVisiN_map(h, w, CV_8UC3);

	vector<Mat> vVisi_map;
	for (k=0;k<nCam;k++)
	{
		Mat mtmp(h,w,CV_8UC3);
		vVisi_map.push_back(mtmp);
	}

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			uchar nnn = mVisiN.at<uchar>(i,j);
			uchar visi = mVisi.at<uchar>(i,j);

			if (nnn==0)
			{
				mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else if (nnn==1)
			{
				mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
				mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else if (nnn==2)
			{
				mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
				mVisiN_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else if (nnn==3)
			{
				mVisiN_map.at<Vec3b>(i,j).val[0] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[1] = 255;
				mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
			}
			else
			{
				mVisiN_map.at<Vec3b>(i,j).val[0] = 255;
				mVisiN_map.at<Vec3b>(i,j).val[1] = 0;
				mVisiN_map.at<Vec3b>(i,j).val[2] = 0;
			}

			vector<bool> vbools;
			InterpVisiVector_uchar(visi, vbools);

			for (k=0;k<nCam;k++)
			{
				if (vbools[k])
				{
					vVisi_map[k].at<Vec3b>(i,j).val[0] = 0;
					vVisi_map[k].at<Vec3b>(i,j).val[1] = 0;
					vVisi_map[k].at<Vec3b>(i,j).val[2] = 255;
				} 
				else
				{
					vVisi_map[k].at<Vec3b>(i,j).val[0] = vImgs[idx_ref].at<Vec3b>(i,j).val[0];
					vVisi_map[k].at<Vec3b>(i,j).val[1] = vImgs[idx_ref].at<Vec3b>(i,j).val[1];
					vVisi_map[k].at<Vec3b>(i,j).val[2] = vImgs[idx_ref].at<Vec3b>(i,j).val[2];
				}
			}
		}
	}

	CString strInfo;

	strInfo.Format("D:\\all\\visi map %02d augmented.bmp", idx_ref);
//	imwrite(strInfo.GetBuffer(), mVisi);
	strInfo.Format("D:\\all\\visiN map %02d augmented.bmp", idx_ref);
//	imwrite(strInfo.GetBuffer(), mVisiN_map);

	for (k=0;k<nCam;k++)
	{
		strInfo.Format("D:\\all\\final visi map %02d wrt support image %02d.bmp", idx_ref, vIdx_spt[k]);
//		imwrite(strInfo.GetBuffer(), vVisi_map[k]);
	}

// 	strInfo.Format("D:\\all\\visi map %02d.txt", idx_ref);
// 	FILE * file_visi = fopen(strInfo, "w");
// 
// 	for (i=0;i<h;i++)
// 	{
// 		for (j=0;j<w;j++)
// 		{
// 			fprintf(file_visi, "%d	", mVisi.at<uchar>(i,j));
// 		}
// 		fprintf(file_visi, "\n");
// 	}
// 	fclose(file_visi);
}

// 20140914, self-contained version, take into account not only the depth but also the normal
void DeepVoid::AugmentVisibility_basedonMostLikelyDepthandNormals(const Matx33d & mK0,						// input:	interior matrix of the reference image
																  const Matx33d & mR0,						// input:	rotation matrix of the reference image
																  const Matx31d & mt0,						// input:	translation vector of the reference image
																  const vector<Matx33d> & vKs,				// input:	interior matrix of all support images
																  const vector<Matx33d> & vRs,				// input:	rotation matrix of all support images
																  const vector<Matx31d> & vts,				// input:	translation vectors of all support images
																  const vector<Mat> & vDepths,				// input:	all depth map relative to reference wrt each support image
																  const vector<Mat> & vHxs,					// input:	all hx map relative to reference wrt each support image
																  const vector<Mat> & vHys,					// input:	all hy map relative to reference wrt each support image
																  const vector<Mat> & vScores,				// input:	all score map relative to reference wrt each support image
																  const Mat & mSel,							// input:	selected best support image index for each pixel who generates the most likely depth with reference image
																  Mat & mVisi,								// output:	augmented visibility within support image set based on selected most likely depth
																  double thresh_sigma /*= 1*/,				// input:	image coordinate threshold for grouping depths with the most likely depth
																  double thresh_ang /*= 90*/				// input:
															 	  )
{
	int i,j,k;

	double cos_thresh_ang = cosd(thresh_ang);

	int n_spt = vKs.size();

	int w = vDepths[0].cols;
	int h = vDepths[0].rows;

	double fx0 = mK0(0,0);
	double fy0 = mK0(1,1);
	double fx0_1 = 1/fx0;
	double fy0_1 = 1/fy0;
	double cx0 = mK0(0,2);
	double cy0 = mK0(1,2);

	Mat mVisiN(h, w, CV_8UC1);
	mVisi = Mat(h, w, CV_8UC1);

	for (i=0;i<h;i++)
	{
		double nimgy0 = (i-cy0)*fy0_1;
		for (j=0;j<w;j++)
		{
			uchar bestImg = mSel.at<uchar>(i,j);
			double score_bst = vScores[bestImg].at<float>(i,j);
			if (score_bst<0)
			{
				// if the chosen best depth is invalid, then no need to augment visibility
				// because there are definately no other valid depths available
				mVisi.at<uchar>(i,j) = 0;
				mVisiN.at<uchar>(i,j) = 0;
				continue;
			}

			double nimgx0 = (j-cx0)*fx0_1;

			vector<Point2d> imgPts; vector<Matx31d> wrdPts; vector<Matx33d> vKRs; vector<Matx31d> vKts; vector<Matx31d> vNormals; vector<double> vfax_norm_1;
			// we first compute corresponding image points of every depth values in its corresponding image
			for (k=0;k<n_spt;k++)
			{
				double dk = vDepths[k].at<float>(i,j);
				double hxk = vHxs[k].at<float>(i,j);
				double hyk = vHys[k].at<float>(i,j);

				Matx31d XYZ = GetXYZ_givenDepth(mR0,mt0,nimgx0,nimgy0,dk);
				// project
				Matx33d mKR = vKs[k]*vRs[k];
				Matx31d mKt = vKs[k]*vts[k];
				Matx31d mx = mKR*XYZ + mKt;
				double z_1 = 1/mx(2);

				Point2d pt2d;
				pt2d.x = mx(0)*z_1;
				pt2d.y = mx(1)*z_1;
				imgPts.push_back(pt2d);
				wrdPts.push_back(XYZ);
				vKRs.push_back(mKR);
				vKts.push_back(mKt);

				// 20140908
				// compute the normal of the best estimate
				Matx31d faxk; faxk(2)=1;
				get_normal_givendrhxhy(fx0, fy0, nimgx0, nimgy0, dk, hxk, hyk, faxk(0), faxk(1));
				double nfaxk_1 = 1/norm(faxk);
				vNormals.push_back(faxk);
				vfax_norm_1.push_back(nfaxk_1);
			}

			Matx13d best_norm_t = vNormals[bestImg].t(); // n'

			vector<bool> vbvisi(n_spt);
			vbvisi[bestImg] = true;

			uchar visiN = 1;

			for (k=0;k<n_spt;k++)
			{
				// if current checked image is the best image itself
				// or if it is a invalid depth, then continue, no need to cluster this depth
				if (k==bestImg){continue;}
				if (vScores[k].at<float>(i,j)<0){vbvisi[k]=false; continue;}

				// we first check if current normal estimate is consistent with the best estimate or not
				Matx<double,1,1> cosa = best_norm_t * vNormals[k];
				double cosa_d = cosa(0)*vfax_norm_1[bestImg]*vfax_norm_1[k];
				if (cosa_d<cos_thresh_ang) // this means the angle between the best normal and current normal is bigger than certain threshold
				{
					vbvisi[k]=false; // current estimate is denied, because its normal estimate is not quite consistent with the extracted best one
					continue;
				}
				//////////////////////////////////////////////////////////////////////////

				// then we check if kth depth point falls into best depth image radius
				Matx31d mx = vKRs[bestImg]*wrdPts[k] + vKts[bestImg];
				double z_1 = 1/mx(2);

				double dx = mx(0)*z_1-imgPts[bestImg].x;
				double dy = mx(1)*z_1-imgPts[bestImg].y;

				double d = sqrt(dx*dx+dy*dy);

				if (d<thresh_sigma)
				{
					vbvisi[k] = true;
					visiN++;
					continue;
				}

				// then check if best depth point falls into kth image radius
				mx = vKRs[k]*wrdPts[bestImg] + vKts[k];
				z_1 = 1/mx(2);

				dx = mx(0)*z_1-imgPts[k].x;
				dy = mx(1)*z_1-imgPts[k].y;

				d = sqrt(dx*dx+dy*dy);

				if (d<thresh_sigma)
				{
					vbvisi[k] = true;
					visiN++;
				} 
				else
				{
					vbvisi[k] = false;
				}
			}

			uchar visi = GetVisibilityVector_uchar(vbvisi);

			mVisi.at<uchar>(i,j) = visi;
			mVisiN.at<uchar>(i,j) = visiN;
		}
	}
}

// 20141013, self-contained version, take into account not only the depth but also the normal
void DeepVoid::AugmentVisibility_basedonMostLikelyDepthandNormals_SURE(const Matx33d & mK0,						// input:	interior matrix of the reference image
																	   const Matx33d & mR0,						// input:	rotation matrix of the reference image
																	   const Matx31d & mt0,						// input:	translation vector of the reference image
																	   const vector<Matx33d> & vKs,				// input:	interior matrix of all support images
																	   const vector<Matx33d> & vRs,				// input:	rotation matrix of all support images
																	   const vector<Matx31d> & vts,				// input:	translation vectors of all support images
																	   const vector<Mat> & vDepths,				// input:	all depth map relative to reference wrt each support image
																	   const vector<Mat> & vHxs,				// input:	all hx map relative to reference wrt each support image
																	   const vector<Mat> & vHys,				// input:	all hy map relative to reference wrt each support image
																	   const vector<Mat> & vScores,				// input:	all score map relative to reference wrt each support image
																	   const Mat & mSel,						// input:	selected best support image index for each pixel who generates the most likely depth with reference image
																	   Mat & mVisi,								// output:	augmented visibility within support image set based on selected most likely depth
																	   double thresh_sigma /*= 1*/,				// input:	image coordinate threshold for grouping depths with the most likely depth
																	   double thresh_ang /*= 90*/				// input:
																	   )
{
	int i,j,k;

	double cos_thresh_ang = cosd(thresh_ang);

	int n_spt = vKs.size();

	int w = vDepths[0].cols;
	int h = vDepths[0].rows;

	double fx0 = mK0(0,0);
	double fy0 = mK0(1,1);
	double fx0_1 = 1/fx0;
	double fy0_1 = 1/fy0;
	double cx0 = mK0(0,2);
	double cy0 = mK0(1,2);

	Mat mVisiN(h, w, CV_8UC1);
	mVisi = Mat(h, w, CV_8UC1);

	for (i=0;i<h;i++)
	{
		double nimgy0 = (i-cy0)*fy0_1;
		for (j=0;j<w;j++)
		{
			uchar bestImg = mSel.at<uchar>(i,j);
			double score_bst = vScores[bestImg].at<float>(i,j);
			if (score_bst<0)
			{
				// if the chosen best depth is invalid, then no need to augment visibility
				// because there are definately no other valid depths available
				mVisi.at<uchar>(i,j) = 0;
				mVisiN.at<uchar>(i,j) = 0;
				continue;
			}

			double nimgx0 = (j-cx0)*fx0_1;

			Matx31d vNImg; // the normalized image point i.e. the direction of the line of sight
			vNImg(0) = nimgx0;
			vNImg(1) = nimgy0;
			vNImg(2) = 1;
			Matx31d vRrNImg = mR0.t()*vNImg;  // Rr'nx

			vector<Matx31d> vNormals; vector<double> vfax_norm_1;
			vector<double> vdmin, vdmax;

			// we first compute corresponding image points of every depth values in its corresponding image
			for (k=0;k<n_spt;k++)
			{
				double dk = vDepths[k].at<float>(i,j);
				double hxk = vHxs[k].at<float>(i,j);
				double hyk = vHys[k].at<float>(i,j);

				Matx31d XYZ = GetXYZ_givenDepth(mR0,mt0,nimgx0,nimgy0,dk);
				// project
				Matx33d mKR = vKs[k]*vRs[k];
				Matx31d mKt = vKs[k]*vts[k];
				Matx31d mx = mKR*XYZ + mKt;
				double z_1 = 1/mx(2);

				Matx31d a = mKR*vRrNImg;

				Point2d pt2d;
				pt2d.x = mx(0)*z_1;
				pt2d.y = mx(1)*z_1;
				
				double ddmin, ddmax;
				ComputeDepthUncertainBoundary(pt2d.x, pt2d.y, mx(2), a(0), a(1), a(2), ddmin, ddmax, thresh_sigma);
				double dmin = dk+ddmin;
				double dmax = dk+ddmax;
				vdmin.push_back(dmin);
				vdmax.push_back(dmax);

				// 20140908
				// compute the normal of the best estimate
				Matx31d faxk; faxk(2)=1;
				get_normal_givendrhxhy(fx0, fy0, nimgx0, nimgy0, dk, hxk, hyk, faxk(0), faxk(1));
				double nfaxk_1 = 1/norm(faxk);
				vNormals.push_back(faxk);
				vfax_norm_1.push_back(nfaxk_1);
			}

			Matx13d best_norm_t = vNormals[bestImg].t(); // n'

			vector<bool> vbvisi(n_spt);
			vbvisi[bestImg] = true;

			uchar visiN = 1;

			for (k=0;k<n_spt;k++)
			{
				// if current checked image is the best image itself
				// or if it is a invalid depth, then continue, no need to cluster this depth
				if (k==bestImg){continue;}
				if (vScores[k].at<float>(i,j)<0){vbvisi[k]=false; continue;}

				// we first check if current normal estimate is consistent with the best estimate or not
				Matx<double,1,1> cosa = best_norm_t * vNormals[k];
				double cosa_d = cosa(0)*vfax_norm_1[bestImg]*vfax_norm_1[k];
				if (cosa_d<cos_thresh_ang) // this means the angle between the best normal and current normal is bigger than certain threshold
				{
					vbvisi[k]=false; // current estimate is denied, because its normal estimate is not quite consistent with the extracted best one
					continue;
				}
				//////////////////////////////////////////////////////////////////////////

				// then we check if kth uncertainty range overlap the most likely uncertainty range or not
				if (vdmin[bestImg]>vdmax[k] || vdmin[k]>vdmax[bestImg])
				{
					vbvisi[k] = false; // no overlap
				} 
				else
				{
					vbvisi[k] = true; // overlaps
					visiN++;
				}
			}

			uchar visi = GetVisibilityVector_uchar(vbvisi);

			mVisi.at<uchar>(i,j) = visi;
			mVisiN.at<uchar>(i,j) = visiN;
		}
	}
}

// 20141218, self-contained version, take into account not only the depth but also the normal
// one support image produce multiple candidates from different scale
// given dij denoting depth map generated from ith pyramid level with jth support image
// the depth maps in input vDepths are arranged as [d00 | d01 | d10 | d11 | d20 | d21 | d30 | d31]
void DeepVoid::AugmentVisibility_basedonMostLikelyDepthandNormals_SURE_MultiScales(const Matx33d & mK0,			// input:	interior matrix of the reference image
																				   const Matx33d & mR0,			// input:	rotation matrix of the reference image
																				   const Matx31d & mt0,			// input:	translation vector of the reference image
																				   const vector<Matx33d> & vKs,	// input:	interior matrix of all support images
																				   const vector<Matx33d> & vRs,	// input:	rotation matrix of all support images
																				   const vector<Matx31d> & vts,	// input:	translation vectors of all support images
																				   const vector<Mat> & vDepths,	// input:	all depth map relative to reference wrt each support image
																				   const vector<Mat> & vHxs,	// input:	all hx map relative to reference wrt each support image
																				   const vector<Mat> & vHys,	// input:	all hy map relative to reference wrt each support image
																				   const vector<Mat> & vScores,	// input:	all score map relative to reference wrt each support image
																				   const Mat & mSel,			// input:	selected best support image index for each pixel who generates the most likely depth with reference image
																				   Mat & mVisi,					// output:	augmented visibility within support image set based on selected most likely depth
																				   double thresh_sigma /*= 1*/,	// input:	image coordinate threshold for grouping depths with the most likely depth
																				   double thresh_ang /*= 90*/	// input:
																				   )
{
	int i,j,k;

	double cos_thresh_ang = cosd(thresh_ang);

	int n_spt = vKs.size(); // total number of support images

	int n_candidates = vDepths.size(); // total number of candidates

	int n_level = n_candidates/n_spt; // total number of scales

	int w = vDepths[0].cols;
	int h = vDepths[0].rows;

	double fx0 = mK0(0,0);
	double fy0 = mK0(1,1);
	double fx0_1 = 1/fx0;
	double fy0_1 = 1/fy0;
	double cx0 = mK0(0,2);
	double cy0 = mK0(1,2);

	Mat mVisiN(h, w, CV_8UC1);
	mVisi = Mat(h, w, CV_8UC1);

	for (i=0;i<h;i++)
	{
		double nimgy0 = (i-cy0)*fy0_1;
		for (j=0;j<w;j++)
		{
			uchar bestImg = mSel.at<uchar>(i,j);
			double score_bst = vScores[bestImg].at<float>(i,j);
			if (score_bst<0)
			{
				// if the chosen best depth is invalid, then no need to augment visibility
				// because there are definately no other valid depths available
				mVisi.at<uchar>(i,j) = 0;
				mVisiN.at<uchar>(i,j) = 0;
				continue;
			}

			double nimgx0 = (j-cx0)*fx0_1;

			Matx31d vNImg; // the normalized image point i.e. the direction of the line of sight
			vNImg(0) = nimgx0;
			vNImg(1) = nimgy0;
			vNImg(2) = 1;
			Matx31d vRrNImg = mR0.t()*vNImg;  // Rr'nx

			vector<Matx31d> vNormals; vector<double> vfax_norm_1;
			vector<double> vdmin, vdmax;

			// we first compute corresponding image points of every depth values in its corresponding image
			for (k=0;k<n_candidates;k++)
			{
				int idxSpt = k%n_spt;				

				double dk = vDepths[k].at<float>(i,j);
				double hxk = vHxs[k].at<float>(i,j);
				double hyk = vHys[k].at<float>(i,j);

				Matx31d XYZ = GetXYZ_givenDepth(mR0,mt0,nimgx0,nimgy0,dk);
				// project
				Matx33d mKR = vKs[idxSpt]*vRs[idxSpt];
				Matx31d mKt = vKs[idxSpt]*vts[idxSpt];
				Matx31d mx = mKR*XYZ + mKt;
				double z_1 = 1/mx(2);

				Matx31d a = mKR*vRrNImg;

				Point2d pt2d;
				pt2d.x = mx(0)*z_1;
				pt2d.y = mx(1)*z_1;

				double ddmin, ddmax;
				ComputeDepthUncertainBoundary(pt2d.x, pt2d.y, mx(2), a(0), a(1), a(2), ddmin, ddmax, thresh_sigma);
				double dmin = dk+ddmin;
				double dmax = dk+ddmax;
				vdmin.push_back(dmin);
				vdmax.push_back(dmax);

				// 20140908
				// compute the normal of the best estimate
				Matx31d faxk; faxk(2)=1;
				get_normal_givendrhxhy(fx0, fy0, nimgx0, nimgy0, dk, hxk, hyk, faxk(0), faxk(1));
				double nfaxk_1 = 1/norm(faxk);
				vNormals.push_back(faxk);
				vfax_norm_1.push_back(nfaxk_1);
			}

			Matx13d best_norm_t = vNormals[bestImg].t(); // n'

			vector<bool> vbvisi(n_spt);
			for (k=0;k<n_spt;k++){vbvisi[k] = false;}
			int idxSpt = bestImg%n_spt;
			vbvisi[idxSpt] = true;

			uchar visiN = 1;

			for (k=0;k<n_candidates;k++)
			{
				// if current checked image is the best image itself
				// or if it is a invalid depth, then continue, no need to cluster this depth
				if (k==bestImg){continue;}
				if (vScores[k].at<float>(i,j)<0){continue;}

				// we first check if current normal estimate is consistent with the best estimate or not
				Matx<double,1,1> cosa = best_norm_t * vNormals[k];
				double cosa_d = cosa(0)*vfax_norm_1[bestImg]*vfax_norm_1[k];
				if (cosa_d<cos_thresh_ang) // this means the angle between the best normal and current normal is bigger than certain threshold
				{
					continue;
				}
				//////////////////////////////////////////////////////////////////////////

				// then we check if kth uncertainty range overlap the most likely uncertainty range or not
				if (vdmin[bestImg]>vdmax[k] || vdmin[k]>vdmax[bestImg])
				{
					continue; // no overlap
				} 
				else
				{
					idxSpt = k%n_spt; // index of currently checked support image
					if (!vbvisi[idxSpt])
					{
						vbvisi[idxSpt] = true; // overlaps
						visiN++;
					}
				}
			}

			uchar visi = GetVisibilityVector_uchar(vbvisi);

			mVisi.at<uchar>(i,j) = visi;
			mVisiN.at<uchar>(i,j) = visiN;
		}
	}
}

// 20140904, visibility determined, then start depth fusion or optimization by taking account all observations
void DeepVoid::DepthFusion_minimizingProjErrors(const vector<Matx33d> & vKs,				// input:	all interior matrix
											    const vector<Matx33d> & vRs,				// input:	all rotation matrix
											    const vector<Matx31d> & vts,				// input:	all translation vectors
											    const vector<double> & vfx_1,				// input:	
											    const vector<double> & vfy_1,				// input:
												const vector<Mat> & vImgs,					// input:	all images
											    const vector<vector<int>> & vIdxSupports,	// input:	all images' support images' index
											    int idx_ref,								// input:	the reference image index
											    const vector<Mat> & vDepths,				// input:	all depth map relative to reference wrt each support image
											    const vector<Mat> & vHxs,					// input:	all hx map relative to reference wrt each support image
											    const vector<Mat> & vHys,					// input:	all hy map relative to reference wrt each support image
											    const vector<Mat> & vScores,				// input:	all score map relative to reference wrt each support image
											    const Mat & mSel,							// input:	selected best support image index for each pixel who generates the most likely depth with reference image
											    const Mat & mVisi,							// input:	augmented visibility within support image set based on selected most likely depth
											    Mat & mDepth,								// output:	fused depths
											    Mat & mHx,									// output:	fused hxs
											    Mat & mHy,									// output:	fused hys
											    Mat & mScore,								// output:	fused scores
												int maxIter /*= 128*/,
												double xEps /*= 1.0E-8*/,					// input: threshold
												double fEps /*= 1.0E-6*/					// input: threshold
											    )
{
	int i,j,k;

	int w = vDepths[0].cols;
	int h = vDepths[0].rows;

	vector<int> vIdx_spts = vIdxSupports[idx_ref];

	double cx = vKs[idx_ref](0,2);
	double cy = vKs[idx_ref](1,2);
	double fx_1 = vfx_1[idx_ref];
	double fy_1 = vfy_1[idx_ref];

	mDepth = Mat(h, w, CV_32FC1);
	mHx = Mat(h, w, CV_32FC1);
	mHy = Mat(h, w, CV_32FC1);
	mScore = Mat(h, w, CV_32FC1);

	CString strInfo;

	for (i=0;i<h;i++)
	{
		strInfo.Format("fuse row %04d of image %02d", i, idx_ref);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		double nimgy = (i-cy)*fy_1;

		for (j=0;j<w;j++)
		{
			double nimgx = (j-cx)*fx_1;

			int idx_sel = mSel.at<uchar>(i,j);

			uchar visi = mVisi.at<uchar>(i,j);
			vector<bool> vbools; int nVisi;
			InterpVisiVector_uchar(visi, vbools, &nVisi);

			if (nVisi<2) // at least 2 observations, or there is obviously no need
			{
				mDepth.at<float>(i,j) = vDepths[idx_sel].at<float>(i,j);
				mHx.at<float>(i,j) = vHxs[idx_sel].at<float>(i,j);
				mHy.at<float>(i,j) = vHys[idx_sel].at<float>(i,j);
				mScore.at<float>(i,j) = vScores[idx_sel].at<float>(i,j);
				continue;
			}

			vector<Matx33d> vKs_visi, vRs_visi;
			vector<Matx31d> vts_visi;
			vector<double> vds;

			for (k=0;k<vIdx_spts.size();k++)
			{
				if (vbools[k])
				{
					vKs_visi.push_back(vKs[vIdx_spts[k]]);
					vRs_visi.push_back(vRs[vIdx_spts[k]]);
					vts_visi.push_back(vts[vIdx_spts[k]]);
					vds.push_back(vDepths[k].at<float>(i,j));
				}
			}

			double depth_optim;
			optim_gn_depth_minimizingProjError(vRs[idx_ref], vts[idx_ref], vKs_visi, vRs_visi, vts_visi, vds, nimgx, nimgy, depth_optim, maxIter, xEps, fEps);

			// hx hy adopt the mean values
			double sum_hx = 0;
			double sum_hy = 0;

			for (k=0;k<vIdx_spts.size();k++)
			{
				if (vbools[k])
				{
					sum_hx += vHxs[k].at<float>(i,j);
					sum_hy += vHys[k].at<float>(i,j);
				}
			}

			double hx_optim = sum_hx/nVisi;
			double hy_optim = sum_hy/nVisi;

			mDepth.at<float>(i,j) = depth_optim;
			mHx.at<float>(i,j) = hx_optim;
			mHy.at<float>(i,j) = hy_optim;
			mScore.at<float>(i,j) = vScores[idx_sel].at<float>(i,j);
		}
	}

	Mat mDepth_map, mHx_map, mHy_map, mScore_map(h, w, CV_8UC3);

	double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

	minMaxIdx(mDepth, &min_depth, &max_depth);
	minMaxIdx(mHx, &min_incre_x, &max_incre_x);
	minMaxIdx(mHy, &min_incre_y, &max_incre_y);

	mDepth.convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
	mHx.convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
	mHy.convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			if (mScore.at<float>(i,j)<0)
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = 0;
				mScore_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
				mScore_map.at<Vec3b>(i,j).val[2] = 0;
			}
		}
	}

	strInfo.Format("D:\\all\\depth map %02d fused.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mDepth_map);
	strInfo.Format("D:\\all\\hx map %02d fused.bmp", idx_ref);
//	imwrite(strInfo.GetBuffer(), mHx_map);
	strInfo.Format("D:\\all\\hy map %02d fused.bmp", idx_ref);
//	imwrite(strInfo.GetBuffer(), mHy_map);
	strInfo.Format("D:\\all\\score map %02d fused.bmp", idx_ref);
//	imwrite(strInfo.GetBuffer(), mScore_map);

	Mat mNormColor;
	GetNormColorField(vKs[idx_ref],vRs[idx_ref],vts[idx_ref],1/vKs[idx_ref](0,0),1/vKs[idx_ref](1,1),mDepth,mHx,mHy,mNormColor);
	strInfo.Format("D:\\all\\normcolor map %02d fused.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mNormColor);

	strInfo.Format("D:\\all\\cloud points %02d fused.txt", idx_ref);
	OutputPointCloud(strInfo,vKs[idx_ref],vRs[idx_ref],vts[idx_ref],1/vKs[idx_ref](0,0),1/vKs[idx_ref](1,1),vImgs[idx_ref],mDepth,mHx,mHy,mScore);
}

// 20140913, self-contained version, visibility determined, then start depth fusion or optimization by taking account all observations
void DeepVoid::DepthFusion_minimizingProjErrors(const Matx33d & mK0,			// input:	interior matrix of reference image
											    const Matx33d & mR0,			// input:	rotation matrix of reference image
											    const Matx31d & mt0,			// input:	translation vector of reference image
											    const vector<Matx33d> & vKs,	// input:	interior matrix of all support images
											    const vector<Matx33d> & vRs,	// input:	rotation matrix of all support images
											    const vector<Matx31d> & vts,	// input:	translation vectors of all support images
											    const vector<Mat> & vDepths,	// input:	all depth map relative to reference wrt each support image
											    const vector<Mat> & vHxs,		// input:	all hx map relative to reference wrt each support image
											    const vector<Mat> & vHys,		// input:	all hy map relative to reference wrt each support image
											    const vector<Mat> & vScores,	// input:	all score map relative to reference wrt each support image
											    const Mat & mSel,				// input:	selected best support image index for each pixel who generates the most likely depth with reference image
											    const Mat & mVisi,				// input:	augmented visibility within support image set based on selected most likely depth
											    Mat & mDepth,					// output:	fused depths
											    Mat & mHx,						// output:	fused hxs
											    Mat & mHy,						// output:	fused hys
											    Mat & mScore,					// output:	fused scores
											    int maxIter/* = 128*/,
											    double xEps /*= 1.0E-8*/,		// input: threshold
											    double fEps/* = 1.0E-6*/		// input: threshold
											    )
{
	int i,j,k;

	int w = vDepths[0].cols;
	int h = vDepths[0].rows;

	int n_spt = vDepths.size(); // number of support images

	double fx0_1 = 1/mK0(0,0);
	double fy0_1 = 1/mK0(1,1);
	double cx0 = mK0(0,2);
	double cy0 = mK0(1,2);

	mDepth = Mat(h, w, CV_32FC1);
	mHx = Mat(h, w, CV_32FC1);
	mHy = Mat(h, w, CV_32FC1);
	mScore = Mat(h, w, CV_32FC1);

	for (i=0;i<h;i++)
	{
		double nimgy0 = (i-cy0)*fy0_1;

		for (j=0;j<w;j++)
		{
			double nimgx0 = (j-cx0)*fx0_1;

			int idx_sel = mSel.at<uchar>(i,j);

			uchar visi = mVisi.at<uchar>(i,j);
			vector<bool> vbools; int nVisi;
			InterpVisiVector_uchar(visi, vbools, &nVisi);

			if (nVisi<2) // at least 2 observations, or there is obviously no need
			{
				mDepth.at<float>(i,j) = vDepths[idx_sel].at<float>(i,j);
				mHx.at<float>(i,j) = vHxs[idx_sel].at<float>(i,j);
				mHy.at<float>(i,j) = vHys[idx_sel].at<float>(i,j);
				mScore.at<float>(i,j) = vScores[idx_sel].at<float>(i,j);
				continue;
			}

			vector<Matx33d> vKs_visi, vRs_visi;
			vector<Matx31d> vts_visi;
			vector<double> vds;

			for (k=0;k<n_spt;k++)
			{
				if (vbools[k])
				{
					vKs_visi.push_back(vKs[k]);
					vRs_visi.push_back(vRs[k]);
					vts_visi.push_back(vts[k]);
					vds.push_back(vDepths[k].at<float>(i,j));
				}
			}

			double depth_optim;
			optim_gn_depth_minimizingProjError(mR0, mt0, vKs_visi, vRs_visi, vts_visi, vds, nimgx0, nimgy0, depth_optim, maxIter, xEps, fEps);

			// hx hy adopt the mean values
			double sum_hx = 0;
			double sum_hy = 0;

			for (k=0;k<n_spt;k++)
			{
				if (vbools[k])
				{
					sum_hx += vHxs[k].at<float>(i,j);
					sum_hy += vHys[k].at<float>(i,j);
				}
			}

			double hx_optim = sum_hx/nVisi;
			double hy_optim = sum_hy/nVisi;

			mDepth.at<float>(i,j) = depth_optim;
			mHx.at<float>(i,j) = hx_optim;
			mHy.at<float>(i,j) = hy_optim;
			mScore.at<float>(i,j) = vScores[idx_sel].at<float>(i,j);
		}
	}
}

// 20140905, visibility determined, use the mean values of depth,hx and hy as initial values to optimize final depth and normal by MPGC
void DeepVoid::MPGC_20140905(const vector<Matx33d> & vKs,				// input:	all interior matrix
						     const vector<Matx33d> & vRs,				// input:	all rotation matrix
						     const vector<Matx31d> & vts,				// input:	all translation vectors
						     const vector<double> & vfx_1,				// input:	
						     const vector<double> & vfy_1,				// input:
						     const vector<Mat> & vImgs,					// input:	all images
						     const vector<vector<int>> & vIdxSupports,	// input:	all images' support images' index
						     int idx_ref,								// input:	the reference image index
						     const vector<Mat> & vDepths,				// input:	all depth map relative to reference wrt each support image
						     const vector<Mat> & vHxs,					// input:	all hx map relative to reference wrt each support image
						     const vector<Mat> & vHys,					// input:	all hy map relative to reference wrt each support image
						     const vector<Mat> & vScores,				// input:	all score map relative to reference wrt each support image
						     const Mat & mSel,							// input:	selected best support image index for each pixel who generates the most likely depth with reference image
						     const Mat & mVisi,							// input:	augmented visibility within support image set based on selected most likely depth
						     Mat & mDepth,								// output:	optimized depths
						     Mat & mHx,									// output:	optimized hxs
						     Mat & mHy,									// output:	optimized hys
						     Mat & mScore,								// output:	optimized scores
							 int pw,									// input:	image patch width
							 int ph,									// input:	image patch height
						     int maxIter /*= 128*/,
						     double xEps /*= 1.0E-8*/,					// input: threshold
						     double fEps /*= 1.0E-6*/					// input: threshold
						     )
{
	int i,j,k;

	int w = vDepths[0].cols;
	int h = vDepths[0].rows;

	int hpw = (pw-1)*0.5; // half patch width
	int hph = (ph-1)*0.5; // half patch height

	double min_depth, max_depth;
	minMaxIdx(vDepths[0], &min_depth, &max_depth);

	vector<int> vIdx_spts = vIdxSupports[idx_ref];

	mDepth = Mat(h, w, CV_32FC1);
	mHx = Mat(h, w, CV_32FC1);
	mHy = Mat(h, w, CV_32FC1);
	mScore = Mat(h, w, CV_32FC1);

	CString strInfo;

	for (i=0;i<h;i++)
	{
		strInfo.Format("MPGC-optimizing row %04d of image %02d", i, idx_ref);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		for (j=0;j<w;j++)
		{
			int idx_sel = mSel.at<uchar>(i,j);

			uchar visi = mVisi.at<uchar>(i,j);
			vector<bool> vbools; int nVisi;
			InterpVisiVector_uchar(visi, vbools, &nVisi);

			if (nVisi<1) // there got be at least 1 observation to start MPGC optimization
			{
				mDepth.at<float>(i,j) = vDepths[idx_sel].at<float>(i,j);
				mHx.at<float>(i,j) = vHxs[idx_sel].at<float>(i,j);
				mHy.at<float>(i,j) = vHys[idx_sel].at<float>(i,j);
				mScore.at<float>(i,j) = vScores[idx_sel].at<float>(i,j);
				continue;
			}

			double sum_depth = 0;
			double sum_hx = 0;
			double sum_hy = 0;
			double sum_score = 0;
			for (k=0;k<vIdx_spts.size();k++)
			{
				if (vbools[k])
				{
					sum_depth+=vDepths[k].at<float>(i,j);
					sum_hx += vHxs[k].at<float>(i,j);
					sum_hy += vHys[k].at<float>(i,j);
					sum_score += vScores[k].at<float>(i,j);
				}
			}

			double nVisi_1 = 1.0/nVisi; // have to be 1.0/nVisi, not 1/nVisi, or nVisi_1 will be 0.
			double depth_init = sum_depth*nVisi_1;	// initial depth is the mean value of multiple observations
			double hx_init = sum_hx*nVisi_1;		// initial hx is the mean value of multiple observations
			double hy_init = sum_hy*nVisi_1;		// initial hy is the mean value of multiple observations 
			double score_init = sum_score*nVisi_1;	// initial ncc value is the mean value of multiple observations

			int i_real, j_real;
			MakeSureNotOutBorder(j,i,j_real,i_real,hpw,w,h);

			double depth_optim, hx_optim, hy_optim, score_optim;

			optim_gn_drhxhyck_NCCcontrolled(vKs,vRs,vts,vfx_1,vfy_1,vImgs,vIdxSupports,idx_ref,j_real,i_real,visi,pw,ph,
				depth_init,hx_init,hy_init,score_init,depth_optim,hx_optim,hy_optim,score_optim,maxIter,xEps,fEps);

			// the optimized depth must be within certain range, or all parameters are mean values
			if (depth_optim>min_depth && depth_optim<max_depth)
			{
				mDepth.at<float>(i,j) = depth_optim;
				mHx.at<float>(i,j) = hx_optim;
				mHy.at<float>(i,j) = hy_optim;
				mScore.at<float>(i,j) = score_optim;
			}
			else
			{
				mDepth.at<float>(i,j) = depth_init;
				mHx.at<float>(i,j) = hx_init;
				mHy.at<float>(i,j) = hy_init;
				mScore.at<float>(i,j) = score_init;
			}
		}
	}

	Mat mDepth_map, mHx_map, mHy_map, mScore_map(h, w, CV_8UC3);

	double min_incre_x, max_incre_x, min_incre_y, max_incre_y;

	minMaxIdx(mDepth, &min_depth, &max_depth);
	minMaxIdx(mHx, &min_incre_x, &max_incre_x);
	minMaxIdx(mHy, &min_incre_y, &max_incre_y);

	mDepth.convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
	mHx.convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
	mHy.convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			if (mScore.at<float>(i,j)<0)
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = 0;
				mScore_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
				mScore_map.at<Vec3b>(i,j).val[2] = 0;
			}
		}
	}

	strInfo.Format("D:\\all\\depth map %02d MPGC-optimized.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mDepth_map);
	strInfo.Format("D:\\all\\hx map %02d MPGC-optimized.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mHx_map);
	strInfo.Format("D:\\all\\hy map %02d MPGC-optimized.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mHy_map);
	strInfo.Format("D:\\all\\score map %02d MPGC-optimized.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mScore_map);

	Mat mNormColor;
	GetNormColorField(vKs[idx_ref],vRs[idx_ref],vts[idx_ref],1/vKs[idx_ref](0,0),1/vKs[idx_ref](1,1),mDepth,mHx,mHy,mNormColor);
	strInfo.Format("D:\\all\\normcolor map %02d MPGC-optimized.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mNormColor);

	strInfo.Format("D:\\all\\cloud points %02d MPGC-optimized.txt", idx_ref);
	OutputPointCloud(strInfo,vKs[idx_ref],vRs[idx_ref],vts[idx_ref],1/vKs[idx_ref](0,0),1/vKs[idx_ref](1,1),vImgs[idx_ref],mDepth,mHx,mHy,mScore);
}

// 20140910, visibility determined, use the mean values of depth,hx and hy as initial values to optimize final depth and normal by MPGC
void DeepVoid::MPGC_20140910(const vector<Matx33d> & vKs,				// input:	all interior matrix
						     const vector<Matx33d> & vRs,				// input:	all rotation matrix
						     const vector<Matx31d> & vts,				// input:	all translation vectors
						     const vector<double> & vfx_1,				// input:	
						     const vector<double> & vfy_1,				// input:
						     const vector<Mat> & vImgs,					// input:	all images
						     const vector<vector<int>> & vIdxSupports,	// input:	all images' support images' index
						     int idx_ref,								// input:	the reference image index
						     const vector<Mat> & vDepths,				// input:	all depth map relative to reference wrt each support image
						     const vector<Mat> & vHxs,					// input:	all hx map relative to reference wrt each support image
						     const vector<Mat> & vHys,					// input:	all hy map relative to reference wrt each support image
						     const vector<Mat> & vScores,				// input:	all score map relative to reference wrt each support image
							 const Mat & mDepth_ML,
							 const Mat & mHx_ML,
							 const Mat & mHy_ML,
						     const Mat & mSel,							// input:	selected best support image index for each pixel who generates the most likely depth with reference image
						     const Mat & mVisi,							// input:	augmented visibility within support image set based on selected most likely depth
						     Mat & mDepth,								// output:	optimized depths
						     Mat & mHx,									// output:	optimized hxs
						     Mat & mHy,									// output:	optimized hys
						     Mat & mScore,								// output:	optimized scores
							 int pw,									// input:	image patch width
							 int ph,									// input:	image patch height
							 double ratio /*= 0.01*/,
						     int maxIter /*= 128*/,
						     double xEps /*= 1.0E-8*/,					// input: threshold
						     double fEps /*= 1.0E-6*/					// input: threshold
						     )
{
	int i,j,k,ii,jj;

	int w = vDepths[0].cols;
	int h = vDepths[0].rows;

	int hpw = (pw-1)*0.5; // half patch width
	int hph = (ph-1)*0.5; // half patch height

	double min_depth, max_depth;
	minMaxIdx(vDepths[0], &min_depth, &max_depth);

	vector<int> vIdx_spts = vIdxSupports[idx_ref];

	vector<Mat> vVisis;
	for (k=0;k<vIdx_spts.size();k++)
	{
		Mat mBvisi(h,w,CV_8UC1,Scalar(0));
		vVisis.push_back(mBvisi);
	}

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			uchar visi = mVisi.at<uchar>(i,j);
			vector<bool> vbools;
			InterpVisiVector_uchar(visi, vbools);

			for (k=0;k<vIdx_spts.size();k++)
			{
				if (vbools[k])
				{
					vVisis[k].at<uchar>(i,j) = 1;
				}
			}
		}
	}

	mDepth = Mat(h, w, CV_32FC1);
	mHx = Mat(h, w, CV_32FC1);
	mHy = Mat(h, w, CV_32FC1);
	mScore = Mat(h, w, CV_32FC1);

	CString strInfo;

	for (i=0;i<h;i++)
	{
		strInfo.Format("MPGC-optimizing row %04d of image %02d", i, idx_ref);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		for (j=0;j<w;j++)
		{
			int idx_sel = mSel.at<uchar>(i,j);

			uchar visi = mVisi.at<uchar>(i,j);
			vector<bool> vbools; int nVisi;
			InterpVisiVector_uchar(visi, vbools, &nVisi);

			if (nVisi<1) // there got be at least 1 observation to start MPGC optimization
			{
				mDepth.at<float>(i,j) = vDepths[idx_sel].at<float>(i,j);
				mHx.at<float>(i,j) = vHxs[idx_sel].at<float>(i,j);
				mHy.at<float>(i,j) = vHys[idx_sel].at<float>(i,j);
				mScore.at<float>(i,j) = vScores[idx_sel].at<float>(i,j);
				continue;
			}

			double sum_depth = 0;
			double sum_hx = 0;
			double sum_hy = 0;
			double sum_score = 0;
			for (k=0;k<vIdx_spts.size();k++)
			{
				if (vbools[k])
				{
					sum_depth+=vDepths[k].at<float>(i,j);
					sum_hx += vHxs[k].at<float>(i,j);
					sum_hy += vHys[k].at<float>(i,j);
					sum_score += vScores[k].at<float>(i,j);
				}
			}

			double nVisi_1 = 1.0/nVisi; // have to be 1.0/nVisi, not 1/nVisi, or nVisi_1 will be 0.
			double depth_init = sum_depth*nVisi_1;	// initial depth is the mean value of multiple observations
			double hx_init = sum_hx*nVisi_1;		// initial hx is the mean value of multiple observations
			double hy_init = sum_hy*nVisi_1;		// initial hy is the mean value of multiple observations 
// 			double depth_init = mDepth_ML.at<float>(i,j);	// initial depth is the most likely value
// 			double hx_init = mHx_ML.at<float>(i,j);		// initial hx is the most likely value
// 			double hy_init = mHy_ML.at<float>(i,j);		// initial hy is the most likely value
			double score_init = sum_score*nVisi_1;	// initial ncc value is the mean value of multiple observations

			int i_real, j_real;
			MakeSureNotOutBorder(j,i,j_real,i_real,hpw,w,h);

			//////////////////////////////////////////////////////////////////////////
			Mat mD_patch(mDepth_ML,cv::Rect(j_real-hpw, i_real-hph, pw, ph));
			
			Mat mOut; int nValid;
			Clustering_depth_4(mD_patch,hpw,hph,mOut,nValid,ratio);

			vector<Mat> vMasks; vector<int> vNum;
			for (k=0;k<vIdx_spts.size();k++)
			{
				if (vbools[k])
				{
					Mat mMask(ph, pw, CV_8UC1, Scalar(0));
					int num = 0;

					for (ii=-hph;ii<=hph;ii++)
					{
						for (jj=-hpw;jj<=hpw;jj++)
						{
							if (mOut.at<uchar>(ii+hph,jj+hpw)==1&&vVisis[k].at<uchar>(i_real+ii,j_real+jj)==1)
							{
								mMask.at<uchar>(ii+hph,jj+hpw) = 1;
								++num;
							}
						}
					}

					vMasks.push_back(mMask);
					vNum.push_back(num);
				}
			}
			//////////////////////////////////////////////////////////////////////////

			double depth_optim, hx_optim, hy_optim, score_optim;

			optim_gn_drhxhyck_NCCcontrolled_masks(vKs,vRs,vts,vfx_1,vfy_1,vImgs,vIdxSupports,vMasks,vNum,idx_ref,j_real,i_real,visi,pw,ph,
				depth_init,hx_init,hy_init,score_init,depth_optim,hx_optim,hy_optim,score_optim,maxIter,xEps,fEps);

			// the optimized depth must be within certain range, or all parameters are mean values
			if (depth_optim>min_depth && depth_optim<max_depth)
			{
				mDepth.at<float>(i,j) = depth_optim;
				mHx.at<float>(i,j) = hx_optim;
				mHy.at<float>(i,j) = hy_optim;
				mScore.at<float>(i,j) = score_optim;
			}
			else
			{
				mDepth.at<float>(i,j) = depth_init;
				mHx.at<float>(i,j) = hx_init;
				mHy.at<float>(i,j) = hy_init;
				mScore.at<float>(i,j) = score_init;
			}
		}
	}

	Mat mDepth_map, mHx_map, mHy_map, mScore_map(h, w, CV_8UC3);

	double min_incre_x, max_incre_x, min_incre_y, max_incre_y;

	minMaxIdx(mDepth, &min_depth, &max_depth);
	minMaxIdx(mHx, &min_incre_x, &max_incre_x);
	minMaxIdx(mHy, &min_incre_y, &max_incre_y);

	mDepth.convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
	mHx.convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
	mHy.convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			if (mScore.at<float>(i,j)<0)
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = 0;
				mScore_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
				mScore_map.at<Vec3b>(i,j).val[2] = 0;
			}
		}
	}

	strInfo.Format("D:\\all\\depth map %02d MPGC-optimized.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mDepth_map);
	strInfo.Format("D:\\all\\hx map %02d MPGC-optimized.bmp", idx_ref);
//	imwrite(strInfo.GetBuffer(), mHx_map);
	strInfo.Format("D:\\all\\hy map %02d MPGC-optimized.bmp", idx_ref);
//	imwrite(strInfo.GetBuffer(), mHy_map);
	strInfo.Format("D:\\all\\score map %02d MPGC-optimized.bmp", idx_ref);
//	imwrite(strInfo.GetBuffer(), mScore_map);

	Mat mNormColor;
	GetNormColorField(vKs[idx_ref],vRs[idx_ref],vts[idx_ref],1/vKs[idx_ref](0,0),1/vKs[idx_ref](1,1),mDepth,mHx,mHy,mNormColor);
	strInfo.Format("D:\\all\\normcolor map %02d MPGC-optimized.bmp", idx_ref);
	imwrite(strInfo.GetBuffer(), mNormColor);

	strInfo.Format("D:\\all\\cloud points %02d MPGC-optimized.txt", idx_ref);
	OutputPointCloud(strInfo,vKs[idx_ref],vRs[idx_ref],vts[idx_ref],1/vKs[idx_ref](0,0),1/vKs[idx_ref](1,1),vImgs[idx_ref],mDepth,mHx,mHy,mScore);
}

// 20140910, self-contained, visibility determined, use the mean values of depth,hx and hy as initial values to optimize final depth and normal by MPGC
void DeepVoid::MPGC_20140910(const Matx33d & mK0,			// input:	interior matrix of reference image
						     const Matx33d & mR0,			// input:	rotation matrix of reference image
						     const Matx31d & mt0,			// input:	translation vector of reference image
							 const Mat & img0,				// input:	reference image
						     const vector<Matx33d> & vKs,	// input:	interior matrix of all support images
						     const vector<Matx33d> & vRs,	// input:	rotation matrix of all support images
						     const vector<Matx31d> & vts,	// input:	translation vectors of all support images
						     const vector<Mat> & vImgs,		// input:	images of all support images
						     const vector<Mat> & vDepths,	// input:	all depth map relative to reference wrt each support image
						     const vector<Mat> & vHxs,		// input:	all hx map relative to reference wrt each support image
						     const vector<Mat> & vHys,		// input:	all hy map relative to reference wrt each support image
						     const vector<Mat> & vScores,	// input:	all score map relative to reference wrt each support image
						     const Mat & mDepth_ML,
						     const Mat & mHx_ML,
						     const Mat & mHy_ML,
						     const Mat & mSel,				// input:	selected best support image index for each pixel who generates the most likely depth with reference image
						     const Mat & mVisi,				// input:	augmented visibility within support image set based on selected most likely depth
						     Mat & mDepth,					// output:	fused depths
						     Mat & mHx,						// output:	fused hxs
						     Mat & mHy,						// output:	fused hys
						     Mat & mScore,					// output:	fused scores
						     int pw,						// input:	image patch width
						     int ph,						// input:	image patch height
						     double ratio /*= 0.01*/,
						     int maxIter /*= 128*/,
						     double xEps /*= 1.0E-8*/,		// input: threshold
						     double fEps /*= 1.0E-6*/		// input: threshold
						     )
{
	int i,j,k,ii,jj;

	int w = vDepths[0].cols;
	int h = vDepths[0].rows;

	int n_spt = vKs.size(); // number of support images

	int hpw = (pw-1)*0.5; // half patch width
	int hph = (ph-1)*0.5; // half patch height

	double min_depth, max_depth;
	minMaxIdx(vDepths[0], &min_depth, &max_depth);

	vector<Mat> vVisis;
	for (k=0;k<n_spt;k++)
	{
		Mat mBvisi(h,w,CV_8UC1,Scalar(0));
		vVisis.push_back(mBvisi);
	}

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			uchar visi = mVisi.at<uchar>(i,j);
			vector<bool> vbools;
			InterpVisiVector_uchar(visi, vbools);

			for (k=0;k<n_spt;k++)
			{
				if (vbools[k])
				{
					vVisis[k].at<uchar>(i,j) = 1;
				}
			}
		}
	}

	mDepth = Mat(h, w, CV_32FC1);
	mHx = Mat(h, w, CV_32FC1);
	mHy = Mat(h, w, CV_32FC1);
	mScore = Mat(h, w, CV_32FC1);

	CString strInfo;

	for (i=0;i<h;i++)
	{
		strInfo.Format("MPGC-optimizing row %04d", i);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		for (j=0;j<w;j++)
		{
			int idx_sel = mSel.at<uchar>(i,j);

			uchar visi = mVisi.at<uchar>(i,j);
			vector<bool> vbools; int nVisi;
			InterpVisiVector_uchar(visi, vbools, &nVisi);

			if (nVisi<1) // there got be at least 1 observation to start MPGC optimization
			{
				mDepth.at<float>(i,j) = vDepths[idx_sel].at<float>(i,j);
				mHx.at<float>(i,j) = vHxs[idx_sel].at<float>(i,j);
				mHy.at<float>(i,j) = vHys[idx_sel].at<float>(i,j);
				mScore.at<float>(i,j) = vScores[idx_sel].at<float>(i,j);
				continue;
			}

			double sum_depth = 0;
			double sum_hx = 0;
			double sum_hy = 0;
			double sum_score = 0;
			for (k=0;k<n_spt;k++)
			{
				if (vbools[k])
				{
					sum_depth+=vDepths[k].at<float>(i,j);
					sum_hx += vHxs[k].at<float>(i,j);
					sum_hy += vHys[k].at<float>(i,j);
					sum_score += vScores[k].at<float>(i,j);
				}
			}

			double nVisi_1 = 1.0/nVisi; // have to be 1.0/nVisi, not 1/nVisi, or nVisi_1 will be 0.
			double depth_init = sum_depth*nVisi_1;	// initial depth is the mean value of multiple observations
			double hx_init = sum_hx*nVisi_1;		// initial hx is the mean value of multiple observations
			double hy_init = sum_hy*nVisi_1;		// initial hy is the mean value of multiple observations 
			double score_init = sum_score*nVisi_1;	// initial ncc value is the mean value of multiple observations

			int i_real, j_real;
			MakeSureNotOutBorder(j,i,j_real,i_real,hpw,w,h);

			//////////////////////////////////////////////////////////////////////////
			// generate mask
			Mat mD_patch(mDepth_ML,cv::Rect(j_real-hpw, i_real-hph, pw, ph));

			Mat mOut; int nValid;
			Clustering_depth_4(mD_patch,hpw,hph,mOut,nValid,ratio);

			vector<Mat> vMasks_visi; vector<int> vNum_visi;
			vector<Matx33d> vKs_visi, vRs_visi; vector<Matx31d> vts_visi; vector<Mat> vImgs_visi;
			for (k=0;k<n_spt;k++)
			{
				if (vbools[k])
				{
					Mat mMask(ph, pw, CV_8UC1, Scalar(0));
					int num = 0;

					for (ii=-hph;ii<=hph;ii++)
					{
						for (jj=-hpw;jj<=hpw;jj++)
						{
							if (mOut.at<uchar>(ii+hph,jj+hpw)==1&&vVisis[k].at<uchar>(i_real+ii,j_real+jj)==1)
							{
								mMask.at<uchar>(ii+hph,jj+hpw) = 1;
								++num;
							}
						}
					}

					vMasks_visi.push_back(mMask);
					vNum_visi.push_back(num);
					vKs_visi.push_back(vKs[k]);
					vRs_visi.push_back(vRs[k]);
					vts_visi.push_back(vts[k]);
					vImgs_visi.push_back(vImgs[k]);
				}
			}
			//////////////////////////////////////////////////////////////////////////

			double depth_optim, hx_optim, hy_optim, score_optim;

			optim_gn_drhxhyck_NCCcontrolled_masks(mK0,mR0,mt0,img0,vKs_visi,vRs_visi,vts_visi,vImgs_visi,vMasks_visi,vNum_visi,j_real,i_real,pw,ph,
				depth_init,hx_init,hy_init,score_init,depth_optim,hx_optim,hy_optim,score_optim,maxIter,xEps,fEps);

			// the optimized depth must be within certain range, or all parameters are mean values
			if (depth_optim>min_depth && depth_optim<max_depth)
			{
				mDepth.at<float>(i,j) = depth_optim;
				mHx.at<float>(i,j) = hx_optim;
				mHy.at<float>(i,j) = hy_optim;
				mScore.at<float>(i,j) = score_optim;
			}
			else
			{
				mDepth.at<float>(i,j) = depth_init;
				mHx.at<float>(i,j) = hx_init;
				mHy.at<float>(i,j) = hy_init;
				mScore.at<float>(i,j) = score_init;
			}
		}
	}
}

// 20150207, self-contained, visibility determined, use the most likely values of depth,hx and hy as initial values to optimize final depth and normal by MPGC
void DeepVoid::MPGC_20150207(const Matx33d & mK0,					// input:	interior matrix of reference image
						     const Matx33d & mR0,					// input:	rotation matrix of reference image
							 const Matx31d & mt0,					// input:	translation vector of reference image
						     const Mat & img0,						// input:	reference image
						     const vector<Matx33d> & vKs,			// input:	interior matrix of all support images
						     const vector<Matx33d> & vRs,			// input:	rotation matrix of all support images
						     const vector<Matx31d> & vts,			// input:	translation vectors of all support images
						     const vector<Mat> & vImgs,				// input:	images of all support images
						     const Mat & mDepth_ML,
						     const Mat & mHx_ML,
						     const Mat & mHy_ML,
						     const Mat & mScore_ML,
						     const Mat & mVisi,						// input:	augmented visibility within support image set based on selected most likely depth
						     Mat & mDepth,							// output:	fused depths
						     Mat & mHx,								// output:	fused hxs
						     Mat & mHy,								// output:	fused hys
						     Mat & mScore,							// output:	fused scores
						     int pw,								// input:	image patch width
						     int ph,								// input:	image patch height
						     int maxIter /*= 128*/,
						     double xEps /*= 1.0E-8*/,				// input: threshold
						     double fEps /*= 1.0E-6*/				// input: threshold
						     )
{
	int i,j,k,ii,jj;

	int w = mDepth_ML.cols;
	int h = mDepth_ML.rows;

	int n_spt = vKs.size(); // number of support images

	int hpw = (pw-1)*0.5; // half patch width
	int hph = (ph-1)*0.5; // half patch height

	Mat mMask(ph, pw, CV_8UC1, Scalar(1));

	double min_depth, max_depth;
	minMaxIdx(mDepth_ML, &min_depth, &max_depth);

	mDepth = Mat(h, w, CV_32FC1);
	mHx = Mat(h, w, CV_32FC1);
	mHy = Mat(h, w, CV_32FC1);
	mScore = Mat(h, w, CV_32FC1);

	CString strInfo;

	for (i=0;i<h;i++)
	{
		strInfo.Format("Multi-View MPGC-optimizing row %04d", i);
//		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		for (j=0;j<w;j++)
		{
			uchar visi = mVisi.at<uchar>(i,j);
			vector<bool> vbools; int nVisi;
			InterpVisiVector_uchar(visi, vbools, &nVisi);

			if (nVisi<1) // there got be at least 1 observation to start MPGC optimization
			{
				mDepth.at<float>(i,j) = mDepth_ML.at<float>(i,j);
				mHx.at<float>(i,j) = mHx_ML.at<float>(i,j);
				mHy.at<float>(i,j) = mHy_ML.at<float>(i,j);
				mScore.at<float>(i,j) = mScore_ML.at<float>(i,j);
				continue;
			}

			double depth_init = mDepth_ML.at<float>(i,j);	// initial depth is the most likely value
			double hx_init = mHx_ML.at<float>(i,j);			// initial hx is the most likely value
			double hy_init = mHy_ML.at<float>(i,j);			// initial hy is the most likely value
			double score_init = mScore_ML.at<float>(i,j);	// initial ncc value is the most likely value

			int i_real, j_real;
			MakeSureNotOutBorder(j,i,j_real,i_real,hpw,w,h);

			//////////////////////////////////////////////////////////////////////////
			// generate mask
			vector<Mat> vMasks_visi; vector<int> vNum_visi;
			vector<Matx33d> vKs_visi, vRs_visi; vector<Matx31d> vts_visi; vector<Mat> vImgs_visi;
			for (k=0;k<n_spt;k++)
			{
				if (vbools[k])
				{
					vMasks_visi.push_back(mMask); // 掩膜的值全为1，说明掩膜没起作用，区域内的所有像素都参与MPGC
					vNum_visi.push_back(pw*ph);
					vKs_visi.push_back(vKs[k]);
					vRs_visi.push_back(vRs[k]);
					vts_visi.push_back(vts[k]);
					vImgs_visi.push_back(vImgs[k]);
				}
			}
			//////////////////////////////////////////////////////////////////////////

			double depth_optim, hx_optim, hy_optim, score_optim;

			if (optim_gn_drhxhyck_NCCcontrolled_masks(mK0,mR0,mt0,img0,vKs_visi,vRs_visi,vts_visi,vImgs_visi,vMasks_visi,vNum_visi,j_real,i_real,pw,ph,
				depth_init,hx_init,hy_init,score_init,depth_optim,hx_optim,hy_optim,score_optim,maxIter,xEps,fEps))
			{
				// the optimized depth must be within certain range, or all parameters are mean values
				if (depth_optim>min_depth && depth_optim<max_depth)
				{
					mDepth.at<float>(i,j) = depth_optim;
					mHx.at<float>(i,j) = hx_optim;
					mHy.at<float>(i,j) = hy_optim;
					mScore.at<float>(i,j) = score_optim;
					continue;
				}
			}

			mDepth.at<float>(i,j) = depth_init;
			mHx.at<float>(i,j) = hx_init;
			mHy.at<float>(i,j) = hy_init;
			mScore.at<float>(i,j) = score_init;
		}
	}
}

// 20141215, self-contained, do mpgc with only one support image
void DeepVoid::MPGC_Binocular_20141215(const Matx33d & mK0,		// input:	interior matrix of reference image
									   const Matx33d & mR0,		// input:	rotation matrix of reference image
									   const Matx31d & mt0,		// input:	translation vector of reference image
									   const Mat & img0,		// input:	reference image
									   const Matx33d & mK,		// input:	interior matrix of the support image
									   const Matx33d & mR,		// input:	rotation matrix of the support image
									   const Matx31d & mt,		// input:	translation vectors of the support image
									   const Mat & img,			// input:	the support image
									   Mat & mDepth,			// in&output:	initial and optimized depth
									   Mat & mHx,				// in&output:	initial and optimized hx
									   Mat & mHy,				// in&output:	initial and optimized hy
									   Mat & mScore,			// in&output:	initial and optimized score
									   int pw,					// input:	image patch width
									   int ph,					// input:	image patch height
									   int maxIter /*= 128*/,
									   double xEps /*= 1.0E-8*/,// input: threshold
									   double fEps /*= 1.0E-6*/	// input: threshold
									   )
{
	int i,j,k,ii,jj;

	int w = mDepth.cols;
	int h = mDepth.rows;

	int hpw = (pw-1)*0.5; // half patch width
	int hph = (ph-1)*0.5; // half patch height

	double min_depth, max_depth;
	minMaxIdx(mDepth, &min_depth, &max_depth);

	Mat mMask(ph, pw, CV_8UC1, Scalar(1));

	vector<Matx33d> vKs_visi,vRs_visi;
	vector<Matx31d> vts_visi;
	vector<Mat> vImgs_visi, vMasks_visi;
	vector<int> vNum_visi;

	vKs_visi.push_back(mK); vRs_visi.push_back(mR); vts_visi.push_back(mt);
	vImgs_visi.push_back(img); vMasks_visi.push_back(mMask);
	vNum_visi.push_back(pw*ph);

	CString strInfo;

	for (i=0;i<h;i++)
	{
		strInfo.Format("Binocular MPGC-optimizing row %04d", i);
//		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		for (j=0;j<w;j++)
		{
			double depth_init = mDepth.at<float>(i,j);
			double hx_init = mHx.at<float>(i,j);
			double hy_init = mHy.at<float>(i,j);
			double score_init = mScore.at<float>(i,j);

			if (score_init<=0)
			{
				continue;
			}

			int i_real, j_real;
			MakeSureNotOutBorder(j,i,j_real,i_real,hpw,w,h);

			double depth_optim, hx_optim, hy_optim, score_optim;

			if (optim_gn_drhxhyck_NCCcontrolled_masks(mK0,mR0,mt0,img0,vKs_visi,vRs_visi,vts_visi,vImgs_visi,vMasks_visi,vNum_visi,j_real,i_real,pw,ph,
				depth_init,hx_init,hy_init,score_init,depth_optim,hx_optim,hy_optim,score_optim,maxIter,xEps,fEps))
			{
				// the optimized depth must be within certain range, or all parameters are mean values
				if (depth_optim>min_depth && depth_optim<max_depth)
				{
					mDepth.at<float>(i,j) = depth_optim;
					mHx.at<float>(i,j) = hx_optim;
					mHy.at<float>(i,j) = hy_optim;
					mScore.at<float>(i,j) = score_optim;
				}
			}
		}
	}
}

// invalidate those pixels whose normal estimate is obviously wrong by setting its score to -1
void DeepVoid::InvalidatePixels_byNormal(const cam_data & cam0,
									     const cam_data & cam,
									     const Mat & mDepth,
									     const Mat & mHx,
									     const Mat & mHy,
									     Mat & mScore,
										 int k,
									     double thresh_ang /*= 90*/
									     )
{
	int i,j;

	int w = mDepth.cols;
	int h = mDepth.rows;

	double fx0 = cam0.fx; double fy0 = cam0.fy;
	double cx0 = cam0.cx; double cy0 = cam0.cy;
	double fx0_1 = 1/fx0; double fy0_1 = 1/fy0;

	double fx = cam.fx; double fy = cam.fy;
	double cx = cam.cx; double cy = cam.cy;
	double fx_1 = 1/fx; double fy_1 = 1/fy;


	Matx33d mR0,mK0,mR,mK; Matx31d mt0,mt;

	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mR0(i,j) = cam0.R[i*3+j];
			mR(i,j) = cam.R[i*3+j];
		}
	}
	mK0(0,0) = cam0.fx;	mK0(0,1) = cam0.s;  mK0(0,2) = cam0.cx;
	mK0(1,1) = cam0.fy;	mK0(1,2) = cam0.cy; mK0(2,2) = 1;
	mt0(0) = cam0.t[0];	mt0(1) = cam0.t[1]; mt0(2) = cam0.t[2];

	mK(0,0) = cam.fx;	mK(0,1) = cam.s;  mK(0,2) = cam.cx;
	mK(1,1) = cam.fy;	mK(1,2) = cam.cy; mK(2,2) = 1;
	mt(0) = cam.t[0];	mt(1) = cam.t[1]; mt(2) = cam.t[2];

	Matx33d mKR = mK*mR;
	Matx31d mKt = mK*mt;

	for (i=0;i<h;i++)
	{
		double nimgy0 = (i-cy0)*fy0_1;

		for (j=0;j<w;j++)
		{
			double score = mScore.at<float>(i,j);

			if (score < 1.0E-4)
			{
				mScore.at<float>(i,j) = -1; // if score is 0, it is also set to -1
				continue;
			}

			double nimgx0 = (j-cx0)*fx0_1;

			double depth  = mDepth.at<float>(i,j);
			double hx = mHx.at<float>(i,j);
			double hy = mHy.at<float>(i,j);

			// compute corresponding 3d point
			Matx31d XYZ = GetXYZ_givenDepth(mR0, mt0, nimgx0, nimgy0, depth);

			// compute corresponding normal
			Matx31d mn0; mn0(2)=1;
			get_normal_givendrhxhy(fx0, fy0, nimgx0, nimgy0, depth, hx, hy, mn0(0), mn0(1));
			Matx31d mnw = -mR0.t()*mn0; // convert the normal into world coordinate system
			double nmnw = norm(mnw);

			// project
			Matx31d mx = mKR*XYZ + mKt;

			double z_1 = 1/mx(2);

			double img_x = mx(0)*z_1;
			double img_y = mx(1)*z_1;

			// current line of sight
			Matx31d msightvec; // from image point to optical center
			msightvec(0) = -(img_x-cx)*fx_1;
			msightvec(1) = -(img_y-cy)*fy_1;
			msightvec(2) = -1;
			Matx31d mnk = mR*mnw;
			Matx<double, 1, 1> mcosa = mnk.t()*msightvec;
			double cosa = mcosa(0)/(nmnw*norm(msightvec));
			double ang = acos(cosa)*R2D; // 0-180
			if (ang>=90)
			{
				mScore.at<float>(i,j) = -1; // ang is supposed to be smaller than 90 if it is visible
			} 
		}
	}

	Mat mScore_map(h, w, CV_8UC3);

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			if (mScore.at<float>(i,j)<0)
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = 0;
				mScore_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
				mScore_map.at<Vec3b>(i,j).val[2] = 0;
			}
		}
	}

	CString strInfo;
	strInfo.Format("D:\\all\\score map after invalidation with image %02d.bmp", k);
	imwrite(strInfo.GetBuffer(), mScore_map);
}

// invalidate those pixels whose normal estimate is obviously wrong by setting its score to -1
void DeepVoid::InvalidatePixels_byNormal(const Matx33d & mK0, const Matx33d & mK,		// input: mK0 reference image, mK one specific support image
									     const Matx33d & mR0, const Matx33d & mR,		// input: mR0 reference image, mR one specific support image
									     const Matx31d & mt0, const Matx31d & mt,		// input: mt0 reference image, mt one specific support image
									     double fx0_1, double fx_1,					// input: fx0_1 = 1/fx0, fx_1 = 1/fx
									     double fy0_1, double fy_1,					// input: fy0_1 = 1/fy0, fy_1 = 1/fy
										 int idx0, int idx,
									     const Mat & mDepth,
									     const Mat & mHx,
									     const Mat & mHy,
									     Mat & mScore,
									     double thresh_ang/* = 90*/,
										 double thresh_ncc /*= 1.0E-4*/
									     )
{
	int i,j;

	int w = mDepth.cols;
	int h = mDepth.rows;

	double fx0 = mK0(0,0); double fy0 = mK0(1,1);
	double cx0 = mK0(0,2); double cy0 = mK0(1,2);
	
	double fx = mK(0,0); double fy = mK(1,1);
	double cx = mK(0,2); double cy = mK(1,2);

	Matx33d mKR = mK*mR;
	Matx31d mKt = mK*mt;

	for (i=0;i<h;i++)
	{
		double nimgy0 = (i-cy0)*fy0_1;

		for (j=0;j<w;j++)
		{
			double score = mScore.at<float>(i,j);

			if (score < thresh_ncc)
			{
				mScore.at<float>(i,j) = -1; // if score is 0, it is also set to -1
				continue;
			}

			double nimgx0 = (j-cx0)*fx0_1;

			double depth  = mDepth.at<float>(i,j);
			double hx = mHx.at<float>(i,j);
			double hy = mHy.at<float>(i,j);

			// compute corresponding 3d point
			Matx31d XYZ = GetXYZ_givenDepth(mR0, mt0, nimgx0, nimgy0, depth);

			// compute corresponding normal
			Matx31d mn0; mn0(2)=1;
			get_normal_givendrhxhy(fx0, fy0, nimgx0, nimgy0, depth, hx, hy, mn0(0), mn0(1));
			Matx31d mnw = -mR0.t()*mn0; // convert the normal into world coordinate system
			double nmnw = norm(mnw);

			// project
			Matx31d mx = mKR*XYZ + mKt;

			double z_1 = 1/mx(2);

			double img_x = mx(0)*z_1;
			double img_y = mx(1)*z_1;

			// current line of sight
			Matx31d msightvec; // from image point to optical center
			msightvec(0) = -(img_x-cx)*fx_1;
			msightvec(1) = -(img_y-cy)*fy_1;
			msightvec(2) = -1;
			Matx31d mnk = mR*mnw;
			Matx<double, 1, 1> mcosa = mnk.t()*msightvec;
			double cosa = mcosa(0)/(nmnw*norm(msightvec));
			double ang = acos(cosa)*R2D; // 0-180
			if (ang>=thresh_ang)
			{
				mScore.at<float>(i,j) = -1; // ang is supposed to be smaller than 90 if it is visible
			} 
		}
	}

// 	Mat mScore_map(h, w, CV_8UC3);
// 
// 	for (i=0;i<h;i++)
// 	{
// 		for (j=0;j<w;j++)
// 		{
// 			if (mScore.at<float>(i,j)<0)
// 			{
// 				mScore_map.at<Vec3b>(i,j).val[0] = 0;
// 				mScore_map.at<Vec3b>(i,j).val[1] = 0;
// 				mScore_map.at<Vec3b>(i,j).val[2] = 255;
// 			}
// 			else
// 			{
// 				mScore_map.at<Vec3b>(i,j).val[0] = 0;
// 				mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
// 				mScore_map.at<Vec3b>(i,j).val[2] = 0;
// 			}
// 		}
// 	}
// 
// 	CString strInfo;
// 	strInfo.Format("D:\\all\\score map %02d after invalidation with image %02d.bmp", idx0, idx);
// 	imwrite(strInfo.GetBuffer(), mScore_map);
}

// 20140914, self-contained version, invalidate those pixels whose normal estimate is obviously wrong by setting its score to -1
void DeepVoid::InvalidatePixels_byNormal(const Matx33d & mK0, 		// input:	mK0 reference image
									     const Matx33d & mR0, 		// input:	mR0 reference image
									     const Matx31d & mt0, 		// input:	mt0 reference image
									     const Matx33d & mK,		// input:	mK one specific support image
									     const Matx33d & mR,		// input:	mR one specific support image
									     const Matx31d & mt,		// input:	mt one specific support image
									     const Mat & mDepth,
									     const Mat & mHx,
									     const Mat & mHy,
									     Mat & mScore,
									     double thresh_ang /*= 90*/,
									     double thresh_ncc/* = 1.0E-4*/
									    )
{
	int i,j;

	int w = mDepth.cols;
	int h = mDepth.rows;

	double cos_thresh_ang = cosd(thresh_ang);

	double fx0 = mK0(0,0); double fy0 = mK0(1,1);
	double fx0_1 = 1/fx0;  double fy0_1 = 1/fy0;
	double cx0 = mK0(0,2); double cy0 = mK0(1,2);

	double fx = mK(0,0); double fy = mK(1,1);
	double fx_1 = 1/fx;  double fy_1 = 1/fy;
	double cx = mK(0,2); double cy = mK(1,2);

	Matx33d mKR = mK*mR;
	Matx31d mKt = mK*mt;

	for (i=0;i<h;i++)
	{
		double nimgy0 = (i-cy0)*fy0_1;

		for (j=0;j<w;j++)
		{
			double score = mScore.at<float>(i,j);

			if (score < thresh_ncc)
			{
				mScore.at<float>(i,j) = -1; // if score is 0, it is also set to -1
				continue;
			}

			double nimgx0 = (j-cx0)*fx0_1;

			double depth  = mDepth.at<float>(i,j);
			double hx = mHx.at<float>(i,j);
			double hy = mHy.at<float>(i,j);

			// compute corresponding 3d point
			Matx31d XYZ = GetXYZ_givenDepth(mR0, mt0, nimgx0, nimgy0, depth);

			// compute corresponding normal
			Matx31d mn0; mn0(2)=1;
			get_normal_givendrhxhy(fx0, fy0, nimgx0, nimgy0, depth, hx, hy, mn0(0), mn0(1));
			Matx31d mnw = -mR0.t()*mn0; // convert the normal into world coordinate system
			double nmnw = norm(mnw);

			// project
			Matx31d mx = mKR*XYZ + mKt;

			double z_1 = 1/mx(2);

			double img_x = mx(0)*z_1;
			double img_y = mx(1)*z_1;

			// current line of sight
			Matx31d msightvec; // from image point to optical center
			msightvec(0) = -(img_x-cx)*fx_1;
			msightvec(1) = -(img_y-cy)*fy_1;
			msightvec(2) = -1;
			Matx31d mnk = mR*mnw;
			Matx<double, 1, 1> mcosa = mnk.t()*msightvec;
			double cosa = mcosa(0)/(nmnw*norm(msightvec));

			if (cosa<=cos_thresh_ang)
			{
				mScore.at<float>(i,j) = -1; // ang is supposed to be smaller than 90 if it is visible
			} 
		}
	}
}

// 20140827 with simplified MRF model only considering depth
void DeepVoid::MVDE_package_01(const vector<cam_data> & vCams,			// input:	all images' orientations
							   const vector<Mat> & vImgs,				// input:	all images
							   const vector<vector<int>> & vIdxSupports,// input:	all images' support images' index
							   const vector<CloudPoint> & clouds,		// input:	the cloud points
							   vector<Mat> & vDepths,					// output:	all generated depths
							   vector<Mat> & vHxs,						// output:	all generated depth gradients
							   vector<Mat> & vHys,						// output:	all generated depth gradients
							   vector<Mat> & vScores,					// output:	all scores, and -1 indicates an invalid estimate
							   vector<Mat> & vVisis,					// output:	all estimated visibilities within corresponding support image set
							   int size /*= 5*/,						// input:	the window size of the image patch, should be odd number
							   double angLimit /*= 80*/,				// input:	the angular range limit of the normal of every object point, in angle, not radian
							   int maxIter /*= 4*/,						// input:	maximum iteration
							   double factor /*= 0.5*/,
							   int nRandSamp /*= 6*/,
							   double thresh_ang /*= 90*/,				// input:	the normal angle constraint, if this value is 360, then no constraint at all
							   double thresh_ncc /*= 0.95*/,			// input:	the ncc threshold after patchmatch, ncc value is supposed to be very high if it's matched correctly after patchmatch
							   double thresh_imgpt_sigma /*= 1*/,
							   double thresh_ratio /*= 0.001*/,
							   double thresh_ang_removeSmall /*= 85*/,
							   double thresh_area_removeSmall /*= 15*/,
							   int maxIter_optim /*= 128*/,
							   double xEps /*= 1.0E-8*/,				// input: threshold
							   double fEps /*= 1.0E-6*/					// input: threshold
							   )
{
	int i,j,k,ii,jj,kk;

	int nImg = vCams.size();
	int w = vImgs[0].cols;
	int h = vImgs[0].rows;
	int n_cloud = clouds.size();

	double tana = tan(angLimit*D2R);

	// get corresponding orientation matrix //////////////////////////////////////////////////////////////////////////
	vector<Matx33d> vRs,vKs; vector<Matx31d> vts;
	vector<double> vfx_1, vfy_1;
	vector<double> vd_max, vd_min, vh_max, vh_min;

	for (k=0;k<nImg;k++)
	{
		Matx33d mR,mK; Matx31d mt;

		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR(i,j) = vCams[k].R[i*3+j];
			}
		}
		mK(0,0) = vCams[k].fx;	mK(0,1) = vCams[k].s;  mK(0,2) = vCams[k].cx;
		mK(1,1) = vCams[k].fy;	mK(1,2) = vCams[k].cy; mK(2,2) = 1;
		mt(0) = vCams[k].t[0];	mt(1) = vCams[k].t[1]; mt(2) = vCams[k].t[2];

		double fx = vCams[k].fx; double fy = vCams[k].fy;
		double fx_1 = 1/fx;		 double fy_1 = 1/fy;

		vRs.push_back(mR);
		vKs.push_back(mK);
		vts.push_back(mt);
		vfx_1.push_back(fx_1);
		vfy_1.push_back(fy_1);

		double f=(fx+fy)*0.5;
		double tana_f = tana/f;

		double depth_min;
		double depth_max;

		for (jj=0;jj<n_cloud;jj++)
		{
			Matx31d mX;

			mX(0) = clouds[jj].m_pt.x;
			mX(1) = clouds[jj].m_pt.y;
			mX(2) = clouds[jj].m_pt.z;

			mX = mR*mX+mt;

			double depth = mX(2);

			if (jj == 0)
			{
				depth_min = depth;
				depth_max = depth;
			} 
			else
			{
				if (depth<depth_min)
				{
					depth_min = depth;
				}
				if (depth>depth_max)
				{
					depth_max = depth;
				}
			}
		}

		double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

		double depth_ext = (depth_max-depth_min)*ratio_ext;

		depth_max += depth_ext;

		double tmp = depth_min - depth_ext;

		if (tmp<0)
		{
			depth_min = 0;
		} 
		else
		{
			depth_min = tmp;
		}

		double h_max = tana_f * depth_max;

		vd_max.push_back(depth_max);
		vd_min.push_back(depth_min);
		vh_max.push_back(h_max);
		vh_min.push_back(-h_max);
	}
	//////////////////////////////////////////////////////////////////////////////////////////////////////////////////

	vDepths.clear(); vHxs.clear(); vHys.clear(); vScores.clear(); vVisis.clear();

	for (k=0;k<nImg;k++)
//	for (k=0;k<1;k++)
	{
		vector<Mat> vDepths_bin, vHxs_bin, vHys_bin, vScores_bin;


// 		// first generate depths w.r.t each support image of the reference image
// 		PatchMatch_Binocular(vKs,vRs,vts,vfx_1,vfy_1,vImgs,vIdxSupports,clouds,vd_max,vd_min,vh_max,vh_min,k,
// 			vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,size,angLimit,maxIter,factor,nRandSamp);


		// read them in //////////////////////////////////////////////////////////////////////////
		for (kk=0;kk<vIdxSupports[k].size();kk++)
		{
			Mat mDepth(h, w, CV_32FC1), mHx(h, w, CV_32FC1), mHy(h, w, CV_32FC1), mScore(h, w, CV_32FC1);

			int idx_spt = vIdxSupports[k][kk];

			CString strInfo;
// 			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 02 - dinoR\\%02d\\final PatchMatch depth map %02d with image %02d.txt", k,k,idx_spt);
// 			FILE * file_depth = fopen(strInfo, "r");
// 			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 02 - dinoR\\%02d\\final PatchMatch hx map %02d with image %02d.txt", k,k,idx_spt);
// 			FILE * file_hx = fopen(strInfo, "r");
// 			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 02 - dinoR\\%02d\\final PatchMatch hy map %02d with image %02d.txt", k,k,idx_spt);
// 			FILE * file_hy = fopen(strInfo, "r");
// 			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 02 - dinoR\\%02d\\final PatchMatch score map %02d with image %02d.txt", k,k,idx_spt);
// 			FILE * file_score = fopen(strInfo, "r");

			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 00 - templeR\\%02d\\final PatchMatch depth map %02d with image %02d.txt", k,k,idx_spt);
			FILE * file_depth = fopen(strInfo, "r");
			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 00 - templeR\\%02d\\final PatchMatch hx map %02d with image %02d.txt", k,k,idx_spt);
			FILE * file_hx = fopen(strInfo, "r");
			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 00 - templeR\\%02d\\final PatchMatch hy map %02d with image %02d.txt", k,k,idx_spt);
			FILE * file_hy = fopen(strInfo, "r");
			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 00 - templeR\\%02d\\final PatchMatch score map %02d with image %02d.txt", k,k,idx_spt);
			FILE * file_score = fopen(strInfo, "r");

			// at the same time evaluate all parameters
			for (i=0;i<h;i++)
			{
				for (j=0;j<w;j++)
				{
					double depth,hx,hy,score;
					int tmp;
					fscanf(file_depth, "%lf	", &depth);
					fscanf(file_hx, "%lf	", &hx);
					fscanf(file_hy, "%lf	", &hy);
					fscanf(file_score, "%lf	", &score);

					mDepth.at<float>(i,j) = depth;
					mHx.at<float>(i,j) = hx;
					mHy.at<float>(i,j) = hy;
					mScore.at<float>(i,j) = score;
				}
			}
			fclose(file_depth);
			fclose(file_hx);
			fclose(file_hy);
			fclose(file_score);

			vDepths_bin.push_back(mDepth);
			vHxs_bin.push_back(mHx);
			vHys_bin.push_back(mHy);
			vScores_bin.push_back(mScore);
		}
		//////////////////////////////////////////////////////////////////////////


		for (kk=0;kk<vIdxSupports[k].size();kk++)
		{
			int idx_spt = vIdxSupports[k][kk];
			// then invalidate those estimates whose normals are not reasonable and whose scores are smaller than certain threshold
			InvalidatePixels_byNormal(vKs[k],vKs[idx_spt],vRs[k],vRs[idx_spt],vts[k],vts[idx_spt],vfx_1[k],vfx_1[idx_spt],vfy_1[k],vfy_1[idx_spt],k,idx_spt,
				vDepths_bin[kk], vHxs_bin[kk], vHys_bin[kk], vScores_bin[kk], thresh_ang, thresh_ncc);

			// here we can then eliminate all small depth regions detected by fast mesh
//			RemoveSmallDepthRegions_4(vAllCams[0], vAllImgs[0], vDepths[3], vScores[3], 80, vAllImgs[0].cols*vAllImgs[0].rows/400.0);
		}

		Mat mSel, mVisi;
		Mat mDepth_ML, mHx_ML, mHy_ML, mScore_ML;

		Extract_MRF_d_DP_withInvalids(vKs[k],vRs[k],vts[k],vfx_1[k],vfy_1[k],vImgs[k],k,
			vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mSel,mDepth_ML,mHx_ML,mHy_ML,mScore_ML);

		AugmentVisibility_basedonMostLikelyDepth(vKs,vRs,vts,vfx_1,vfy_1,vImgs,vIdxSupports,k,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mSel,mVisi,thresh_imgpt_sigma);

		Mat mDepth_MPGC, mHx_MPGC, mHy_MPGC, mScore_MPGC;
		MPGC_20140905(vKs,vRs,vts,vfx_1,vfy_1,vImgs,vIdxSupports,k,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mSel,mVisi,
			mDepth_MPGC,mHx_MPGC,mHy_MPGC,mScore_MPGC,size,size,maxIter_optim,xEps,fEps);

		Mat mDepth_fused, mHx_fused, mHy_fused, mScore_fused;
		DepthFusion_minimizingProjErrors(vKs,vRs,vts,vfx_1,vfy_1,vImgs,vIdxSupports,k,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mSel,mVisi,
			mDepth_fused,mHx_fused,mHy_fused,mScore_fused,maxIter_optim,xEps,fEps);

		vDepths.push_back(mDepth_MPGC);
		vHxs.push_back(mHx_MPGC);
		vHys.push_back(mHy_MPGC);
		vScores.push_back(mScore_MPGC);
		vVisis.push_back(mVisi);
	}

	// depth consistency check
	for (k=0;k<nImg;k++)
	{
		DepthConsistencyCheck(vKs,vRs,vts,vfx_1,vfy_1,vIdxSupports,k,vDepths,vHxs,vHys,vScores,vVisis,thresh_ratio);

		// and remove small depth regions
		RemoveSmallDepthRegions_4(vKs[k],vRs[k],vts[k],vfx_1[k],vfy_1[k],vImgs[k],k,vDepths[k],vHxs[k],vHys[k],vScores[k],thresh_ang_removeSmall,thresh_area_removeSmall);
	}
}

// 20140909 with complete MRF model
void DeepVoid::MVDE_package_02(const vector<cam_data> & vCams,			// input:	all images' orientations
							   const vector<Mat> & vImgs,				// input:	all images
							   const vector<vector<int>> & vIdxSupports,// input:	all images' support images' index
							   const vector<CloudPoint> & clouds,		// input:	the cloud points
							   vector<Mat> & vDepths,					// output:	all generated depths
							   vector<Mat> & vHxs,						// output:	all generated depth gradients
							   vector<Mat> & vHys,						// output:	all generated depth gradients
							   vector<Mat> & vScores,					// output:	all scores, and -1 indicates an invalid estimate
							   vector<Mat> & vVisis,					// output:	all estimated visibilities within corresponding support image set
							   int size /*= 5*/,						// input:	the window size of the image patch, should be odd number
							   double angLimit /*= 80*/,				// input:	the angular range limit of the normal of every object point, in angle, not radian
							   int maxIter /*= 4*/,						// input:	maximum iteration
							   double factor /*= 0.5*/,
							   int nRandSamp /*= 6*/,
							   double thresh_ang /*= 90*/,				// input:	the normal angle constraint, if this value is 360, then no constraint at all
							   double thresh_ncc /*= 0.95*/,			// input:	the ncc threshold after patchmatch, ncc value is supposed to be very high if it's matched correctly after patchmatch
							   double P1 /*= 1.5*/,
							   double P2 /*= 0.1*/,
							   double thresh_imgpt_sigma /*= 1*/,
							   double thresh_ratio /*= 0.001*/,
							   double thresh_ratio_depthdiscon /*= 0.01*/,
							   double thresh_ang_removeSmall /*= 85*/,
							   double thresh_area_removeSmall /*= 15*/,
							   int maxIter_optim /*= 128*/,
							   double xEps /*= 1.0E-8*/,				// input: threshold
							   double fEps /*= 1.0E-6*/					// input: threshold
							   )
{
	int i,j,k,ii,jj,kk;

	int nImg = vCams.size();
	int w = vImgs[0].cols;
	int h = vImgs[0].rows;
	int n_cloud = clouds.size();

	double tana = tan(angLimit*D2R);

	// get corresponding orientation matrix //////////////////////////////////////////////////////////////////////////
	vector<Matx33d> vRs,vKs; vector<Matx31d> vts;
	vector<double> vfx_1, vfy_1;
	vector<double> vd_max, vd_min, vh_max, vh_min;

	for (k=0;k<nImg;k++)
	{
		Matx33d mR,mK; Matx31d mt;

		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR(i,j) = vCams[k].R[i*3+j];
			}
		}
		mK(0,0) = vCams[k].fx;	mK(0,1) = vCams[k].s;  mK(0,2) = vCams[k].cx;
		mK(1,1) = vCams[k].fy;	mK(1,2) = vCams[k].cy; mK(2,2) = 1;
		mt(0) = vCams[k].t[0];	mt(1) = vCams[k].t[1]; mt(2) = vCams[k].t[2];

		double fx = vCams[k].fx; double fy = vCams[k].fy;
		double fx_1 = 1/fx;		 double fy_1 = 1/fy;

		vRs.push_back(mR);
		vKs.push_back(mK);
		vts.push_back(mt);
		vfx_1.push_back(fx_1);
		vfy_1.push_back(fy_1);

		double f=(fx+fy)*0.5;
		double tana_f = tana/f;

		double depth_min;
		double depth_max;

		for (jj=0;jj<n_cloud;jj++)
		{
			Matx31d mX;

			mX(0) = clouds[jj].m_pt.x;
			mX(1) = clouds[jj].m_pt.y;
			mX(2) = clouds[jj].m_pt.z;

			mX = mR*mX+mt;

			double depth = mX(2);

			if (jj == 0)
			{
				depth_min = depth;
				depth_max = depth;
			} 
			else
			{
				if (depth<depth_min)
				{
					depth_min = depth;
				}
				if (depth>depth_max)
				{
					depth_max = depth;
				}
			}
		}

		double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

		double depth_ext = (depth_max-depth_min)*ratio_ext;

		depth_max += depth_ext;

		double tmp = depth_min - depth_ext;

		if (tmp<0)
		{
			depth_min = 0;
		} 
		else
		{
			depth_min = tmp;
		}

		double h_max = tana_f * depth_max;

		vd_max.push_back(depth_max);
		vd_min.push_back(depth_min);
		vh_max.push_back(h_max);
		vh_min.push_back(-h_max);
	}
	//////////////////////////////////////////////////////////////////////////////////////////////////////////////////

	vDepths.clear(); vHxs.clear(); vHys.clear(); vScores.clear(); vVisis.clear();

	for (k=0;k<nImg;k++)
//	for (k=0;k<1;k++)
	{
		vector<Mat> vDepths_bin, vHxs_bin, vHys_bin, vScores_bin;


// 		// first generate depths w.r.t each support image of the reference image
// 		PatchMatch_Binocular(vKs,vRs,vts,vfx_1,vfy_1,vImgs,vIdxSupports,clouds,vd_max,vd_min,vh_max,vh_min,k,
// 			vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,size,angLimit,maxIter,factor,nRandSamp);


		// read them in //////////////////////////////////////////////////////////////////////////
		for (kk=0;kk<vIdxSupports[k].size();kk++)
		{
			Mat mDepth(h, w, CV_32FC1), mHx(h, w, CV_32FC1), mHy(h, w, CV_32FC1), mScore(h, w, CV_32FC1);

			int idx_spt = vIdxSupports[k][kk];

			CString strInfo;
// 			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 02 - dinoR\\%02d\\final PatchMatch depth map %02d with image %02d.txt", k,k,idx_spt);
// 			FILE * file_depth = fopen(strInfo, "r");
// 			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 02 - dinoR\\%02d\\final PatchMatch hx map %02d with image %02d.txt", k,k,idx_spt);
// 			FILE * file_hx = fopen(strInfo, "r");
// 			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 02 - dinoR\\%02d\\final PatchMatch hy map %02d with image %02d.txt", k,k,idx_spt);
// 			FILE * file_hy = fopen(strInfo, "r");
// 			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 02 - dinoR\\%02d\\final PatchMatch score map %02d with image %02d.txt", k,k,idx_spt);
// 			FILE * file_score = fopen(strInfo, "r");

			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 00 - templeR\\%02d\\final PatchMatch depth map %02d with image %02d.txt", k,k,idx_spt);
			FILE * file_depth = fopen(strInfo, "r");
			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 00 - templeR\\%02d\\final PatchMatch hx map %02d with image %02d.txt", k,k,idx_spt);
			FILE * file_hx = fopen(strInfo, "r");
			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 00 - templeR\\%02d\\final PatchMatch hy map %02d with image %02d.txt", k,k,idx_spt);
			FILE * file_hy = fopen(strInfo, "r");
			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 00 - templeR\\%02d\\final PatchMatch score map %02d with image %02d.txt", k,k,idx_spt);
			FILE * file_score = fopen(strInfo, "r");

// 			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 01 - dinoSparseR\\%02d\\final PatchMatch depth map %02d with image %02d.txt", k,k,idx_spt);
// 			FILE * file_depth = fopen(strInfo, "r");
// 			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 01 - dinoSparseR\\%02d\\final PatchMatch hx map %02d with image %02d.txt", k,k,idx_spt);
// 			FILE * file_hx = fopen(strInfo, "r");
// 			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 01 - dinoSparseR\\%02d\\final PatchMatch hy map %02d with image %02d.txt", k,k,idx_spt);
// 			FILE * file_hy = fopen(strInfo, "r");
// 			strInfo.Format("D:\\all\\20140802 new hope\\ultimate fullrun 01 - dinoSparseR\\%02d\\final PatchMatch score map %02d with image %02d.txt", k,k,idx_spt);
// 			FILE * file_score = fopen(strInfo, "r");


			// at the same time evaluate all parameters
			for (i=0;i<h;i++)
			{
				for (j=0;j<w;j++)
				{
					double depth,hx,hy,score;
					int tmp;
					fscanf(file_depth, "%lf	", &depth);
					fscanf(file_hx, "%lf	", &hx);
					fscanf(file_hy, "%lf	", &hy);
					fscanf(file_score, "%lf	", &score);

					mDepth.at<float>(i,j) = depth;
					mHx.at<float>(i,j) = hx;
					mHy.at<float>(i,j) = hy;
					mScore.at<float>(i,j) = score;
				}
			}
			fclose(file_depth);
			fclose(file_hx);
			fclose(file_hy);
			fclose(file_score);

			vDepths_bin.push_back(mDepth);
			vHxs_bin.push_back(mHx);
			vHys_bin.push_back(mHy);
			vScores_bin.push_back(mScore);
		}
		//////////////////////////////////////////////////////////////////////////


		for (kk=0;kk<vIdxSupports[k].size();kk++)
		{
			int idx_spt = vIdxSupports[k][kk];
			// then invalidate those estimates whose normals are not reasonable and whose scores are smaller than certain threshold
			InvalidatePixels_byNormal(vKs[k],vKs[idx_spt],vRs[k],vRs[idx_spt],vts[k],vts[idx_spt],vfx_1[k],vfx_1[idx_spt],vfy_1[k],vfy_1[idx_spt],k,idx_spt,
				vDepths_bin[kk], vHxs_bin[kk], vHys_bin[kk], vScores_bin[kk], thresh_ang, thresh_ncc);

			// here we can then eliminate all small depth regions detected by fast mesh
//			RemoveSmallDepthRegions_4(vAllCams[0], vAllImgs[0], vDepths[3], vScores[3], 80, vAllImgs[0].cols*vAllImgs[0].rows/400.0);
		}

		Mat mSel, mVisi;
		Mat mDepth_ML, mHx_ML, mHy_ML, mScore_ML;
		Extract_MRF_ncc_d_n_DP_withInvalids(vKs[k],vRs[k],vts[k],vfx_1[k],vfy_1[k],vImgs[k],k,
			vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mSel,mDepth_ML,mHx_ML,mHy_ML,mScore_ML,P1,P2);

		AugmentVisibility_basedonMostLikelyDepthandNormals(vKs,vRs,vts,vfx_1,vfy_1,vImgs,vIdxSupports,k,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mSel,mVisi,thresh_imgpt_sigma,90);

		Mat mDepth_MPGC, mHx_MPGC, mHy_MPGC, mScore_MPGC;
// 		MPGC_20140905(vKs,vRs,vts,vfx_1,vfy_1,vImgs,vIdxSupports,k,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mSel,mVisi,
// 			mDepth_MPGC,mHx_MPGC,mHy_MPGC,mScore_MPGC,size,size,maxIter_optim,xEps,fEps);
		MPGC_20140910(vKs,vRs,vts,vfx_1,vfy_1,vImgs,vIdxSupports,k,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mDepth_ML,mHx_ML,mHy_ML,mSel,mVisi,
			mDepth_MPGC,mHx_MPGC,mHy_MPGC,mScore_MPGC,size,size,thresh_ratio_depthdiscon,maxIter_optim,xEps,fEps);

		Mat mDepth_fused, mHx_fused, mHy_fused, mScore_fused;
		DepthFusion_minimizingProjErrors(vKs,vRs,vts,vfx_1,vfy_1,vImgs,vIdxSupports,k,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mSel,mVisi,
			mDepth_fused,mHx_fused,mHy_fused,mScore_fused,maxIter_optim,xEps,fEps);

		vDepths.push_back(mDepth_MPGC);
		vHxs.push_back(mHx_MPGC);
		vHys.push_back(mHy_MPGC);
		vScores.push_back(mScore_MPGC);
		vVisis.push_back(mVisi);
	}

	// depth consistency check
	for (k=0;k<nImg;k++)
	{
		DepthConsistencyCheck(vKs,vRs,vts,vfx_1,vfy_1,vIdxSupports,k,vDepths,vHxs,vHys,vScores,vVisis,thresh_ratio);

		// and remove small depth regions
		RemoveSmallDepthRegions_4(vKs[k],vRs[k],vts[k],vfx_1[k],vfy_1[k],vImgs[k],k,vDepths[k],vHxs[k],vHys[k],vScores[k],thresh_ang_removeSmall,thresh_area_removeSmall);
	}
}

// 20140914, parallel version, with complete MRF model
void DeepVoid::MVDE_package_final(const CString & path_output,					// input:	the path of output file folder
								  const vector<cam_data> & vCams,				// input:	all images' orientations
								  const vector<CString> & vPaths_imgs,			// input:	file paths of all input images
								  const vector<Mat> & vSilhouettes,				// input:	Silhouettes of all images
								  const vector<vector<int>> & vIdxSupports,		// input:	all images' support images' index
								  const vector<vector<CloudPoint>> & vClouds,	// input:	all point clouds, one for each input image
								  vector<Mat> & vDepths,						// output:	all generated depths
								  vector<Mat> & vHxs,							// output:	all generated depth gradients
								  vector<Mat> & vHys,							// output:	all generated depth gradients
								  vector<Mat> & vScores,						// output:	all scores, and -1 indicates an invalid estimate
								  vector<Mat> & vVisis,							// output:	all estimated visibilities within corresponding support image set
								  int size /*= 5*/,								// input:	the window size of the image patch, should be odd number
								  double angLimit /*= 80*/,						// input:	the angular range limit of the normal of every object point, in angle, not radian
								  int maxIter /*= 4*/,							// input:	maximum iteration
								  double factor /*= 0.5*/,
								  int nRandSamp /*= 6*/,
								  double thresh_ang /*= 90*/,					// input:	the normal angle constraint, if this value is 360, then no constraint at all
								  double thresh_ncc /*= 0.95*/,					// input:	the ncc threshold after patchmatch, ncc value is supposed to be very high if it's matched correctly after patchmatch
								  double P1 /*= 1.5*/,
								  double P2 /*= 0.1*/,
								  double thresh_imgpt_sigma /*= 1*/,
								  double thresh_ratio /*= 0.001*/,
								  double thresh_area_removeSmall /*= 15*/,
								  int maxIter_optim /*= 128*/,
								  double xEps /*= 1.0E-8*/,						// input: threshold
								  double fEps /*= 1.0E-6*/,						// input: threshold
								  bool bMPGCFinal /*= true*/					// input: use MPGC optimized or directly Most likely results
								  )
{
	int i,j,k,ii,jj,kk;

	int nImg = vCams.size();
	
	vDepths.clear(); vHxs.clear(); vHys.clear(); vScores.clear(); vVisis.clear();

	double tana = tan(angLimit*D2R);

	CString strInfo;

	// get corresponding orientation matrix //////////////////////////////////////////////////////////////////////////
	vector<Matx33d> vRs,vKs; vector<Matx31d> vts;

	for (k=0;k<nImg;k++)
	{
		Matx33d mR,mK; Matx31d mt;

		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR(i,j) = vCams[k].R[i*3+j];
			}
		}
		mK(0,0) = vCams[k].fx;	mK(0,1) = vCams[k].s;  mK(0,2) = vCams[k].cx;
		mK(1,1) = vCams[k].fy;	mK(1,2) = vCams[k].cy; mK(2,2) = 1;
		mt(0) = vCams[k].t[0];	mt(1) = vCams[k].t[1]; mt(2) = vCams[k].t[2];

		vRs.push_back(mR);
		vKs.push_back(mK);
		vts.push_back(mt);
	}
	//////////////////////////////////////////////////////////////////////////////////////////////////////////////////

	for (k=0;k<nImg;k++)
//	for (k=0;k<1;k++)
	{
		int n_spt = vIdxSupports[k].size();

		Matx33d mK0 = vKs[k];
		Matx33d mR0 = vRs[k];
		Matx31d mt0 = vts[k];

		double fx0_1 = 1/mK0(0,0);
		double fy0_1 = 1/mK0(1,1);

		double ratio_disc = 2*tana/(mK0(0,0)+mK0(1,1)); // ratio = tan(beta)/f = tan(beta)/((fx+fy)*0.5) = 2*tan(beta)/(fx+fy)

		CString path = vPaths_imgs[k];

		Mat img0 = imread(path.GetBuffer(), CV_LOAD_IMAGE_UNCHANGED);

		int h = img0.rows;
		int w = img0.cols;

		vector<Matx33d> vKs_spt, vRs_spt; vector<Matx31d> vts_spt;
		vector<Mat> vImgs_spt;

		for (kk=0;kk<n_spt;kk++)
		{
			int idx_spt = vIdxSupports[k][kk];
			vKs_spt.push_back(vKs[idx_spt]);
			vRs_spt.push_back(vRs[idx_spt]);
			vts_spt.push_back(vts[idx_spt]);

			path = vPaths_imgs[idx_spt];

			Mat img = imread(path.GetBuffer(), CV_LOAD_IMAGE_UNCHANGED);

			vImgs_spt.push_back(img);
		}

		vector<Mat> vDepths_bin, vHxs_bin, vHys_bin, vScores_bin;

		// first generate depths w.r.t each support image of the reference image
//		PatchMatch_Binocular(mK0,mR0,mt0,img0,vKs_spt,vRs_spt,vts_spt,vImgs_spt,vClouds[k],vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,size,angLimit,maxIter,factor,nRandSamp);
		PatchMatch_Binocular_3DPropagation(mK0,mR0,mt0,img0,vKs_spt,vRs_spt,vts_spt,vImgs_spt,vClouds[k],vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,size,angLimit,maxIter,factor,nRandSamp);

		// print them out or read them in //////////////////////////////////////////////////////////////////////////
		for (kk=0;kk<n_spt;kk++)
		{
			int idx_spt = vIdxSupports[k][kk];

			// print them out ////////////////////////////////////////////////////////////////
			strInfo.Format("%03d final PatchMatch depth map with image %03d.txt",k,idx_spt);
			FILE * file_depth = fopen(path_output+strInfo, "w");
			strInfo.Format("%03d final PatchMatch hx map with image %03d.txt",k,idx_spt);
			FILE * file_hx = fopen(path_output+strInfo, "w");
			strInfo.Format("%03d final PatchMatch hy map with image %03d.txt",k,idx_spt);
			FILE * file_hy = fopen(path_output+strInfo, "w");
			strInfo.Format("%03d final PatchMatch score map with image %03d.txt",k,idx_spt);
			FILE * file_score = fopen(path_output+strInfo, "w");

			// at the same time evaluate all parameters
			for (i=0;i<h;i++)
			{
				for (j=0;j<w;j++)
				{
					fprintf(file_depth, "%.16f	", vDepths_bin[kk].at<float>(i,j));
					fprintf(file_hx, "%.16f	", vHxs_bin[kk].at<float>(i,j));
					fprintf(file_hy, "%.16f	", vHys_bin[kk].at<float>(i,j));
					fprintf(file_score, "%.16f	", vScores_bin[kk].at<float>(i,j));
				}
				fprintf(file_depth, "\n");
				fprintf(file_hx, "\n");
				fprintf(file_hy, "\n");
				fprintf(file_score, "\n");
			}
			fclose(file_depth);
			fclose(file_hx);
			fclose(file_hy);
			fclose(file_score);

			// read them in //////////////////////////////////////////////////////
// 			Mat mDepth(h, w, CV_32FC1), mHx(h, w, CV_32FC1), mHy(h, w, CV_32FC1), mScore(h, w, CV_32FC1);
// 
// 			strInfo.Format("%03d final PatchMatch depth map with image %03d.txt",k,idx_spt);
// 			FILE * file_depth = fopen(path_output+strInfo, "r");
// 			strInfo.Format("%03d final PatchMatch hx map with image %03d.txt",k,idx_spt);
// 			FILE * file_hx = fopen(path_output+strInfo, "r");
// 			strInfo.Format("%03d final PatchMatch hy map with image %03d.txt",k,idx_spt);
// 			FILE * file_hy = fopen(path_output+strInfo, "r");
// 			strInfo.Format("%03d final PatchMatch score map with image %03d.txt",k,idx_spt);
// 			FILE * file_score = fopen(path_output+strInfo, "r");
// 
// 			// at the same time evaluate all parameters
// 			for (i=0;i<h;i++)
// 			{
// 				for (j=0;j<w;j++)
// 				{
// 					double depth,hx,hy,score;
// 					int tmp;
// 					fscanf(file_depth, "%lf	", &depth);
// 					fscanf(file_hx, "%lf	", &hx);
// 					fscanf(file_hy, "%lf	", &hy);
// 					fscanf(file_score, "%lf	", &score);
// 
// 					mDepth.at<float>(i,j) = depth;
// 					mHx.at<float>(i,j) = hx;
// 					mHy.at<float>(i,j) = hy;
// 					mScore.at<float>(i,j) = score;
// 				}
// 			}
// 			fclose(file_depth);
// 			fclose(file_hx);
// 			fclose(file_hy);
// 			fclose(file_score);
// 
// 			vDepths_bin.push_back(mDepth);
// 			vHxs_bin.push_back(mHx);
// 			vHys_bin.push_back(mHy);
// 			vScores_bin.push_back(mScore);
		}
		//////////////////////////////////////////////////////////////////////////

		for (kk=0;kk<n_spt;kk++)
		{
			// then invalidate those estimates whose normals are not reasonable and whose scores are smaller than certain threshold
			InvalidatePixels_byNormal(mK0,mR0,mt0,vKs_spt[kk],vRs_spt[kk],vts_spt[kk],vDepths_bin[kk],vHxs_bin[kk],vHys_bin[kk],vScores_bin[kk],thresh_ang,thresh_ncc);

			// here we can then eliminate all small depth regions detected by fast mesh
//			RemoveSmallDepthRegions_4(mK0,mR0,mt0,vDepths_bin[kk],vScores_bin[kk],thresh_ratio_depthdiscon,thresh_area_removeSmall);
		}

		Mat mSel, mVisi;
		Mat mDepth_ML, mHx_ML, mHy_ML, mScore_ML;
		Extract_MRF_ncc_d_n_DP_withInvalids(mK0,mR0,mt0,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mSel,mDepth_ML,mHx_ML,mHy_ML,mScore_ML,P1,P2);

//		AugmentVisibility_basedonMostLikelyDepthandNormals(mK0,mR0,mt0,vKs_spt,vRs_spt,vts_spt,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mSel,mVisi,thresh_imgpt_sigma,90);
		AugmentVisibility_basedonMostLikelyDepthandNormals_SURE(mK0,mR0,mt0,vKs_spt,vRs_spt,vts_spt,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mSel,mVisi,thresh_imgpt_sigma,90);

		Mat mDepth_MPGC, mHx_MPGC, mHy_MPGC, mScore_MPGC;
		MPGC_20140910(mK0,mR0,mt0,img0,vKs_spt,vRs_spt,vts_spt,vImgs_spt,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mDepth_ML,mHx_ML,mHy_ML,mSel,mVisi,
			mDepth_MPGC,mHx_MPGC,mHy_MPGC,mScore_MPGC,size,size,ratio_disc,maxIter_optim,xEps,fEps);

		Mat mDepth_fused, mHx_fused, mHy_fused, mScore_fused;
		DepthFusion_minimizingProjErrors(mK0,mR0,mt0,vKs_spt,vRs_spt,vts_spt,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mSel,mVisi,
			mDepth_fused,mHx_fused,mHy_fused,mScore_fused,maxIter_optim,xEps,fEps);

		// draw visibility w.r.t each support image
		vector<Mat> vVisi_map;
		for (kk=0;kk<n_spt;kk++)
		{
			Mat mtmp(h,w,CV_8UC3);
			vVisi_map.push_back(mtmp);
		}

		for (i=0;i<h;i++)
		{
			for (j=0;j<w;j++)
			{
				uchar visi = mVisi.at<uchar>(i,j);

				vector<bool> vbools;
				InterpVisiVector_uchar(visi, vbools);

				for (kk=0;kk<n_spt;kk++)
				{
					if (vbools[kk])
					{
						vVisi_map[kk].at<Vec3b>(i,j).val[0] = img0.at<Vec3b>(i,j).val[0];
						vVisi_map[kk].at<Vec3b>(i,j).val[1] = img0.at<Vec3b>(i,j).val[1];
						vVisi_map[kk].at<Vec3b>(i,j).val[2] = img0.at<Vec3b>(i,j).val[2];
					} 
					else
					{
						vVisi_map[kk].at<Vec3b>(i,j).val[0] = 0;
						vVisi_map[kk].at<Vec3b>(i,j).val[1] = 0;
						vVisi_map[kk].at<Vec3b>(i,j).val[2] = 255;
					}
				}
			}
		}

		for (kk=0;kk<n_spt;kk++)
		{
			strInfo.Format("%03d final visi map wrt support image %03d.bmp", k, vIdxSupports[k][kk]);
			imwrite((path_output+strInfo).GetBuffer(), vVisi_map[kk]);
		}

		// output to images
		CString strFile;
		strFile.Format("%03d depth map after MRF.bmp", k);
		SaveParaField2Img(path_output+strFile, mDepth_ML);

		strFile.Format("%03d depth map after MPGC.bmp", k);
		SaveParaField2Img(path_output+strFile, mDepth_MPGC);

		strFile.Format("%03d score map after MRF.bmp", k);
		SaveScoreField2Img(path_output+strFile, mScore_ML);

		strFile.Format("%03d score map after MPGC.bmp", k);
		SaveScoreField2Img(path_output+strFile, mScore_MPGC);
		
		Mat mNormColor;
		GetNormColorField(mK0, mR0, mt0, fx0_1, fy0_1, mDepth_ML, mHx_ML, mHy_ML, mNormColor);
		strFile.Format("%03d normal map after MRF.bmp", k);
		imwrite((path_output+strFile).GetBuffer(), mNormColor);

		GetNormColorField(mK0, mR0, mt0, fx0_1, fy0_1, mDepth_MPGC, mHx_MPGC, mHy_MPGC, mNormColor);
		strFile.Format("%03d normal map after MPGC.bmp", k);
		imwrite((path_output+strFile).GetBuffer(), mNormColor);

		strFile.Format("%03d point cloud after MRF.txt", k);
		OutputPointCloud(path_output+strFile,mK0,mR0,mt0,fx0_1,fy0_1,img0,mDepth_ML,mHx_ML,mHy_ML,mScore_ML);

		strFile.Format("%03d point cloud after MPGC.txt", k);
		OutputPointCloud(path_output+strFile,mK0,mR0,mt0,fx0_1,fy0_1,img0,mDepth_MPGC,mHx_MPGC,mHy_MPGC,mScore_MPGC);

		// output to files
		if (bMPGCFinal) // output MPGC results as the final results
		{
			strFile.Format("%03d depth map after MPGC.txt", k);
			FILE * file_depth = fopen(path_output+strFile, "w");
			strFile.Format("%03d hx map after MPGC.txt", k);
			FILE * file_hx = fopen(path_output+strFile, "w");
			strFile.Format("%03d hy map after MPGC.txt", k);
			FILE * file_hy = fopen(path_output+strFile, "w");
			strFile.Format("%03d score map after MPGC.txt", k);
			FILE * file_score = fopen(path_output+strFile, "w");
			strFile.Format("%03d visi map.txt", k);
			FILE * file_visi = fopen(path_output+strFile, "w");

			// at the same time evaluate all parameters
			for (i=0;i<h;i++)
			{
				for (j=0;j<w;j++)
				{
					fprintf(file_depth, "%.16f	", mDepth_MPGC.at<float>(i,j));
					fprintf(file_hx, "%.16f	", mHx_MPGC.at<float>(i,j));
					fprintf(file_hy, "%.16f	", mHy_MPGC.at<float>(i,j));
					fprintf(file_score, "%.16f	", mScore_MPGC.at<float>(i,j));
					fprintf(file_visi, "%d	", mVisi.at<uchar>(i,j));
				}
				fprintf(file_depth, "\n");
				fprintf(file_hx, "\n");
				fprintf(file_hy, "\n");
				fprintf(file_score, "\n");
				fprintf(file_visi, "\n");
			}
			fclose(file_depth);
			fclose(file_hx);
			fclose(file_hy);
			fclose(file_score);
			fclose(file_visi);
		} 
		else // output Most likely results as the final results
		{
			strFile.Format("%03d depth map after MRF.txt", k);
			FILE * file_depth = fopen(path_output+strFile, "w");
			strFile.Format("%03d hx map after MRF.txt", k);
			FILE * file_hx = fopen(path_output+strFile, "w");
			strFile.Format("%03d hy map after MRF.txt", k);
			FILE * file_hy = fopen(path_output+strFile, "w");
			strFile.Format("%03d score map after MRF.txt", k);
			FILE * file_score = fopen(path_output+strFile, "w");
			strFile.Format("%03d visi map.txt", k);
			FILE * file_visi = fopen(path_output+strFile, "w");

			// at the same time evaluate all parameters
			for (i=0;i<h;i++)
			{
				for (j=0;j<w;j++)
				{
					fprintf(file_depth, "%.16f	", mDepth_ML.at<float>(i,j));
					fprintf(file_hx, "%.16f	", mHx_ML.at<float>(i,j));
					fprintf(file_hy, "%.16f	", mHy_ML.at<float>(i,j));
					fprintf(file_score, "%.16f	", mScore_ML.at<float>(i,j));
					fprintf(file_visi, "%d	", mVisi.at<uchar>(i,j));
				}
				fprintf(file_depth, "\n");
				fprintf(file_hx, "\n");
				fprintf(file_hy, "\n");
				fprintf(file_score, "\n");
				fprintf(file_visi, "\n");
			}
			fclose(file_depth);
			fclose(file_hx);
			fclose(file_hy);
			fclose(file_score);
			fclose(file_visi);
		}
	}
	return;

	// depth consistency check
	for (k=0;k<nImg;k++)
	{
		strInfo.Format("check image %03d", k);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		int n_spt = vIdxSupports[k].size();

		Matx33d mK0 = vKs[k];
		Matx33d mR0 = vRs[k];
		Matx31d mt0 = vts[k];

		double fx0_1 = 1/mK0(0,0);
		double fy0_1 = 1/mK0(1,1);

		double ratio_disc = 2*tana/(mK0(0,0)+mK0(1,1)); // ratio = tan(beta)/f = tan(beta)/((fx+fy)*0.5) = 2*tan(beta)/(fx+fy)

		CString path = vPaths_imgs[k];

		Mat img0 = imread(path.GetBuffer(), CV_LOAD_IMAGE_UNCHANGED);

		int h0 = img0.rows;
		int w0 = img0.cols;

		Mat mDepth0(h0,w0,CV_32FC1), mHx0(h0,w0,CV_32FC1), mHy0(h0,w0,CV_32FC1), mScore0(h0,w0,CV_32FC1), mVisi0(h0,w0,CV_8UC1);

		// read-in the reference fields
		CString strFile;

		FILE * file_depth;
		FILE * file_hx;
		FILE * file_hy;
		FILE * file_score;
		FILE * file_visi;

		if (bMPGCFinal)
		{
			strFile.Format("%03d depth map after MPGC.txt", k);
			file_depth = fopen(path_output+strFile, "r");
			strFile.Format("%03d hx map after MPGC.txt", k);
			file_hx = fopen(path_output+strFile, "r");
			strFile.Format("%03d hy map after MPGC.txt", k);
			file_hy = fopen(path_output+strFile, "r");
			strFile.Format("%03d score map after MPGC.txt", k);
			file_score = fopen(path_output+strFile, "r");
			strFile.Format("%03d visi map.txt", k);
			file_visi = fopen(path_output+strFile, "r");
		} 
		else
		{
			strFile.Format("%03d depth map after MRF.txt", k);
			file_depth = fopen(path_output+strFile, "r");
			strFile.Format("%03d hx map after MRF.txt", k);
			file_hx = fopen(path_output+strFile, "r");
			strFile.Format("%03d hy map after MRF.txt", k);
			file_hy = fopen(path_output+strFile, "r");
			strFile.Format("%03d score map after MRF.txt", k);
			file_score = fopen(path_output+strFile, "r");
			strFile.Format("%03d visi map.txt", k);
			file_visi = fopen(path_output+strFile, "r");
		}
		
		// at the same time evaluate all parameters
		for (i=0;i<h0;i++)
		{
			for (j=0;j<w0;j++)
			{
				double depth,hx,hy,score;
				int tmp;
				fscanf(file_depth, "%lf	", &depth);
				fscanf(file_hx, "%lf	", &hx);
				fscanf(file_hy, "%lf	", &hy);
				fscanf(file_score, "%lf	", &score);

				mDepth0.at<float>(i,j) = depth;
				mHx0.at<float>(i,j) = hx;
				mHy0.at<float>(i,j) = hy;
				mScore0.at<float>(i,j) = score;

				fscanf(file_visi, "%d	", &tmp);
				mVisi0.at<uchar>(i,j) = (uchar)tmp;
			}
		}
		fclose(file_depth);
		fclose(file_hx);
		fclose(file_hy);
		fclose(file_score);
		fclose(file_visi);

		vector<Matx33d> vKs_spt, vRs_spt; vector<Matx31d> vts_spt;
//		vector<Mat> vImgs_spt;

		vector<Mat> vDepths_spt, vHxs_spt, vHys_spt;

		for (kk=0;kk<n_spt;kk++)
		{
			int idx_spt = vIdxSupports[k][kk];
			vKs_spt.push_back(vKs[idx_spt]);
			vRs_spt.push_back(vRs[idx_spt]);
			vts_spt.push_back(vts[idx_spt]);

			path = vPaths_imgs[idx_spt];

			Mat img = imread(path.GetBuffer(), CV_LOAD_IMAGE_UNCHANGED);

			int h = img.rows;
			int w = img.cols;

//			vImgs_spt.push_back(img);

			Mat mDepth(h,w,CV_32FC1), mHx(h,w,CV_32FC1), mHy(h,w,CV_32FC1);

			// read-in the support fields
			if (bMPGCFinal)
			{
				strFile.Format("%03d depth map after MPGC.txt", idx_spt);
				file_depth = fopen(path_output+strFile, "r");
				strFile.Format("%03d hx map after MPGC.txt", idx_spt);
				file_hx = fopen(path_output+strFile, "r");
				strFile.Format("%03d hy map after MPGC.txt", idx_spt);
				file_hy = fopen(path_output+strFile, "r");
			} 
			else
			{
				strFile.Format("%03d depth map after MRF.txt", idx_spt);
				file_depth = fopen(path_output+strFile, "r");
				strFile.Format("%03d hx map after MRF.txt", idx_spt);
				file_hx = fopen(path_output+strFile, "r");
				strFile.Format("%03d hy map after MRF.txt", idx_spt);
				file_hy = fopen(path_output+strFile, "r");
			}
			
			// at the same time evaluate all parameters
			for (i=0;i<h;i++)
			{
				for (j=0;j<w;j++)
				{
					double depth,hx,hy;
					fscanf(file_depth, "%lf	", &depth);
					fscanf(file_hx, "%lf	", &hx);
					fscanf(file_hy, "%lf	", &hy);

					mDepth.at<float>(i,j) = depth;
					mHx.at<float>(i,j) = hx;
					mHy.at<float>(i,j) = hy;
				}
			}
			fclose(file_depth);
			fclose(file_hx);
			fclose(file_hy);

			vDepths_spt.push_back(mDepth);
			vHxs_spt.push_back(mHx);
			vHys_spt.push_back(mHy);
		}

		DepthConsistencyCheck(mK0,mR0,mt0,mDepth0,mVisi0,mScore0,vKs_spt,vRs_spt,vts_spt,vDepths_spt,vHxs_spt,vHys_spt,thresh_ratio);

		strFile.Format("%03d score map after depth consistency check.bmp", k);
		SaveScoreField2Img(path_output+strFile, mScore0);


		// and remove small depth regions
		RemoveSmallDepthRegions_4(mK0,mR0,mt0,mDepth0,mScore0,ratio_disc,thresh_area_removeSmall);

		strFile.Format("%03d score map after removing small regions.bmp", k);
		SaveScoreField2Img(path_output+strFile, mScore0);
		
		strFile.Format("%03d point cloud final.txt", k);
		OutputPointCloud(path_output+strFile,mK0,mR0,mt0,fx0_1,fy0_1,img0,mDepth0,mHx0,mHy0,mScore0);


		// further using silhouettes to filter more outliers
// 		VisualHullConstraint(k,vKs,vRs,vts,vSilhouettes,mDepth0,mScore0,2);
// 
// 		strFile.Format("%03d score map after enforcing silhouette constraint.bmp", k);
// 		SaveScoreField2Img(path_output+strFile, mScore0);
// 
// 		strFile.Format("%03d point cloud final after enforcing silhouette constraint.txt", k);
// 		OutputPointCloud(path_output+strFile,mK0,mR0,mt0,fx0_1,fy0_1,img0,mDepth0,mHx0,mHy0,mScore0);
	}
}

// 20141209, for Zhou's data, the very original Multi-view patchmatch version
void DeepVoid::MVDE_package_141209(const CString & path_output,				// input:	the path of output file folder
								   const vector<cam_data> & vCams,			// input:	all images' orientations
								   const vector<CString> & vPaths_imgs,		// input:	file paths of all input images
								   const vector<Mat> & vSilhouettes,			// input:	Silhouettes of all images
								   const vector<vector<int>> & vIdxSupports,	// input:	all images' support images' index
								   const vector<vector<CloudPoint>> & vClouds,// input:	all point clouds, one for each input image
								   vector<Mat> & vDepths,						// output:	all generated depths
								   vector<Mat> & vHxs,						// output:	all generated depth gradients
								   vector<Mat> & vHys,						// output:	all generated depth gradients
								   vector<Mat> & vScores,						// output:	all scores, and -1 indicates an invalid estimate
								   vector<Mat> & vVisis,						// output:	all estimated visibilities within corresponding support image set
								   int size /*= 5*/,							// input:	the window size of the image patch, should be odd number
								   double angLimit /*= 80*/,					// input:	the angular range limit of the normal of every object point, in angle, not radian
								   int maxIter /*= 4*/,						// input:	maximum iteration
								   double factor /*= 0.5*/,
								   int nRandSamp /*= 6*/,
								   double thresh_ang /*= 90*/,				// input:	the normal angle constraint, if this value is 360, then no constraint at all
								   double thresh_ncc /*= 0.95*/,				// input:	the ncc threshold after patchmatch, ncc value is supposed to be very high if it's matched correctly after patchmatch
								   double P1 /*= 1.5*/,
								   double P2 /*= 0.1*/,
								   double thresh_imgpt_sigma /*= 1*/,
								   double thresh_ratio /*= 0.001*/,
								   double thresh_area_removeSmall /*= 15*/,
								   int maxIter_optim /*= 128*/,
								   double xEps /*= 1.0E-8*/,					// input: threshold
								   double fEps /*= 1.0E-6*/					// input: threshold
								   )
{
	int i,j,k,ii,jj,kk;

	int nImg = vCams.size();

	vDepths.clear(); vHxs.clear(); vHys.clear(); vScores.clear(); vVisis.clear();

	double tana = tan(angLimit*D2R);

	CString strInfo;

	// get corresponding orientation matrix //////////////////////////////////////////////////////////////////////////
	vector<Matx33d> vRs,vKs; vector<Matx31d> vts;

	for (k=0;k<nImg;k++)
	{
		Matx33d mR,mK; Matx31d mt;

		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR(i,j) = vCams[k].R[i*3+j];
			}
		}
		mK(0,0) = vCams[k].fx;	mK(0,1) = vCams[k].s;  mK(0,2) = vCams[k].cx;
		mK(1,1) = vCams[k].fy;	mK(1,2) = vCams[k].cy; mK(2,2) = 1;
		mt(0) = vCams[k].t[0];	mt(1) = vCams[k].t[1]; mt(2) = vCams[k].t[2];

		vRs.push_back(mR);
		vKs.push_back(mK);
		vts.push_back(mt);
	}
	//////////////////////////////////////////////////////////////////////////////////////////////////////////////////

//	for (k=0;k<nImg;k++)
	for (k=6;k<7;k++)
	{
		int n_spt = vIdxSupports[k].size();

		Matx33d mK0 = vKs[k];
		Matx33d mR0 = vRs[k];
		Matx31d mt0 = vts[k];

		double fx0_1 = 1/mK0(0,0);
		double fy0_1 = 1/mK0(1,1);

		double ratio_disc = 2*tana/(mK0(0,0)+mK0(1,1)); // ratio = tan(beta)/f = tan(beta)/((fx+fy)*0.5) = 2*tan(beta)/(fx+fy)

		CString path = vPaths_imgs[k];

		Mat img0 = imread(path.GetBuffer(), CV_LOAD_IMAGE_UNCHANGED);

		int h = img0.rows;
		int w = img0.cols;

		vector<Matx33d> vKs_spt, vRs_spt; vector<Matx31d> vts_spt;
		vector<Mat> vImgs_spt;

		for (kk=0;kk<n_spt;kk++)
		{
			int idx_spt = vIdxSupports[k][kk];
			vKs_spt.push_back(vKs[idx_spt]);
			vRs_spt.push_back(vRs[idx_spt]);
			vts_spt.push_back(vts[idx_spt]);

			path = vPaths_imgs[idx_spt];

			Mat img = imread(path.GetBuffer(), CV_LOAD_IMAGE_UNCHANGED);

			vImgs_spt.push_back(img);
		}

		// try pyramid ///////////////////////////////////////////////////////////
		Pyramid(mK0,mR0,mt0,img0,vKs_spt,vRs_spt,vts_spt,vImgs_spt,vClouds[k],
			size,thresh_ncc,angLimit,maxIter,factor,nRandSamp,4,1);
		continue;
		//////////////////////////////////////////////////////////////////////////

		vector<Mat> vDepths_bin, vHxs_bin, vHys_bin, vScores_bin;

		Mat mSel, mVisi_MVPM;
		Mat mDepth_MVPM, mHx_MVPM, mHy_MVPM, mScore_MVPM;

		// directly conduct multi-view PatchMatch to estimate depth
		PatchMatch_141209(mK0,mR0,mt0,img0,vKs_spt,vRs_spt,vts_spt,vImgs_spt,vClouds[k],
			mDepth_MVPM,mHx_MVPM,mHy_MVPM,mScore_MVPM,mVisi_MVPM,size,thresh_ncc,angLimit,maxIter,factor,nRandSamp);

		// print them out or read them in //////////////////////////////////////////////////////////////////////////
// 		for (kk=0;kk<n_spt;kk++)
// 		{
// 			int idx_spt = vIdxSupports[k][kk];
// 
// 			// print them out ////////////////////////////////////////////////////////////////
// 			strInfo.Format("%03d final PatchMatch depth map with image %03d.txt",k,idx_spt);
// 			FILE * file_depth = fopen(path_output+strInfo, "w");
// 			strInfo.Format("%03d final PatchMatch hx map with image %03d.txt",k,idx_spt);
// 			FILE * file_hx = fopen(path_output+strInfo, "w");
// 			strInfo.Format("%03d final PatchMatch hy map with image %03d.txt",k,idx_spt);
// 			FILE * file_hy = fopen(path_output+strInfo, "w");
// 			strInfo.Format("%03d final PatchMatch score map with image %03d.txt",k,idx_spt);
// 			FILE * file_score = fopen(path_output+strInfo, "w");
// 
// 			// at the same time evaluate all parameters
// 			for (i=0;i<h;i++)
// 			{
// 				for (j=0;j<w;j++)
// 				{
// 					fprintf(file_depth, "%.16f	", vDepths_bin[kk].at<float>(i,j));
// 					fprintf(file_hx, "%.16f	", vHxs_bin[kk].at<float>(i,j));
// 					fprintf(file_hy, "%.16f	", vHys_bin[kk].at<float>(i,j));
// 					fprintf(file_score, "%.16f	", vScores_bin[kk].at<float>(i,j));
// 				}
// 				fprintf(file_depth, "\n");
// 				fprintf(file_hx, "\n");
// 				fprintf(file_hy, "\n");
// 				fprintf(file_score, "\n");
// 			}
// 			fclose(file_depth);
// 			fclose(file_hx);
// 			fclose(file_hy);
// 			fclose(file_score);
// 
// 			// read them in //////////////////////////////////////////////////////
// 			// 			Mat mDepth(h, w, CV_32FC1), mHx(h, w, CV_32FC1), mHy(h, w, CV_32FC1), mScore(h, w, CV_32FC1);
// 			// 
// 			// 			strInfo.Format("%03d final PatchMatch depth map with image %03d.txt",k,idx_spt);
// 			// 			FILE * file_depth = fopen(path_output+strInfo, "r");
// 			// 			strInfo.Format("%03d final PatchMatch hx map with image %03d.txt",k,idx_spt);
// 			// 			FILE * file_hx = fopen(path_output+strInfo, "r");
// 			// 			strInfo.Format("%03d final PatchMatch hy map with image %03d.txt",k,idx_spt);
// 			// 			FILE * file_hy = fopen(path_output+strInfo, "r");
// 			// 			strInfo.Format("%03d final PatchMatch score map with image %03d.txt",k,idx_spt);
// 			// 			FILE * file_score = fopen(path_output+strInfo, "r");
// 			// 
// 			// 			// at the same time evaluate all parameters
// 			// 			for (i=0;i<h;i++)
// 			// 			{
// 			// 				for (j=0;j<w;j++)
// 			// 				{
// 			// 					double depth,hx,hy,score;
// 			// 					int tmp;
// 			// 					fscanf(file_depth, "%lf	", &depth);
// 			// 					fscanf(file_hx, "%lf	", &hx);
// 			// 					fscanf(file_hy, "%lf	", &hy);
// 			// 					fscanf(file_score, "%lf	", &score);
// 			// 
// 			// 					mDepth.at<float>(i,j) = depth;
// 			// 					mHx.at<float>(i,j) = hx;
// 			// 					mHy.at<float>(i,j) = hy;
// 			// 					mScore.at<float>(i,j) = score;
// 			// 				}
// 			// 			}
// 			// 			fclose(file_depth);
// 			// 			fclose(file_hx);
// 			// 			fclose(file_hy);
// 			// 			fclose(file_score);
// 			// 
// 			// 			vDepths_bin.push_back(mDepth);
// 			// 			vHxs_bin.push_back(mHx);
// 			// 			vHys_bin.push_back(mHy);
// 			// 			vScores_bin.push_back(mScore);
// 		}
// 		//////////////////////////////////////////////////////////////////////////
// 
// 		for (kk=0;kk<n_spt;kk++)
// 		{
// 			// then invalidate those estimates whose normals are not reasonable and whose scores are smaller than certain threshold
// 			InvalidatePixels_byNormal(mK0,mR0,mt0,vKs_spt[kk],vRs_spt[kk],vts_spt[kk],vDepths_bin[kk],vHxs_bin[kk],vHys_bin[kk],vScores_bin[kk],thresh_ang,thresh_ncc);
// 
// 			// here we can then eliminate all small depth regions detected by fast mesh
// 			//			RemoveSmallDepthRegions_4(mK0,mR0,mt0,vDepths_bin[kk],vScores_bin[kk],thresh_ratio_depthdiscon,thresh_area_removeSmall);
// 		}
// 
// 		Mat mSel, mVisi;
// 		Mat mDepth_ML, mHx_ML, mHy_ML, mScore_ML;
// 		Extract_MRF_ncc_d_n_DP_withInvalids(mK0,mR0,mt0,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mSel,mDepth_ML,mHx_ML,mHy_ML,mScore_ML,P1,P2);
// 
// 		//		AugmentVisibility_basedonMostLikelyDepthandNormals(mK0,mR0,mt0,vKs_spt,vRs_spt,vts_spt,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mSel,mVisi,thresh_imgpt_sigma,90);
// 		AugmentVisibility_basedonMostLikelyDepthandNormals_SURE(mK0,mR0,mt0,vKs_spt,vRs_spt,vts_spt,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mSel,mVisi,thresh_imgpt_sigma,90);
// 
// 		Mat mDepth_MPGC, mHx_MPGC, mHy_MPGC, mScore_MPGC;
// 		MPGC_20140910(mK0,mR0,mt0,img0,vKs_spt,vRs_spt,vts_spt,vImgs_spt,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mDepth_ML,mHx_ML,mHy_ML,mSel,mVisi,
// 			mDepth_MPGC,mHx_MPGC,mHy_MPGC,mScore_MPGC,size,size,ratio_disc,maxIter_optim,xEps,fEps);
// 
// 		Mat mDepth_fused, mHx_fused, mHy_fused, mScore_fused;
// 		DepthFusion_minimizingProjErrors(mK0,mR0,mt0,vKs_spt,vRs_spt,vts_spt,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mSel,mVisi,
// 			mDepth_fused,mHx_fused,mHy_fused,mScore_fused,maxIter_optim,xEps,fEps);

		// draw visibility w.r.t each support image
		vector<Mat> vVisi_map;
		for (kk=0;kk<n_spt;kk++)
		{
			Mat mtmp(h,w,CV_8UC3);
			vVisi_map.push_back(mtmp);
		}

		for (i=0;i<h;i++)
		{
			for (j=0;j<w;j++)
			{
				uchar visi = mVisi_MVPM.at<uchar>(i,j);

				vector<bool> vbools;
				InterpVisiVector_uchar(visi, vbools);

				for (kk=0;kk<n_spt;kk++)
				{
					if (vbools[kk])
					{
						vVisi_map[kk].at<Vec3b>(i,j).val[0] = img0.at<Vec3b>(i,j).val[0];
						vVisi_map[kk].at<Vec3b>(i,j).val[1] = img0.at<Vec3b>(i,j).val[1];
						vVisi_map[kk].at<Vec3b>(i,j).val[2] = img0.at<Vec3b>(i,j).val[2];
					} 
					else
					{
						vVisi_map[kk].at<Vec3b>(i,j).val[0] = 0;
						vVisi_map[kk].at<Vec3b>(i,j).val[1] = 0;
						vVisi_map[kk].at<Vec3b>(i,j).val[2] = 255;
					}
				}
			}
		}

		for (kk=0;kk<n_spt;kk++)
		{
			strInfo.Format("%03d final visi map wrt support image %03d.bmp", k, vIdxSupports[k][kk]);
			imwrite((path_output+strInfo).GetBuffer(), vVisi_map[kk]);
		}

		// output to images
		CString strFile;

		strFile.Format("%03d depth map after MVPM.bmp", k);
		SaveParaField2Img(path_output+strFile, mDepth_MVPM);

		strFile.Format("%03d score map after MVPM.bmp", k);
		SaveScoreField2Img(path_output+strFile, mScore_MVPM);

		Mat mNormColor;
		GetNormColorField(mK0, mR0, mt0, fx0_1, fy0_1, mDepth_MVPM, mHx_MVPM, mHy_MVPM, mNormColor);
		strFile.Format("%03d normal map after MVPM.bmp", k);
		imwrite((path_output+strFile).GetBuffer(), mNormColor);

		strFile.Format("%03d point cloud after MVPM.txt", k);
		OutputPointCloud(path_output+strFile,mK0,mR0,mt0,fx0_1,fy0_1,img0,mDepth_MVPM,mHx_MVPM,mHy_MVPM,mScore_MVPM);

		// output to files
		strFile.Format("%03d depth map after MVPM.txt", k);
		FILE * file_depth = fopen(path_output+strFile, "w");
		strFile.Format("%03d hx map after MVPM.txt", k);
		FILE * file_hx = fopen(path_output+strFile, "w");
		strFile.Format("%03d hy map after MVPM.txt", k);
		FILE * file_hy = fopen(path_output+strFile, "w");
		strFile.Format("%03d score map after MVPM.txt", k);
		FILE * file_score = fopen(path_output+strFile, "w");
		strFile.Format("%03d visi map.txt", k);
		FILE * file_visi = fopen(path_output+strFile, "w");

		// at the same time evaluate all parameters
		for (i=0;i<h;i++)
		{
			for (j=0;j<w;j++)
			{
				fprintf(file_depth, "%.16f	", mDepth_MVPM.at<float>(i,j));
				fprintf(file_hx, "%.16f	", mHx_MVPM.at<float>(i,j));
				fprintf(file_hy, "%.16f	", mHy_MVPM.at<float>(i,j));
				fprintf(file_score, "%.16f	", mScore_MVPM.at<float>(i,j));
				fprintf(file_visi, "%d	", mVisi_MVPM.at<uchar>(i,j));
			}
			fprintf(file_depth, "\n");
			fprintf(file_hx, "\n");
			fprintf(file_hy, "\n");
			fprintf(file_score, "\n");
			fprintf(file_visi, "\n");
		}
		fclose(file_depth);
		fclose(file_hx);
		fclose(file_hy);
		fclose(file_score);
		fclose(file_visi);
	}
	return;

	// depth consistency check
	for (k=0;k<nImg;k++)
	{
		strInfo.Format("check image %03d", k);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		int n_spt = vIdxSupports[k].size();

		Matx33d mK0 = vKs[k];
		Matx33d mR0 = vRs[k];
		Matx31d mt0 = vts[k];

		double fx0_1 = 1/mK0(0,0);
		double fy0_1 = 1/mK0(1,1);

		double ratio_disc = 2*tana/(mK0(0,0)+mK0(1,1)); // ratio = tan(beta)/f = tan(beta)/((fx+fy)*0.5) = 2*tan(beta)/(fx+fy)

		CString path = vPaths_imgs[k];

		Mat img0 = imread(path.GetBuffer(), CV_LOAD_IMAGE_UNCHANGED);

		int h0 = img0.rows;
		int w0 = img0.cols;

		Mat mDepth0(h0,w0,CV_32FC1), mHx0(h0,w0,CV_32FC1), mHy0(h0,w0,CV_32FC1), mScore0(h0,w0,CV_32FC1), mVisi0(h0,w0,CV_8UC1);

		// read-in the reference fields
		CString strFile;
		strFile.Format("%03d depth map after MVPM.txt", k);
		FILE * file_depth = fopen(path_output+strFile, "r");
		strFile.Format("%03d hx map after MVPM.txt", k);
		FILE * file_hx = fopen(path_output+strFile, "r");
		strFile.Format("%03d hy map after MVPM.txt", k);
		FILE * file_hy = fopen(path_output+strFile, "r");
		strFile.Format("%03d score map after MVPM.txt", k);
		FILE * file_score = fopen(path_output+strFile, "r");
		strFile.Format("%03d visi map.txt", k);
		FILE * file_visi = fopen(path_output+strFile, "r");

		// at the same time evaluate all parameters
		for (i=0;i<h0;i++)
		{
			for (j=0;j<w0;j++)
			{
				double depth,hx,hy,score;
				int tmp;
				fscanf(file_depth, "%lf	", &depth);
				fscanf(file_hx, "%lf	", &hx);
				fscanf(file_hy, "%lf	", &hy);
				fscanf(file_score, "%lf	", &score);

				mDepth0.at<float>(i,j) = depth;
				mHx0.at<float>(i,j) = hx;
				mHy0.at<float>(i,j) = hy;
				mScore0.at<float>(i,j) = score;

				fscanf(file_visi, "%d	", &tmp);
				mVisi0.at<uchar>(i,j) = (uchar)tmp;
			}
		}
		fclose(file_depth);
		fclose(file_hx);
		fclose(file_hy);
		fclose(file_score);
		fclose(file_visi);

		vector<Matx33d> vKs_spt, vRs_spt; vector<Matx31d> vts_spt;
		//		vector<Mat> vImgs_spt;

		vector<Mat> vDepths_spt, vHxs_spt, vHys_spt;

		for (kk=0;kk<n_spt;kk++)
		{
			int idx_spt = vIdxSupports[k][kk];
			vKs_spt.push_back(vKs[idx_spt]);
			vRs_spt.push_back(vRs[idx_spt]);
			vts_spt.push_back(vts[idx_spt]);

			path = vPaths_imgs[idx_spt];

			Mat img = imread(path.GetBuffer(), CV_LOAD_IMAGE_UNCHANGED);

			int h = img.rows;
			int w = img.cols;

			//			vImgs_spt.push_back(img);

			Mat mDepth(h,w,CV_32FC1), mHx(h,w,CV_32FC1), mHy(h,w,CV_32FC1);

			// read-in the reference fields
			strFile.Format("%03d depth map after MVPM.txt", idx_spt);
			file_depth = fopen(path_output+strFile, "r");
			strFile.Format("%03d hx map after MVPM.txt", idx_spt);
			file_hx = fopen(path_output+strFile, "r");
			strFile.Format("%03d hy map after MVPM.txt", idx_spt);
			file_hy = fopen(path_output+strFile, "r");

			// at the same time evaluate all parameters
			for (i=0;i<h;i++)
			{
				for (j=0;j<w;j++)
				{
					double depth,hx,hy;
					fscanf(file_depth, "%lf	", &depth);
					fscanf(file_hx, "%lf	", &hx);
					fscanf(file_hy, "%lf	", &hy);

					mDepth.at<float>(i,j) = depth;
					mHx.at<float>(i,j) = hx;
					mHy.at<float>(i,j) = hy;
				}
			}
			fclose(file_depth);
			fclose(file_hx);
			fclose(file_hy);

			vDepths_spt.push_back(mDepth);
			vHxs_spt.push_back(mHx);
			vHys_spt.push_back(mHy);
		}

		DepthConsistencyCheck(mK0,mR0,mt0,mDepth0,mVisi0,mScore0,vKs_spt,vRs_spt,vts_spt,vDepths_spt,vHxs_spt,vHys_spt,thresh_ratio);

		strFile.Format("%03d score map after depth consistency check.bmp", k);
		SaveScoreField2Img(path_output+strFile, mScore0);


		// and remove small depth regions
		RemoveSmallDepthRegions_4(mK0,mR0,mt0,mDepth0,mScore0,ratio_disc,thresh_area_removeSmall);

		strFile.Format("%03d score map after removing small regions.bmp", k);
		SaveScoreField2Img(path_output+strFile, mScore0);

		strFile.Format("%03d point cloud final.txt", k);
		OutputPointCloud(path_output+strFile,mK0,mR0,mt0,fx0_1,fy0_1,img0,mDepth0,mHx0,mHy0,mScore0);


		// further using silhouettes to filter more outliers
// 		VisualHullConstraint(k,vKs,vRs,vts,vSilhouettes,mDepth0,mScore0,2);
// 
// 		strFile.Format("%03d score map after enforcing silhouette constraint.bmp", k);
// 		SaveScoreField2Img(path_output+strFile, mScore0);
// 
// 		strFile.Format("%03d point cloud final after enforcing silhouette constraint.txt", k);
// 		OutputPointCloud(path_output+strFile,mK0,mR0,mt0,fx0_1,fy0_1,img0,mDepth0,mHx0,mHy0,mScore0);
	}
}

// 20150206, for Zhou's data, the very original Multi-view patchmatch version
void DeepVoid::MVDE_package_150206(const CString & path_output,				// input:	the path of output file folder
								   const vector<cam_data> & vCams,			// input:	all images' orientations
								   const vector<CString> & vPaths_imgs,		// input:	file paths of all input images
								   const vector<Mat> & vSilhouettes,		// input:	Silhouettes of all images
								   const vector<vector<int>> & vIdxSupports,// input:	all images' support images' index
								   const vector<CloudPoint> & vClouds,		// input:	all point clouds, one for each input image
								   vector<Mat> & vDepths,					// output:	all generated depths
								   vector<Mat> & vHxs,						// output:	all generated depth gradients
								   vector<Mat> & vHys,						// output:	all generated depth gradients
								   vector<Mat> & vScores,					// output:	all scores, and -1 indicates an invalid estimate
								   vector<Mat> & vVisis,					// output:	all estimated visibilities within corresponding support image set
								   int size /*= 5*/,						// input:	the window size of the image patch, should be odd number
								   double angLimit /*= 80*/,				// input:	the angular range limit of the normal of every object point, in angle, not radian
								   int maxIter /*= 4*/,						// input:	maximum iteration
								   double factor /*= 0.5*/,
								   int nRandSamp /*= 6*/,
								   double thresh_ang /*= 90*/,				// input:	the normal angle constraint, if this value is 360, then no constraint at all
								   double thresh_ncc /*= 0.95*/,			// input:	the ncc threshold after patchmatch, ncc value is supposed to be very high if it's matched correctly after patchmatch
								   double P1 /*= 1.5*/,
								   double P2 /*= 0.1*/,
								   double thresh_imgpt_sigma /*= 1*/,
								   int nLevel /*= 4*/,						// input:	number of pyramid levels
								   int idxOutLevel /*= 0*/,					// input:	output final results at pyramid level idxOutLevel, default is level 0, i.e. the highest resolution level
								   double thresh_ratio /*= 0.001*/,
								   double thresh_WH_Ratio_removeSmall,		// input:	
								   int maxIter_optim /*= 128*/,
								   double xEps /*= 1.0E-8*/,				// input: threshold
								   double fEps /*= 1.0E-6*/,				// input: threshold
								   bool bMPGCFinal /*= true*/				// input: use MPGC optimized or directly Most likely results
								   )
{
	int i,j,k,ii,jj,kk;

	int nImg = vCams.size();

	vDepths.clear(); vHxs.clear(); vHys.clear(); vScores.clear(); vVisis.clear();

	double tana = tan(angLimit*D2R);

	int nPix = pow(2.0,idxOutLevel);
	double nPix_1 = 1.0/nPix;

	CString strInfo;

	// get corresponding orientation matrix //////////////////////////////////////////////////////////////////////////
	vector<Matx33d> vRs,vKs; vector<Matx31d> vts;

	for (k=0;k<nImg;k++)
	{
		Matx33d mR,mK; Matx31d mt;

		for (i=0;i<3;i++)
		{
			for (j=0;j<3;j++)
			{
				mR(i,j) = vCams[k].R[i*3+j];
			}
		}
		mK(0,0) = vCams[k].fx;	mK(0,1) = vCams[k].s;  mK(0,2) = vCams[k].cx;
		mK(1,1) = vCams[k].fy;	mK(1,2) = vCams[k].cy; mK(2,2) = 1;
		mt(0) = vCams[k].t[0];	mt(1) = vCams[k].t[1]; mt(2) = vCams[k].t[2];

		vRs.push_back(mR);
		vKs.push_back(mK);
		vts.push_back(mt);
	}
	//////////////////////////////////////////////////////////////////////////////////////////////////////////////////

	omp_set_dynamic(0); // Disable dynamic adjustment of the number of threads.
	int nProcs = omp_get_num_procs(); // number of processors of this computer
	omp_set_num_threads(nProcs);

	#pragma omp parallel for
	for (k=0;k<nImg;k++)
	{
		int n_spt = vIdxSupports[k].size();

		if (n_spt<1)
		{
			// 支持图数量小于 1 说明当前参考图像还没有完成定向，当然理论上也有可能是完成了定向，但确实没有合适的支持图集，
			// 不过我觉得实际出现这种情况的概率为 0，因为没有合适支持图集那么一开始 SfM 的时候它完成定向的可能性也很小了
			// anyway, 不管是未完成定向还是没有合适支持图集，该参考图都不应该继续后续的密集重建了
			continue;
		}

		Matx33d mK0 = vKs[k];
		Matx33d mR0 = vRs[k];
		Matx31d mt0 = vts[k];

		CString path = vPaths_imgs[k];

		Mat img0;

		vector<Matx33d> vKs_spt, vRs_spt; vector<Matx31d> vts_spt;
		vector<Mat> vImgs_spt;

		#pragma omp critical // 同时只能有一个thread执行下面这段代码，为了避免潜在的冲突
		{
			int thread_id = omp_get_thread_num();
			strInfo.Format("start generating surface map of image %03d in thread %03d with %03d support images", k, thread_id, n_spt);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			img0 = imread(path.GetBuffer(), CV_LOAD_IMAGE_UNCHANGED);

			for (kk=0;kk<n_spt;kk++)
			{
				int idx_spt = vIdxSupports[k][kk];
				vKs_spt.push_back(vKs[idx_spt]);
				vRs_spt.push_back(vRs[idx_spt]);
				vts_spt.push_back(vts[idx_spt]);

				path = vPaths_imgs[idx_spt];

				Mat img = imread(path.GetBuffer(), CV_LOAD_IMAGE_UNCHANGED);

				vImgs_spt.push_back(img);
			}
		}

		Mat mDepth_final, mHx_final, mHy_final, mScore_final, mVisi_final, img0_outLevel;
		SurfaceMapEstimation_oneImg_Pyramid(mK0,mR0,mt0,img0,vKs_spt,vRs_spt,vts_spt,vImgs_spt,vClouds,
			path_output,mDepth_final,mHx_final,mHy_final,mScore_final,mVisi_final,img0_outLevel,size,angLimit,maxIter,factor,nRandSamp,
			thresh_ang,thresh_ncc,P1,P2,thresh_imgpt_sigma,nLevel,idxOutLevel,maxIter_optim,xEps,fEps,bMPGCFinal);

		// 输出结果至指定文件夹
		CString str;
		str.Format("%03d depth map at pyramid level %03d.bmp", k, idxOutLevel);
		SaveParaField2Img(path_output+str, mDepth_final);

		str.Format("%03d score map at pyramid level %03d.bmp", k, idxOutLevel);
		SaveScoreField2Img(path_output+str, mScore_final);

		Matx33d mK0_samp;
		mK0_samp(0,0) = mK0(0,0)*nPix_1;
		mK0_samp(1,1) = mK0(1,1)*nPix_1;
		mK0_samp(0,2) = mK0(0,2)*nPix_1;
		mK0_samp(1,2) = mK0(1,2)*nPix_1;
		mK0_samp(0,1) = mK0(0,1);
		mK0_samp(2,2) = 1;

		double fx0l_1 = 1.0/mK0_samp(0,0);
		double fy0l_1 = 1.0/mK0_samp(1,1);

		Mat mNormColor;
		GetNormColorField(mK0_samp,mR0,mt0,fx0l_1,fy0l_1,mDepth_final,mHx_final,mHy_final,mNormColor);
		str.Format("%03d normal map at pyramid level %03d.bmp", k, idxOutLevel);
		imwrite((path_output+str).GetBuffer(), mNormColor);

		str.Format("%03d point cloud at pyramid level %03d.txt", k, idxOutLevel);
		OutputPointCloud(path_output+str,mK0_samp,mR0,mt0,fx0l_1,fy0l_1,img0_outLevel,
			mDepth_final,mHx_final,mHy_final,mScore_final);

		// draw visibility w.r.t each support image
		vector<Mat> vVisi_map;
		for (kk=0;kk<n_spt;kk++)
		{
			Mat mtmp(mVisi_final.rows,mVisi_final.cols,CV_8UC3);
			vVisi_map.push_back(mtmp);
		}

		for (i=0;i<mVisi_final.rows;i++)
		{
			for (j=0;j<mVisi_final.cols;j++)
			{
				uchar visi = mVisi_final.at<uchar>(i,j);

				vector<bool> vbools;
				InterpVisiVector_uchar(visi, vbools);

				for (kk=0;kk<n_spt;kk++)
				{
					if (vbools[kk])
					{
						vVisi_map[kk].at<Vec3b>(i,j).val[0] = img0_outLevel.at<Vec3b>(i,j).val[0];
						vVisi_map[kk].at<Vec3b>(i,j).val[1] = img0_outLevel.at<Vec3b>(i,j).val[1];
						vVisi_map[kk].at<Vec3b>(i,j).val[2] = img0_outLevel.at<Vec3b>(i,j).val[2];
					} 
					else
					{
						vVisi_map[kk].at<Vec3b>(i,j).val[0] = 0;
						vVisi_map[kk].at<Vec3b>(i,j).val[1] = 0;
						vVisi_map[kk].at<Vec3b>(i,j).val[2] = 255;
					}
				}
			}
		}

		for (kk=0;kk<n_spt;kk++)
		{
			str.Format("%03d visi map at pyramid level %03d wrt support image %03d.bmp", k, idxOutLevel, vIdxSupports[k][kk]);
			imwrite((path_output+str).GetBuffer(), vVisi_map[kk]);
		}

		str.Format("%03d image down-sampled at pyramid level %03d.bmp", k, idxOutLevel);
		imwrite((path_output+str).GetBuffer(), img0_outLevel);

		// output to files
		str.Format("%03d depth map at pyramid level %03d.txt", k, idxOutLevel);
		FILE * file_depth = fopen(path_output+str, "w");
		str.Format("%03d hx map at pyramid level %03d.txt", k, idxOutLevel);
		FILE * file_hx = fopen(path_output+str, "w");
		str.Format("%03d hy map at pyramid level %03d.txt", k, idxOutLevel);
		FILE * file_hy = fopen(path_output+str, "w");
		str.Format("%03d score map at pyramid level %03d.txt", k, idxOutLevel);
		FILE * file_score = fopen(path_output+str, "w");
		str.Format("%03d visi map at pyramid level %03d.txt", k, idxOutLevel);
		FILE * file_visi = fopen(path_output+str, "w");

		// at the same time evaluate all parameters
		for (i=0;i<img0_outLevel.rows;i++)
		{
			for (j=0;j<img0_outLevel.cols;j++)
			{
				fprintf(file_depth, "%.16f	", mDepth_final.at<float>(i,j));
				fprintf(file_hx, "%.16f	", mHx_final.at<float>(i,j));
				fprintf(file_hy, "%.16f	", mHy_final.at<float>(i,j));
				fprintf(file_score, "%.16f	", mScore_final.at<float>(i,j));
				fprintf(file_visi, "%d	", mVisi_final.at<uchar>(i,j));
			}
			fprintf(file_depth, "\n");
			fprintf(file_hx, "\n");
			fprintf(file_hy, "\n");
			fprintf(file_score, "\n");
			fprintf(file_visi, "\n");
		}
		fclose(file_depth);
		fclose(file_hx);
		fclose(file_hy);
		fclose(file_score);
		fclose(file_visi);
	}

	// depth consistency check
	for (k=0;k<nImg;k++)
	{
		int n_spt = vIdxSupports[k].size();

		if (n_spt<1)
		{
			continue;
		}

		strInfo.Format("check image %03d", k);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		Matx33d mK0 = vKs[k];
		Matx33d mR0 = vRs[k];
		Matx31d mt0 = vts[k];

		Matx33d mK0_samp;
		mK0_samp(0,0) = mK0(0,0)*nPix_1;
		mK0_samp(1,1) = mK0(1,1)*nPix_1;
		mK0_samp(0,2) = mK0(0,2)*nPix_1;
		mK0_samp(1,2) = mK0(1,2)*nPix_1;
		mK0_samp(0,1) = mK0(0,1);
		mK0_samp(2,2) = 1;

		double fx0l_1 = 1.0/mK0_samp(0,0);
		double fy0l_1 = 1.0/mK0_samp(1,1);

		double ratio_disc = 2*tana/(mK0_samp(0,0)+mK0_samp(1,1)); // ratio = tan(beta)/f = tan(beta)/((fx+fy)*0.5) = 2*tan(beta)/(fx+fy)

		CString strFile;
		strFile.Format("%03d image down-sampled at pyramid level %03d.bmp", k, idxOutLevel);

		Mat img0 = imread((path_output+strFile).GetBuffer(), CV_LOAD_IMAGE_UNCHANGED);

		int h0 = img0.rows;
		int w0 = img0.cols;

		Mat mDepth0(h0,w0,CV_32FC1), mHx0(h0,w0,CV_32FC1), mHy0(h0,w0,CV_32FC1), mScore0(h0,w0,CV_32FC1), mVisi0(h0,w0,CV_8UC1);

		// read-in the reference fields
		strFile.Format("%03d depth map at pyramid level %03d.txt", k, idxOutLevel);
		FILE * file_depth = fopen(path_output+strFile, "r");
		strFile.Format("%03d hx map at pyramid level %03d.txt", k, idxOutLevel);
		FILE * file_hx = fopen(path_output+strFile, "r");
		strFile.Format("%03d hy map at pyramid level %03d.txt", k, idxOutLevel);
		FILE * file_hy = fopen(path_output+strFile, "r");
		strFile.Format("%03d score map at pyramid level %03d.txt", k, idxOutLevel);
		FILE * file_score = fopen(path_output+strFile, "r");
		strFile.Format("%03d visi map at pyramid level %03d.txt", k, idxOutLevel);
		FILE * file_visi = fopen(path_output+strFile, "r");

		// at the same time evaluate all parameters
		for (i=0;i<h0;i++)
		{
			for (j=0;j<w0;j++)
			{
				double depth,hx,hy,score;
				int tmp;
				fscanf(file_depth, "%lf	", &depth);
				fscanf(file_hx, "%lf	", &hx);
				fscanf(file_hy, "%lf	", &hy);
				fscanf(file_score, "%lf	", &score);

				mDepth0.at<float>(i,j) = depth;
				mHx0.at<float>(i,j) = hx;
				mHy0.at<float>(i,j) = hy;
				mScore0.at<float>(i,j) = score;

				fscanf(file_visi, "%d	", &tmp);
				mVisi0.at<uchar>(i,j) = (uchar)tmp;
			}
		}
		fclose(file_depth);
		fclose(file_hx);
		fclose(file_hy);
		fclose(file_score);
		fclose(file_visi);

		vector<Matx33d> vKs_spt, vRs_spt; vector<Matx31d> vts_spt;

		vector<Mat> vDepths_spt, vHxs_spt, vHys_spt;

		for (kk=0;kk<n_spt;kk++)
		{
			int idx_spt = vIdxSupports[k][kk];

			vRs_spt.push_back(vRs[idx_spt]);
			vts_spt.push_back(vts[idx_spt]);

			Matx33d mK_spt = vKs[idx_spt];

			Matx33d mK_samp;
			mK_samp(0,0) = mK_spt(0,0)*nPix_1;
			mK_samp(1,1) = mK_spt(1,1)*nPix_1;
			mK_samp(0,2) = mK_spt(0,2)*nPix_1;
			mK_samp(1,2) = mK_spt(1,2)*nPix_1;
			mK_samp(0,1) = mK_spt(0,1);
			mK_samp(2,2) = 1;

			vKs_spt.push_back(mK_samp);

			strFile.Format("%03d image down-sampled at pyramid level %03d.bmp", idx_spt, idxOutLevel);
			
			Mat img = imread((path_output+strFile).GetBuffer(), CV_LOAD_IMAGE_UNCHANGED);

			int h = img.rows;
			int w = img.cols;

			Mat mDepth(h,w,CV_32FC1), mHx(h,w,CV_32FC1), mHy(h,w,CV_32FC1);

			// read-in the support fields
			strFile.Format("%03d depth map at pyramid level %03d.txt", idx_spt, idxOutLevel);
			file_depth = fopen(path_output+strFile, "r");
			strFile.Format("%03d hx map at pyramid level %03d.txt", idx_spt, idxOutLevel);
			file_hx = fopen(path_output+strFile, "r");
			strFile.Format("%03d hy map at pyramid level %03d.txt", idx_spt, idxOutLevel);
			file_hy = fopen(path_output+strFile, "r");

			// at the same time evaluate all parameters
			for (i=0;i<h;i++)
			{
				for (j=0;j<w;j++)
				{
					double depth,hx,hy;
					fscanf(file_depth, "%lf	", &depth);
					fscanf(file_hx, "%lf	", &hx);
					fscanf(file_hy, "%lf	", &hy);

					mDepth.at<float>(i,j) = depth;
					mHx.at<float>(i,j) = hx;
					mHy.at<float>(i,j) = hy;
				}
			}
			fclose(file_depth);
			fclose(file_hx);
			fclose(file_hy);

			vDepths_spt.push_back(mDepth);
			vHxs_spt.push_back(mHx);
			vHys_spt.push_back(mHy);
		}

		DepthConsistencyCheck(mK0_samp,mR0,mt0,mDepth0,mVisi0,mScore0,vKs_spt,vRs_spt,vts_spt,vDepths_spt,vHxs_spt,vHys_spt,thresh_ratio);

		strFile.Format("%03d score map at pyramid level %03d after depth consistency check.bmp", k, idxOutLevel);
		SaveScoreField2Img(path_output+strFile, mScore0);

		// and remove small depth regions
		double area_tmp = w0*h0*thresh_WH_Ratio_removeSmall*thresh_WH_Ratio_removeSmall;
		int area_pix = floor_fast(area_tmp)+1;
		RemoveSmallDepthRegions_4(mK0_samp,mR0,mt0,mDepth0,mScore0,ratio_disc,area_pix);

		strFile.Format("%03d score map at pyramid level %03d after removing small regions.bmp", k, idxOutLevel);
		SaveScoreField2Img(path_output+strFile, mScore0);

		strFile.Format("%03d point cloud at pyramid level %03d final.txt", k, idxOutLevel);
		OutputPointCloud(path_output+strFile,mK0_samp,mR0,mt0,fx0l_1,fy0l_1,img0,mDepth0,mHx0,mHy0,mScore0);


		// further using silhouettes to filter more outliers
// 		VisualHullConstraint(k,vKs,vRs,vts,vSilhouettes,mDepth0,mScore0,2);
// 
// 		strFile.Format("%03d score map after enforcing silhouette constraint.bmp", k);
// 		SaveScoreField2Img(path_output+strFile, mScore0);
// 
// 		strFile.Format("%03d point cloud final after enforcing silhouette constraint.txt", k);
// 		OutputPointCloud(path_output+strFile,mK0,mR0,mt0,fx0_1,fy0_1,img0,mDepth0,mHx0,mHy0,mScore0);
	}
}

// 20140827, conduct patchmatch for reference image with every support image at each time without view propagation
void DeepVoid::PatchMatch_Binocular(const vector<Matx33d> & vKs,				// input:	all interior matrix
								    const vector<Matx33d> & vRs,				// input:	all rotation matrix
								    const vector<Matx31d> & vts,				// input:	all translation vectors
								    const vector<double> & vfx_1,				// input:	
								    const vector<double> & vfy_1,				// input:
								    const vector<Mat> & vImgs,					// input:	all images
								    const vector<vector<int>> & vIdxSupports,	// input:	all images' support images' index
								    const vector<CloudPoint> & clouds,			// input:	the cloud points
									const vector<double> & vd_max,				// input:	maximal depth of each depth map
									const vector<double> & vd_min,				// input:	minimal depth of each depth map
									const vector<double> & vh_max,				// input:	maximal depth gradient of each depth map
									const vector<double> & vh_min,				// input:	minimal depth gradient of each depth map
								    int idx_ref,								// input:	the reference image index
								    vector<Mat> & vDepths,						// output:	all the depth maps
								    vector<Mat> & vHxs,							// output:	all the hx maps
								    vector<Mat> & vHys,							// output:	all the hy maps
								    vector<Mat> & vScores,						// output:	all the score maps
								    int size /*= 5*/,							// input:	the window size of the image patch, should be odd number
								    double angLimit /*= 80*/,					// input:	the angular range limit of the normal of every object point, in angle, not radian
								    int maxIter /*= 4*/,						// input:	maximum iteration
								    double factor /*= 0.5*/,
								    int nRandSamp /*= 6*/
								    )
{
	int i,j,k,ii,jj,rk;

	vDepths.clear(); vHxs.clear(); vHys.clear(); vScores.clear();

	vector<int> vIdx_spt = vIdxSupports[idx_ref];

	int nImg_spt = vIdx_spt.size();
	int n_cloud = clouds.size();
	int imgWidth = vImgs[0].cols;
	int imgHeight = vImgs[0].rows;
	int wndSizeHalf = (size-1)/2;

	double depth_max = vd_max[idx_ref];
	double depth_min = vd_min[idx_ref];
	double h_max = vh_max[idx_ref];
	double h_min = vh_min[idx_ref];
	double d_range = depth_max-depth_min;
	double h_range = h_max-h_min;

	CString strInfo;
	// initialize all depth, hx, hy maps randomly
	for (k=0;k<nImg_spt;k++)
	{
		Mat mDepth, mHx, mHy, mScore(imgHeight, imgWidth, CV_32FC1);
		InitRndField(vKs[idx_ref], vRs[idx_ref], vts[idx_ref], clouds, angLimit, imgWidth, imgHeight, mDepth, mHx, mHy);
		vDepths.push_back(mDepth);
		vHxs.push_back(mHx);
		vHys.push_back(mHy);

		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial depth map %02d with image %02d.txt", idx_ref, vIdx_spt[k]);
		FILE * file_depth = fopen(strInfo, "w");
		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial hx map %02d with image %02d.txt", idx_ref, vIdx_spt[k]);
		FILE * file_hx = fopen(strInfo, "w");
		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial hy map %02d with image %02d.txt", idx_ref, vIdx_spt[k]);
		FILE * file_hy = fopen(strInfo, "w");
		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial score map %02d with image %02d.txt", idx_ref, vIdx_spt[k]);
		FILE * file_score = fopen(strInfo, "w");

		// at the same time evaluate all parameters
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("evaluate row %04d with image %02d", i, k);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				int i_real, j_real, nVisi;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				double depth = vDepths[k].at<float>(i,j);
				double hx = vHxs[k].at<float>(i,j);
				double hy = vHys[k].at<float>(i,j);

				double score, angle;
				CheckOnePixel_givenOneParamSet_oneImg(vKs[idx_ref],vKs[vIdx_spt[k]],vRs[idx_ref],vRs[vIdx_spt[k]],vts[idx_ref],vts[vIdx_spt[k]],
					vfx_1[idx_ref],vfx_1[vIdx_spt[k]],vfy_1[idx_ref],vfy_1[vIdx_spt[k]],vImgs[idx_ref],vImgs[vIdx_spt[k]],j_real,i_real,depth,hx,hy,score,angle,size);

				mScore.at<float>(i,j) = score;

				fprintf(file_depth, "%.12f	", mDepth.at<float>(i,j));
				fprintf(file_hx, "%.12f	", mHx.at<float>(i,j));
				fprintf(file_hy, "%.12f	", mHy.at<float>(i,j));
				fprintf(file_score, "%.12f	", mScore.at<float>(i,j));
			}
			fprintf(file_depth, "\n");
			fprintf(file_hx, "\n");
			fprintf(file_hy, "\n");
			fprintf(file_score, "\n");
		}

		vScores.push_back(mScore);

		fclose(file_depth);
		fclose(file_hx);
		fclose(file_hy);
		fclose(file_score);

		// 		Mat mDepth(imgHeight, imgWidth, CV_32FC1), mHx(imgHeight, imgWidth, CV_32FC1), mHy(imgHeight, imgWidth, CV_32FC1), mScore(imgHeight, imgWidth, CV_32FC1);
		//  		
		// 		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial depth map with image %02d.txt", k);
		//  		FILE * file_depth = fopen(strInfo, "r");
		//  		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial hx map with image %02d.txt", k);
		//  		FILE * file_hx = fopen(strInfo, "r");
		//  		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial hy map with image %02d.txt", k);
		//  		FILE * file_hy = fopen(strInfo, "r");
		//  		strInfo.Format("C:\\Users\\DeepVoid\\Desktop\\init\\initial score map with image %02d.txt", k);
		//  		FILE * file_score = fopen(strInfo, "r");
		//  
		//  		// at the same time evaluate all parameters
		//  		for (i=0;i<imgHeight;i++)
		//  		{
		//  			for (j=0;j<imgWidth;j++)
		//  			{
		//  				double depth,hx,hy,score;
		//  				int tmp;
		//  				fscanf(file_depth, "%lf	", &depth);
		//  				fscanf(file_hx, "%lf	", &hx);
		//  				fscanf(file_hy, "%lf	", &hy);
		//  				fscanf(file_score, "%lf	", &score);
		//  
		//  				mDepth.at<float>(i,j) = depth;
		//  				mHx.at<float>(i,j) = hx;
		//  				mHy.at<float>(i,j) = hy;
		//  				mScore.at<float>(i,j) = score;
		//  			}
		//  		}
		//  		fclose(file_depth);
		//  		fclose(file_hx);
		//  		fclose(file_hy);
		//  		fclose(file_score);
		//  
		//  		vDepths.push_back(mDepth);
		//  		vHxs.push_back(mHx);
		//  		vHys.push_back(mHy);
		//  		vScores.push_back(mScore);
	}

	// start propagation
	for (ii=0;ii<maxIter;ii++)
	{
		if (ii%2 == 0)
		{
			for (k=0;k<nImg_spt;k++)
			{
				for (i=0;i<imgHeight;i++)
				{
					strInfo.Format("evaluate row %04d with image %02d in iteration %02d", i, k, ii);
					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

					for (j=0;j<imgWidth;j++)
					{
						int i_real, j_real, nVisi;
						MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

						vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
						vector<double> vScores_candidates;

						// first evaluate current parameter set for (i,j)
						double depth0 = vDepths[k].at<float>(i,j);
						double hx0 = vHxs[k].at<float>(i,j);
						double hy0 = vHys[k].at<float>(i,j);
						double score0 = vScores[k].at<float>(i,j);

						vScores_candidates.push_back(score0);
						vDepths_candidates.push_back(depth0);
						vHx_candidates.push_back(hx0);
						vHy_candidates.push_back(hy0);

						if (j-1>=0) // means that there is a left neighbor
						{
							double hx_left = vHxs[k].at<float>(i,j-1);
							double hy_left = vHys[k].at<float>(i,j-1);
							double depth_left = vDepths[k].at<float>(i,j-1)/*+hx_left*/; // add the corresponding depth gradient of the left pixel

							double score_left, angle_left;
							CheckOnePixel_givenOneParamSet_oneImg(vKs[idx_ref],vKs[vIdx_spt[k]],vRs[idx_ref],vRs[vIdx_spt[k]],vts[idx_ref],vts[vIdx_spt[k]],
								vfx_1[idx_ref],vfx_1[vIdx_spt[k]],vfy_1[idx_ref],vfy_1[vIdx_spt[k]],vImgs[idx_ref],vImgs[vIdx_spt[k]],j_real,i_real,depth_left,hx_left,hy_left,score_left,angle_left,size);

							vScores_candidates.push_back(score_left);

							vDepths_candidates.push_back(depth_left);
							vHx_candidates.push_back(hx_left);
							vHy_candidates.push_back(hy_left);
						}

						if (i-1>=0) // means that there is a upper neighbor
						{
							double hx_upper = vHxs[k].at<float>(i-1,j);
							double hy_upper = vHys[k].at<float>(i-1,j);
							double depth_upper = vDepths[k].at<float>(i-1,j)/*+hy_upper*/;

							double score_upper,angle_upper;
							CheckOnePixel_givenOneParamSet_oneImg(vKs[idx_ref],vKs[vIdx_spt[k]],vRs[idx_ref],vRs[vIdx_spt[k]],vts[idx_ref],vts[vIdx_spt[k]],
								vfx_1[idx_ref],vfx_1[vIdx_spt[k]],vfy_1[idx_ref],vfy_1[vIdx_spt[k]],vImgs[idx_ref],vImgs[vIdx_spt[k]],j_real,i_real,depth_upper,hx_upper,hy_upper,score_upper,angle_upper,size);

							vScores_candidates.push_back(score_upper);

							vDepths_candidates.push_back(depth_upper);
							vHx_candidates.push_back(hx_upper);
							vHy_candidates.push_back(hy_upper);
						}

						vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						double max_score = *iterDouble;
						int idx_max_score = iterDouble - vScores_candidates.begin();

						double depth_possible = vDepths_candidates[idx_max_score];
						double hx_possible = vHx_candidates[idx_max_score];
						double hy_possible = vHy_candidates[idx_max_score];
						double score_possible = max_score;

						vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

						vScores_candidates.push_back(score_possible);
						vDepths_candidates.push_back(depth_possible);
						vHx_candidates.push_back(hx_possible);
						vHy_candidates.push_back(hy_possible);

						for (rk=0;rk<nRandSamp;rk++)
						{
							double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
							if (rk==0)
							{
								d_max_k = depth_max;
								d_min_k = depth_min;
								hx_max_k = h_max;
								hx_min_k = h_min;
								hy_max_k = h_max;
								hy_min_k = h_min;
							}
							else
							{
								double factor_k = pow(factor, rk);
								double d_r = factor_k*d_range*0.5;
								double h_r = factor_k*h_range*0.5;
								DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
								DetermineInterval(h_max, h_min, hx_possible, h_r, hx_max_k, hx_min_k);
								DetermineInterval(h_max, h_min, hy_possible, h_r, hy_max_k, hy_min_k);
							}

							// generate current parameter set
							double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
							double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
							double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

							double score_k,angle_k;
							CheckOnePixel_givenOneParamSet_oneImg(vKs[idx_ref],vKs[vIdx_spt[k]],vRs[idx_ref],vRs[vIdx_spt[k]],vts[idx_ref],vts[vIdx_spt[k]],
								vfx_1[idx_ref],vfx_1[vIdx_spt[k]],vfy_1[idx_ref],vfy_1[vIdx_spt[k]],vImgs[idx_ref],vImgs[vIdx_spt[k]],j_real,i_real,depth_k,hx_k,hy_k,score_k,angle_k,size);

							vScores_candidates.push_back(score_k);

							vDepths_candidates.push_back(depth_k);
							vHx_candidates.push_back(hx_k);
							vHy_candidates.push_back(hy_k);
						}

						iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						max_score = *iterDouble;
						idx_max_score = iterDouble - vScores_candidates.begin();

						vDepths[k].at<float>(i,j) = vDepths_candidates[idx_max_score];
						vHxs[k].at<float>(i,j) = vHx_candidates[idx_max_score];
						vHys[k].at<float>(i,j) = vHy_candidates[idx_max_score];
						vScores[k].at<float>(i,j) = max_score;
					}
				}

				Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3);

				double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

				minMaxIdx(vDepths[k], &min_depth, &max_depth);
				minMaxIdx(vHxs[k], &min_incre_x, &max_incre_x);
				minMaxIdx(vHys[k], &min_incre_y, &max_incre_y);

				vDepths[k].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
				vHxs[k].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
				vHys[k].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

				for (i=0;i<imgHeight;i++)
				{
					for (j=0;j<imgWidth;j++)
					{
						if (vScores[k].at<float>(i,j)<0)
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = 0;
							mScore_map.at<Vec3b>(i,j).val[2] = 255;
						}
						else
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*vScores[k].at<float>(i,j));
							mScore_map.at<Vec3b>(i,j).val[2] = 0;
						}
					}
				}

				strInfo.Format("D:\\all\\depth map %02d iteration %02d with image %02d.bmp", idx_ref, ii, vIdx_spt[k]);
				imwrite(strInfo.GetBuffer(), mDepth_map);
				strInfo.Format("D:\\all\\hx map %02d iteration %02d with image %02d.bmp", idx_ref, ii, vIdx_spt[k]);
				imwrite(strInfo.GetBuffer(), mHx_map);
				strInfo.Format("D:\\all\\hy map %02d iteration %02d with image %02d.bmp", idx_ref, ii, vIdx_spt[k]);
				imwrite(strInfo.GetBuffer(), mHy_map);
				strInfo.Format("D:\\all\\score map %02d iteration %02d with image %02d.bmp", idx_ref, ii, vIdx_spt[k]);
				imwrite(strInfo.GetBuffer(), mScore_map);

				Mat mNormColor;
				GetNormColorField(vKs[idx_ref], vRs[idx_ref], vts[idx_ref], vfx_1[idx_ref], vfy_1[idx_ref], vDepths[k], vHxs[k], vHys[k], mNormColor);
				strInfo.Format("D:\\all\\normcolor map %02d iteration %02d with image %02d.bmp", idx_ref, ii, vIdx_spt[k]);
				imwrite(strInfo.GetBuffer(), mNormColor);

				strInfo.Format("D:\\all\\cloud points %02d iteration %02d with image %02d.txt", idx_ref, ii, vIdx_spt[k]);
				OutputPointCloud(strInfo,vKs[idx_ref],vRs[idx_ref],vts[idx_ref],vfx_1[idx_ref],vfy_1[idx_ref],vImgs[idx_ref],vDepths[k],vHxs[k],vHys[k],vScores[k]);
			}
		} 
		else
		{
			for (k=(nImg_spt-1);k>=0;k--)
			{
				for (i=imgHeight-1;i>=0;i--)
				{
					strInfo.Format("evaluate row %04d with image %02d in iteration %02d", i, k, ii);
					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

					for (j=imgWidth-1;j>=0;j--)
					{
						int i_real, j_real, nVisi;
						MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

						vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
						vector<double> vScores_candidates;

						// first evaluate current parameter set for (i,j)
						double depth0 = vDepths[k].at<float>(i,j);
						double hx0 = vHxs[k].at<float>(i,j);
						double hy0 = vHys[k].at<float>(i,j);
						double score0 = vScores[k].at<float>(i,j);

						vScores_candidates.push_back(score0);
						vDepths_candidates.push_back(depth0);
						vHx_candidates.push_back(hx0);
						vHy_candidates.push_back(hy0);

						if (j+1<imgWidth) // means that there is a right neighbor
						{
							double hx_right = vHxs[k].at<float>(i,j+1);
							double hy_right = vHys[k].at<float>(i,j+1);
							double depth_right = vDepths[k].at<float>(i,j+1)/*-hx_right*/;

							double score_right,angle_right;
							CheckOnePixel_givenOneParamSet_oneImg(vKs[idx_ref],vKs[vIdx_spt[k]],vRs[idx_ref],vRs[vIdx_spt[k]],vts[idx_ref],vts[vIdx_spt[k]],
								vfx_1[idx_ref],vfx_1[vIdx_spt[k]],vfy_1[idx_ref],vfy_1[vIdx_spt[k]],vImgs[idx_ref],vImgs[vIdx_spt[k]],j_real,i_real,depth_right,hx_right,hy_right,score_right,angle_right,size);

							vScores_candidates.push_back(score_right);

							vDepths_candidates.push_back(depth_right);
							vHx_candidates.push_back(hx_right);
							vHy_candidates.push_back(hy_right);
						}

						if (i+1<imgHeight) // means that there is a lower neighbor
						{
							double hx_lower = vHxs[k].at<float>(i+1,j);
							double hy_lower = vHys[k].at<float>(i+1,j);
							double depth_lower = vDepths[k].at<float>(i+1,j)/*-hy_lower*/;

							double score_lower,angle_lower;
							CheckOnePixel_givenOneParamSet_oneImg(vKs[idx_ref],vKs[vIdx_spt[k]],vRs[idx_ref],vRs[vIdx_spt[k]],vts[idx_ref],vts[vIdx_spt[k]],
								vfx_1[idx_ref],vfx_1[vIdx_spt[k]],vfy_1[idx_ref],vfy_1[vIdx_spt[k]],vImgs[idx_ref],vImgs[vIdx_spt[k]],j_real,i_real,depth_lower,hx_lower,hy_lower,score_lower,angle_lower,size);

							vScores_candidates.push_back(score_lower);

							vDepths_candidates.push_back(depth_lower);
							vHx_candidates.push_back(hx_lower);
							vHy_candidates.push_back(hy_lower);
						}

						vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						double max_score = *iterDouble;
						int idx_max_score = iterDouble - vScores_candidates.begin();

						double depth_possible = vDepths_candidates[idx_max_score];
						double hx_possible = vHx_candidates[idx_max_score];
						double hy_possible = vHy_candidates[idx_max_score];
						double score_possible = max_score;

						vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

						vScores_candidates.push_back(score_possible);
						vDepths_candidates.push_back(depth_possible);
						vHx_candidates.push_back(hx_possible);
						vHy_candidates.push_back(hy_possible);

						for (rk=0;rk<nRandSamp;rk++)
						{
							double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
							if (rk==0)
							{
								d_max_k = depth_max;
								d_min_k = depth_min;
								hx_max_k = h_max;
								hx_min_k = h_min;
								hy_max_k = h_max;
								hy_min_k = h_min;
							}
							else
							{
								double factor_k = pow(factor, rk);
								double d_r = factor_k*d_range*0.5;
								double h_r = factor_k*h_range*0.5;
								DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
								DetermineInterval(h_max, h_min, hx_possible, h_r, hx_max_k, hx_min_k);
								DetermineInterval(h_max, h_min, hy_possible, h_r, hy_max_k, hy_min_k);
							}

							// generate current parameter set
							double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
							double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
							double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

							double score_k,angle_k;
							CheckOnePixel_givenOneParamSet_oneImg(vKs[idx_ref],vKs[vIdx_spt[k]],vRs[idx_ref],vRs[vIdx_spt[k]],vts[idx_ref],vts[vIdx_spt[k]],
								vfx_1[idx_ref],vfx_1[vIdx_spt[k]],vfy_1[idx_ref],vfy_1[vIdx_spt[k]],vImgs[idx_ref],vImgs[vIdx_spt[k]],j_real,i_real,depth_k,hx_k,hy_k,score_k,angle_k,size);

							vScores_candidates.push_back(score_k);

							vDepths_candidates.push_back(depth_k);
							vHx_candidates.push_back(hx_k);
							vHy_candidates.push_back(hy_k);
						}

						iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						max_score = *iterDouble;
						idx_max_score = iterDouble - vScores_candidates.begin();

						vDepths[k].at<float>(i,j) = vDepths_candidates[idx_max_score];
						vHxs[k].at<float>(i,j) = vHx_candidates[idx_max_score];
						vHys[k].at<float>(i,j) = vHy_candidates[idx_max_score];
						vScores[k].at<float>(i,j) = max_score;
					}
				}

				Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3);

				double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

				minMaxIdx(vDepths[k], &min_depth, &max_depth);
				minMaxIdx(vHxs[k], &min_incre_x, &max_incre_x);
				minMaxIdx(vHys[k], &min_incre_y, &max_incre_y);

				vDepths[k].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
				vHxs[k].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
				vHys[k].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

				for (i=0;i<imgHeight;i++)
				{
					for (j=0;j<imgWidth;j++)
					{
						if (vScores[k].at<float>(i,j)<0)
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = 0;
							mScore_map.at<Vec3b>(i,j).val[2] = 255;
						}
						else
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*vScores[k].at<float>(i,j));
							mScore_map.at<Vec3b>(i,j).val[2] = 0;
						}
					}
				}

				strInfo.Format("D:\\all\\depth map %02d iteration %02d with image %02d.bmp", idx_ref, ii, vIdx_spt[k]);
				imwrite(strInfo.GetBuffer(), mDepth_map);
				strInfo.Format("D:\\all\\hx map %02d iteration %02d with image %02d.bmp", idx_ref, ii, vIdx_spt[k]);
				imwrite(strInfo.GetBuffer(), mHx_map);
				strInfo.Format("D:\\all\\hy map %02d iteration %02d with image %02d.bmp", idx_ref, ii, vIdx_spt[k]);
				imwrite(strInfo.GetBuffer(), mHy_map);
				strInfo.Format("D:\\all\\score map %02d iteration %02d with image %02d.bmp", idx_ref, ii, vIdx_spt[k]);
				imwrite(strInfo.GetBuffer(), mScore_map);

				Mat mNormColor;
				GetNormColorField(vKs[idx_ref], vRs[idx_ref], vts[idx_ref], vfx_1[idx_ref], vfy_1[idx_ref], vDepths[k], vHxs[k], vHys[k], mNormColor);
				strInfo.Format("D:\\all\\normcolor map %02d iteration %02d with image %02d.bmp", idx_ref, ii, vIdx_spt[k]);
				imwrite(strInfo.GetBuffer(), mNormColor);

				strInfo.Format("D:\\all\\cloud points %02d iteration %02d with image %02d.txt", idx_ref, ii, vIdx_spt[k]);
				OutputPointCloud(strInfo,vKs[idx_ref],vRs[idx_ref],vts[idx_ref],vfx_1[idx_ref],vfy_1[idx_ref],vImgs[idx_ref],vDepths[k],vHxs[k],vHys[k],vScores[k]);
			}
		}
	}

	for (k=0;k<nImg_spt;k++)
	{
		strInfo.Format("D:\\all\\final PatchMatch depth map %02d with image %02d.txt", idx_ref, vIdx_spt[k]);
		FILE * file_depth = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch hx map %02d with image %02d.txt", idx_ref, vIdx_spt[k]);
		FILE * file_hx = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch hy map %02d with image %02d.txt", idx_ref, vIdx_spt[k]);
		FILE * file_hy = fopen(strInfo, "w");
		strInfo.Format("D:\\all\\final PatchMatch score map %02d with image %02d.txt", idx_ref, vIdx_spt[k]);
		FILE * file_score = fopen(strInfo, "w");

		// at the same time evaluate all parameters
		for (i=0;i<imgHeight;i++)
		{
			for (j=0;j<imgWidth;j++)
			{
				fprintf(file_depth, "%.12f	", vDepths[k].at<float>(i,j));
				fprintf(file_hx, "%.12f	", vHxs[k].at<float>(i,j));
				fprintf(file_hy, "%.12f	", vHys[k].at<float>(i,j));
				fprintf(file_score, "%.12f	", vScores[k].at<float>(i,j));
			}
			fprintf(file_depth, "\n");
			fprintf(file_hx, "\n");
			fprintf(file_hy, "\n");
			fprintf(file_score, "\n");
		}
		fclose(file_depth);
		fclose(file_hx);
		fclose(file_hy);
		fclose(file_score);
	}
}

// 20140914, self-contained version, conduct patchmatch for reference image with every support image at each time without view propagation
void DeepVoid::PatchMatch_Binocular(const Matx33d & mK0,				// input:	interior matrix of the reference image
								    const Matx33d & mR0,				// input:	rotation matrix of the reference image
								    const Matx31d & mt0,				// input:	translation vectors of the reference image
								    const Mat & img0,					// input:	the reference image
								    const vector<Matx33d> & vKs,		// input:	interior matrix of all support images
								    const vector<Matx33d> & vRs,		// input:	rotation matrix of all support images
								    const vector<Matx31d> & vts,		// input:	translation vectors of all support images
								    const vector<Mat> & vImgs,			// input:	all support images
								    const vector<CloudPoint> & clouds,	// input:	the given sparse cloud points
								    vector<Mat> & vDepths,				// output:	all the depth maps
								    vector<Mat> & vHxs,					// output:	all the hx maps
								    vector<Mat> & vHys,					// output:	all the hy maps
								    vector<Mat> & vScores,				// output:	all the score maps
								    int size /*= 5*/,					// input:	the window size of the image patch, should be odd number
								    double angLimit /*= 80*/,			// input:	the angular range limit of the normal of every object point, in angle, not radian
								    int maxIter /*= 4*/,				// input:	maximum iteration
								    double factor /*= 0.5*/,
								    int nRandSamp /*= 6*/
								    )
{
	int i,j,k,ii,jj,rk;

	vDepths.clear(); vHxs.clear(); vHys.clear(); vScores.clear();

	int n_spt = vKs.size();
	int n_cloud = clouds.size();

	int imgWidth = img0.cols;
	int imgHeight = img0.rows;
	int wndSizeHalf = (size-1)/2;

	double fx0_1 = 1/mK0(0,0);
	double fy0_1 = 1/mK0(1,1);

	vector<double> vfx_1, vfy_1;
	for (k=0;k<n_spt;k++)
	{
		double fx_1 = 1/vKs[k](0,0);
		double fy_1 = 1/vKs[k](1,1);

		vfx_1.push_back(fx_1);
		vfy_1.push_back(fy_1);
	}

	// determine maximal and minimal parameters //////////////////////////////////////////////////////////////////////////
	double tana = tan(angLimit*D2R);

	double fx0 = mK0(0,0); double fy0 = mK0(1,1);

	double f=(fx0+fy0)*0.5;
	double tana_f = tana/f;

	double depth_min;
	double depth_max;

	for (jj=0;jj<n_cloud;jj++)
	{
		Matx31d mX;

		mX(0) = clouds[jj].m_pt.x;
		mX(1) = clouds[jj].m_pt.y;
		mX(2) = clouds[jj].m_pt.z;

		mX = mR0*mX+mt0;

		double depth = mX(2);

		if (jj == 0)
		{
			depth_min = depth;
			depth_max = depth;
		} 
		else
		{
			if (depth<depth_min)
			{
				depth_min = depth;
			}
			if (depth>depth_max)
			{
				depth_max = depth;
			}
		}
	}

	double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

	double depth_ext = (depth_max-depth_min)*ratio_ext;

	depth_max += depth_ext;

	double tmp = depth_min - depth_ext;

	if (tmp<0)
	{
		depth_min = 0;
	} 
	else
	{
		depth_min = tmp;
	}

	double h_max = tana_f * depth_max;
	double h_min = -h_max;

	double d_range = depth_max-depth_min;
	double h_range = h_max-h_min;
	//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

	CString strInfo;
	// initialize all depth, hx, hy maps randomly
	for (k=0;k<n_spt;k++)
	{
		Mat mDepth, mHx, mHy, mScore(imgHeight, imgWidth, CV_32FC1);
		InitRndField(mK0,mR0,mt0,depth_min,depth_max,angLimit,imgWidth,imgHeight,mDepth,mHx,mHy);
		vDepths.push_back(mDepth);
		vHxs.push_back(mHx);
		vHys.push_back(mHy);

		// at the same time evaluate all parameters
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("evaluate row %04d with image %02d", i, k);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				int i_real, j_real, nVisi;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				double depth = vDepths[k].at<float>(i,j);
				double hx = vHxs[k].at<float>(i,j);
				double hy = vHys[k].at<float>(i,j);

				double score, angle;
				CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth,hx,hy,score,angle,size);

				mScore.at<float>(i,j) = score;
			}
		}

		vScores.push_back(mScore);
	}

	// start propagation
	for (ii=0;ii<maxIter;ii++)
	{
		if (ii%2 == 0)
		{
			for (k=0;k<n_spt;k++)
			{
				for (i=0;i<imgHeight;i++)
				{
					strInfo.Format("evaluate row %04d with image %02d in iteration %02d", i, k, ii);
					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

					for (j=0;j<imgWidth;j++)
					{
						int i_real, j_real, nVisi;
						MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

						vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
						vector<double> vScores_candidates;

						// first evaluate current parameter set for (i,j)
						double depth0 = vDepths[k].at<float>(i,j);
						double hx0 = vHxs[k].at<float>(i,j);
						double hy0 = vHys[k].at<float>(i,j);
						double score0 = vScores[k].at<float>(i,j);

						vScores_candidates.push_back(score0);
						vDepths_candidates.push_back(depth0);
						vHx_candidates.push_back(hx0);
						vHy_candidates.push_back(hy0);

						if (j-1>=0) // means that there is a left neighbor
						{
							double hx_left = vHxs[k].at<float>(i,j-1);
							double hy_left = vHys[k].at<float>(i,j-1);
							double depth_left = vDepths[k].at<float>(i,j-1)/*+hx_left*/; // add the corresponding depth gradient of the left pixel

							double score_left, angle_left;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_left,hx_left,hy_left,score_left,angle_left,size);

							vScores_candidates.push_back(score_left);

							vDepths_candidates.push_back(depth_left);
							vHx_candidates.push_back(hx_left);
							vHy_candidates.push_back(hy_left);
						}

						if (i-1>=0) // means that there is a upper neighbor
						{
							double hx_upper = vHxs[k].at<float>(i-1,j);
							double hy_upper = vHys[k].at<float>(i-1,j);
							double depth_upper = vDepths[k].at<float>(i-1,j)/*+hy_upper*/;

							double score_upper,angle_upper;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_upper,hx_upper,hy_upper,score_upper,angle_upper,size);

							vScores_candidates.push_back(score_upper);

							vDepths_candidates.push_back(depth_upper);
							vHx_candidates.push_back(hx_upper);
							vHy_candidates.push_back(hy_upper);
						}

						vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						double max_score = *iterDouble;
						int idx_max_score = iterDouble - vScores_candidates.begin();

						double depth_possible = vDepths_candidates[idx_max_score];
						double hx_possible = vHx_candidates[idx_max_score];
						double hy_possible = vHy_candidates[idx_max_score];
						double score_possible = max_score;

						vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

						vScores_candidates.push_back(score_possible);
						vDepths_candidates.push_back(depth_possible);
						vHx_candidates.push_back(hx_possible);
						vHy_candidates.push_back(hy_possible);

						for (rk=0;rk<nRandSamp;rk++)
						{
							double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
							if (rk==0)
							{
								d_max_k = depth_max;
								d_min_k = depth_min;
								hx_max_k = h_max;
								hx_min_k = h_min;
								hy_max_k = h_max;
								hy_min_k = h_min;
							}
							else
							{
								double factor_k = pow(factor, rk);
								double d_r = factor_k*d_range*0.5;
								double h_r = factor_k*h_range*0.5;
								DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
								DetermineInterval(h_max, h_min, hx_possible, h_r, hx_max_k, hx_min_k);
								DetermineInterval(h_max, h_min, hy_possible, h_r, hy_max_k, hy_min_k);
							}

							// generate current parameter set
							double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
							double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
							double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

							double score_k,angle_k;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_k,hx_k,hy_k,score_k,angle_k,size);

							vScores_candidates.push_back(score_k);

							vDepths_candidates.push_back(depth_k);
							vHx_candidates.push_back(hx_k);
							vHy_candidates.push_back(hy_k);
						}

						iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						max_score = *iterDouble;
						idx_max_score = iterDouble - vScores_candidates.begin();

						vDepths[k].at<float>(i,j) = vDepths_candidates[idx_max_score];
						vHxs[k].at<float>(i,j) = vHx_candidates[idx_max_score];
						vHys[k].at<float>(i,j) = vHy_candidates[idx_max_score];
						vScores[k].at<float>(i,j) = max_score;
					}
				}

				Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3);

				double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

				minMaxIdx(vDepths[k], &min_depth, &max_depth);
				minMaxIdx(vHxs[k], &min_incre_x, &max_incre_x);
				minMaxIdx(vHys[k], &min_incre_y, &max_incre_y);

				vDepths[k].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
				vHxs[k].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
				vHys[k].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

				for (i=0;i<imgHeight;i++)
				{
					for (j=0;j<imgWidth;j++)
					{
						if (vScores[k].at<float>(i,j)<0)
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = 0;
							mScore_map.at<Vec3b>(i,j).val[2] = 255;
						}
						else
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*vScores[k].at<float>(i,j));
							mScore_map.at<Vec3b>(i,j).val[2] = 0;
						}
					}
				}

				strInfo.Format("D:\\all\\depth map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mDepth_map);
				strInfo.Format("D:\\all\\hx map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mHx_map);
				strInfo.Format("D:\\all\\hy map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mHy_map);
				strInfo.Format("D:\\all\\score map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mScore_map);

				Mat mNormColor;
				GetNormColorField(mK0, mR0, mt0, fx0_1, fy0_1, vDepths[k], vHxs[k], vHys[k], mNormColor);
				strInfo.Format("D:\\all\\normcolor map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mNormColor);

				strInfo.Format("D:\\all\\cloud points iteration %02d with image %02d.txt", ii, k);
				OutputPointCloud(strInfo,mK0,mR0,mt0,fx0_1,fy0_1,img0,vDepths[k],vHxs[k],vHys[k],vScores[k]);
			}
		} 
		else
		{
			for (k=(n_spt-1);k>=0;k--)
			{
				for (i=imgHeight-1;i>=0;i--)
				{
					strInfo.Format("evaluate row %04d with image %02d in iteration %02d", i, k, ii);
					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

					for (j=imgWidth-1;j>=0;j--)
					{
						int i_real, j_real, nVisi;
						MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

						vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
						vector<double> vScores_candidates;

						// first evaluate current parameter set for (i,j)
						double depth0 = vDepths[k].at<float>(i,j);
						double hx0 = vHxs[k].at<float>(i,j);
						double hy0 = vHys[k].at<float>(i,j);
						double score0 = vScores[k].at<float>(i,j);

						vScores_candidates.push_back(score0);
						vDepths_candidates.push_back(depth0);
						vHx_candidates.push_back(hx0);
						vHy_candidates.push_back(hy0);

						if (j+1<imgWidth) // means that there is a right neighbor
						{
							double hx_right = vHxs[k].at<float>(i,j+1);
							double hy_right = vHys[k].at<float>(i,j+1);
							double depth_right = vDepths[k].at<float>(i,j+1)/*-hx_right*/;

							double score_right,angle_right;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_right,hx_right,hy_right,score_right,angle_right,size);

							vScores_candidates.push_back(score_right);

							vDepths_candidates.push_back(depth_right);
							vHx_candidates.push_back(hx_right);
							vHy_candidates.push_back(hy_right);
						}

						if (i+1<imgHeight) // means that there is a lower neighbor
						{
							double hx_lower = vHxs[k].at<float>(i+1,j);
							double hy_lower = vHys[k].at<float>(i+1,j);
							double depth_lower = vDepths[k].at<float>(i+1,j)/*-hy_lower*/;

							double score_lower,angle_lower;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_lower,hx_lower,hy_lower,score_lower,angle_lower,size);

							vScores_candidates.push_back(score_lower);

							vDepths_candidates.push_back(depth_lower);
							vHx_candidates.push_back(hx_lower);
							vHy_candidates.push_back(hy_lower);
						}

						vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						double max_score = *iterDouble;
						int idx_max_score = iterDouble - vScores_candidates.begin();

						double depth_possible = vDepths_candidates[idx_max_score];
						double hx_possible = vHx_candidates[idx_max_score];
						double hy_possible = vHy_candidates[idx_max_score];
						double score_possible = max_score;

						vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

						vScores_candidates.push_back(score_possible);
						vDepths_candidates.push_back(depth_possible);
						vHx_candidates.push_back(hx_possible);
						vHy_candidates.push_back(hy_possible);

						for (rk=0;rk<nRandSamp;rk++)
						{
							double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
							if (rk==0)
							{
								d_max_k = depth_max;
								d_min_k = depth_min;
								hx_max_k = h_max;
								hx_min_k = h_min;
								hy_max_k = h_max;
								hy_min_k = h_min;
							}
							else
							{
								double factor_k = pow(factor, rk);
								double d_r = factor_k*d_range*0.5;
								double h_r = factor_k*h_range*0.5;
								DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
								DetermineInterval(h_max, h_min, hx_possible, h_r, hx_max_k, hx_min_k);
								DetermineInterval(h_max, h_min, hy_possible, h_r, hy_max_k, hy_min_k);
							}

							// generate current parameter set
							double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
							double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
							double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

							double score_k,angle_k;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_k,hx_k,hy_k,score_k,angle_k,size);

							vScores_candidates.push_back(score_k);

							vDepths_candidates.push_back(depth_k);
							vHx_candidates.push_back(hx_k);
							vHy_candidates.push_back(hy_k);
						}

						iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						max_score = *iterDouble;
						idx_max_score = iterDouble - vScores_candidates.begin();

						vDepths[k].at<float>(i,j) = vDepths_candidates[idx_max_score];
						vHxs[k].at<float>(i,j) = vHx_candidates[idx_max_score];
						vHys[k].at<float>(i,j) = vHy_candidates[idx_max_score];
						vScores[k].at<float>(i,j) = max_score;
					}
				}

				Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3);

				double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

				minMaxIdx(vDepths[k], &min_depth, &max_depth);
				minMaxIdx(vHxs[k], &min_incre_x, &max_incre_x);
				minMaxIdx(vHys[k], &min_incre_y, &max_incre_y);

				vDepths[k].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
				vHxs[k].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
				vHys[k].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

				for (i=0;i<imgHeight;i++)
				{
					for (j=0;j<imgWidth;j++)
					{
						if (vScores[k].at<float>(i,j)<0)
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = 0;
							mScore_map.at<Vec3b>(i,j).val[2] = 255;
						}
						else
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*vScores[k].at<float>(i,j));
							mScore_map.at<Vec3b>(i,j).val[2] = 0;
						}
					}
				}

				strInfo.Format("D:\\all\\depth map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mDepth_map);
				strInfo.Format("D:\\all\\hx map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mHx_map);
				strInfo.Format("D:\\all\\hy map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mHy_map);
				strInfo.Format("D:\\all\\score map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mScore_map);

				Mat mNormColor;
				GetNormColorField(mK0, mR0, mt0, fx0_1, fy0_1, vDepths[k], vHxs[k], vHys[k], mNormColor);
				strInfo.Format("D:\\all\\normcolor map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mNormColor);

				strInfo.Format("D:\\all\\cloud points iteration %02d with image %02d.txt", ii, k);
				OutputPointCloud(strInfo,mK0,mR0,mt0,fx0_1,fy0_1,img0,vDepths[k],vHxs[k],vHys[k],vScores[k]);
			}
		}
	}
}

// 20141013, self-contained version, conduct patchmatch for reference image with every support image at each time without view propagation
// with propagation between different layers.
void DeepVoid::PatchMatch_Binocular_3DPropagation(const Matx33d & mK0,				// input:	interior matrix of the reference image
												  const Matx33d & mR0,				// input:	rotation matrix of the reference image
												  const Matx31d & mt0,				// input:	translation vectors of the reference image
												  const Mat & img0,					// input:	the reference image
												  const vector<Matx33d> & vKs,		// input:	interior matrix of all support images
												  const vector<Matx33d> & vRs,		// input:	rotation matrix of all support images
												  const vector<Matx31d> & vts,		// input:	translation vectors of all support images
												  const vector<Mat> & vImgs,		// input:	all support images
												  const vector<CloudPoint> & clouds,// input:	the given sparse cloud points
												  vector<Mat> & vDepths,			// output:	all the depth maps
												  vector<Mat> & vHxs,				// output:	all the hx maps
												  vector<Mat> & vHys,				// output:	all the hy maps
												  vector<Mat> & vScores,			// output:	all the score maps
												  int size /*= 5*/,					// input:	the window size of the image patch, should be odd number
												  double angLimit /*= 80*/,			// input:	the angular range limit of the normal of every object point, in angle, not radian
												  int maxIter /*= 4*/,				// input:	maximum iteration
												  double factor /*= 0.5*/,
												  int nRandSamp /*= 6*/
												  )
{
	int i,j,k,ii,jj,kk,rk;

	vDepths.clear(); vHxs.clear(); vHys.clear(); vScores.clear();

	int n_spt = vKs.size();
	int n_cloud = clouds.size();

	int imgWidth = img0.cols;
	int imgHeight = img0.rows;
	int wndSizeHalf = (size-1)/2;

	double fx0_1 = 1/mK0(0,0);
	double fy0_1 = 1/mK0(1,1);

	vector<double> vfx_1, vfy_1;
	for (k=0;k<n_spt;k++)
	{
		double fx_1 = 1/vKs[k](0,0);
		double fy_1 = 1/vKs[k](1,1);

		vfx_1.push_back(fx_1);
		vfy_1.push_back(fy_1);
	}

	// determine maximal and minimal parameters //////////////////////////////////////////////////////////////////////////
	double tana = tan(angLimit*D2R);

	double fx0 = mK0(0,0); double fy0 = mK0(1,1);

	double f=(fx0+fy0)*0.5;
	double tana_f = tana/f;

	double depth_min;
	double depth_max;

	for (jj=0;jj<n_cloud;jj++)
	{
		Matx31d mX;

		mX(0) = clouds[jj].m_pt.x;
		mX(1) = clouds[jj].m_pt.y;
		mX(2) = clouds[jj].m_pt.z;

		mX = mR0*mX+mt0;

		double depth = mX(2);

		if (jj == 0)
		{
			depth_min = depth;
			depth_max = depth;
		} 
		else
		{
			if (depth<depth_min)
			{
				depth_min = depth;
			}
			if (depth>depth_max)
			{
				depth_max = depth;
			}
		}
	}

	double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

	double depth_ext = (depth_max-depth_min)*ratio_ext;

	depth_max += depth_ext;

	double tmp = depth_min - depth_ext;

	if (tmp<0)
	{
		depth_min = 0;
	} 
	else
	{
		depth_min = tmp;
	}

	double h_max = tana_f * depth_max;
	double h_min = -h_max;

	double d_range = depth_max-depth_min;
	double h_range = h_max-h_min;
	//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

	CString strInfo;
	// initialize all depth, hx, hy maps randomly
	for (k=0;k<n_spt;k++)
	{
		Mat mDepth, mHx, mHy, mScore(imgHeight, imgWidth, CV_32FC1);
		InitRndField(mK0,mR0,mt0,depth_min,depth_max,angLimit,imgWidth,imgHeight,mDepth,mHx,mHy);
		vDepths.push_back(mDepth);
		vHxs.push_back(mHx);
		vHys.push_back(mHy);

		// at the same time evaluate all parameters
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("evaluate row %04d with image %02d", i, k);
//			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				int i_real, j_real, nVisi;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				double depth = vDepths[k].at<float>(i,j);
				double hx = vHxs[k].at<float>(i,j);
				double hy = vHys[k].at<float>(i,j);

				double score, angle;
				CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth,hx,hy,score,angle,size);

				mScore.at<float>(i,j) = score;
			}
		}

		vScores.push_back(mScore);
	}

	// start propagation
	for (ii=0;ii<maxIter;ii++)
	{
		if (ii%2 == 0)
		{
			for (k=0;k<n_spt;k++)
			{
				for (i=0;i<imgHeight;i++)
				{
					strInfo.Format("evaluate row %04d with image %02d in iteration %02d", i, k, ii);
//					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

					for (j=0;j<imgWidth;j++)
					{
						int i_real, j_real, nVisi;
						MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

						vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
						vector<double> vScores_candidates;

						// first evaluate current parameter set for (i,j)
						double depth0 = vDepths[k].at<float>(i,j);
						double hx0 = vHxs[k].at<float>(i,j);
						double hy0 = vHys[k].at<float>(i,j);
						double score0 = vScores[k].at<float>(i,j);

						vScores_candidates.push_back(score0);
						vDepths_candidates.push_back(depth0);
						vHx_candidates.push_back(hx0);
						vHy_candidates.push_back(hy0);

						if (j-1>=0) // means that there is a left neighbor
						{
							double hx_left = vHxs[k].at<float>(i,j-1);
							double hy_left = vHys[k].at<float>(i,j-1);
							double depth_left = vDepths[k].at<float>(i,j-1)/*+hx_left*/; // add the corresponding depth gradient of the left pixel

							double score_left, angle_left;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_left,hx_left,hy_left,score_left,angle_left,size);

							vScores_candidates.push_back(score_left);

							vDepths_candidates.push_back(depth_left);
							vHx_candidates.push_back(hx_left);
							vHy_candidates.push_back(hy_left);
						}

						if (i-1>=0) // means that there is a upper neighbor
						{
							double hx_upper = vHxs[k].at<float>(i-1,j);
							double hy_upper = vHys[k].at<float>(i-1,j);
							double depth_upper = vDepths[k].at<float>(i-1,j)/*+hy_upper*/;

							double score_upper,angle_upper;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_upper,hx_upper,hy_upper,score_upper,angle_upper,size);

							vScores_candidates.push_back(score_upper);

							vDepths_candidates.push_back(depth_upper);
							vHx_candidates.push_back(hx_upper);
							vHy_candidates.push_back(hy_upper);
						}

						for (kk=0;kk<k;kk++)
						{
							double hx_kk = vHxs[kk].at<float>(i,j);
							double hy_kk = vHys[kk].at<float>(i,j);
							double depth_kk = vDepths[kk].at<float>(i,j);

							double score_kk,angle_kk;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_kk,hx_kk,hy_kk,score_kk,angle_kk,size);

							vScores_candidates.push_back(score_kk);

							vDepths_candidates.push_back(depth_kk);
							vHx_candidates.push_back(hx_kk);
							vHy_candidates.push_back(hy_kk);
						}

						vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						double max_score = *iterDouble;
						int idx_max_score = iterDouble - vScores_candidates.begin();

						double depth_possible = vDepths_candidates[idx_max_score];
						double hx_possible = vHx_candidates[idx_max_score];
						double hy_possible = vHy_candidates[idx_max_score];
						double score_possible = max_score;

						vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

						vScores_candidates.push_back(score_possible);
						vDepths_candidates.push_back(depth_possible);
						vHx_candidates.push_back(hx_possible);
						vHy_candidates.push_back(hy_possible);

						for (rk=0;rk<nRandSamp;rk++)
						{
							double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
							if (rk==0)
							{
								d_max_k = depth_max;
								d_min_k = depth_min;
								hx_max_k = h_max;
								hx_min_k = h_min;
								hy_max_k = h_max;
								hy_min_k = h_min;
							}
							else
							{
								double factor_k = pow(factor, rk);
								double d_r = factor_k*d_range*0.5;
								double h_r = factor_k*h_range*0.5;
								DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
								DetermineInterval(h_max, h_min, hx_possible, h_r, hx_max_k, hx_min_k);
								DetermineInterval(h_max, h_min, hy_possible, h_r, hy_max_k, hy_min_k);
							}

							// generate current parameter set
							double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
							double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
							double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

							double score_k,angle_k;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_k,hx_k,hy_k,score_k,angle_k,size);

							vScores_candidates.push_back(score_k);

							vDepths_candidates.push_back(depth_k);
							vHx_candidates.push_back(hx_k);
							vHy_candidates.push_back(hy_k);
						}

						iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						max_score = *iterDouble;
						idx_max_score = iterDouble - vScores_candidates.begin();

						vDepths[k].at<float>(i,j) = vDepths_candidates[idx_max_score];
						vHxs[k].at<float>(i,j) = vHx_candidates[idx_max_score];
						vHys[k].at<float>(i,j) = vHy_candidates[idx_max_score];
						vScores[k].at<float>(i,j) = max_score;
					}
				}

				Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3);

				double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

				minMaxIdx(vDepths[k], &min_depth, &max_depth);
				minMaxIdx(vHxs[k], &min_incre_x, &max_incre_x);
				minMaxIdx(vHys[k], &min_incre_y, &max_incre_y);

				vDepths[k].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
				vHxs[k].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
				vHys[k].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

				for (i=0;i<imgHeight;i++)
				{
					for (j=0;j<imgWidth;j++)
					{
						if (vScores[k].at<float>(i,j)<0)
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = 0;
							mScore_map.at<Vec3b>(i,j).val[2] = 255;
						}
						else
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*vScores[k].at<float>(i,j));
							mScore_map.at<Vec3b>(i,j).val[2] = 0;
						}
					}
				}

// 				strInfo.Format("D:\\all\\depth map iteration %02d with image %02d.bmp", ii, k);
// 				imwrite(strInfo.GetBuffer(), mDepth_map);
// 				strInfo.Format("D:\\all\\hx map iteration %02d with image %02d.bmp", ii, k);
// 				imwrite(strInfo.GetBuffer(), mHx_map);
// 				strInfo.Format("D:\\all\\hy map iteration %02d with image %02d.bmp", ii, k);
// 				imwrite(strInfo.GetBuffer(), mHy_map);
// 				strInfo.Format("D:\\all\\score map iteration %02d with image %02d.bmp", ii, k);
// 				imwrite(strInfo.GetBuffer(), mScore_map);
// 
// 				Mat mNormColor;
// 				GetNormColorField(mK0, mR0, mt0, fx0_1, fy0_1, vDepths[k], vHxs[k], vHys[k], mNormColor);
// 				strInfo.Format("D:\\all\\normcolor map iteration %02d with image %02d.bmp", ii, k);
// 				imwrite(strInfo.GetBuffer(), mNormColor);
// 
// 				strInfo.Format("D:\\all\\cloud points iteration %02d with image %02d.txt", ii, k);
// 				OutputPointCloud(strInfo,mK0,mR0,mt0,fx0_1,fy0_1,img0,vDepths[k],vHxs[k],vHys[k],vScores[k]);
			}
		} 
		else
		{
			for (k=(n_spt-1);k>=0;k--)
			{
				for (i=imgHeight-1;i>=0;i--)
				{
					strInfo.Format("evaluate row %04d with image %02d in iteration %02d", i, k, ii);
//					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

					for (j=imgWidth-1;j>=0;j--)
					{
						int i_real, j_real, nVisi;
						MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

						vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
						vector<double> vScores_candidates;

						// first evaluate current parameter set for (i,j)
						double depth0 = vDepths[k].at<float>(i,j);
						double hx0 = vHxs[k].at<float>(i,j);
						double hy0 = vHys[k].at<float>(i,j);
						double score0 = vScores[k].at<float>(i,j);

						vScores_candidates.push_back(score0);
						vDepths_candidates.push_back(depth0);
						vHx_candidates.push_back(hx0);
						vHy_candidates.push_back(hy0);

						if (j+1<imgWidth) // means that there is a right neighbor
						{
							double hx_right = vHxs[k].at<float>(i,j+1);
							double hy_right = vHys[k].at<float>(i,j+1);
							double depth_right = vDepths[k].at<float>(i,j+1)/*-hx_right*/;

							double score_right,angle_right;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_right,hx_right,hy_right,score_right,angle_right,size);

							vScores_candidates.push_back(score_right);

							vDepths_candidates.push_back(depth_right);
							vHx_candidates.push_back(hx_right);
							vHy_candidates.push_back(hy_right);
						}

						if (i+1<imgHeight) // means that there is a lower neighbor
						{
							double hx_lower = vHxs[k].at<float>(i+1,j);
							double hy_lower = vHys[k].at<float>(i+1,j);
							double depth_lower = vDepths[k].at<float>(i+1,j)/*-hy_lower*/;

							double score_lower,angle_lower;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_lower,hx_lower,hy_lower,score_lower,angle_lower,size);

							vScores_candidates.push_back(score_lower);

							vDepths_candidates.push_back(depth_lower);
							vHx_candidates.push_back(hx_lower);
							vHy_candidates.push_back(hy_lower);
						}

						for (kk=(n_spt-1);kk>k;kk--)
						{
							double hx_kk = vHxs[kk].at<float>(i,j);
							double hy_kk = vHys[kk].at<float>(i,j);
							double depth_kk = vDepths[kk].at<float>(i,j);

							double score_kk,angle_kk;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_kk,hx_kk,hy_kk,score_kk,angle_kk,size);

							vScores_candidates.push_back(score_kk);

							vDepths_candidates.push_back(depth_kk);
							vHx_candidates.push_back(hx_kk);
							vHy_candidates.push_back(hy_kk);
						}

						vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						double max_score = *iterDouble;
						int idx_max_score = iterDouble - vScores_candidates.begin();

						double depth_possible = vDepths_candidates[idx_max_score];
						double hx_possible = vHx_candidates[idx_max_score];
						double hy_possible = vHy_candidates[idx_max_score];
						double score_possible = max_score;

						vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

						vScores_candidates.push_back(score_possible);
						vDepths_candidates.push_back(depth_possible);
						vHx_candidates.push_back(hx_possible);
						vHy_candidates.push_back(hy_possible);

						for (rk=0;rk<nRandSamp;rk++)
						{
							double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
							if (rk==0)
							{
								d_max_k = depth_max;
								d_min_k = depth_min;
								hx_max_k = h_max;
								hx_min_k = h_min;
								hy_max_k = h_max;
								hy_min_k = h_min;
							}
							else
							{
								double factor_k = pow(factor, rk);
								double d_r = factor_k*d_range*0.5;
								double h_r = factor_k*h_range*0.5;
								DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
								DetermineInterval(h_max, h_min, hx_possible, h_r, hx_max_k, hx_min_k);
								DetermineInterval(h_max, h_min, hy_possible, h_r, hy_max_k, hy_min_k);
							}

							// generate current parameter set
							double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
							double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
							double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

							double score_k,angle_k;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_k,hx_k,hy_k,score_k,angle_k,size);

							vScores_candidates.push_back(score_k);

							vDepths_candidates.push_back(depth_k);
							vHx_candidates.push_back(hx_k);
							vHy_candidates.push_back(hy_k);
						}

						iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						max_score = *iterDouble;
						idx_max_score = iterDouble - vScores_candidates.begin();

						vDepths[k].at<float>(i,j) = vDepths_candidates[idx_max_score];
						vHxs[k].at<float>(i,j) = vHx_candidates[idx_max_score];
						vHys[k].at<float>(i,j) = vHy_candidates[idx_max_score];
						vScores[k].at<float>(i,j) = max_score;
					}
				}

				Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3);

				double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

				minMaxIdx(vDepths[k], &min_depth, &max_depth);
				minMaxIdx(vHxs[k], &min_incre_x, &max_incre_x);
				minMaxIdx(vHys[k], &min_incre_y, &max_incre_y);

				vDepths[k].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
				vHxs[k].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
				vHys[k].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

				for (i=0;i<imgHeight;i++)
				{
					for (j=0;j<imgWidth;j++)
					{
						if (vScores[k].at<float>(i,j)<0)
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = 0;
							mScore_map.at<Vec3b>(i,j).val[2] = 255;
						}
						else
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*vScores[k].at<float>(i,j));
							mScore_map.at<Vec3b>(i,j).val[2] = 0;
						}
					}
				}

// 				strInfo.Format("D:\\all\\depth map iteration %02d with image %02d.bmp", ii, k);
// 				imwrite(strInfo.GetBuffer(), mDepth_map);
// 				strInfo.Format("D:\\all\\hx map iteration %02d with image %02d.bmp", ii, k);
// 				imwrite(strInfo.GetBuffer(), mHx_map);
// 				strInfo.Format("D:\\all\\hy map iteration %02d with image %02d.bmp", ii, k);
// 				imwrite(strInfo.GetBuffer(), mHy_map);
// 				strInfo.Format("D:\\all\\score map iteration %02d with image %02d.bmp", ii, k);
// 				imwrite(strInfo.GetBuffer(), mScore_map);
// 
// 				Mat mNormColor;
// 				GetNormColorField(mK0, mR0, mt0, fx0_1, fy0_1, vDepths[k], vHxs[k], vHys[k], mNormColor);
// 				strInfo.Format("D:\\all\\normcolor map iteration %02d with image %02d.bmp", ii, k);
// 				imwrite(strInfo.GetBuffer(), mNormColor);
// 
// 				strInfo.Format("D:\\all\\cloud points iteration %02d with image %02d.txt", ii, k);
// 				OutputPointCloud(strInfo,mK0,mR0,mt0,fx0_1,fy0_1,img0,vDepths[k],vHxs[k],vHys[k],vScores[k]);
			}
		}
	}
}

// 20141215, self-contained version, conduct patchmatch for reference image with every support image at each time without view propagation.
// with propagation between different layers.
// with initial estimates propagated from higher level on pyramid or lower resolution image.
void DeepVoid::PatchMatch_Binocular_3DPropagation_givenInit(const Matx33d & mK0,				// input:	interior matrix of the reference image
														    const Matx33d & mR0,				// input:	rotation matrix of the reference image
														    const Matx31d & mt0,				// input:	translation vectors of the reference image
														    const Mat & img0,					// input:	the reference image
														    const vector<Matx33d> & vKs,		// input:	interior matrix of all support images
														    const vector<Matx33d> & vRs,		// input:	rotation matrix of all support images
														    const vector<Matx31d> & vts,		// input:	translation vectors of all support images
														    const vector<Mat> & vImgs,			// input:	all support images
														    const vector<CloudPoint> & clouds,	// input:	the given sparse cloud points
															vector<Mat> & vDepths,				// in&output:	all the depth maps
															vector<Mat> & vHxs,					// in&output:	all the hx maps
															vector<Mat> & vHys,					// in&output:	all the hy maps
															vector<Mat> & vScores,				// in&output:	all the score maps
														    int size /*= 5*/,					// input:	the window size of the image patch, should be odd number
														    double angLimit /*= 80*/,			// input:	the angular range limit of the normal of every object point, in angle, not radian
														    int maxIter /*= 4*/,				// input:	maximum iteration
															double factor /*= 0.5*/,			// input:	decreasing factor
															double radius_factor /*= 0.01*/,	// input:	sampling radius factor
														    int nRandSamp /*= 6*/
														    )
{
	int i,j,k,ii,jj,kk,rk;

	int n_spt = vKs.size();
	int n_cloud = clouds.size();

	int imgWidth = img0.cols;
	int imgHeight = img0.rows;
	int wndSizeHalf = (size-1)/2;

	double fx0_1 = 1/mK0(0,0);
	double fy0_1 = 1/mK0(1,1);

	vector<double> vfx_1, vfy_1;
	for (k=0;k<n_spt;k++)
	{
		double fx_1 = 1/vKs[k](0,0);
		double fy_1 = 1/vKs[k](1,1);

		vfx_1.push_back(fx_1);
		vfy_1.push_back(fy_1);
	}

	// determine maximal and minimal parameters //////////////////////////////////////////////////////////////////////////
	double tana = tan(angLimit*D2R);

	double fx0 = mK0(0,0); double fy0 = mK0(1,1);

	double f=(fx0+fy0)*0.5;
	double tana_f = tana/f;

	double depth_min;
	double depth_max;

	for (jj=0;jj<n_cloud;jj++)
	{
		Matx31d mX;

		mX(0) = clouds[jj].m_pt.x;
		mX(1) = clouds[jj].m_pt.y;
		mX(2) = clouds[jj].m_pt.z;

		mX = mR0*mX+mt0;

		double depth = mX(2);

		if (jj == 0)
		{
			depth_min = depth;
			depth_max = depth;
		} 
		else
		{
			if (depth<depth_min)
			{
				depth_min = depth;
			}
			if (depth>depth_max)
			{
				depth_max = depth;
			}
		}
	}

	double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

	double depth_ext = (depth_max-depth_min)*ratio_ext;

	depth_max += depth_ext;

	double tmp = depth_min - depth_ext;

	if (tmp<0)
	{
		depth_min = 0;
	} 
	else
	{
		depth_min = tmp;
	}

	double h_max = tana_f * depth_max;
	double h_min = -h_max;

	double d_range = depth_max-depth_min;
	double h_range = h_max-h_min;
	//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

	CString strInfo;
	// initialize all depth, hx, hy maps randomly
	for (k=0;k<n_spt;k++)
	{
		// at the same time evaluate all parameters
		for (i=0;i<imgHeight;i++)
		{
			strInfo.Format("evaluate row %04d with image %02d", i, k);
			theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

			for (j=0;j<imgWidth;j++)
			{
				int i_real, j_real, nVisi;
				MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

				double depth = vDepths[k].at<float>(i,j);
				double hx = vHxs[k].at<float>(i,j);
				double hy = vHys[k].at<float>(i,j);

				double score, angle;
				CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth,hx,hy,score,angle,size);

				vScores[k].at<float>(i,j) = score;
			}
		}
	}

	// start propagation
	for (ii=0;ii<maxIter;ii++)
	{
		if (ii%2 == 0)
		{
			for (k=0;k<n_spt;k++)
			{
				for (i=0;i<imgHeight;i++)
				{
					strInfo.Format("evaluate row %04d with image %02d in iteration %02d", i, k, ii);
					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

					for (j=0;j<imgWidth;j++)
					{
						int i_real, j_real, nVisi;
						MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

						vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
						vector<double> vScores_candidates;

						// first evaluate current parameter set for (i,j)
						double depth0 = vDepths[k].at<float>(i,j);
						double hx0 = vHxs[k].at<float>(i,j);
						double hy0 = vHys[k].at<float>(i,j);
						double score0 = vScores[k].at<float>(i,j);

						vScores_candidates.push_back(score0);
						vDepths_candidates.push_back(depth0);
						vHx_candidates.push_back(hx0);
						vHy_candidates.push_back(hy0);

						if (j-1>=0) // means that there is a left neighbor
						{
							double hx_left = vHxs[k].at<float>(i,j-1);
							double hy_left = vHys[k].at<float>(i,j-1);
							double depth_left = vDepths[k].at<float>(i,j-1)/*+hx_left*/; // add the corresponding depth gradient of the left pixel

							double score_left, angle_left;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_left,hx_left,hy_left,score_left,angle_left,size);

							vScores_candidates.push_back(score_left);

							vDepths_candidates.push_back(depth_left);
							vHx_candidates.push_back(hx_left);
							vHy_candidates.push_back(hy_left);
						}

						if (i-1>=0) // means that there is a upper neighbor
						{
							double hx_upper = vHxs[k].at<float>(i-1,j);
							double hy_upper = vHys[k].at<float>(i-1,j);
							double depth_upper = vDepths[k].at<float>(i-1,j)/*+hy_upper*/;

							double score_upper,angle_upper;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_upper,hx_upper,hy_upper,score_upper,angle_upper,size);

							vScores_candidates.push_back(score_upper);

							vDepths_candidates.push_back(depth_upper);
							vHx_candidates.push_back(hx_upper);
							vHy_candidates.push_back(hy_upper);
						}

						for (kk=0;kk<k;kk++)
						{
							double hx_kk = vHxs[kk].at<float>(i,j);
							double hy_kk = vHys[kk].at<float>(i,j);
							double depth_kk = vDepths[kk].at<float>(i,j);

							double score_kk,angle_kk;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_kk,hx_kk,hy_kk,score_kk,angle_kk,size);

							vScores_candidates.push_back(score_kk);

							vDepths_candidates.push_back(depth_kk);
							vHx_candidates.push_back(hx_kk);
							vHy_candidates.push_back(hy_kk);
						}

						vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						double max_score = *iterDouble;
						int idx_max_score = iterDouble - vScores_candidates.begin();

						double depth_possible = vDepths_candidates[idx_max_score];
						double hx_possible = vHx_candidates[idx_max_score];
						double hy_possible = vHy_candidates[idx_max_score];
						double score_possible = max_score;

						vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

						vScores_candidates.push_back(score_possible);
						vDepths_candidates.push_back(depth_possible);
						vHx_candidates.push_back(hx_possible);
						vHy_candidates.push_back(hy_possible);

						for (rk=0;rk<nRandSamp;rk++)
						{
							double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
							
							double factor_k = pow(factor, rk);
							double d_r = factor_k*d_range*0.5*radius_factor;
							double h_r = factor_k*h_range*0.5*radius_factor;
							DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
							DetermineInterval(h_max, h_min, hx_possible, h_r, hx_max_k, hx_min_k);
							DetermineInterval(h_max, h_min, hy_possible, h_r, hy_max_k, hy_min_k);

							// generate current parameter set
							double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
							double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
							double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

							double score_k,angle_k;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_k,hx_k,hy_k,score_k,angle_k,size);

							vScores_candidates.push_back(score_k);

							vDepths_candidates.push_back(depth_k);
							vHx_candidates.push_back(hx_k);
							vHy_candidates.push_back(hy_k);
						}

						iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						max_score = *iterDouble;
						idx_max_score = iterDouble - vScores_candidates.begin();

						vDepths[k].at<float>(i,j) = vDepths_candidates[idx_max_score];
						vHxs[k].at<float>(i,j) = vHx_candidates[idx_max_score];
						vHys[k].at<float>(i,j) = vHy_candidates[idx_max_score];
						vScores[k].at<float>(i,j) = max_score;
					}
				}

				Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3);

				double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

				minMaxIdx(vDepths[k], &min_depth, &max_depth);
				minMaxIdx(vHxs[k], &min_incre_x, &max_incre_x);
				minMaxIdx(vHys[k], &min_incre_y, &max_incre_y);

				vDepths[k].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
				vHxs[k].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
				vHys[k].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

				for (i=0;i<imgHeight;i++)
				{
					for (j=0;j<imgWidth;j++)
					{
						if (vScores[k].at<float>(i,j)<0)
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = 0;
							mScore_map.at<Vec3b>(i,j).val[2] = 255;
						}
						else
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*vScores[k].at<float>(i,j));
							mScore_map.at<Vec3b>(i,j).val[2] = 0;
						}
					}
				}

				strInfo.Format("D:\\all\\depth map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mDepth_map);
				strInfo.Format("D:\\all\\hx map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mHx_map);
				strInfo.Format("D:\\all\\hy map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mHy_map);
				strInfo.Format("D:\\all\\score map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mScore_map);

				Mat mNormColor;
				GetNormColorField(mK0, mR0, mt0, fx0_1, fy0_1, vDepths[k], vHxs[k], vHys[k], mNormColor);
				strInfo.Format("D:\\all\\normcolor map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mNormColor);

				strInfo.Format("D:\\all\\cloud points iteration %02d with image %02d.txt", ii, k);
				OutputPointCloud(strInfo,mK0,mR0,mt0,fx0_1,fy0_1,img0,vDepths[k],vHxs[k],vHys[k],vScores[k]);
			}
		} 
		else
		{
			for (k=(n_spt-1);k>=0;k--)
			{
				for (i=imgHeight-1;i>=0;i--)
				{
					strInfo.Format("evaluate row %04d with image %02d in iteration %02d", i, k, ii);
					theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

					for (j=imgWidth-1;j>=0;j--)
					{
						int i_real, j_real, nVisi;
						MakeSureNotOutBorder(j,i,j_real,i_real,wndSizeHalf,imgWidth,imgHeight);

						vector<double> vDepths_candidates, vHx_candidates, vHy_candidates;
						vector<double> vScores_candidates;

						// first evaluate current parameter set for (i,j)
						double depth0 = vDepths[k].at<float>(i,j);
						double hx0 = vHxs[k].at<float>(i,j);
						double hy0 = vHys[k].at<float>(i,j);
						double score0 = vScores[k].at<float>(i,j);

						vScores_candidates.push_back(score0);
						vDepths_candidates.push_back(depth0);
						vHx_candidates.push_back(hx0);
						vHy_candidates.push_back(hy0);

						if (j+1<imgWidth) // means that there is a right neighbor
						{
							double hx_right = vHxs[k].at<float>(i,j+1);
							double hy_right = vHys[k].at<float>(i,j+1);
							double depth_right = vDepths[k].at<float>(i,j+1)/*-hx_right*/;

							double score_right,angle_right;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_right,hx_right,hy_right,score_right,angle_right,size);

							vScores_candidates.push_back(score_right);

							vDepths_candidates.push_back(depth_right);
							vHx_candidates.push_back(hx_right);
							vHy_candidates.push_back(hy_right);
						}

						if (i+1<imgHeight) // means that there is a lower neighbor
						{
							double hx_lower = vHxs[k].at<float>(i+1,j);
							double hy_lower = vHys[k].at<float>(i+1,j);
							double depth_lower = vDepths[k].at<float>(i+1,j)/*-hy_lower*/;

							double score_lower,angle_lower;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_lower,hx_lower,hy_lower,score_lower,angle_lower,size);

							vScores_candidates.push_back(score_lower);

							vDepths_candidates.push_back(depth_lower);
							vHx_candidates.push_back(hx_lower);
							vHy_candidates.push_back(hy_lower);
						}

						for (kk=(n_spt-1);kk>k;kk--)
						{
							double hx_kk = vHxs[kk].at<float>(i,j);
							double hy_kk = vHys[kk].at<float>(i,j);
							double depth_kk = vDepths[kk].at<float>(i,j);

							double score_kk,angle_kk;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_kk,hx_kk,hy_kk,score_kk,angle_kk,size);

							vScores_candidates.push_back(score_kk);

							vDepths_candidates.push_back(depth_kk);
							vHx_candidates.push_back(hx_kk);
							vHy_candidates.push_back(hy_kk);
						}

						vector <double>::iterator iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						double max_score = *iterDouble;
						int idx_max_score = iterDouble - vScores_candidates.begin();

						double depth_possible = vDepths_candidates[idx_max_score];
						double hx_possible = vHx_candidates[idx_max_score];
						double hy_possible = vHy_candidates[idx_max_score];
						double score_possible = max_score;

						vDepths_candidates.clear(); vHx_candidates.clear(); vHy_candidates.clear(); vScores_candidates.clear();

						vScores_candidates.push_back(score_possible);
						vDepths_candidates.push_back(depth_possible);
						vHx_candidates.push_back(hx_possible);
						vHy_candidates.push_back(hy_possible);

						for (rk=0;rk<nRandSamp;rk++)
						{
							double d_min_k, d_max_k, hx_min_k, hx_max_k, hy_min_k, hy_max_k;
							
							double factor_k = pow(factor, rk);
							double d_r = factor_k*d_range*0.5*radius_factor;
							double h_r = factor_k*h_range*0.5*radius_factor;
							DetermineInterval(depth_max, depth_min, depth_possible, d_r, d_max_k, d_min_k);
							DetermineInterval(h_max, h_min, hx_possible, h_r, hx_max_k, hx_min_k);
							DetermineInterval(h_max, h_min, hy_possible, h_r, hy_max_k, hy_min_k);

							// generate current parameter set
							double depth_k = rng_initRndField.uniform(d_min_k, d_max_k);
							double hx_k = rng_initRndField.uniform(hx_min_k, hx_max_k);
							double hy_k = rng_initRndField.uniform(hy_min_k, hy_max_k);

							double score_k,angle_k;
							CheckOnePixel_givenOneParamSet_oneImg(mK0,mR0,mt0,img0,fx0_1,fy0_1,vKs[k],vRs[k],vts[k],vImgs[k],vfx_1[k],vfy_1[k],j_real,i_real,depth_k,hx_k,hy_k,score_k,angle_k,size);

							vScores_candidates.push_back(score_k);

							vDepths_candidates.push_back(depth_k);
							vHx_candidates.push_back(hx_k);
							vHy_candidates.push_back(hy_k);
						}

						iterDouble = max_element(vScores_candidates.begin(), vScores_candidates.end());
						max_score = *iterDouble;
						idx_max_score = iterDouble - vScores_candidates.begin();

						vDepths[k].at<float>(i,j) = vDepths_candidates[idx_max_score];
						vHxs[k].at<float>(i,j) = vHx_candidates[idx_max_score];
						vHys[k].at<float>(i,j) = vHy_candidates[idx_max_score];
						vScores[k].at<float>(i,j) = max_score;
					}
				}

				Mat mDepth_map, mHx_map, mHy_map, mScore_map(imgHeight, imgWidth, CV_8UC3);

				double min_depth, max_depth, min_incre_x, max_incre_x, min_incre_y, max_incre_y;

				minMaxIdx(vDepths[k], &min_depth, &max_depth);
				minMaxIdx(vHxs[k], &min_incre_x, &max_incre_x);
				minMaxIdx(vHys[k], &min_incre_y, &max_incre_y);

				vDepths[k].convertTo(mDepth_map, CV_8UC1, 255/(max_depth-min_depth), -255*min_depth/(max_depth-min_depth));
				vHxs[k].convertTo(mHx_map, CV_8UC1, 255/(max_incre_x-min_incre_x), -255*min_incre_x/(max_incre_x-min_incre_x));
				vHys[k].convertTo(mHy_map, CV_8UC1, 255/(max_incre_y-min_incre_y), -255*min_incre_y/(max_incre_y-min_incre_y));

				for (i=0;i<imgHeight;i++)
				{
					for (j=0;j<imgWidth;j++)
					{
						if (vScores[k].at<float>(i,j)<0)
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = 0;
							mScore_map.at<Vec3b>(i,j).val[2] = 255;
						}
						else
						{
							mScore_map.at<Vec3b>(i,j).val[0] = 0;
							mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*vScores[k].at<float>(i,j));
							mScore_map.at<Vec3b>(i,j).val[2] = 0;
						}
					}
				}

				strInfo.Format("D:\\all\\depth map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mDepth_map);
				strInfo.Format("D:\\all\\hx map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mHx_map);
				strInfo.Format("D:\\all\\hy map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mHy_map);
				strInfo.Format("D:\\all\\score map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mScore_map);

				Mat mNormColor;
				GetNormColorField(mK0, mR0, mt0, fx0_1, fy0_1, vDepths[k], vHxs[k], vHys[k], mNormColor);
				strInfo.Format("D:\\all\\normcolor map iteration %02d with image %02d.bmp", ii, k);
				imwrite(strInfo.GetBuffer(), mNormColor);

				strInfo.Format("D:\\all\\cloud points iteration %02d with image %02d.txt", ii, k);
				OutputPointCloud(strInfo,mK0,mR0,mt0,fx0_1,fy0_1,img0,vDepths[k],vHxs[k],vHys[k],vScores[k]);
			}
		}
	}
}

// 20141013
void DeepVoid::ComputeDepthUncertainBoundary(double imgxj0, double imgyj0,		// input:	the matching image point in support image
										     double dj0,						// input:	the depth of the reconstructed object point w.r.t the support image
										     double a1, double a2, double a3,	// input:	[a1 a2 a3]' = KjRjRr'nx
										     double & ddmin,					// output:	the depth decrement of the lower boundary w.r.t the reconstructed depth
										     double & ddmax,					// output:	the depth decrement of the upper boundary w.r.t the reconstructed depth
										     double thresh_imgpt_sigma /*= 1*/	// input:	the uncertainty of the matching image point 		
										     )
{
	double sigma2 = thresh_imgpt_sigma*thresh_imgpt_sigma;

	double tmp1 = a1 - a3*imgxj0;
	double tmp2 = a2 - a3*imgyj0;

	double a = tmp1*tmp1 + tmp2*tmp2 - sigma2*a3*a3;
	double b = -2*sigma2*a3*dj0;
	double c = -sigma2*dj0*dj0;

	double tmp3 = sqrt(b*b - 4*a*c);
	double tmp4 = 0.5/a;

	ddmin = (-b - tmp3) * tmp4;
	ddmax = (-b + tmp3) * tmp4;
}

// 通过AfxMessageBox把矩阵显示在屏幕上
void DeepVoid::PrintMatrix2Screen_uchar(const Mat & mat,
									    CString title /*= ""*/,
									    WriteMode mode /*= WRITEMODE_LF*/
									    )    
{
	if (mat.empty())
	{
		if (title != "")
		{
			CString str;
			str.Format("%s\n\nNull Matrix!", title);
			AfxMessageBox(str);
		} 
		else
		{
			AfxMessageBox("Null Matrix!");
		}
	} 
	else
	{
		CString sMat, sEle;

		int i, j;
		for (i=0; i<mat.rows; i++)
		{
			for (j=0; j<mat.cols; j++)
			{
				sEle.Format("%d	", mat.at<uchar>(i,j));
				
				sMat += sEle;
			}
			sEle.Format("\n");
			sMat += sEle;
		}

		if (title != "")
		{
			sEle.Format("%s\n\n", title);
			sMat = sEle + sMat;
		}

		AfxMessageBox(sMat);
	}
}

// 通过AfxMessageBox把矩阵显示在屏幕上
void DeepVoid::PrintMatrix2Screen_double(const Mat & mat,
										 CString title /*= ""*/,
										 WriteMode mode /*= WRITEMODE_LF*/
										 )    
{
	if (mat.empty())
	{
		if (title != "")
		{
			CString str;
			str.Format("%s\n\nNull Matrix!", title);
			AfxMessageBox(str);
		} 
		else
		{
			AfxMessageBox("Null Matrix!");
		}
	} 
	else
	{
		CString sMat, sEle;

		int i, j;
		for (i=0; i<mat.rows; i++)
		{
			for (j=0; j<mat.cols; j++)
			{
				if (mode == WRITEMODE_LF)
				{
					sEle.Format("%lf	", mat.at<double>(i,j));
				} 
				else
				{
					sEle.Format("%.12e	", mat.at<double>(i,j));
				}

				sMat += sEle;
			}
			sEle.Format("\n");
			sMat += sEle;
		}

		if (title != "")
		{
			sEle.Format("%s\n\n", title);
			sMat = sEle + sMat;
		}

		AfxMessageBox(sMat);
	}
}

void DeepVoid::SaveMat2File_double(CString path, const Mat & mat, WriteMode mode /*= WRITEMODE_LF*/)
{
	FILE * pFile = fopen(path, "a");
	
	int rows = mat.rows;
	int cols = mat.cols;

	int i,j;

	fprintf(pFile, "(%d, %d)\n\n", rows, cols);

	for (i = 0; i < rows; i++)
	{
		for (j = 0; j < cols; j++)
		{
			switch (mode)
			{
			case WRITEMODE_E:
				fprintf(pFile, "%.12e	", mat.at<double>(i,j));
				break;

			case WRITEMODE_LF:
				fprintf(pFile, "%lf	", mat.at<double>(i,j));
				break;

			default:
				break;
			}
		}
		fprintf(pFile, "\n");
	}
	fprintf(pFile, "\n\n");
	
	fclose(pFile);
}

// 计算两向量间夹角的余弦 [-1, 1]
double DeepVoid::ComputeCosa(const Matx31d & vec1, const Matx31d & vec2)
{
	Matx<double, 1, 1> mcosa = vec1.t()*vec2;        // v1'v2
	double cosa = mcosa(0)/(norm(vec1)*norm(vec2));  // cosa = v1'v2/|v1||v2|

	if (cosa>1)
	{
		cosa=1;
	}
	if (cosa<-1)
	{
		cosa=-1;
	}

	return cosa;
}

// 计算两向量间夹角, in radian, 0-π
double DeepVoid::ComputeAngle(const Matx31d & vec1, const Matx31d & vec2)
{
	return acos(ComputeCosa(vec1,vec2));
}

void DeepVoid::SaveParaField2Img(CString & path, const Mat & field)
{
	Mat mField_map;

	double min_val, max_val;

	minMaxIdx(field, &min_val, &max_val);

	field.convertTo(mField_map, CV_8UC1, 255/(max_val-min_val), -255*min_val/(max_val-min_val));

	imwrite(path.GetBuffer(), mField_map);
}

void DeepVoid::SaveScoreField2Img(CString & path, const Mat & mScore)
{
	int i,j;

	int h = mScore.rows;
	int w = mScore.cols;

	Mat mScore_map(h, w, CV_8UC3);

	for (i=0;i<h;i++)
	{
		for (j=0;j<w;j++)
		{
			if (mScore.at<float>(i,j)<0)
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = 0;
				mScore_map.at<Vec3b>(i,j).val[2] = 255;
			}
			else
			{
				mScore_map.at<Vec3b>(i,j).val[0] = 0;
				mScore_map.at<Vec3b>(i,j).val[1] = FTOI(255*mScore.at<float>(i,j));
				mScore_map.at<Vec3b>(i,j).val[2] = 0;
			}
		}
	}

	imwrite(path.GetBuffer(), mScore_map);
}

// enforce silhouette-consistency constraint
void DeepVoid::VisualHullConstraint(int idx,							// input:	the index of current checked image
								    const vector<Matx33d> & vKs,		// input:	interior matrix of all images
								    const vector<Matx33d> & vRs,		// input:	rotation matrix of all images
								    const vector<Matx31d> & vts,		// input:	translation vectors of all images
								    const vector<Mat> & vSilhouettes,	// input:	silhouettes of objects
								    const Mat & mDepth,					// input:	depth map estimate
								    Mat & mScore,						// output:	the score map
									int radius/* = 2*/					// input:
								    )
{
	int i,j,k,ii,jj;

	int w = vSilhouettes[idx].cols;
	int h = vSilhouettes[idx].rows;
	int n = vSilhouettes.size();

	double fx = vKs[idx](0,0);
	double fy = vKs[idx](1,1);
	double fx_1 = 1/fx;
	double fy_1 = 1/fy;
	double cx = vKs[idx](0,2);
	double cy = vKs[idx](1,2);

	for (i=0;i<h;i++)
	{
		double nimgy = (i-cy)*fy_1;

		for (j=0;j<w;j++)
		{
			double nimgx = (j-cx)*fx_1;

			double score = mScore.at<float>(i,j);
			double depth = mDepth.at<float>(i,j);

			if (score<0)
			{
				continue;
			}
			
			// outside the object silhouette
			if (vSilhouettes[idx].at<uchar>(i,j)<128)
			{
				mScore.at<float>(i,j) = -1;
				continue;
			}

			// get XYZ object point
			Matx31d XYZ = GetXYZ_givenDepth(vRs[idx],vts[idx],nimgx,nimgy,depth);

			for (k=0;k<n;k++)
			{
				if (k==idx)
				{
					continue;
				}

				// project to kth image
				Matx31d imgpt = vKs[k]*vRs[k]*XYZ+vKs[k]*vts[k];
				double z_1 = 1/imgpt(2);
				double imgx = imgpt(0)*z_1;
				double imgy = imgpt(1)*z_1;

				if (imgx<0 || imgx>w-1 || imgy<0 || imgy>h-1)
				{
					continue;
				}

				int xk_int = int(imgx+0.5);
				int yk_int = int(imgy+0.5);

				if (vSilhouettes[k].at<uchar>(yk_int,xk_int)<128)
				{
					bool bNon = true;
					for (ii=-radius;ii<=radius;ii++)
					{
						for (jj=-radius;jj<=radius;jj++)
						{
							int u = xk_int+jj;
							int v = yk_int+ii;
							if (u<0 || u>w-1 || v<0 || v>h-1)
							{
								continue;
							}
							uchar bk = vSilhouettes[k].at<uchar>(v,u);
							if (bk>128)
							{
								bNon = false;
								break;
							}
						}
						if (!bNon)
						{
							break;
						}
					}

					if (bNon) // confirmed
					{
						mScore.at<float>(i,j) = -1;
						break;
					}
				} 
		
// 				uchar bk = vSilhouettes[k].at<uchar>(yk_int,xk_int);
// 
// 				// violated the silhouette-consistency constraint
// 				if (bk<128)
// 				{
// 					mScore.at<float>(i,j) = -1;
// 					break;
// 				}
			}
		}
	}
}

// Downsampling
void DeepVoid::DownSample(const Mat & img,	// input:	original image
						  Mat & img_samp,	// output:	down sampled image
						  int n /*= 2*/		// input:	sample one pixel every n pixels
						  )
{
	int i,j;

	int nChannel = img.channels();

	int w_new = img.cols/n;
	int h_new = img.rows/n;

	if (nChannel==1)
	{
		img_samp = Mat(h_new,w_new,CV_8UC1); // graylevel

		for (i=0;i<h_new;i++)
		{
			for (j=0;j<w_new;j++)
			{
				img_samp.at<uchar>(i,j)=img.at<uchar>(i*n,j*n);
			}
		}
	} 
	else
	{
		img_samp = Mat(h_new,w_new,CV_8UC3); // color

		for (i=0;i<h_new;i++)
		{
			for (j=0;j<w_new;j++)
			{
				img_samp.at<Vec3b>(i,j)=img.at<Vec3b>(i*n,j*n);
			}
		}
	}
}

// augment the value field of a lower resolution image into a higher resolution image
void DeepVoid::AugmentField(const Mat & field,		// input:	lower resolution image to be augmented
						    Mat & field_aug,		// output:	the augmented field
						    int width, int height,	// input:	size of augmented field
						    int n /*= 2*/,			// input:	replicate value of one pixel for n pixels
							double factor /*= 1*/	// input:	optional input, factor
						    )
{
	int i,j;

	field_aug = Mat(height,width,CV_32FC1);

	double n_1 = 1.0/n;

	for (i=0;i<height;i++)
	{
		int i0=i*n_1;

		if (i0>=field.rows)
		{
			i0=field.rows-1;
		}

		for (j=0;j<width;j++)
		{
			int j0=j*n_1;

			if (j0>=field.cols)
			{
				j0=field.cols-1;
			}

			field_aug.at<float>(i,j) = field.at<float>(i0,j0)*factor;
		}
	}
}

// augment the value field of a lower resolution image into a higher resolution image
void DeepVoid::AugmentField_Interp(const Mat & field,		// input:	lower resolution image to be augmented
								   Mat & field_aug,			// output:	the augmented field
								   int width, int height,	// input:	size of augmented field
								   int n /*= 2*/,			// input:	replicate value of one pixel for n pixels
								   double factor /*= 1*/	// input:	optional input, factor
								   )
{
	int i,j;

	field_aug = Mat(height,width,CV_32FC1);

	double n_1 = 1.0/n;

	for (i=0;i<height;i++)
	{
		double i0=i*n_1; // the double row index in the lower resolution field

		int y1 = floor_fast(i0);// the y coordinate of the two top points
		if (y1>=(field.rows-1))
		{
			y1=field.rows-2;
		}
		int y2 = y1+1;			// the y coordinate of the two bottom points

		for (j=0;j<width;j++)
		{
			double j0=j*n_1; // the double col index in the lower resolution field

			int x1 = floor_fast(j0);// the x coordinate of the two left points
			if (x1>=(field.cols-1))
			{
				x1=field.cols-2;
			}
			int x2 = x1+1;			// the x coordinate of the two right points

			double f1 = field.at<float>(y1,x1)*factor; // topleft
			double f2 = field.at<float>(y1,x2)*factor; // topright
			double f3 = field.at<float>(y2,x1)*factor; // bottomleft
			double f4 = field.at<float>(y2,x2)*factor; // bottomright

			double f = BilinearInterp(j0, i0, x1, x2, y1, y2, f1, f2, f3, f4);

			field_aug.at<float>(i,j) = f;
		}
	}
}

// pyramid 20141211
void DeepVoid::Pyramid(const Matx33d & mK0,					// input:	interior matrix of the reference image
					   const Matx33d & mR0,					// input:	rotation matrix of the reference image
					   const Matx31d & mt0,					// input:	translation vectors of the reference image
					   const Mat & img0,					// input:	the reference image
					   const vector<Matx33d> & vKs,			// input:	interior matrix of all support images
					   const vector<Matx33d> & vRs,			// input:	rotation matrix of all support images
					   const vector<Matx31d> & vts,			// input:	translation vectors of all support images
					   const vector<Mat> & vImgs,			// input:	all support images
					   const vector<CloudPoint> & clouds,	// input:	the given sparse cloud points
					   int size /*= 5*/,					// input:	the window size of the image patch, should be odd number
					   double thresh_ncc /*= 0.8*/,			// input:	the threshold within which to be considered as a successful ncc
					   double angLimit /*= 80*/,			// input:	the angular range limit of the normal of every object point, in angle, not radian
					   int maxIter /*= 4*/,					// input:	maximum iteration
					   double factor /*= 0.5*/,				// input:	decreasing factor
					   int nRandSamp /*= 6*/,				// input:	number of times of random sampling
					   int nLevel /*= 4*/,					// input:	number of pyramid levels
					   int idxOutLevel /*= 0*/				// input:	output final results at pyramid level idxOutLevel, default is level 0, i.e. the highest resolution level
					   )
{
	int i,j,k,ii,jj,kk,rk,l;

	int n_spt = vKs.size();
	int n_cloud = clouds.size();

	int imgWidth = img0.cols;
	int imgHeight = img0.rows;
	int wndSizeHalf = (size-1)/2;

	double fx0_1 = 1/mK0(0,0);
	double fy0_1 = 1/mK0(1,1);

	vector<double> vfx_1, vfy_1;
	for (k=0;k<n_spt;k++)
	{
		double fx_1 = 1/vKs[k](0,0);
		double fy_1 = 1/vKs[k](1,1);

		vfx_1.push_back(fx_1);
		vfy_1.push_back(fy_1);
	}

	// determine maximal and minimal parameters //////////////////////////////////////////////////////////////////////////
	double tana = tan(angLimit*D2R);

	double fx0 = mK0(0,0); double fy0 = mK0(1,1);

	double f=(fx0+fy0)*0.5;
	double tana_f = tana/f;

	double depth_min;
	double depth_max;

	for (jj=0;jj<n_cloud;jj++)
	{
		Matx31d mX;

		mX(0) = clouds[jj].m_pt.x;
		mX(1) = clouds[jj].m_pt.y;
		mX(2) = clouds[jj].m_pt.z;

		mX = mR0*mX+mt0;

		double depth = mX(2);

		if (jj == 0)
		{
			depth_min = depth;
			depth_max = depth;
		} 
		else
		{
			if (depth<depth_min)
			{
				depth_min = depth;
			}
			if (depth>depth_max)
			{
				depth_max = depth;
			}
		}
	}

	double ratio_ext = 0.05; // the range of depth is extended on both directions by 5%

	double depth_ext = (depth_max-depth_min)*ratio_ext;

	depth_max += depth_ext;

	double tmp = depth_min - depth_ext;

	if (tmp<0)
	{
		depth_min = 0;
	} 
	else
	{
		depth_min = tmp;
	}

	double h_max = tana_f * depth_max;
	double h_min = -h_max;

	double d_range = depth_max-depth_min;
	double h_range = h_max-h_min;
	//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

	vector<Matx33d> vK0s;
	vK0s.push_back(mK0);

	vector<Mat> vPyramidImgs;
//	buildPyramid(img0, vPyramidImgs, nLevel-1); // build gaussian pyramid OpenCV
	vPyramidImgs.push_back(img0);

	// construct pyramid intrinsic parameters
	for (l=1;l<nLevel;l++)
	{
		int nPix = pow(2.0,l);

		Mat img_samp;
		DownSample(img0, img_samp, nPix);
		vPyramidImgs.push_back(img_samp);

		double nPix_1 = 1.0/nPix;

		Matx33d mK0_samp;
		mK0_samp(0,0) = mK0(0,0)*nPix_1;
		mK0_samp(1,1) = mK0(1,1)*nPix_1;
		mK0_samp(0,2) = mK0(0,2)*nPix_1;
		mK0_samp(1,2) = mK0(1,2)*nPix_1;
		mK0_samp(0,1) = mK0(0,1);
		mK0_samp(2,2) = 1;
		vK0s.push_back(mK0_samp);
	}	

	// do patchmatch for the lowest resolution reference image first
	vector<Mat> vDepths_l,vHxs_l,vHys_l,vScores_l;

	PatchMatch_Binocular_3DPropagation(vK0s[nLevel-1],mR0,mt0,vPyramidImgs[nLevel-1],vKs,vRs,vts,vImgs,clouds,
		vDepths_l,vHxs_l,vHys_l,vScores_l,size,angLimit,maxIter,factor,nRandSamp);

	for (k=0;k<n_spt;k++)
	{
		MPGC_Binocular_20141215(vK0s[nLevel-1],mR0,mt0,vPyramidImgs[nLevel-1],vKs[k],vRs[k],vts[k],vImgs[k],
			vDepths_l[k],vHxs_l[k],vHys_l[k],vScores_l[k],size,size,5);

		CString str;
		str.Format("D:\\all\\depth map with %03d support image in pyramid level %03d.bmp", k, nLevel-1);
		SaveParaField2Img(str, vDepths_l[k]);

		str.Format("D:\\all\\hx map with %03d support image in pyramid level %03d.bmp", k, nLevel-1);
		SaveParaField2Img(str, vHxs_l[k]);

		str.Format("D:\\all\\hy map with %03d support image in pyramid level %03d.bmp", k, nLevel-1);
		SaveParaField2Img(str, vHys_l[k]);

		str.Format("D:\\all\\score map with %03d support image in pyramid level %03d.bmp", k, nLevel-1);
		SaveScoreField2Img(str, vScores_l[k]);

		double fx0l_1 = 1.0/vK0s[nLevel-1](0,0);
		double fy0l_1 = 1.0/vK0s[nLevel-1](1,1);

		Mat mNormColor;
		GetNormColorField(vK0s[nLevel-1],mR0,mt0,fx0l_1,fy0l_1,vDepths_l[k],vHxs_l[k],vHys_l[k],mNormColor);
		str.Format("D:\\all\\normal map with %03d support image in pyramid level %03d.bmp", k, nLevel-1);
		imwrite(str.GetBuffer(), mNormColor);

		str.Format("D:\\all\\point cloud with %03d support image in pyramid level %03d.txt", k, nLevel-1);
		OutputPointCloud(str,vK0s[nLevel-1],mR0,mt0,fx0l_1,fy0l_1,vPyramidImgs[nLevel-1],
			vDepths_l[k],vHxs_l[k],vHys_l[k],vScores_l[k]);
	}

	vector<vector<Mat>> vDepths_allLevels,vHxs_allLevels,vHys_allLevels,vScores_allLevels;

	vDepths_allLevels.push_back(vDepths_l);
	vHxs_allLevels.push_back(vHxs_l);
	vHys_allLevels.push_back(vHys_l);
	vScores_allLevels.push_back(vScores_l);

	for (l=(nLevel-2);l>=idxOutLevel;l--)
	{
		for (k=0;k<n_spt;k++)
		{
// 			AugmentField(vDepths_allLevels[nLevel-2-l][k],vDepths_l[k],vPyramidImgs[l].cols,vPyramidImgs[l].rows,2);
// 			AugmentField(vHxs_allLevels[nLevel-2-l][k],vHxs_l[k],vPyramidImgs[l].cols,vPyramidImgs[l].rows,2,0.5);
// 			AugmentField(vHys_allLevels[nLevel-2-l][k],vHys_l[k],vPyramidImgs[l].cols,vPyramidImgs[l].rows,2,0.5);
// 			AugmentField(vScores_allLevels[nLevel-2-l][k],vScores_l[k],vPyramidImgs[l].cols,vPyramidImgs[l].rows,2);

			AugmentField_Interp(vDepths_allLevels[nLevel-2-l][k],vDepths_l[k],vPyramidImgs[l].cols,vPyramidImgs[l].rows,2);
			AugmentField_Interp(vHxs_allLevels[nLevel-2-l][k],vHxs_l[k],vPyramidImgs[l].cols,vPyramidImgs[l].rows,2,0.5);
			AugmentField_Interp(vHys_allLevels[nLevel-2-l][k],vHys_l[k],vPyramidImgs[l].cols,vPyramidImgs[l].rows,2,0.5);
			AugmentField_Interp(vScores_allLevels[nLevel-2-l][k],vScores_l[k],vPyramidImgs[l].cols,vPyramidImgs[l].rows,2);

// 			CString str;
// 			str.Format("D:\\all\\depth map with %03d support image propagated to pyramid level %03d.bmp", k, l);
// 			SaveParaField2Img(str, vDepths_l[k]);
// 
// 			str.Format("D:\\all\\hx map with %03d support image propagated to pyramid level %03d.bmp", k, l);
// 			SaveParaField2Img(str, vHxs_l[k]);
// 
// 			str.Format("D:\\all\\hy map with %03d support image propagated to pyramid level %03d.bmp", k, l);
// 			SaveParaField2Img(str, vHys_l[k]);
// 
// 			str.Format("D:\\all\\score map with %03d support image propagated to pyramid level %03d.bmp", k, l);
// 			SaveScoreField2Img(str, vScores_l[k]);
// 
// 			double fx0l_1 = 1.0/vK0s[l](0,0);
// 			double fy0l_1 = 1.0/vK0s[l](1,1);
// 
// 			Mat mNormColor;
// 			GetNormColorField(vK0s[l],mR0,mt0,fx0l_1,fy0l_1,vDepths_l[k],vHxs_l[k],vHys_l[k],mNormColor);
// 			str.Format("D:\\all\\normal map with %03d support image propagated to pyramid level %03d.bmp", k, l);
// 			imwrite(str.GetBuffer(), mNormColor);
// 
// 			str.Format("D:\\all\\point cloud with %03d support image propagated to pyramid level %03d.txt", k, l);
// 			OutputPointCloud(str,vK0s[l],mR0,mt0,fx0l_1,fy0l_1,vPyramidImgs[l],
// 				vDepths_l[k],vHxs_l[k],vHys_l[k],vScores_l[k]);
		}

// 		PatchMatch_Binocular_3DPropagation_givenInit(vK0s[l],mR0,mt0,vPyramidImgs[l],vKs,vRs,vts,vImgs,clouds,
// 			vDepths_l,vHxs_l,vHys_l,vScores_l,size,angLimit,maxIter,factor,0.01,2);

		for (k=0;k<n_spt;k++)
		{
			MPGC_Binocular_20141215(vK0s[l],mR0,mt0,vPyramidImgs[l],vKs[k],vRs[k],vts[k],vImgs[k],
				vDepths_l[k],vHxs_l[k],vHys_l[k],vScores_l[k],size,size,5);

			CString str;
			str.Format("D:\\all\\depth map with %03d support image in pyramid level %03d.bmp", k, l);
			SaveParaField2Img(str, vDepths_l[k]);

			str.Format("D:\\all\\hx map with %03d support image in pyramid level %03d.bmp", k, l);
			SaveParaField2Img(str, vHxs_l[k]);

			str.Format("D:\\all\\hy map with %03d support image in pyramid level %03d.bmp", k, l);
			SaveParaField2Img(str, vHys_l[k]);

			str.Format("D:\\all\\score map with %03d support image in pyramid level %03d.bmp", k, l);
			SaveScoreField2Img(str, vScores_l[k]);

			double fx0l_1 = 1.0/vK0s[l](0,0);
			double fy0l_1 = 1.0/vK0s[l](1,1);

			Mat mNormColor;
			GetNormColorField(vK0s[l],mR0,mt0,fx0l_1,fy0l_1,vDepths_l[k],vHxs_l[k],vHys_l[k],mNormColor);
			str.Format("D:\\all\\normal map with %03d support image in pyramid level %03d.bmp", k, l);
			imwrite(str.GetBuffer(), mNormColor);

			str.Format("D:\\all\\point cloud with %03d support image in pyramid level %03d.txt", k, l);
			OutputPointCloud(str,vK0s[l],mR0,mt0,fx0l_1,fy0l_1,vPyramidImgs[l],
				vDepths_l[k],vHxs_l[k],vHys_l[k],vScores_l[k]);
		}

		vDepths_allLevels.push_back(vDepths_l);
		vHxs_allLevels.push_back(vHxs_l);
		vHys_allLevels.push_back(vHys_l);
		vScores_allLevels.push_back(vScores_l);
	}

	int w_out = vPyramidImgs[idxOutLevel].cols;
	int h_out = vPyramidImgs[idxOutLevel].rows;

	// propagate candidates from all higher level ///////////////////////////////////
	vector<Mat> vDepths_all, vHxs_all, vHys_all, vScores_all;
	for (l=(nLevel-1);l>idxOutLevel;l--)
	{
		int l_diff = l-idxOutLevel;

		int nPix = pow(2.0, l_diff);

		double nPix_1 = 1.0/nPix;

		for (k=0;k<n_spt;k++)
		{
			Mat mDepth, mHx, mHy, mScore;
			AugmentField_Interp(vDepths_allLevels[nLevel-1-l][k],mDepth,w_out,h_out,nPix);
			AugmentField_Interp(vHxs_allLevels[nLevel-1-l][k],mHx,w_out,h_out,nPix,nPix_1);
			AugmentField_Interp(vHys_allLevels[nLevel-1-l][k],mHy,w_out,h_out,nPix,nPix_1);
			AugmentField_Interp(vScores_allLevels[nLevel-1-l][k],mScore,w_out,h_out,nPix);

			vDepths_all.push_back(mDepth);
			vHxs_all.push_back(mHx);
			vHys_all.push_back(mHy);
			vScores_all.push_back(mScore);
		}
	}

	for (k=0;k<n_spt;k++)
	{
		vDepths_all.push_back(vDepths_allLevels[nLevel-1-idxOutLevel][k]);
		vHxs_all.push_back(vHxs_allLevels[nLevel-1-idxOutLevel][k]);
		vHys_all.push_back(vHys_allLevels[nLevel-1-idxOutLevel][k]);
		vScores_all.push_back(vScores_allLevels[nLevel-1-idxOutLevel][k]);
	}

	for (k=0;k<vDepths_all.size();k++)
	{
		int l_tmp = k/n_spt;

		int idxSpt = k%n_spt;

		int l = nLevel-1-l_tmp;

		// then invalidate those estimates whose normals are not reasonable and whose scores are smaller than certain threshold
		InvalidatePixels_byNormal(vK0s[idxOutLevel],mR0,mt0,vKs[idxSpt],vRs[idxSpt],vts[idxSpt],
			vDepths_all[k],vHxs_all[k],vHys_all[k],vScores_all[k],90,0.95);

		CString str;
		str.Format("D:\\all\\depth map with %03d support image propagated to pyramid level %03d from level %03d.bmp", idxSpt, idxOutLevel, l);
		SaveParaField2Img(str, vDepths_all[k]);

		str.Format("D:\\all\\hx map with %03d support image propagated to pyramid level %03d from level %03d.bmp", idxSpt, idxOutLevel, l);
		SaveParaField2Img(str, vHxs_all[k]);

		str.Format("D:\\all\\hy map with %03d support image propagated to pyramid level %03d from level %03d.bmp", idxSpt, idxOutLevel, l);
		SaveParaField2Img(str, vHys_all[k]);

		str.Format("D:\\all\\score map with %03d support image propagated to pyramid level %03d from level %03d.bmp", idxSpt, idxOutLevel, l);
		SaveScoreField2Img(str, vScores_all[k]);

		double fx0l_1 = 1.0/vK0s[idxOutLevel](0,0);
		double fy0l_1 = 1.0/vK0s[idxOutLevel](1,1);

		Mat mNormColor;
		GetNormColorField(vK0s[idxOutLevel],mR0,mt0,fx0l_1,fy0l_1,vDepths_all[k],vHxs_all[k],vHys_all[k],mNormColor);
		str.Format("D:\\all\\normal map with %03d support image propagated to pyramid level %03d from level %03d.bmp", idxSpt, idxOutLevel, l);
		imwrite(str.GetBuffer(), mNormColor);

		str.Format("D:\\all\\point cloud with %03d support image propagated to pyramid level %03d from level %03d.txt", idxSpt, idxOutLevel, l);
		OutputPointCloud(str,vK0s[idxOutLevel],mR0,mt0,fx0l_1,fy0l_1,vPyramidImgs[idxOutLevel],
			vDepths_all[k],vHxs_all[k],vHys_all[k],vScores_all[k]);
	}
	//////////////////////////////////////////////////////////////////////////////////

	
	Mat mSel, mVisi;
	Mat mDepth_ML, mHx_ML, mHy_ML, mScore_ML;
	Extract_MRF_ncc_d_n_DP_withInvalids(vK0s[idxOutLevel],mR0,mt0,vDepths_all,vHxs_all,vHys_all,vScores_all,mSel,mDepth_ML,mHx_ML,mHy_ML,mScore_ML,1.5,0.01);

	CString str;
	str.Format("D:\\all\\Most likely depth map at pyramid level %03d.bmp", idxOutLevel);
	SaveParaField2Img(str, mDepth_ML);

	str.Format("D:\\all\\Most likely hx map at pyramid level %03d.bmp", idxOutLevel);
	SaveParaField2Img(str, mHx_ML);

	str.Format("D:\\all\\Most likely hy map at pyramid level %03d.bmp", idxOutLevel);
	SaveParaField2Img(str, mHy_ML);

	str.Format("D:\\all\\Most likely score map at pyramid level %03d.bmp", idxOutLevel);
	SaveScoreField2Img(str, mScore_ML);

	double fx0l_1 = 1.0/vK0s[idxOutLevel](0,0);
	double fy0l_1 = 1.0/vK0s[idxOutLevel](1,1);

	Mat mNormColor;
	GetNormColorField(vK0s[idxOutLevel],mR0,mt0,fx0l_1,fy0l_1,mDepth_ML,mHx_ML,mHy_ML,mNormColor);
	str.Format("D:\\all\\Most likely normal map at pyramid level %03d.bmp", idxOutLevel);
	imwrite(str.GetBuffer(), mNormColor);

	str.Format("D:\\all\\Most likely point cloud at pyramid level %03d.txt", idxOutLevel);
	OutputPointCloud(str,vK0s[idxOutLevel],mR0,mt0,fx0l_1,fy0l_1,vPyramidImgs[idxOutLevel],
		mDepth_ML,mHx_ML,mHy_ML,mScore_ML);

	AugmentVisibility_basedonMostLikelyDepthandNormals_SURE_MultiScales(vK0s[idxOutLevel],mR0,mt0,vKs,vRs,vts,
		vDepths_all,vHxs_all,vHys_all,vScores_all,mSel,mVisi,4,90);

	// draw visibility w.r.t each support image
	vector<Mat> vVisi_map;
	for (kk=0;kk<n_spt;kk++)
	{
		Mat mtmp(mVisi.rows,mVisi.cols,CV_8UC3);
		vVisi_map.push_back(mtmp);
	}

	for (i=0;i<mVisi.rows;i++)
	{
		for (j=0;j<mVisi.cols;j++)
		{
			uchar visi = mVisi.at<uchar>(i,j);

			vector<bool> vbools;
			InterpVisiVector_uchar(visi, vbools);

			for (kk=0;kk<n_spt;kk++)
			{
				if (vbools[kk])
				{
					vVisi_map[kk].at<Vec3b>(i,j).val[0] = vPyramidImgs[idxOutLevel].at<Vec3b>(i,j).val[0];
					vVisi_map[kk].at<Vec3b>(i,j).val[1] = vPyramidImgs[idxOutLevel].at<Vec3b>(i,j).val[1];
					vVisi_map[kk].at<Vec3b>(i,j).val[2] = vPyramidImgs[idxOutLevel].at<Vec3b>(i,j).val[2];
				} 
				else
				{
					vVisi_map[kk].at<Vec3b>(i,j).val[0] = 0;
					vVisi_map[kk].at<Vec3b>(i,j).val[1] = 0;
					vVisi_map[kk].at<Vec3b>(i,j).val[2] = 255;
				}
			}
		}
	}

	for (kk=0;kk<n_spt;kk++)
	{
		str.Format("D:\\all\\final visi map at pyramid level %03d wrt support image %03d.bmp", idxOutLevel, kk);
		imwrite(str.GetBuffer(), vVisi_map[kk]);
	}
// 
// 	Mat mDepth_MPGC, mHx_MPGC, mHy_MPGC, mScore_MPGC;
// 	MPGC_20140910(mK0,mR0,mt0,img0,vKs_spt,vRs_spt,vts_spt,vImgs_spt,vDepths_bin,vHxs_bin,vHys_bin,vScores_bin,mDepth_ML,mHx_ML,mHy_ML,mSel,mVisi,
// 		mDepth_MPGC,mHx_MPGC,mHy_MPGC,mScore_MPGC,size,size,ratio_disc,maxIter_optim,xEps,fEps);
}

// 20150207, zhaokunz, pyramid
// 目标是通过采用金字塔机制（应对若纹理、减少计算量）为后续的多图 MPGC 提供合适的深度和法向的优化初值，以及每个像素相对于每幅支持图像的可见性
// 函数可以输出低于源图像分辨率的深度及法向图，并不一定非得是源尺寸
// 当然如果输出低分辨率的深度及法向图，输出的深度及法向图的内参数也是成比例改变的
void DeepVoid::SurfaceMapEstimation_oneImg_Pyramid(const Matx33d & mK0,						// input:	interior matrix of the reference image
												   const Matx33d & mR0,						// input:	rotation matrix of the reference image
												   const Matx31d & mt0,						// input:	translation vectors of the reference image
												   const Mat & img0,						// input:	the reference image
												   const vector<Matx33d> & vKs,				// input:	interior matrix of all support images
												   const vector<Matx33d> & vRs,				// input:	rotation matrix of all support images
												   const vector<Matx31d> & vts,				// input:	translation vectors of all support images
												   const vector<Mat> & vImgs,				// input:	all support images
												   const vector<CloudPoint> & clouds,		// input:	the given sparse cloud points
												   CString path_output,						// input:	the path of output file folder
												   Mat & mDepth_final,						// output:	final depth map，为输出层的分辨率
												   Mat & mHx_final,							// output:	final hx map，为输出层的分辨率
												   Mat & mHy_final,							// output:	final hy map，为输出层的分辨率
												   Mat & mScore_final,						// output:	final score map，为输出层的分辨率
												   Mat & mVisi_final,						// output:	final visi map，为输出层的分辨率
												   Mat & img0_outLevel,						// output:	the low resolution reference image in the out level
												   int size /*= 5*/,						// input:	the window size of the image patch, should be odd number
												   double angLimit /*= 80*/,				// input:	the angular range limit of the normal of every object point, in angle, not radian
												   int maxIter /*= 4*/,						// input:	maximum iteration
												   double factor /*= 0.5*/,					// input:	PatchMatch的时候随机采样的半径缩小因子
												   int nRandSamp /*= 6*/,					// input:	PatchMatch中在随机搜索环节进行随机采样的次数
												   double thresh_ang /*= 90*/,				// input:	the normal angle constraint, if this value is 360, then no constraint at all
												   double thresh_ncc /*= 0.95*/,			// input:	the ncc threshold after patchmatch, ncc value is supposed to be very high if it's matched correctly after patchmatch
												   double P1 /*= 1.5*/,						// input:	MRF时候对深度加的惩罚因子
												   double P2 /*= 0.1*/,						// input:	MRF时候对法向加的惩罚因子
												   double thresh_imgpt_sigma /*= 1*/,		// input:	经验的像点匹配精度，拓展可见性时需要用到
												   int nLevel /*= 4*/,						// input:	number of pyramid levels
												   int idxOutLevel /*= 0*/,					// input:	output final results at pyramid level idxOutLevel, default is level 0, i.e. the highest resolution level
												   int maxIter_optim /*= 128*/,				
												   double xEps /*= 1.0E-8*/,				// input: threshold
												   double fEps /*= 1.0E-6*/,				// input: threshold
												   bool bMPGCFinal /*= true*/				// input: use MPGC optimized or directly Most likely results
												   )
{
	int i,j,k,l;

 	int n_spt = vKs.size();

	vector<Matx33d> vK0s;
	vK0s.push_back(mK0);

	vector<Mat> vPyramidImgs;
//	buildPyramid(img0, vPyramidImgs, nLevel-1); // build gaussian pyramid OpenCV
	vPyramidImgs.push_back(img0);

	// 1. 生成当前参考图像的金字塔图集及对应的内参数
	// 第0层为原始图像（最大分辨率），金字塔顶层为分辨率最低的图像
	for (l=1;l<nLevel;l++)
	{
		int nPix = pow(2.0,l);

		Mat img_samp;
		DownSample(img0, img_samp, nPix);
		vPyramidImgs.push_back(img_samp);

		double nPix_1 = 1.0/nPix;

		Matx33d mK0_samp;
		mK0_samp(0,0) = mK0(0,0)*nPix_1;
		mK0_samp(1,1) = mK0(1,1)*nPix_1;
		mK0_samp(0,2) = mK0(0,2)*nPix_1;
		mK0_samp(1,2) = mK0(1,2)*nPix_1;
		mK0_samp(0,1) = mK0(0,1);
		mK0_samp(2,2) = 1;
		vK0s.push_back(mK0_samp);
	}
	//////////////////////////////////////////////////////////////////////////

	// 2. 利用金字塔顶层（最小分辨率）参考图像和其所有N个原始尺寸支持图像来做PatchMatch (PM)，得到N个最小分辨率的参考图像深度图
	vector<Mat> vDepths_l,vHxs_l,vHys_l,vScores_l;

	PatchMatch_Binocular_3DPropagation(vK0s[nLevel-1],mR0,mt0,vPyramidImgs[nLevel-1],vKs,vRs,vts,vImgs,clouds,
		vDepths_l,vHxs_l,vHys_l,vScores_l,size,angLimit,maxIter,factor,nRandSamp);
	//////////////////////////////////////////////////////////////////////////

	// 3. 通过双目MPGC来优化上述PM得到的N个最小分辨率深度图
	for (k=0;k<n_spt;k++)
	{
		MPGC_Binocular_20141215(vK0s[nLevel-1],mR0,mt0,vPyramidImgs[nLevel-1],vKs[k],vRs[k],vts[k],vImgs[k],
			vDepths_l[k],vHxs_l[k],vHys_l[k],vScores_l[k],size,size,maxIter_optim,xEps,fEps);
	}

	vector<vector<Mat>> vDepths_allLevels,vHxs_allLevels,vHys_allLevels,vScores_allLevels;
	//////////////////////////////////////////////////////////////////////////

	// 把该N个最小分辨率深度图存入容器，这些容器里存储的参数场是按倒金字塔排布的，即最小分辨率的参数场位于最底层，高分辨率的位于高层
	vDepths_allLevels.push_back(vDepths_l);
	vHxs_allLevels.push_back(vHxs_l);
	vHys_allLevels.push_back(vHys_l);
	vScores_allLevels.push_back(vScores_l);

	// 4. 低层（分辨率增加）参数场利用上一层估计优化的参数场升采样插值出来的等分辨率参数场作为初值，通过双目MPGC来进一步优化一下，并存入容器
	// 最低到用户指定的输出层
	for (l=(nLevel-2);l>=idxOutLevel;l--)
	{
		for (k=0;k<n_spt;k++)
		{
			AugmentField_Interp(vDepths_allLevels[nLevel-2-l][k],vDepths_l[k],vPyramidImgs[l].cols,vPyramidImgs[l].rows,2);
			AugmentField_Interp(vHxs_allLevels[nLevel-2-l][k],vHxs_l[k],vPyramidImgs[l].cols,vPyramidImgs[l].rows,2,0.5);
			AugmentField_Interp(vHys_allLevels[nLevel-2-l][k],vHys_l[k],vPyramidImgs[l].cols,vPyramidImgs[l].rows,2,0.5);
			AugmentField_Interp(vScores_allLevels[nLevel-2-l][k],vScores_l[k],vPyramidImgs[l].cols,vPyramidImgs[l].rows,2);
		}

// 		PatchMatch_Binocular_3DPropagation_givenInit(vK0s[l],mR0,mt0,vPyramidImgs[l],vKs,vRs,vts,vImgs,clouds,
// 			vDepths_l,vHxs_l,vHys_l,vScores_l,size,angLimit,maxIter,factor,0.01,2);

		for (k=0;k<n_spt;k++)
		{
			MPGC_Binocular_20141215(vK0s[l],mR0,mt0,vPyramidImgs[l],vKs[k],vRs[k],vts[k],vImgs[k],
				vDepths_l[k],vHxs_l[k],vHys_l[k],vScores_l[k],size,size,maxIter_optim,xEps,fEps);
		}

		vDepths_allLevels.push_back(vDepths_l);
		vHxs_allLevels.push_back(vHxs_l);
		vHys_allLevels.push_back(vHys_l);
		vScores_allLevels.push_back(vScores_l);
	}
	//////////////////////////////////////////////////////////////////////////

	int w_out = vPyramidImgs[idxOutLevel].cols;
	int h_out = vPyramidImgs[idxOutLevel].rows;

	// 5. 从各低于输出层分辨率的层传递candidates过来，这里的容器也是按倒金字塔形来排布的
	vector<Mat> vDepths_all, vHxs_all, vHys_all, vScores_all;
	for (l=(nLevel-1);l>idxOutLevel;l--)
	{
		int l_diff = l-idxOutLevel;

		int nPix = pow(2.0, l_diff);

		double nPix_1 = 1.0/nPix;

		for (k=0;k<n_spt;k++)
		{
			Mat mDepth, mHx, mHy, mScore;
			AugmentField_Interp(vDepths_allLevels[nLevel-1-l][k],mDepth,w_out,h_out,nPix);
			AugmentField_Interp(vHxs_allLevels[nLevel-1-l][k],mHx,w_out,h_out,nPix,nPix_1);
			AugmentField_Interp(vHys_allLevels[nLevel-1-l][k],mHy,w_out,h_out,nPix,nPix_1);
			AugmentField_Interp(vScores_allLevels[nLevel-1-l][k],mScore,w_out,h_out,nPix);

			vDepths_all.push_back(mDepth);
			vHxs_all.push_back(mHx);
			vHys_all.push_back(mHy);
			vScores_all.push_back(mScore);
		}
	}
	// 这里是把输出层的参数场存入容器
	for (k=0;k<n_spt;k++)
	{
		vDepths_all.push_back(vDepths_allLevels[nLevel-1-idxOutLevel][k]);
		vHxs_all.push_back(vHxs_allLevels[nLevel-1-idxOutLevel][k]);
		vHys_all.push_back(vHys_allLevels[nLevel-1-idxOutLevel][k]);
		vScores_all.push_back(vScores_allLevels[nLevel-1-idxOutLevel][k]);
	}
	//////////////////////////////////////////////////////////////////////////

	// 6. 把所有候选参数场（共有N*L个候选场，L为从最低分辨率层到输出层的总层数）中法向不合理以及相似性度量过低的候选参数置为无效，使其不能参与后续的MRF融合
	for (k=0;k<vDepths_all.size();k++)
	{
		int idxSpt = k%n_spt;

		// then invalidate those estimates whose normals are not reasonable and whose scores are smaller than certain threshold
		InvalidatePixels_byNormal(vK0s[idxOutLevel],mR0,mt0,vKs[idxSpt],vRs[idxSpt],vts[idxSpt],
			vDepths_all[k],vHxs_all[k],vHys_all[k],vScores_all[k],thresh_ang,thresh_ncc);
	}
	//////////////////////////////////////////////////////////////////////////////////

	Mat mSel;
	Mat mDepth_ML, mHx_ML, mHy_ML, mScore_ML;
	// 7. 基于MRF模型，从所有候选参数中为每个像素寻找一个最似然的参数值
	Extract_MRF_ncc_d_n_DP_withInvalids(vK0s[idxOutLevel],mR0,mt0,vDepths_all,vHxs_all,vHys_all,vScores_all,mSel,mDepth_ML,mHx_ML,mHy_ML,mScore_ML,P1,P2);
	//////////////////////////////////////////////////////////////////////////

	// 8. 通过聚类拓展每个像素相对于各参考图像的可见性
	double mul_factor = pow(2.0, idxOutLevel);
	AugmentVisibility_basedonMostLikelyDepthandNormals_SURE_MultiScales(vK0s[idxOutLevel],mR0,mt0,vKs,vRs,vts,
		vDepths_all,vHxs_all,vHys_all,vScores_all,mSel,mVisi_final,thresh_imgpt_sigma*mul_factor,90);
	//////////////////////////////////////////////////////////////////////////

	// 9. 多图MPGC，像素的所有可见图像（冗余观测）都参与到MPGC当中来优化深度和法向估计
	Mat mDepth_MPGC, mHx_MPGC, mHy_MPGC, mScore_MPGC;
	MPGC_20150207(vK0s[idxOutLevel],mR0,mt0,vPyramidImgs[idxOutLevel],vKs,vRs,vts,vImgs,mDepth_ML,mHx_ML,mHy_ML,mScore_ML,mVisi_final,
		mDepth_MPGC,mHx_MPGC,mHy_MPGC,mScore_MPGC,size,size,maxIter_optim,xEps,fEps);
	//////////////////////////////////////////////////////////////////////////

	// 10. 选择最终可以输出的输出层参数场，到底是MRF融合后的，还是MPGC多图优化后的
	if (bMPGCFinal)
	{
		mDepth_final = mDepth_MPGC.clone();
		mHx_final    = mHx_MPGC.clone();
		mHy_final    = mHy_MPGC.clone();
		mScore_final = mScore_MPGC.clone();
	} 
	else
	{
		mDepth_final = mDepth_ML.clone();
		mHx_final    = mHx_ML.clone();
		mHy_final    = mHy_ML.clone();
		mScore_final = mScore_ML.clone();
	}

	img0_outLevel = vPyramidImgs[idxOutLevel].clone();

	// 11. 把结果输出到输出目录中
// 	CString str;
// 	str.Format("%03d depth map at pyramid level %03d.bmp", idxRefImg, idxOutLevel);
// 	SaveParaField2Img(path_output+str, mDepth_final);
// 
// 	str.Format("%03d score map at pyramid level %03d.bmp", idxRefImg, idxOutLevel);
// 	SaveScoreField2Img(path_output+str, mScore_final);
// 
// 	double fx0l_1 = 1.0/vK0s[idxOutLevel](0,0);
// 	double fy0l_1 = 1.0/vK0s[idxOutLevel](1,1);
// 
// 	Mat mNormColor;
// 	GetNormColorField(vK0s[idxOutLevel],mR0,mt0,fx0l_1,fy0l_1,mDepth_final,mHx_final,mHy_final,mNormColor);
// 	str.Format("%03d normal map at pyramid level %03d.bmp", idxRefImg, idxOutLevel);
// 	imwrite((path_output+str).GetBuffer(), mNormColor);
// 
// 	str.Format("%03d point cloud at pyramid level %03d.txt", idxRefImg, idxOutLevel);
// 	OutputPointCloud(path_output+str,vK0s[idxOutLevel],mR0,mt0,fx0l_1,fy0l_1,vPyramidImgs[idxOutLevel],
// 		mDepth_final,mHx_final,mHy_final,mScore_final);
// 
// 	// draw visibility w.r.t each support image
// 	vector<Mat> vVisi_map;
// 	for (int kk=0;kk<n_spt;kk++)
// 	{
// 		Mat mtmp(mVisi_final.rows,mVisi_final.cols,CV_8UC3);
// 		vVisi_map.push_back(mtmp);
// 	}
// 
// 	for (i=0;i<mVisi_final.rows;i++)
// 	{
// 		for (j=0;j<mVisi_final.cols;j++)
// 		{
// 			uchar visi = mVisi_final.at<uchar>(i,j);
// 
// 			vector<bool> vbools;
// 			InterpVisiVector_uchar(visi, vbools);
// 
// 			for (int kk=0;kk<n_spt;kk++)
// 			{
// 				if (vbools[kk])
// 				{
// 					vVisi_map[kk].at<Vec3b>(i,j).val[0] = vPyramidImgs[idxOutLevel].at<Vec3b>(i,j).val[0];
// 					vVisi_map[kk].at<Vec3b>(i,j).val[1] = vPyramidImgs[idxOutLevel].at<Vec3b>(i,j).val[1];
// 					vVisi_map[kk].at<Vec3b>(i,j).val[2] = vPyramidImgs[idxOutLevel].at<Vec3b>(i,j).val[2];
// 				} 
// 				else
// 				{
// 					vVisi_map[kk].at<Vec3b>(i,j).val[0] = 0;
// 					vVisi_map[kk].at<Vec3b>(i,j).val[1] = 0;
// 					vVisi_map[kk].at<Vec3b>(i,j).val[2] = 255;
// 				}
// 			}
// 		}
// 	}
// 
// 	for (int kk=0;kk<n_spt;kk++)
// 	{
// 		str.Format("%03d visi map at pyramid level %03d wrt support image %03d.bmp", idxRefImg, idxOutLevel, idxSpts[kk]);
// 		imwrite((path_output+str).GetBuffer(), vVisi_map[kk]);
// 	}
// 
// 	// output to files
// 	str.Format("%03d depth map at pyramid level %03d.txt", idxRefImg, idxOutLevel);
// 	FILE * file_depth = fopen(path_output+str, "w");
// 	str.Format("%03d hx map at pyramid level %03d.txt", idxRefImg, idxOutLevel);
// 	FILE * file_hx = fopen(path_output+str, "w");
// 	str.Format("%03d hy map at pyramid level %03d.txt", idxRefImg, idxOutLevel);
// 	FILE * file_hy = fopen(path_output+str, "w");
// 	str.Format("%03d score map at pyramid level %03d.txt", idxRefImg, idxOutLevel);
// 	FILE * file_score = fopen(path_output+str, "w");
// 	str.Format("%03d visi map at pyramid level %03d.txt", idxRefImg, idxOutLevel);
// 	FILE * file_visi = fopen(path_output+str, "w");
// 
// 	// at the same time evaluate all parameters
// 	for (i=0;i<vPyramidImgs[idxOutLevel].rows;i++)
// 	{
// 		for (j=0;j<vPyramidImgs[idxOutLevel].cols;j++)
// 		{
// 			fprintf(file_depth, "%.16f	", mDepth_final.at<float>(i,j));
// 			fprintf(file_hx, "%.16f	", mHx_final.at<float>(i,j));
// 			fprintf(file_hy, "%.16f	", mHy_final.at<float>(i,j));
// 			fprintf(file_score, "%.16f	", mScore_final.at<float>(i,j));
// 			fprintf(file_visi, "%d	", mVisi_final.at<uchar>(i,j));
// 		}
// 		fprintf(file_depth, "\n");
// 		fprintf(file_hx, "\n");
// 		fprintf(file_hy, "\n");
// 		fprintf(file_score, "\n");
// 		fprintf(file_visi, "\n");
// 	}
// 	fclose(file_depth);
// 	fclose(file_hx);
// 	fclose(file_hy);
// 	fclose(file_score);
// 	fclose(file_visi);
}

void DeepVoid::SaveFeatures2File(CString path, const vector<KeyPoint> & keypoints)
{
	int i;

	int nPts = keypoints.size();

	FILE * file = fopen(path, "w");

	for (i=0;i<nPts;i++)
	{
		KeyPoint keypt = keypoints[i];
		fprintf(file, "%.6f	%.6f	%.6f	%.6f	%.6f	%d	%d\n", keypt.pt.x, keypt.pt.y, keypt.size, keypt.angle, keypt.response, keypt.octave, keypt.class_id);
	}

	fclose(file);
}

void DeepVoid::SaveFeatures2File(CString path, const Features & feats)
{
	int i;

	int nPts = feats.key_points.size();

	FILE * file = fopen(path, "w");

	for (i=0;i<nPts;i++)
	{
		KeyPoint keypt = feats.key_points[i];
		fprintf(file, "%.6f	%.6f	%.6f	%.6f	%.6f	%d	%d	%d	%d\n", keypt.pt.x, keypt.pt.y, keypt.size, keypt.angle, keypt.response,
			keypt.octave, keypt.class_id, feats.idx_pt[i], feats.tracks[i]);
	}

	fclose(file);
}

// zhaokunz, 20150107, <multiple view geometry in computer vision 2nd edition> p.107
// Normalizing transformations based on isotropic scaling
// return 3*3 transformation matrix
Matx33d DeepVoid::NormalizePts_2D(const vector<Point2f> & pts, vector<Point2f> & pts_t)
{
	int i;

	int n = pts.size();

	pts_t.clear();

	double sum_x = 0;
	double sum_y = 0;

	for (i=0;i<n;i++)
	{
		sum_x += pts[i].x;
		sum_y += pts[i].y;
	}

	double mean_x = sum_x/n;
	double mean_y = sum_y/n;

	double sum_d = 0;

	for (i=0;i<n;i++)
	{
		double x = pts[i].x - mean_x;
		double y = pts[i].y - mean_y;

		sum_d += sqrt(x*x+y*y);
	}

	double s = sqrt(2.0)*n/sum_d;

	Matx33d mT;
	mT(0,0) = s;
	mT(1,1) = s;
	mT(0,2) = -s*mean_x;
	mT(1,2) = -s*mean_y;
	mT(2,2) = 1;

	for (i=0;i<n;i++)
	{
		Matx31d mPt;
		mPt(0) = pts[i].x;
		mPt(1) = pts[i].y;
		mPt(2) = 1;

		Matx31d mPt_t = mT*mPt;

		Point2f pt_t;
		pt_t.x = mPt_t(0);
		pt_t.y = mPt_t(1);

		pts_t.push_back(pt_t);
	}

	return mT;
}

// zhaokunz, 20150107, compute the epipole in the left image from fundamental matrix
// Fe = 0, i.e. e is the right null-vector of F
Matx31d DeepVoid::Epipole_Left(const Matx33d & mF)
{
	Matx31d e;
	SVD::solveZ(mF,e);

	return e;
}

// zhaokunz, 20150107, compute the epipole in the right image from fundamental matrix
// Fte' = 0, i.e. e' is the right null-vector of Ft
Matx31d DeepVoid::Epipole_Right(const Matx33d & mF)
{
	Matx31d e;
	SVD::solveZ(mF.t(),e);

	return e;
}

Matx33d DeepVoid::CrossMat(const Matx31d & v)
{
	Matx33d m;

	m(0,1)=-v(2); m(0,2)= v(1);
	m(1,0)= v(2); m(1,2)=-v(0);
	m(2,0)=-v(1); m(2,1)= v(0);

	return m;
}

Matx33d DeepVoid::CrossMat(const Matx13d & v)
{
	Matx33d m;

	m(0,1)=-v(2); m(0,2)= v(1);
	m(1,0)= v(2); m(1,2)=-v(0);
	m(2,0)=-v(1); m(2,1)= v(0);

	return m;
}

// P0 = [I|0], P1 = [[e']x F | e']
void DeepVoid::GetCameraMatfromF(const Matx33d & mF, Matx34d & mP0, Matx34d & mP1)
{
	int i,j;

	for (i=0;i<3;i++)
	{
		for (j=0;j<4;j++)
		{
			if (i==j)
			{
				mP0(i,j) = 1;
			} 
			else
			{
				mP0(i,j) = 0;
			}
		}
	}

	// epipole in the right image
	Matx31d e = Epipole_Right(mF);
	// the skew-symmetric matrix corresponding to e
	Matx33d me = CrossMat(e);
	// [e']x F
	Matx33d meF = me*mF;

	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mP1(i,j) = meF(i,j);
		}
	}

	mP1(0,3) = e(0);
	mP1(1,3) = e(1);
	mP1(2,3) = e(2);
}

// 20150111, zhaokunz, 计算返回二维点坐标 (x, y) 至二维直线 Ax + By + C = 0 的距离
double DeepVoid::CalcuDistance_Pt2Line_2D(double x, double y,				// 二维点坐标
										  double A, double B, double C		// 二维直线表达式
										  )
{
	return fabs(A * x + B * y + C) / sqrt(A * A + B * B);
}

// 20150111, zhaokunz, get the inliers given the fundamental matrix
int DeepVoid::GetInliers(const vector<KeyPoint> & pts0,	// input:	keypoints in the left image
						 const vector<KeyPoint> & pts1,	// input:	keypoints in the right image
						 const Matx33d & mF,			// input:	the given fundamental matrix
						 const vector<DMatch> & matches,// input:	the given initial matches
						 vector<uchar> & status,		// output:	with 1 indicating an inlier, and 0 indicating an outlier
						 double thresh /*= 3.0*/		// input:	the point to epipolar line distance threshold
						 )
{
	int i;

	int n = matches.size(); // number of correspondences

	Matx33d mFt = mF.t();

	status.clear();

	vector<Point2f> vErrs;

	int count = 0;

	for (i=0;i<n;i++)
	{
		KeyPoint pt0 = pts0[matches[i].queryIdx];
		KeyPoint pt1 = pts1[matches[i].trainIdx];

		Matx31d xyw0;
		xyw0(0) = pt0.pt.x; xyw0(1) = pt0.pt.y; xyw0(2) = 1;

		Matx31d xyw1;
		xyw1(0) = pt1.pt.x; xyw1(1) = pt1.pt.y; xyw1(2) = 1;

		Matx31d l1 = mF*xyw0;		// l'=Fx
		Matx31d l0 = mFt*xyw1;

		double d1 = CalcuDistance_Pt2Line_2D(xyw1(0), xyw1(1), l1(0), l1(1), l1(2));
		double d0 = CalcuDistance_Pt2Line_2D(xyw0(0), xyw0(1), l0(0), l0(1), l0(2));

		Point2f err;
		err.x = d0; err.y = d1;
		vErrs.push_back(err);

		if (d0>=thresh || d1>=thresh)
		{
			status.push_back(0);
		} 
		else
		{
			status.push_back(1);
			count++;
		}
	}

	return count;
}

// 20150112, zhaokunz, get the inliers given the fundamental matrix
int DeepVoid::GetInliers(const vector<KeyPoint> & pts0,	// input:	keypoints in the left image
					     const vector<KeyPoint> & pts1,	// input:	keypoints in the right image
					     const Matx33d & mF,			// input:	the given fundamental matrix
					     const vector<DMatch> & matches,// input:	the given initial matches
					     vector<DMatch> & matches_out,	// output:	all inliers
					     double thresh /*= 3.0*/		// input:	the point to epipolar line distance threshold
					     )
{
	int i;

	int n = matches.size();

	vector<uchar> status;

	int count = GetInliers(pts0,pts1,mF,matches,status,thresh);

	matches_out.clear();

	for (i=0;i<n;i++)
	{
		if (status[i])
		{
			matches_out.push_back(matches[i]);
		}
	}

	return count;
}

// 20150131, zhaokunz, 
void DeepVoid::GetInliers_knn(const vector<KeyPoint> & pts0,			// input:	keypoints in the left image
					 		  const vector<KeyPoint> & pts1,			// input:	keypoints in the right image
							  const Matx33d & mF,						// input:	the given fundamental matrix
							  const vector<vector<DMatch>> & matches,	// input:	the given initial matches
							  vector<DMatch> & matches_out,				// output:	all inliers
							  double thresh /*= 3.0*/					// input:	the point to epipolar line distance threshold
							  )
{
	matches_out.clear();

	Matx33d mFt = mF.t();

	for (auto iter_i=matches.begin();iter_i!=matches.end();++iter_i)
	{
		vector<DMatch> matches_valid;

		for (auto iter_j=iter_i->begin();iter_j!=iter_i->end();++iter_j)
		{
			KeyPoint pt0 = pts0[iter_j->queryIdx];
			KeyPoint pt1 = pts1[iter_j->trainIdx];

			Matx31d xyw0;
			xyw0(0) = pt0.pt.x; xyw0(1) = pt0.pt.y; xyw0(2) = 1;

			Matx31d xyw1;
			xyw1(0) = pt1.pt.x; xyw1(1) = pt1.pt.y; xyw1(2) = 1;

			Matx31d l1 = mF*xyw0;		// l'=Fx
			Matx31d l0 = mFt*xyw1;

			double d1 = CalcuDistance_Pt2Line_2D(xyw1(0), xyw1(1), l1(0), l1(1), l1(2));
			double d0 = CalcuDistance_Pt2Line_2D(xyw0(0), xyw0(1), l0(0), l0(1), l0(2));

			if (d0>=thresh || d1>=thresh)
			{
				continue;
			} 
			else
			{
				matches_valid.push_back(*iter_j);
			}
		}

		int n_valid = matches_valid.size();

		if (n_valid!=1)
		{
			continue;
		}

		matches_out.push_back(matches_valid[0]);
	}
}

// 20150112, zhaokunz, delete identical matches
void DeepVoid::DeleteIdenticalMatches(const vector<DMatch> & matches, vector<DMatch> & matches_out)
{
	int i,j;

	int n = matches.size();

	vector<int> vIdentical(n, 0);

	for (i=0;i<n;i++)
	{
		if (vIdentical[i])
		{
			continue;
		}

		DMatch m1 = matches[i];

		for (j=i+1;j<n;j++)
		{
			DMatch m2 = matches[j];

			if (m1.queryIdx == m2.queryIdx && m1.trainIdx == m2.trainIdx)
			{
				// found a identical match
				vIdentical[j] = 1;
			}
		}
	}

	matches_out.clear();

	for (i=0;i<n;i++) 
	{
		if (!vIdentical[i])
		{
			matches_out.push_back(matches[i]);
		}
	}
}

// 20150112, zhaokunz, enforce one-to-one constraint
void DeepVoid::EnsureOne2OneMatches(const vector<DMatch> & matches, vector<DMatch> & matches_out)
{
	int i,j;

	int n = matches.size();

	vector<int> vCancel(n, 0);

	for (i=0;i<n;i++)
	{
		DMatch m1 = matches[i];

		for (j=i+1;j<n;j++)
		{
			DMatch m2 = matches[j];

			if (m1.queryIdx != m2.queryIdx && m1.trainIdx != m2.trainIdx)
			{
				continue;
			}

			vCancel[i] = 1;
			vCancel[j] = 1;
		}
	}

	matches_out.clear();

	for (i=0;i<n;i++) 
	{
		if (!vCancel[i])
		{
			matches_out.push_back(matches[i]);
		}
	}
}

// 20150112, zhaokunz
void DeepVoid::Optim_F_Matches(const vector<KeyPoint> & keys0,		// input:	keypoints in the left image
							   const vector<KeyPoint> & keys1,		// input:	keypoints in the right image
							   const Matx33d & mF_init,				// input:	the initial fundamental matrix
							   const vector<DMatch> & matches_init,	// input:	the big set of matches, containing outliers
							   Matx33d & mF_optim,					// output:	the optimized fundamental matrix using updated set of matches
							   vector<DMatch> & matches_optim,		// output:	the optimized set of inlier matches
							   int maxIter /*= 10*/,				// input:	the maximum number of iterations
							   double xEps /*= 1.0E-8*/,			// input:	threshold
							   double fEps /*= 1.0E-6*/,			// input:	threshold
							   double thresh /*= 3.0*/				// input:	the point to epipolar line distance threshold
							   )
{
	int i;

	int n = matches_init.size(); // number of candidate matches

	Matx33d mF_cur = mF_init;

	vector<uchar> status_cur;

	// get the inliers, given current estimate of fundamental matrix
	int nInliers = GetInliers(keys0,keys1,mF_cur,matches_init,status_cur,thresh);

	CString strInfo;
	strInfo.Format("nInliers: %d", nInliers);
	theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

	bool bSame = false;

	while (!bSame)
	{
		// get the image points of current inliers out
		vector<Point2d> vImgPts0, vImgPts1;

		for (i=0;i<n;i++)
		{
			if (status_cur[i])
			{
				DMatch m = matches_init[i];
				Point2d imgpt0, imgpt1;

				imgpt0.x = keys0[m.queryIdx].pt.x;
				imgpt0.y = keys0[m.queryIdx].pt.y;

				imgpt1.x = keys1[m.trainIdx].pt.x;
				imgpt1.y = keys1[m.trainIdx].pt.y;

				vImgPts0.push_back(imgpt0);
				vImgPts1.push_back(imgpt1);
			}
		}

		// optimize current fundamental matrix using only current inliers
		Matx33d mF_updated;
		bool bSuc = optim_gn_F(vImgPts0,vImgPts1,mF_cur,mF_updated,maxIter,xEps,fEps);

		// get the inliers, given updated estimate of fundamental matrix
		vector<uchar> status_updated;
		nInliers = GetInliers(keys0,keys1,mF_updated,matches_init,status_updated,thresh);

		strInfo.Format("nInliers: %d", nInliers);
		theApp.m_pMainFrame->m_wndShowInfoPane.m_wndShowInfoListCtrl.AddOneInfo(strInfo);

		// to see if all the inliers are the same before and after update
		if (status_updated==status_cur)
		{
			bSame = true;
		}

		mF_cur = mF_updated;
		status_cur = status_updated;
	}

	mF_optim = mF_cur;

	matches_optim.clear();

	for (i=0;i<n;i++)
	{
		if (status_cur[i])
		{
			matches_optim.push_back(matches_init[i]);
		}
	}
}

// 20150114, zhaokunz, P=K[I|0], P'=K'[R|t]
// F = inv(K'')[t]xRinv(K)
Matx33d DeepVoid::GetF_Stereo(const Matx33d & mK0,	// input:	calibration matrix of the reference image
							  const Matx33d & mK1,	// input:	calibration matrix of the matching image
							  const Matx33d & mR1,	// input:	rotation matrix of the matching image
							  const Matx31d & mt1	// input:	translation vector of the matching image
							  )
{
	return mK1.t().inv()*CrossMat(mt1)*mR1*mK0.inv();
}

// 20150125, zhaokunz, the optimal triangulation based on two view epipolar geometry
double DeepVoid::Triangulate_Optimal(const vector<Point2d> & imgpts0,	// input:	the distortion free measured image points in 1st image
								     const Matx33d & mK0,				// input:	the calibration matrix of the 1st image
								     const Matx33d & mR0,				// input:	the rotation matrix of the 1st image
								     const Matx31d & mt0,				// input:	the translation vector of the 1st image
								     const vector<Point2d> & imgpts1,	// input:	the distortion free measured image points in 2nd image
								     const Matx33d & mK1,				// input:	the calibration matrix of the 2nd image
								     const Matx33d & mR1,				// input:	the rotation matrix of the 2nd image
								     const Matx31d & mt1,				// input:	the translation vector of the 2nd image
								     vector<Point3d> & wrdpts,			// output:	the triangulated 3d points
								     vector<Point2d> & errs				// output:	the triangulation errors
								     )
{
	int i,j;

	int n = imgpts0.size();

	Matx33d mKR0 = mK0*mR0;
	Matx31d mKt0 = mK0*mt0;

	Matx33d mKR1 = mK1*mR1;
	Matx31d mKt1 = mK1*mt1;

	// construct camera matrices
	Matx34d mP0,mP1;

	for (i=0;i<3;i++)
	{
		for (j=0;j<3;j++)
		{
			mP0(i,j) = mKR0(i,j);
			mP1(i,j) = mKR1(i,j);
		}
	}

	for (i=0;i<3;i++)
	{
		mP0(i,3) = mKt0(i);
		mP1(i,3) = mKt1(i);
	}

	// first compute the relative orientation between the 1st and 2nd image
	Matx33d mR = mR1*mR0.t();
	Matx31d mt = -mR*mt0+mt1;

	// get the fundamental matrix
	Matx33d mF = GetF_Stereo(mK0, mK1, mR, mt);

	// correct matches
	vector<Point2d> imgpts0_crt,imgpts1_crt;
	correctMatches(mF, imgpts0, imgpts1, imgpts0_crt, imgpts1_crt);

	// triangulate
	Mat mWrdPts;
	triangulatePoints(mP0, mP1, imgpts0_crt, imgpts1_crt, mWrdPts);

	wrdpts.clear();
	errs.clear();
	double sum_d2 = 0;

	for (i=0;i<n;i++)
	{
		Point3d pt;
		double w_1 = 1.0/mWrdPts.at<double>(3,i);

		pt.x = mWrdPts.at<double>(0,i)*w_1;
		pt.y = mWrdPts.at<double>(1,i)*w_1;
		pt.z = mWrdPts.at<double>(2,i)*w_1;

		wrdpts.push_back(pt);

		double dx0 = imgpts0_crt[i].x-imgpts0[i].x;
		double dy0 = imgpts0_crt[i].y-imgpts0[i].y;
		double d20 = dx0*dx0+dy0*dy0;
		double dx1 = imgpts1_crt[i].x-imgpts1[i].x;
		double dy1 = imgpts1_crt[i].y-imgpts1[i].y;
		double d21 = dx1*dx1+dy1*dy1;
		double d2 = d20+d21;
		sum_d2+=d2;

		double d0 = sqrt(d20);
		double d1 = sqrt(d21);

		Point2d err;
		err.x = d0;
		err.y = d1;
		
		errs.push_back(err);
	}

	double err_rpj = sqrt(sum_d2*0.5/n);

	return err_rpj;
}

void DeepVoid::OutputPointCloud(CString strFile,
							    const vector<cam_data> & cams,
							    vector<CloudPoint> & cloud
							    )
{
	FillCloudPoints_RBG_RpjErr(cams, cloud);

	FILE * file = fopen(strFile, "w");
	for (auto iter_pt=cloud.begin();iter_pt!=cloud.end();++iter_pt)
	{
		double sumR = 0;
		double sumG = 0;
		double sumB = 0;
		for (auto iter_img=iter_pt->m_vImgInfos.begin();iter_img!=iter_pt->m_vImgInfos.end();++iter_img)
		{
			sumR += iter_img->m_rgb.val[2];
			sumG += iter_img->m_rgb.val[1];
			sumB += iter_img->m_rgb.val[0];
		}
		int R = (int)sumR/iter_pt->m_vImgInfos.size();
		int G = (int)sumG/iter_pt->m_vImgInfos.size();
		int B = (int)sumB/iter_pt->m_vImgInfos.size();

		fprintf(file, "%lf;%lf;%lf;%d;%d;%d\n", iter_pt->m_pt.x, iter_pt->m_pt.y, iter_pt->m_pt.z, R, G, B);
	}
	fclose(file);
}